Journal of Universal Computer Science, vol. 22, no. 10 (2016), 1319-1338
submitted: 2/3/16, accepted: 22/9/16, appeared: 1/10/16 © J.UCS

Providing Behaviour Awareness in Collaborative Project

Courses

Esunly Medina, Roc Meseguer

Universitat Politecnica de Catalunya, Barcelona, Spain

(Department of Computer Architecture
{esunlyma, meseguer}@ac.upc.edu)

Sergio F. Ochoa

(Computer Science Department

Universidad de Chile, Santiago, Chile

sochoa@dcc.uchile.cl)

Humberto Medina

(Department of Aerospace, Electrical and Electronic Engineering

Coventry University, Conventry, United Kingdom

humberto.medina@coventry.ac.uk)

Abstract: Several studies show that awareness mechanisms can contribute to enhance
the collaboration process among students and the learning experiences during collaborative 
project courses. However, it is not clear what awareness information should be
provided to whom, when it should be provided, and how to obtain and represent such
information in an accurate and understandable way. Regardless the research eﬀorts
done in this area, the problem remains open. By recognizing the diversity of work scenarios 
(contexts) where the collaboration may occur, this research proposes a behaviour
awareness mechanism to support collaborative work in undergraduate project courses.
Based on the authors previous experiences and the literature in the area, the proposed
mechanism considers personal and social awareness components, which represent metrics 
in a visual way, helping students realize their performance, and lecturers intervene
when needed. The trustworthiness of the mechanisms for determining the metrics was
veriﬁed using empirical data, and the usability and usefulness of these metrics were
evaluated with undergraduate students. Experimental results show that this awareness
mechanism is useful, understandable and representative of the observed scenarios.

Key Words: Behaviour awareness, collaboration metrics, visual feedback, undergraduate 
project courses, collaborative work
Category: L.3.1, L.3.6

1

Introduction

Learning by doing is one of the most used instructional paradigms to promote
meaningful learning in engineering education [Freeman et al. 2014]. Lecturers
usually implement this paradigm in their courses making students work in teams
to address particular tasks or projects [Felder et al. 2003]. Typically, the course

1320

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

lecturers and also the students have low visibility about individual and team
performance during collaboration processes, which limits their capability to react 
on time to take corrective pedagogical measures or to rectify and improve
the students behaviour patterns. This situation shows the need to count on automatic 
mechanisms to monitor team members’ activities and provide feedback
accordingly to support students and lecturers. However, implementing this feedback 
mechanism is a complex task due to the large diversity of contexts where
the collaboration may occur.

For helping address that challenge, this research work explored the feasibility
of deﬁning an awareness mechanism to support the collaborative learning activities 
in undergraduate project courses. The result of this work is a Behaviour
Awareness Mechanism (BAM) that provides visual feedback to students and
lecturers. The feedback provided by the BAM is aimed at promoting reﬂection
and encouraging social interactions between students. In addition, the BAM is
intended to be used across diﬀerent Computer-Supported Collaborative Learning 
(CSCL) systems and contexts, providing dynamic and comprehensive feedback 
to the users. Therefore, this awareness mechanism involves several metrics
that should be captured as automatically as possible. Consequently, we consider
courses that are supported by software tools that record information about the
students’ activities such as learning management platforms, software repositories
with version control, project management systems and discussion forums.

The eﬀectiveness of BAM was evaluated using empirical data from courses
of the Polytechnic University of Catalonia (UPC), in Spain. This evaluation
provided evidence that the proposed awareness mechanism can be potentially
computerized and automated, while allowing the intervention of expert users
(i.e., lecturers) for the validation or customization of the awareness provision.
Therefore, the BAM could be embedded as a service in collaborative learning
applications.

Next section discusses the related work. [Section 3] describes the design of
the prototype developed to provide visual feedback to students and [Section 4]
the implementation. [Section 5] reports results of the evaluation of the accuracy
of the awareness provided by BAM. [Section 6] shows and discusses the results
obtained in the evaluation of the usability and usefulness of BAM. Finally, [Section 
7] presents the conclusions and the future work.

2 Related Work

A signiﬁcant body of research has focused on studying the factors that contribute
to the eﬀectiveness and quality of collaboration. For instance, in [O’Dea et al.
2007] the authors conduct a literature review to deﬁne seven general dimensions
that aﬀect the success of a collaboration process (i.e., communication, coordination 
and knowledge management). Similarly, in [Lin et al. 2008] the authors

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1321

identify some other factors that inﬂuence the eﬀectiveness of virtual teams (i.e.,
relationship building, cohesion and satisfaction). These dimensions and factors
are typically used to develop indicators that help determine the usefulness of the
collaborative systems and also monitor and assess collaboration processes. For
instance, in [de Melo et al. 2014] the authors propose a metric to measure the
productivity and engagement of the members of a software team, based on the
information provided by the version control system. Similarly, in [Cosentino et
al. 2014] the information of GitHub version control system is used to assess the
success level of open source software projects. There are also similar works in
collaborative learning scenarios.

2.1 Determining Collaboration in Learning Scenarios

In [Daradoumis et al. 2003], the asynchronous interactions among members of 60
virtual teams were evaluated using information recorded by the BSCW system.
Similarly, in [Chounta et al. 2013] the authors used log ﬁles, collected from
the interactions of students’ teams with handheld devices to assess the teams
performance with regard to the results of a location-based learning game. Results
from the study showed that the teams with the highest performance in the
game were those with the highest activity levels and with the lowest delays
between actions. The study presented in [Chounta et al. 2014] uses properties of
network graphs as metrics to assess the quality of collaboration of synchronous
collaborative learning activities mediated by a shared workspace application. The
study considered four factors aﬀecting the collaboration (communication, joint
information processing, coordination and interpersonal relationship), and the
results showed that the numbers of nodes of the network had a high correlation
with those factors.

2.2 Representing Collaboration in Learning Scenarios

It is recognized that awareness is a valuable feature that aﬀects motivation
[Wu et al. 2014] and group coordination [Kwon et al. 2013], and therefore the
quality of any collaboration process. Consequently, some interesting works in
CSCL have been prompted by the need of providing appropriate awareness support 
to promote active learning and coordinate students’ activities [Kwon et al.
2013, Fransen et al. 2011]. In that line, feedback has been regarded as an extremely 
important awareness mechanism, which inﬂuences positively the learning 
process by providing students with information that allows them to improve
their performance and learning behaviour [Schneider et al. 2015].

Many studies have addressed the feasibility of providing visual feedback functions 
in software systems supporting collaborative learning activities. Some of

1322

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

these studies aim at providing awareness and feedback in e-Learning environments.
 For instance, in [Kwon et al. 2013] the authors propose a Web-based
group coordination tool that visually shows the assessments of the team members 
performance and allows comparing theses values with those from other
teams. A diﬀerent approach is proposed in [Lambropoulos et al. 2012] in which
indicators of presence, participation and interactions among students are used
to provide awareness of the teamwork.

Awareness mechanisms have also been used to support face-to-face collaborative 
learning activities. For instance, in [Melero et al. 2015] the authors propose 
several task-speciﬁc visualizations designed to provide awareness during a
gamiﬁed location-based learning activity. In [Ogata and Yano 2004] the authors
represent collaboration through a knowledge awareness map that shows the relationship 
between the shared knowledge and the current and past interactions
of learners. This representation is used by the students to ﬁnd potential collaborators 
and helpers. In a later work these authors present a system that not only
recommends educational materials to learners, but also potential peer learners
sharing similar interests and experiences [El-Bishouty et al. 2007]. In [Govaerts
et al. 2012] the authors propose the Student Activity Meter, a visual representation 
of the students actions, designed to increase the awareness for learners
and teachers and also to support self-reﬂection. Janssen et al. [Janssen et al.
2007] study the eﬀects of this type of visualization on the students participation
during computer-supported collaborative learning processes.

The previous works diﬀer from the BAM mainly in two diﬀerent aspects:
(i) they focus on a particular type of awareness, such as individual contributions,
 conﬂict or peer feedback, whereas our proposal includes a wider range of
sources for feedback, providing both subjective and objective information, (ii)
their methods of feedback provision are restricted to particular contexts; i.e., the
previously mentioned solutions provide awareness only within the context of a
speciﬁc collaborative activity, and they are linked to a particular collaborative
application. By contrast, BAM is intended to be used across diﬀerent CSCL
systems and contexts. As a result, it uses diverse sources for the calculation of
metrics of eﬀectiveness of collaboration, which allows the provision of dynamic
and comprehensive feedback to the users.

2.3 Making Recommendations

Typically, determining and representing collaboration levels in an instructional
scenario are required steps for intervening the learning process. This intervention 
can be done by providing awareness to the involved people, or particular
recommendations. Concerning the second approach, in [Gonz´alez-Ib´a˜nez et al.
2015] the authors propose a method to determine the feasibility of transforming,

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1323

based on an analysis of beneﬁts and costs, collaboration opportunities into explicit 
recommendations for collaboration. In [Zheng and Yano 2007] the authors
propose a framework for peer-recommendation based on context awareness in
e-learning scenarios.

There are important research eﬀorts to tackle the problem of link prediction
in co-authoring network [Benchettara et al. 2010, Brand˜ao et al. 2013], which
can be adapted for making recommendations in collaborative learning scenarios.
These proposals typically use Social Network Analysis techniques for predicting
new links.

The proposal presented in BAM provides recommendations about potential
collaborators for conducting team learning activities, based on the people previous 
actions and features. Particularly, this proposal considers the students’
collaborative behaviour: communication, coordination, motivation, performance
and satisfaction. Next we explain the proposal in detail.

3 Design of the Behaviour Awareness Mechanism

The Behaviour Awareness Mechanism (BAM) requires a computer-supported
environment that provides students activities information for generating visual
feedback to students and lecturers. The course lecturer and students use regular
software tools to support their activities (including their projects and assign-
ments). Typically, these tools record information about the user activity, which
can be automatically retrieved through an application programming interface
(API) or by processing the data source. Having this information is mandatory
to use BAM; therefore, the ﬁrst operation of the supporting environment is the
Data Capture [Fig. 1], which must determine and ensure that the information
required to illustrate the users’ activities is recorded by the data source and
accessible through an external software component.

During the second step, known as Data Processing, the users’ information is
retrieved and processed by information extractors to obtain the metrics that will
be used to instantiate the awareness components. Finally, the visual feedback to
the user is provided (third step) using metrics obtained in the previous stage.
This feedback intends to promote behavioural changes that impact positively on
the activities of the students. This is reﬂected on the students interactions using
the supporting tools. The lecturer uses this feedback to understand the students
individual and team performance, intervening when necessary.

The visual awareness was designed considering two basic facts: (i) any awareness 
mechanism must provide an understanding of the activities of others as a
context for the activities of the individual [Antunes et al. 2014], and (ii) the
feedback provision must ensure that the students are able to relate their current
state of learning and performance with speciﬁc targets or standards [Nicol et

1324

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

Figure 1: Computer-supported environment required for implementing the
BAM

al. 2006]. Next we describe the components of the proposed visual awareness
mechanism.

3.1 Personal Awareness Component

The Personal Awareness Component (PAC) provides information about the collaborative 
patterns of a speciﬁc student, which is represented using several features 
of the students’ collaborative behaviour. We conducted a literature review
based on previous research work about quality assessment of computer-supported
collaboration processes to determine the features that should be represented in
the PAC. From this study, we found several basic dimensions related to the effectiveness 
of collaboration. These dimensions included aspects related to the
collaboration processes and the way in which the students interact within different 
teams (e.g., participation and coordination). We also considered personal
features aﬀecting collaboration and learning (e.g., motivation, satisfaction, and
individual performance), characteristics of the students’ social interactions (e.g.,
social presence and connectedness) and elements associated with the collaboration 
outcomes (e.g., productivity, solution quality, and team performance). For
the sake of simplicity and to facilitate the visual representation of the PAC, we
classiﬁed and condensed these dimensions into the following types: communication,
 coordination, motivation, performance and satisfaction.

3.2 Social Awareness Component

The Social Awareness Component (SAC) provides social (collective) awareness
and proposes possible suitable collaborators to the user. We use the MultiDimensional 
Scaling (MDS) method to represent students as points in a 2D
space [Buja et al. 2008]. Using MDS the values of the ﬁve collaboration features

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1325

the Collaborative Behaviour Index (CBI) can be mapped into a point in a 2D
space, in such a way that distances between points are preserved. Thus, we can
represent, two students with similar behaviour as two points located at a short
distance from each other. However, it could happen that students having similar
CBI could also have very dissimilar values of the several collaboration features
that compose this index. In that case, the MDS allows us to represent such students 
as two distant points in the SAC; therefore, these students will not be
suggested as potential collaborators.

4

Implementation of the Behaviour Awareness Mechanism

Next subsections present a use case that describe the three steps required for the
implementation of the proposed awareness mechanism. This use case provides
details about the tools and methods used for the implementation of the personal
and social awareness components of the BAM.

4.1 Data Capture

In this use case we used real data traces collected from the behaviour of a
group of students during an academic semester, as the information required
to provide awareness. The data traces correspond to 42 third year students
enrolled in the course “Design of Applications and Services (DSA)”, delivered
at the Castelldefels School of Telecommunications and Aerospace Engineering
of the Polytechnic University of Catalonia. In this course the students had to
run software development project in teams, using several software systems that
allowed the organization and coordination of the team activities as well as the
submissions of assignments and tests.

This dataset included information from the students’ activities recorded in
log ﬁles and opinions collected from online surveys while working within the formal 
learning context. This also included the interactions among students through
collaborative learning tools and software systems used to support their learning
activities. The analysis of the surveys intended to identify the students’ feelings,
opinions and behaviour during the course (both inside and outside the class-
room), as well as the lecturers’ observations about the state and progress of the
students collaboration activities. On the other hand, the log ﬁles collected from
the software platforms provided information about the students’ activities and
performance while working on the course project. These data traces provided
diverse qualitative and quantitative metrics that were used for the calculation of
the ﬁve collaborative behaviour features represented in BAM. Table 1 shows the
data sources considered in this study and a detailed list of the metrics collected
using those sources.

1326

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

Table 1: Data sources and metrics used for the implementation of the BAM

Moodle

Trello

GitHub

- Total # of cards
per team
- Total # of checklists 
per team
- Total # of actions
per team
- # of actions per
member
- Total # of actions
per team
- Ratio of the # of
actions per member
/ total # of actions
per team

- # of
assignment
submissions / updates
- # of
assignment
views
- # of course views
- # of folder views
- # of discussion forum
views
- # of grade views
- # of page views
- # of resource views
- # of URL views
- # of user views
- Final exams grades
- Assignments grades
-
grades
- Collective
grades
- Final project grades
- Final course grade

Individual project

project

- # of commits per
member
- Total # of commits
per team
- Ratio of the # of
commits per member
/ # of commits per
team
- # of
per member
- # of lines deleted
per member
- # of days of activity 
per member
- Total # of
added per team

lines added

lines

Surveys

Collaboration
- # of team meetings
- Total team meeting time
- # of F2F team meetings
- # of virtual team meetings

Motivation
- Students ratings of intrinsic
motivation
- Students ratings of amotivation

- Students ratings of external
regulation
- Students ratings of identiﬁed
regulation

Lecturer observations
- # of class attendances
- Lecturer ratings of individual
engagement

Satisfaction
- Students ratings of the quality
of the information and tools
provided
- Students ratings of satisfaction 
with the learning process
and outputs
- Students ratings of the quality
of collaboration

4.2 Data Processing

The calculation of the ﬁve collaborative behaviour features considered in the
BAM, we used diﬀerent combinations of metrics of the data traces collected
from diﬀerent sources. Hence, each feature is calculated using speciﬁc metrics,
normalizing (from 0 to 100) the values that each metric provides, assigning
weights as multiplying factors, aggregating the resulting values, and applying a
corrective factor. This process can be represented through the following equation:

Feature x =

#of metrics(cid:2)

n=1

αn (Metric n) + β

(1)

where F eaturex represents the collaborative feature to be calculated, x is
the identiﬁcacion number of this feature, n is the number of metrics used, αn
corresponds to the multiplying factors (from 0 to 1) that weigh each metric,
M etricn is a function of a variable s - student – with range between 0 to 100,
and β is a corrective term. The sum of αn and β is 1. From the previous equation
and for the considered feature, we obtain a value within the range 0–100. As an
example, let us consider that we use three metrics to calculate the “Performance”
of a speciﬁc student. That metric includes the individual and group grades of

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1327

Moodle assignments and also the coding frequency as calculated by GitHub. In
this case, the resulting equation for Performance is the following:

Performance = 0.4 (Individual gradesof Moodle )
+0.4 (Groupgradesof Moodle )
+0.2 (GitHubcodingfrequency)

(2)

It is important to take into account that the metrics from each data trace can
lay within any possible range of values; therefore, we must normalize the values
of these metrics. For instance, the “GitHub coding frequency” indicates the
number of items added by a particular student to the software project repository
within a certain time period. We can normalize the GitHub coding frequency,
assigning the values of 0 and 100 respectively to the theoretical maximum and
minimum number of expected additions for a speciﬁc period. Thus, 0 and 100
could correspond to coding frequencies of 1 and 5 additions per week respectively.
Also, notice that in this case the corrective factor is zero and that we assigned
diﬀerent weights to the multiplying factors, giving more importance to some
measurements than to others.

Following the previous considerations, we can automatically generate the ﬁve
collaborative features considered in the BAM, and also determine the weight that
should be given to each metric. The use of machine learning techniques allows
the system learn, over a period of time, how the students collaborate and interact
using the software systems considered as data sources. Based on the learned information,
 the system can recalculate the collaborative behaviour features using
new data. The machine learning algorithms ease the interpretation of the models
used for the features calculation, allowing monitoring by human experts (e.g.,
lecturers) and enabling the validation and ﬁne-tuning of the generated models.
The ﬁrst step to generate a model that automatizes the calculation of the
features, is to ﬁlter the metrics collected from the data sources to discard those
that are not signiﬁcant for the results. To do so, we ﬁrst measured the values of
the collaborative features for each individual student using the ratings provided
by human observers; e.g., assessments of the lecturers and self-reports of the
students about the quality of collaboration during the course.

Once obtained the “real” values of these features, we used three diﬀerent
methods to select the most relevant metrics as shown in Table 2. The Correlation
analysis is used to discard metrics that had either a very high correlation between 
them or a very low correlation with the features. The Correlation Feature
Selection Subset Evaluator [Hall 1998] allows us make a ﬁne-grained selection
of subsets of metrics that are highly correlated with the features while having
low intercorrelation. Finally, the Wrapper method [Kohavi et al. 1997] allows
us select sets of metrics that are speciﬁcally signiﬁcant for a particular learning 
scheme. In our case, we considered a Linear Regression scheme. Using these

1328

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

Table 2: Techniques used for the selection of metrics

Correlation

CFS Subset Evaluator Wrapper Linear ReCommunication 
- Ratio of the # of
actions per member
total # of actions per
team
- Lecturer ratings of
individual engagement
- # of team meetings
- Students ratings of
intrinsic motivation
- # of commits per
member

- # of team meetings
- Lecturer ratings of
individual engagement
- Students ratings of
intrinsic motivation
- # of cards per team
- Ratio of the # of
actions per member
total # of actions per
team

Coordination - Ratio of the # of
actions per member
total # of actions per
team
- # of commits per
member
- Final project grades

- Assignments grades
- # of commits per
member
- Students ratings of
intrinsic motivation
- Ratio of the # of
actions per member
total # of actions per
team

- # of team meetings
- Students ratings of
intrinsic motivation

gression
- Lecturer ratings of
individual engagement
- Students ratings of
intrinsic motivation
- # of cards per team
- Ratio of the # of
actions per member
total # of actions per
team

- # of commits per
member

- Students ratings of
intrinsic motivation

Motivation

Performance

Satisfaction

- Students ratings of
intrinsic motivation
- # of team meetings
- Ratio of the # of
actions per member
total # of actions per
team
- Lecturer ratings of
individual engagement

- Final exams grades
- Final project grades
- # of commits per
member
- Assignments grades

- Final exams grades
- Final project grades

- Final exams grades
- Final project grades

- Assignments grades
- Final project grades
- Final exams grades
- Ratio of the # of
actions per member
total # of actions per
team
- # of commits per
member

- Assignments grades
- Final project grades
- # of team meetings
- Total team meeting
time
- Ratio of the # of
actions per member
total # of actions per
team

- Assignments grades
- Lecturer ratings of
individual engagement
- Ratio of the # of
actions per member
total # of actions per
team

methods, we reduced the initial set of 44 metrics to a subset of only 14. The
correlation values between the subset of selected features and the collaborative
behaviour features is shown in Table 3.

4.3 Feedback Provision

4.3.1 Representation of the Personal Awareness Component

We divided the PAC visualizations into two subcomponents to represent the
students’ collaborative behaviour features. The PAC-CBI [Fig. 2.a] displays an

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1329

Table 3: Selected metrics and correlation with the collaborative behaviour features


Moodle

Trello GitHub Collaboration Motivation

Lecturer

Surveys

s
e
d
a
r
g

s
t
n
e
m
n
g
i
s
s
A

s
e
d
a
r
g

s

m
a
x
e

l
a
n
i
F

s
e
d
a
r
g

t
c
e
j
o
r
p

l
a
n
i
F

s
e
t
a
d
p
u

s
n
o
i
s
s
i

m
b
u
s

t
n
e
m
n
g
i
s
s
a

f
o
#

s
w
e
i
v

t
n
e
m
n
g
i
s
s
a

f
o
#

m
a
e
t

r
e
p

s
d
r
a
c

f
o
#

l
a
t
o
T

s
n
o
i
t
c
a

f
o
#
e
h
t

f
o

o
i
t
a
R

f
o
#

l
a
t
o
t

r
e
b
m
e
m

r
e
p

m
a
e
t

r
e
p

s
n
o
i
t
c
a

Communication 0.47 0.65 0.48 0.33 0.45 0.45 0.88
Coordination 0.54 0.68 0.69 0.23 0.29 0.22 0.86
0.13 0.42 0.21 0.41 0.33 0.30 0.51
0.71 0.90 0.86 0.34 0.27 0.12 0.64
0.89 0.75 0.85 0.40 0.32 0.27 0.74

Motivation
Performance
Satisfaction

e
m

i
t

g
n
i
t
e
e
m
m
a
e
t

l
a
t
o
T
0.29
0.24
0.14
0.53
0.56

r
e
p

s
t
i

m
m
o
c

r
e
b
m
f
o
e
m
#
0.69
0.86
0.41
0.72
0.73

s
g
n
i
t
e
e
m
m
a
e
t

f
o
#
0.71
0.49
0.52
0.60
0.71

Observations

f
o

s
g
n
i
t
a
r

n
o
i
t
a
v
i
t
o
m
c
i
s
n
i
r
t
n
i

s
t
n
e
d
u
t
S
0.66
0.54
0.77
0.33
0.33

e
c
n
a
d
n
e
t
t
a

s
s
a
l
c

f
o
#
0.81
0.79
0.57
0.50
0.58

t
n
e
m
e
g
a
g
n
e

f
o

s
g
n
i
t
a
r

l
a
u
d
i
v
i
d
n
i

r
e
r
u
t
c
e
L
0.75
0.61
0.48
0.53
0.59

e
h
t

h
t
i
w
n
o
i
t
c
a
f
s
i
t
a
s

f
o

s
g
n
i
t
a
r

s
t
n
e
d
u
t
S

s
s
e
c
o
r
p

g
n
i
n
r
a
e
l

0.26
0.27
0.54
0.43
0.65

Figure 2: Design of the visual representations of the CBI and the collaboration
features

overview of the collaborative learning behaviour by combining the collaborative
features through a global rating scheme, deﬁned by the Collaborative Behaviour
Index (CBI). This index is calculated as the average of the represented features
(or CBI elements), and therefore it provides a representation of the overall collaborative 
behaviour of a student. Once the PAC-CBI is displayed, the user can
have more information through the visualization of the PAC-Features [Fig. 2.b],
which shows speciﬁc details about each feature included in the previous subcomponent.


As we can observe in [Fig. 2.a] the PAC-CBI is represented with a coloured
circle, whose size corresponds to the CBI value within a normalized scale from
0 to 100. The four concentric circles represent the theoretical ideal, normalized
minimum, average and maximum values of the CBI for the overall group of

1330

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

Figure 3: Example representations displayed for the PAC

students considered in the representation. This allows us to provide awareness
of the behaviour of a student in comparison to the behaviour of his/her peers.
The PAC-Features subcomponent [see Fig. 2.b] is represented through a
radar diagram. Each feature of the students’ collaborative behaviour is depicted
as a vertex of a coloured pentagon, which size corresponds to the normalized
value of the features. Similar to the PAC-CBI, we depict four concentric pentagons,
 where the ﬁrst one represents the theoretical ideal value expected for
all the behaviour features. This value will be deﬁned by lecturers according to
speciﬁc targets that ideally the students could achieve. The pentagons of variable 
size represent the normalized minimum, average and maximum values of
the features for the overall group of students. This enables a student to compare,
for each feature, his own performance to the one of his/her peers.

Notice that both, the PAC-CBI and the PAC-Features visualizations, represent 
the behaviour of a speciﬁc student to whom the feedback is being displayed
as colour-ﬁlled shapes (a circle and a pentagon, respectively). Moreover, the visualization 
of additional blank shapes, which represent ideal as well as minimum,
average and maximum values, provides such a student with an understanding of
his/her current state with regard to his/her fellow students and the ideal value.
[Fig. 3] shows an example of the visual representation of the collaborative behaviour 
of a student as displayed in the PAC. This representation considers the
CBI index [Fig. 3.a], as a measure of the overall collaborative behaviour, and also
the detail of the ﬁve collaboration dimensions [Fig. 3.b]. Notice that the values
of the features for a student can exceed the maximum value of the overall group
of students, if the student was excluded from the calculation of the minimum,
maximum and average values of the PAC.

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1331

Figure 4: Design of the visual representations of the Social Awareness Component


4.3.2 Representation of the Social Awareness Component

For the visual representation of the SAC, we deﬁned two diﬀerent criteria to recommend 
collaborators. [Fig. 4] shows the “highly recommended collaborators”
and the “other recommended collaborators” areas, where the former includes
at least one potential collaborator that is located at the closest MDS distance
from the represented student, and the latter includes the previous one and it
has a range that covers at least a 20% of the closest potential collaborators.
This percentage was decided on the basis of the Pareto’s principle or 80-20 rule
[Hardy 2010]; therefore we considered that 20% of all possible collaborators can
produce the most signiﬁcant impact on the collaboration process.

This method for suggesting collaborators is based on the correlation between
values of the CBI components for several students. Here, it is possible to recommend 
students who have similar or complementary behaviours in the same
collaboration dimensions. Particularly, [Fig. 4.a] represents the feedback provided 
to a student, where only those possible collaborators with complementary
behaviour are proposed. In this case, students who have high values of certain
behaviour features are suggested as potential collaborators of other students who
have small values in such features and vice verse. [Fig. 4.b] suggests collaborators 
using diﬀerent colours depending on if they have a behaviour similar or
complementary to the student receiving the feedback.

1332

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

5 Evaluating the Accuracy of BAM

We used the Weka workbench system [Hall et al. 2009] for representing and
evaluating the models used to calculate the features of the students’ collaborative 
behaviour. We chose this system since it incorporates a variety of learning
algorithms and some tools for the evaluation and comparison of the results. To
evaluate the accuracy of these models we used the Correlation Coeﬃcient (CC),
the Mean Absolute Error (MAE) and the Root Mean Square Error (RMSE).
The CC indicates the degree of correlation between the models and the values of
the features as captured by the ratings provided by human observers. The MAE
and RSME are common measures used to determine the quality of prediction
models. The MAE gives the same weight to the deviations between the real and
predicted values. By contrast, the RSME weighs large errors higher than small
ones. We use the following deﬁnitions:

MAE :=

(cid:2)
(cid:3)(cid:2)

|predicted –real|/Numberof values
(predicted − real)2/Numberof values

RMSE :=

In a ﬁrst stage we randomly divided the dataset (42 students) in ten groups.
One randomly chose a set used for training and the other nine were used in the
evaluation process; i.e., we conducted a 10-fold cross-validation.

Once the model was processed using the training data set, we evaluated its
prediction accuracy by running the model against the test set, which allowed us
to assess the model using new data. Results show that there is a high correlation
between the prediction models and the “real” values of the features [see Tab. 4].
We can also observe that the prediction errors are relatively small, especially
considering that the granularity required for the visual representation of the features 
should not be very high. Therefore, we can conclude that the prediction
models allow a trustworthy visualization of the collaborative behaviour features
that is representative of the real-word observations. The awareness model requires 
a minimum of four value levels for the representation of the features,
which correspond to the minimum, average, maximum and ideal values represented 
by the BAM. This granularity could be increase up to eight levels to
represent intermediate values between.

In a second stage we conducted a new evaluation of the model, where we
ordered the dataset chronologically, and then we split it in two segments. The
ﬁrst data segment was used to train the model, and the second one was used to
evaluate it. In this second evaluation process we considered training segments of
24%, 47% and 71% of the whole dataset. The results show the error decreases
while increases the size of the training set; particularly in communication, coordination 
and performance Tab. 5. The error tends to be acceptable when using

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1333

Table 4: Evaluation of the model using a cross-validation method

Communication Coordination Motivation Performance Satisfaction

Simple Linear Regression

CC
MAE
RMSE

CC
MAE
RMSE

0.85
0.13
0.16

0.81
0.14
0.20

0.77
0.16
0.20

0.78
0.15
0.19

Multiple Linear Regression

0.70
0.21
0.27

0.51
0.26
0.34

0.87
0.12
0.15

0.86
0.13
0.17

0.87
0.12
0.15

0.92
0.11
0.13

Table 5: Evaluation of the model using a training-test method

Communication Coordination Motivation Performance Satisfaction

24% train

47% train

71% train

MAE
RMSE
MAE
RMSE
MAE
RMSE

0.28
0.31
0.12
0.14
0.10
0.13

0.19
0.23
0.17
0.19
0.12
0.15

0.39
0.44
0.19
0.25
0.21
0.28

0.23
0.30
0.16
0.19
0.13
0.17

0.29
0.33
0.30
0.37
0.30
0.37

a training data segment with a size of at least 47% of the dataset. This does
not occur in the motivation and satisfaction dimensions since they involve few
instances; therefore, some few estimations with a large error produce an important 
negative impact on the prediction of these variables. We have also observed
that large errors in motivation and satisfaction do not occur simultaneously in
the same students. In fact, a large error in motivation tends to be linked to a
small error in satisfaction, and vice verse. Therefore, if we consider as acceptable
an error below 0.25, then all students of the dataset have 4 or 5 features that
can be considered as representative of we can observe in practice.

The results also show that the model generated by the Simple Linear Regression 
scheme obtains the best results. This can be explained due there is overﬁtting 
in the generation of the Multiple Lineal Regression model. This means that
because of the use of multiple metrics, some extreme values (not representative
of the overall behaviour of the students) are taken into account for the creation
of the model. Consequently, it might be necessary to perform further processing
of the data input to eliminate outliers from the data traces.

6 Empirical Evaluation of BAM

The usability of BAM was evaluated using a software component embedded
in the Moodle learning platform, which is used by the students of the DSA
course to support their activities. Then, we conducted a user study involving
42 students of that course whom did not participate in the previous experience.

1334

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

Figure 5: Results of the classiﬁcation tasks

Moodle was used to collect the students data traces, record their answers about
the evaluation tasks and questionnaires, and provide collaboration awareness to
them.

The visual awareness used in the study involved the three representations
considered in BAM. We asked participants to complete three tasks, one for each
visualization type, to evaluate the ﬁtness of the awareness proposal. Then, they
had to indicate whether those ﬁgures represented “poor”, “average” or “good”
student performance, and if some students represented in the SAC were “highly
recommended”, “recommended” or “not recommended” as collaborators. For
simplicity, we named this classiﬁcation tasks according to the rating levels that
they represent as “good”, “medium” or “bad”.

[Fig. 5] shows the results of the classiﬁcation tasks for the three elements of
the BAM, which compose the visual representations of our proposal. As we can
observe, there is a high rate of correct answers (94.91% in average) for all the
ﬁgures, which supports the suitability of our feedback proposal. These results
were useful to provide insights on how suitable the proposed awareness mechanism 
is to classify diﬀerent learning behavioural patterns and suggest possible
collaborators.

In addition, we asked participants to answer several questions to assess the
usability of the three components of the BAM. These questions were taken from
the Usability Perception Scale (UPscale) [Karlin et al. 2013] and the Post-Study
System Usability Questionnaire (PSSUQ) [Lewis 2002]. Both tools were adapted
to suit the purposes of this study and formatted in a 5-point Likert scale. The
resulting usability questionnaires included questions designed to evaluate attributes 
of the visualizations, such as ease of interpretation, learnability, usefulness,
 relevance and intention of use.

The prototype evaluation considered the analysis of the perceived usefulness
of the feedback model, and also its suitability to be used as part of the awareness

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1335

Figure 6: Results of the UPscale questionnaire

support of collaborative learning applications. [Fig. 6] shows the results obtained
from the UPscale, which suggest very positive participants’ perceptions about
the usability (70.42% in average) and engagement (65.69% in average) of the
three kinds of visualizations. These results helped us evaluate the students’ perceived 
satisfaction concerning the information quality and its representation, as
well as the usefulness and comprehensibility of the feedback.

Similarly, the results from the PSSUQ questionnaire indicate a high rate
of participants’ satisfaction (76.31% in average) for such visualizations [Fig. 7].
Considering both usability questionnaires, the results revealed a highest satisfaction 
of the students with the representation provided by the SAC component,
followed by the PAC-Features and the PAC-CBI respectively.

7 Conclusions and Future Work

This paper proposes a Behaviour Awareness Mechanism (BAM) as a method
to provide visual feedback to students while they perform collaborative learning 
activities. This method is intended to enhance the learning experience and
encourage self-reﬂection about the collaboration process. The usability and usefulness 
of this proposal was evaluated through a proof-of-concept evaluation in
an undergraduate course, at the Polytechnic University of Catalonia, Spain. This
evaluation involved the collection of data traces from 42 students enrolled in an
undergraduate software engineering course. Then, a set of 24 new students of
that course used an implementation of BAM to support the activities of their
software development teams.

The obtained results indicate that the BAM is useful to provide aggregate
feedback about the students’ behaviour and performance, using information from
diﬀerent data sources. The implemented awareness mechanism was able to prop1336


Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

Figure 7: Results of the PSSUQ questionnaire

erly represent the collaborative behavioural patterns of the students and suggest
potential collaborators. Although BAM was initially proposed to support undergraduate 
courses, it could also be suitable to support other collaborative learning
scenarios. Next steps in this research involve a more in depth evaluation of BAM.
This will allow us improve the design of the visualizations and investigate how
the provision of feedback aﬀect future behaviour and collaboration dynamics of
the students. Moreover, it is also required to explore several other aspects of the
BAM implementation; for instance, what other sources could be used as data
sources to implement this awareness? what ethical aspect should be considered
in the social awareness since it is based on personal information? and what would
be possible eﬀects on the students self-esteem?

Acknowledgements

This work has also been partially supported by Fondecyt (Chile), grants: 1150252;
by the Spanish Ministry of Science and Innovation (MCI) and FEDER funds of
the EU under the contract TIN2013-47245-C2-1-R and also by the Generalitat
de Catalunya as a Consolidated Research Group 2014-SGR-881.

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

1337

References

[Antunes et al. 2014] Antunes, P., Herskovic, V., Ochoa, S.F., Pino, J.A.: ”Reviewing
the quality of awareness support in collaborative applications”; Journal of Systems
and Software, 89, (2014), 146–169.

[Benchettara et al. 2010] Benchettara, N., Kanawati, R., Rouveirol, C.: ”A supervised
machine learning link prediction approach for academic collaboration recommenda-
tion”; Proceedings of RecSys’10, ACM, Barcelona (2010), 253–256.

[Brand˜ao et al. 2013] Brand˜ao, M.A., Moro, M.M., Lopes, G.R., Oliveira, J.P.M.: ”Using 
link semantics to recommend collaborations in academic social networks”; Proceedings 
of World Wide Web (WWW), ACM, Rio de Janeiro (2013), 833–840.

[Buja et al. 2008] Buja, A., Swayne, D.F., Littman, M.L., Dean, N., Hofmann, H.,
Chen, L.: ”Data visualization with multidimensional scaling”; Journal of Computational 
and Graphical Statistics, 17, 2 (2008), 444–472.

[Chounta et al. 2013] Chounta, I.A., Sintoris, C., Masoura, M., Yiannoutsou, N.,
Avouris, N.M.: ”The Good, the Bad and the Neutral: An Analysis of Team-Gaming
Activity”; Proceedings of Workshop on Collaborative Technologies for Working and
Learning (ECTEL-meets-ECSCW), Paphos (2013), 10–14.

[Chounta et al. 2014] Chounta, I.A., Hecking, T., Hoppe, H.U., Avouris, N.: ”Two
make a network: using graphs to assess the quality of collaboration of dyads”; Proceedings 
of Collaboration and Technology (CRIWG), Springer, Santiago (2014),
53–66.

[Cosentino et al. 2014] Cosentino, V., Izquierdo, J.L.C., Cabot, J.: ”Three Metrics to

Explore the Openness of GitHub projects”; ArXiv e-prints, 1409.4253 (2014).

[Daradoumis et al. 2003] Daradoumis, T., Xhafa, F., Marqus, J. M.: ”Evaluating collaborative 
learning practices in a virtual groupware environment”; Proceedings of
Computers and Advanced Technology in Education (CATE), Rhodes (2003).

[de Melo et al. 2014] de Melo, A.A., Hinz, M., Scheibel, G., Berkenbrock, C.D.M., Gasparini,
 I., Baldo, F.: ”Version Control System Gamiﬁcation: A Proposal to Encourage 
the Engagement of Developers to Collaborate in Software Projects”; Proceedings
of Social Computing and Social Media, Springer, Crete (2014), 550–558.

[El-Bishouty et al. 2007] El-Bishouty, M.M., Ogata, H., Yano, Y.: ”PERKAM: Personalized 
knowledge awareness map for computer supported ubiquitous learning”;
Educational Technology & Society, 10, 3 (2007), 122-134.

[Felder et al. 2003] Felder, R.M., Brent, R.: ”Learning by Doing”; Chemical Engineering 
Education, 37, 4 (2003), 282-283.

[Fransen et al. 2011] Fransen, J., Kirschner, P.A., Erkens, G.: ”Mediating team eﬀectiveness 
in the context of collaborative learning: The importance of team and task
awareness”; Computers in Human Behavior, 27, 3 (2011), 1103–1113.

[Freeman et al. 2014] Freeman, S., Eddy, S.L., McDonough, M., Smith, M.K., Okoroafor,
 N., Jordt, H.: ”Active learning increases student performance in science,
engineering, and mathematics”; Proceedings of the National Academy of Sciences
(2014), 8410-8415.

[Gonz´alez-Ib´a˜nez et al. 2015] Gonz´alez-Ib´a˜nez, R., Shah, C., White, R.W.: ”Capturing
Collabportunities: A method to evaluate collaboration opportunities in information
search using pseudocollaboration”; Journal of the Association for Information Science 
and Technology, 66,9 (2015), 1897-1912.

[Govaerts et al. 2012] Govaerts, S., Verbert, K., Duval, E., Pardo, A.: ”The student
activity meter for awareness and self-reﬂection”; Proceedings of Human Factors in
Computing Systems Extended Abstracts, ACM, Austin (2012), 869–884.

[Gress et al. 2010] Gress, C.L., Fior, M., Hadwin, A.F., Winne, P.H.: ”Measurement
and assessment in computer-supported collaborative learning”; Computers in Human 
Behavior, 26, 5 (2010), 806–814.

[Hall 1998] Hall, M.A.: ”Correlation-based Feature Subset Selection for Machine

Learning”; Hamilton New Zealand (1998).

1338

Medina E., Meseguer R., Ochoa S.F., Medina H.: Providing ...

[Hall et al. 2009] Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten,
 I.H.: ”The WEKA data mining software: an update”; ACM SIGKDD explorations 
newsletter, 11, 1 (2009), 10–18.

[Hardy 2010] Hardy, M.: ”Pareto’s law”; The Mathematical Intelligencer, 32, 3 (2010),

38–43.

[Janssen et al. 2007] Janssen, J., Erkens, G., Kanselaar, G., Jaspers, J.: ”Visualization
of participation: Does it contribute to successful computer-supported collaborative
learning?”; Computers & Education, 49, 4 (2007), 1037-1065.

[Karlin et al. 2013] Karlin, B., Ford, R.: ”The Usability Perception Scale (UPscale): A
measure for evaluating feedback displays”; Proceedings of Design, User Experience,
and Usability (DUXU), Springer, Las vegas (2013), 312–321.

[Kohavi et al. 1997] Kohavi, R., John, G. H.: ”Wrappers for feature subset selection”;

Artiﬁcial intelligence, 97, 1 (1997), 273–324.

[Kwon et al. 2013] Kwon, K., Hong, R. Y., Laﬀey, J. M.: ”The educational impact of
metacognitive group coordination in computer-supported collaborative learning”;
Computers in Human Behavior, 29, 4 (2013), 1271–1281.

[Lambropoulos et al. 2012] Lambropoulos, N., Faulkner, X., Culwin, F.: ”Supporting
social awareness in collaborative e-learning”; British Journal of Educational Technology,
 43, 2 (2012), 295–306.

[Lewis 2002] Lewis, J.R.: ”Psychometric evaluation of the PSSUQ using data from ﬁve
years of usability studies”; International Journal of Human-Computer Interaction,
14, 3-4 (2002), 463–488.

[Lin et al. 2008] Lin, C., Standing, C., Liu, Y.-C.: ”A model to develop eﬀective virtual

teams”; Decision Support Systems, 45, 4 (2008), 1031–1045.

[Melero et al. 2015] Melero, J., Hern´andez-Leo, D., Sun, J., Santos, P., Blat, J.: ”How
was the activity? A visualization support for a case of location-based learning de-
sign”; British Journal of Educational Technology, 46, 2 (2015), 317–329.

[Nicol et al. 2006] Nicol, D. J., Macfarlane-Dick, D.: ”Formative assessment and selfregulated 
learning: A model and seven principles of good feedback practice”; Studies
in higher education, 31, 2 (2006), 199–218.

[O’Dea et al. 2007] O’Dea, A., Harris-Thompson, D., Malek, D., Dominguez, C., Crandall,
 B.: ”Indicators for Assessing Collaboration Technologies”; Proceedings of NDM
Conference, Paciﬁc Grove (2007).

[Ogata and Yano 2004] Ogata, H., Yano, Y.: ”Knowledge awareness map for computersupported 
ubiquitous languagelearning”; Proceedings of Wireless and Mobile Technologies 
in Education (WMTE), IEEE, Jhongli (2004), 19-26.

[Schneider et al. 2015] Schneider, J., Borner, D., van Rosmalen, P., Specht, M.: ”Augmenting 
the Senses: A Review on Sensor-Based Learning Support”; Sensors, 15, 2
(2015), 4097–4133.

[Strijbos 2011] Strijbos, J.W.: ”Assessment of (computer-supported) collaborative

learning”; IEEE Transactions on Learning Technologies, 4, 1 (2011), 59–73.

[Wu et al. 2014] Wu, K., Vassileva, J., Sun, X., Fang, J.: ”Motivating Wiki-Based Collaborative 
Learning by Increasing Awareness of Task Conﬂict: A Design Science Ap-
proach”; Proceedings Collaboration and Technology (CRIWG), Springer, Santiago
(2014), 53–66.

[Zheng and Yano 2007] Zheng, Y., Yano, Y.: ”A framework of context-awareness support 
for peer recommendation in the e-learning context”; British Journal of Educational 
Technology, 38, 2 (2007), 197-210.

