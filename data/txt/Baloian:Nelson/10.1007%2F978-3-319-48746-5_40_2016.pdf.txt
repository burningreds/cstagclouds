Easing Students’ Participation in Class with Hand Gesture

Interfaces

Orlando Erazo1,2(✉), Nelson Baloian1, José A. Pino1, and Gustavo Zurita3

1 Department of Computer Science, Universidad de Chile, Santiago, Chile

{oerazo,nbaloian,jpino}@dcc.uchile.cl

2 Escuela de Informática, Universidad Técnica Estatal de Quevedo, Quevedo, Ecuador

3 Department of Management Control and Information Systems,

Universidad de Chile, Santiago, Chile

gzurita@fen.uchile.cl

Abstract.  Students’  participation  in  traditional  classroom  settings  may  be
hindered due to various reasons, which interrupt the class ﬂow or cause distraction
among the rest of the class members. To tackle that problem, we propose using
applications based on touchless hand gestures (THG) that would allow students
to interact from their own places. The feasibility of this proposal is analyzed in
this work. To do it, we requested students to use two applications from their
physical locations. Obtained qualitative results suggest the proposal may be used
in an acceptable way as the use of applications based on THG becomes wide‐
spread. Actually, students who participated recommend the use of this proposal,
since they may be more motivated to participate actively in the development of
classes, which would result in better teaching-learning processes.
Keywords: Classroom  teaching  ·  Touchless  hand  gestures  ·  Natural  user
interface

1

Introduction

Encouraging students’ participation in traditional classroom lectures frequently makes
teachers ask questions, require students to solve a problem on the blackboard or suggest
them to ask questions about the lecture [1]. However, some students may be reluctant
to participate in class because they may be shy or nervous, or simply they may be afraid
of making mistakes or seem unintelligent. Actually, teachers may experience a drop in
participation when these practices are not properly applied [2]. These problems can
appear when the teacher asks a student to perform a task on the board in front of the
class. This may also interrupt the normal ﬂow of the lecture and cause distraction. One
way to tackle the problem is to equip the classroom with enough computers so that each
student may use one of them [3]. Alternatively, each student may use her own laptop
(e.g., [1]). Given the accessible costs of mobile devices, the teacher could permit the use
of students’ personal devices, tablets or smartphones instead of laptops to participate in
class [2]. Unfortunately, these settings also let students perform activities diﬀerent than
those required for the class [4].

© Springer International Publishing AG 2016
C.R. García et al. (Eds.): UCAmI 2016, Part I, LNCS 10069, pp. 393–399, 2016.
DOI: 10.1007/978-3-319-48746-5_40

394

O. Erazo et al.

The interaction using touchless hand gestures (THG) for educational purposes is
another option that has been studied especially in recent years. Works reporting about
user interfaces (UIs) based on THG are described in [5]. They can be applied with the
aim of enhancing classrooms and immersing students in their learning [6–9]. However,
most of them require students stand in front of a screen at a certain distance to interact
with the applications. This approach has the same problems than the classical one in
which a student works in front of the class. The fact that the student has to go to the right
place may interrupt the class ﬂow, and cause disorders and students’ distraction.

Alternatively,  the  interaction  using  THG  from  students’  location  may  help  to
promote participation in class, but this approach has yet to be explored. Therefore, and
as a ﬁrst step, the goal of this paper is to analyze the feasibility of using UIs based on
THG in classrooms from students’ own physical location. We report on initial qualitative
results that support this proposal and provide the basis to further investigate it.

2 Touchless Hand Gestures in the Classroom

The development of devices like Kinect and Leap Motion (LM) has induced the emer‐
gence of applications allowing users to interact without using intermediate input devices
such as mice and keyboards [10]. Applications of this type use as input the information
conveyed by gestures performed in the air, and hence, physical contact is not required
to manipulate content. Though gestures can be executed with various body parts, we
focus only on THG. This interaction style can be “natural” to users [10], and it can be
used in scenarios where other interaction styles are inadequate.

Education is an application ﬁeld where the use of THG can be advantageous. UIs of
this type can ease and improve teaching and learning by fabricating meaningful class‐
room interactions [5]. They may contribute to increase participation, provide a better
way to present and manipulate teacher’s material, create opportunities for discussion,
and overall create enjoyable classes [5]. Several works have been proposed to support/
complement/improve the learning of diﬀerent subjects and languages at the various
educational levels [6, 7], to control presentations [8], etc.

Although THG can be employed in several scenarios, we focus just on classrooms.
The most frequent use is the learning of speciﬁc topics. In this case, a student is required
to stand on a speciﬁc place in the classroom (e.g., between the whiteboard and the other
students) to interact with the application. For example, she can use the hands to manip‐
ulate 3D models of organs [9] in an anatomy class. An approach slightly diﬀerent is the
simulation of educational scenarios; e.g., a virtual laboratory [6]. Additionally, devices
that enable the use of THG can also ease the development of interactive whiteboards.
Works of this type demonstrate that THG can be used to increase the participation and/
or motivation of students in classrooms. However, their main disadvantage is that they
require a physical space reserved speciﬁcally to allow students to use the applications.
Alternatively, we propose the use of THG to allow students to interact with applications
from their own physical locations.

Our interaction model consists of three phases (Fig. 1): transferring control (TC),
participation (P) and ﬁnishing (F). A teacher controls the application, and hence, she

Easing Students’ Participation in Class

395

must transfer control to a student who will perform the required task. Therefore, transfer
control means the teacher stops being the user who controls the application and the
student is able to use it from that moment onwards. Next, the student starts the interaction
to carry out the task. Several aspects should be considered for this goal: interaction style
(i.e., type of gestures to use), gesture space (i.e., the space to input gestures), gesture set
(e.g., see [10]), and student representation (i.e., how a user recognizes her actions).
Finally, the student concludes the interaction and control returns to the teacher, who
continues with the class or transfers control to another student.

Fig. 1. Proposed concepts for designing hand gesture interfaces for classrooms

A couple of hypothetical examples can further explain our proposal. A teacher is
showing slides projected on a screen. A student has a question which refers to the content
presented some slides back, but the student does not remember exactly which one.
Instead of having the teacher going slides back one by one, the student could take control
(TC) of the presentation from his/her spot, and browse through the slides quickly with
hand gestures until ﬁnding the right one (P). Also, the student can move a cursor over
the slide and make marks to highlight the part the question refers to. After this, another
student or the teacher can take control (F) and perform other tasks. Another scenario is
a  Grammar  class  in  primary  school.  The  teacher  shows  a  sentence  and  asks  about
mistakes it contains. The teacher selects a student (TC) who starts interacting with the
application to answer the question. The student can use various options (P), such as
selecting one from several answers via a push gesture, encircling the answer, high‐
lighting it with a marker, etc. Another student or the teacher can then correct a wrong
answer, or the application itself can automatically give feedback (F).

3

Initial Evaluation

Taking into account that we were interested in learning about the students’ feelings,
beliefs, etc. regarding the proposal, we decided to carry out a focus group to collect
qualitative data about student perceptions as a starting point. The major goal was to get
students’ opinions about the proposal by using the developed prototypes.

3.1 Design
The hardware setup consisted of a notebook, a projected display, and two gesture input
devices, mounted in a classroom in our university campus. Taking into account there

396

O. Erazo et al.

are several devices that can be used to track users’ hand positions and recognize gestures,
we decided to use and test two of them: Kinect and LM. Both devices were connected
to a notebook equipped with an Intel Core i7 processor, 8 GB of RAM. The Kinect was
placed at a height of 1 m, and 2.5 m in front of participants, whereas the LM was placed
on participant’s desk. The wall-projected display, connected to the notebook, had a size
of 2 × 2 m and a resolution of 1360 × 768 pixels.

Two prototypes were developed to verify our proposal. Both used a gesture space in
front of the user, and students were represented with a hand cursor and a silhouette (at
the bottom right). A ﬁrst application (A1, Fig. 2a) allows users to control a program for
presentations (speciﬁcally, we used MS Power Point) performing several THG. Students
may also make some annotations like circling a word or answer, drawing a shape, etc.
Thus, the application allows browsing between slides using swipe gestures; sketching
on a slide by tapping a button to enter to and exit from the drawing mode, gripping to
start drawing, and releasing for ﬁnishing; and erasing the sketch by a wave gesture, all
when the Kinect is used. Tap gesture is exchanged for a thumb gesture (that is recognized
when the user extends her thumb) when the LM is employed. The second application
(A2, Fig. 2b) is more speciﬁc. It was developed thinking on students of a Data Structures
course. A2 allows the building of binary trees based on tap, grip, and release gestures
using Kinect, and thumb gestures using LM (the user opens the thumb for gripping and
hides it for releasing). To do this, the teacher enters the value of a new node and the
student has to insert it in the right place by gripping the node, moving it to the right
place, and releasing it. The application lets students perform node rotations to balance
the tree according to the AVL-tree rules, make tree traversals and show them, clean the
working area, and undo actions.

  

a)

b)

Fig. 2. The developed applications: (a) control a presentation program; (b) build binary trees.

Nine male computer science students (who were not UI designers) volunteered in
the focus group. Seven undergraduate students were attending a course on Data Struc‐
tures; two graduate students completed the group. All participants declared having a
basic experience using Wii or Kinect for playing games.

The focus group started with the moderator’s (a researcher) explanation about the
goal and the use of THG. The moderator explained the idea of using applications based
on THG from students’ spot, and then he asked the participants to sit down only on the
ﬁrst row to start using the applications. First, the moderator explained the goal and use
of A1, and the participants then tried it, ﬁrst using Kinect, and secondly using LM.

Easing Students’ Participation in Class

397

Afterwards, A2 was introduced and used but interchanging the order of the devices.
Finally, the moderator encouraged the participants to have a discussion on their prefer‐
ences, beliefs, and general opinions about the possibility of using this interaction style
according to our proposal, the elements included in the applications, the used devices,
the perceived comfort, and the interaction (in general) by asking open-ended questions.
The focus group lasted about 2 h.

Each participant had to perform several tasks when they were trying the applications.
With three slides they had to advance forward and go backwards, and draw their initials
(two letters) using A1. Concerning the other application (A2), each participant had to
add a node and make a rotation (the options clear and undo were used occasionally when
they were needed). Also, the participants took turns performing each task as they would
do in a class; i.e., there was a moderator assuming the teacher’s role who transferred
control to each student to participate at the proper moment.

3.2 Results
The results described in this section were obtained from the discussion between the
participants after performing the tasks. In general, they gave initial evidence of the
feasibility of using THG to interact with applications from students’ locations.

Concerning the main topic of interest, all participants agreed this style of interaction
could help encourage students to participate in class, and they had no suggestions about
the elements of the interfaces. A few comments in this sense were: “classes will be more
interesting if software of this type is used”, “this proposal is ideal for students like us
who love technology”, and “this proposal could encourage students from secondary and
maybe primary schools to participate in class”.

Concerning the used devices, it was not easy to get an agreement because the partic‐
ipants experienced greater precision using LM than using Kinect, but they said they
preferred the Kinect interaction. At the end, they decided to choose Kinect as the input
device suggesting that it was fun, intuitive, involved more body parts, and they expected
an improvement in device precision in the near future.

Despite participants considered the applications as not diﬃcult to learn and use, they
mentioned the need to have a short learning curve for best results. They also provided
further comments on the interfaces that led to the corresponding improvements. Some
examples of this fact were: using both swipe gestures and buttons to navigate, moving
the initial node to another place, and changing a couple of colors.

4 Discussion and Conclusion

With the aim of easing students participation during traditional classes and avoiding
negative aspects (e.g., distraction and nervousness), we propose to use applications
based on THG to allow students to interact from their physical locations. We have thus
requested students to use two applications in the proposed manner, and the initial results
demonstrate this type of applications could be used in an acceptable way. This proposal
takes advantage of the beneﬁts that THG can oﬀer in the learning process. For instance,

398

O. Erazo et al.

some activities/tasks could be done in a playful and interactive way contributing to
enhance classroom interactions and to ignite student creativity [5].

This proposal may help manage some of the common problems experienced during
the delivery of face-to-face classes, but today there are some practical limitations to
implement it in real classrooms. They mainly refer to gesture acquisition devices. For
example,  LM  oﬀers  acceptable  precision  to  track  hands  and  recognize  gestures.
However, its tracking space may be not large enough to allow recognizing some gestures.
Moreover, student locations would have to be equipped with LMs, which could be
comparable with having a mouse on each desktop. On the other hand, current versions
of Kinect (and similar devices) can only track up to six people and the performance
worsens with a distance over four meters. An alternative may be to use more than one
Kinect to track more students and put the sensors at diﬀerent places (e.g., on the ceiling).
This conﬁguration could be tried in the future, but we envision new and better gesture
input devices that will track more people, at greater distances and ﬁelds of view, and
with lower noise levels (e.g., Google’s Project Soli).

This work has reported initial results, but it is necessary to perform further research.
For example, we should analyze the degree at which this kind of applications would
help encourage students to participate in class and avoid negative aspects. We also
consider important to ask teachers their opinions about our proposal.

Acknowledgments.  This work was partially supported by SENESCYT (Ecuador), NIC (DCC,
Universidad de Chile), and Fondecyt 1161200 (Chile).

References

1. Anderson,  R.J.,  Anderson,  R.,  VanDeGrift,  T.,  Wolfman,  S.,  Yasuhara,  K.:  Promoting
interaction in large classes with computer-mediated feedback. In: Wasson, B., et al. (eds.)
Designing for Change, pp. 119–123. Kluwer Academic Publishers (2003)

2. Ratto, M., Shapiro, R.B., Truong, T.M., Griswold, W.G.: The activeclass project: experiments
in encouraging classroom participation. In: Wasson, B., et al. (eds.) Designing for Change,
pp. 477–486. Kluwer Academic Publishers (2003)

3. Baloian,  N.,  Pino,  J.A.,  Hardings,  J.,  Hoppe,  H.U.:  Monitoring  student  activities  with  a
querying system over electronic worksheets. In: Baloian, N., Burstein, F., Ogata, H., Santoro,
F., Zurita, G. (eds.) CRIWG 2014. LNCS, vol. 8658, pp. 38–52. Springer, Heidelberg (2014).
doi:10.1007/978-3-319-10166-8_4

4. Fried, C.B.: In-class laptop use and its eﬀects on student learning. Comput. Educ. 50(3), 906–

914 (2008)

(2011)

5. Hsu, H.J.: The Potential of Kinect in Education. Int. J. Inform. Educ. Technol. 1(5), 365–370

6. Jagodziński, P., Wolski, R.: Assessment of application technology of natural user interfaces
in the creation of a virtual chemical laboratory. J. Sci. Educ. Technol. 24(1), 16–28 (2015)
7. Lin, T.Y., Chen, C.F., Huang, D.Y., Huang, C.W., Chen, G.D.: Using resource of classroom
and content of textbook to build immersive interactive learning playground. In: ICALT 2014,
pp. 244–248. IEEE Press (2014)

Easing Students’ Participation in Class

399

8. Sommool, Worapot, Battulga, Batbaatar, Shih, Timothy K., Hwang, Wu-Yuin: Using kinect
for holodeck classroom: a framework for presentation and assessment. In: Wang, Jhing-Fa,
Lau, Rynson (eds.) ICWL 2013. LNCS, vol. 8167, pp. 40–49. Springer, Heidelberg (2013)
9. Blum, T., Kleeberger, V., Bichlmeier, C., Navab, N.: mirracle: an augmented reality magic

mirror system for anatomy education. In: VRW 2012, pp. 115–116. IEEE Press (2012)

10. Erazo, O., Pino, J. A.: Predicting task execution time on natural user interfaces based on

touchless hand gestures. In: IUI 2015, pp. 97–109. ACM Press (2015)

