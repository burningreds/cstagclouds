Mobile Sensemaking: Exploring Proximity and Mobile 

Applications in the Classroom 

 

 

 

Abstract.  We  propose  mobile  sensemaking  as  a  collaborative  mechanism  to 
explore and understand information in highly mobile and fluid situations, where 
people  engage  in  multiple  parallel,  rapid  and  ad-hoc  interactions,  rather  than 
participating in large highly-structured decision processes. Mobile sensemaking 
is  explored  in  the  classroom  context,  where  it  has  been  recognized  that  the 
traditional  lectures  should  be  reconstructed  as  active  processes  centered  on 
collaborative  activities.  Mobile  sensemaking  relies  on  mobile  computing 
devices  and  a  proximity  model,  both  organizing  collaborative  activities 
according to the domain context and physical proximity. The paper describes in 
detail the proposed proximity model and the developed mobile application. 

1   Introduction 

Over the last recent years many systems based on mobile computing technology have 
been  developed  for  supporting  collaborative  learning  of  students  in  the  classroom.  
The  goal  of  these  systems  has  been  to  improve  the  quality,  effectiveness  and 
satisfaction of teaching, leveraging the synergies found in small collaborative groups.  
With  the  help  of  appropriate  mobile  technology  and  applications,  teaching  and 
learning  procedures  are  expected  to  achieve  higher  levels  of  engagement,  better 
adjustment to individual and group learning needs, higher learning rates, and better 
quality of time utilization and a better flexibility of teaching for the instructors. 

However,  in  spite  of  such  new  technology,  the  basic  learning  processes  have 
remained  largely  unchanged throughout  this  time.  Furthermore,  to  date,  researchers 
have  mostly  focused  on  bringing  technological  innovation  to  the  classroom,  while 
giving  relatively  little  attention  to  the  more  broad  aspect  of  improving  the  in-class 

instruction using technology in order to enrich the existing “best practices” or create 
new ones.  

Many  educators  agree  that  the  main  disadvantage  of  the  traditional  classroom 
lecture  –  the  one  placing  teachers  as  the  major  focus  of  attention  and  most  critical 
resources  –  is  the  reduced  level  of  interactivity  between  teachers  and  students,  and 
among  the  students  themselves.  The  limited  interaction  possibilities  in  classroom 
lectures  originates  a  set  of  problems  regarding  students’  attention  and  motivation, 
reduced  teachers’  awareness  of  the  actual  learning  accomplishments,  and  lack  of 
flexibility  for  handling  the  necessary  adjustments  regarding  the  teacher’s  and 
students’ goals. 

From  a  pedagogic-psychological  point  of  view,  it  has  been  considered  that 
learning in the classroom should be reconstructed and redefined as an active process 
with more involvement of the student in meaningful learning activities [4], [7]. This 
reconstruction would include [9]: a) promoting students’ engagement in stimulating 
collaborative activities; b) increasing teachers’ awareness of students’ progresses; and 
c)  enriching  the  learning  process  with  more  sophisticated  activities  such  as 
brainstorming, creative thinking, decision making, planning, and critical evaluation of 
the outcomes [14].  

Interacting with their peers by being engaged in collaborative learning activities 
also  represents  an  opportunity  for  the  learner  to  take  hand  in  shaping  the 
informational, communicational and learning process, rather than remaining a passive 
and  individual  recipient.  As  far  as  the  success  of  interactivity  in  the  classroom  is 
concerned, empirical results indicate that: a) lectures are not generally ineffective, but 
are unsuitable to a global knowledge transfer [5]; and b) the diverse learner-centered 
measures positively affect learning success [6]. 

Nevertheless, the classroom lecture remains as the most frequent teaching-learning 
scenario, since it has also important advantages compared to other settings. Especially 
important is the economic aspect regarding the teachers’ cognitive effort: only in a 
classroom lecture a teacher can economically deliver knowledge to a large number of 
students, regarding the resources involved and the time invested.  

Our endeavor is to improve interactivity in the classroom while still keeping the 
learning process efficient in terms of resources and time. We have strong reasons to 
believe that mobile technology provides a technological platform capable to support 
the levels of interactivity required by the active learning process, and we are building 
software mechanisms to conserve the teachers’ effort in this process.  

In this paper we show how wirelessly interconnected handheld computing devices 
may  improve  interactivity  in  the  classroom  involving  university  students  in  more 
sophisticated interactions than those expected in classic lectures, which in turn will 
foster collaborative learning. The focus of this technology is to improve sensemaking 
in  the  classroom,  i.e.  the  students’  ability  to  collectively  explore  and  understand 
information  [16]  while  shifting  the  teacher’s  role  to  the  backstage,  performing 
supporting activities but not coordinating the assigned tasks.  

The  paper  is  organized  as  follows.  Section  2  describes  the  scenario  we  want  to 
support. Section 3 defines the context and proximity concepts in this scenario. Section 
4 describes our proposed proximity model for mobile sensemaking. Section 5 presents 
the  application  implementing  a  sensemaking  activity  in  the  classroom.  Section  6 
discusses this solution and concludes the paper.  

2   Scenario 

Our  working  scenario  considers  a  common  classroom  situation  where  a  teacher 
assigns to a large group of students the task of analyzing a large collection of papers. 
These papers are related in some way, but the relationships must be found out by the 
students  through  exploration  and  collaboration.  When  the  task  is  successfully 
accomplished, the students should have built a coherent list of topics and identified 
their most significant relationships, thus defining a strategic view over the proposed 
research topic, without having every student to read all the papers. 

The  task  enfolds  as  follows.  Each  student  receives  one  or  two  papers  from  the 
teacher and is encouraged to find out the main topics addressed by those papers. This 
individual  task  should  then  contribute  to  the  collaborative  effort.  Students  are 
expected to share their findings with others, identifying common topics, establishing 
relationships, and avoiding misjudgments. This should enfold in a paced and informal 
way,  avoiding  loosing  time  waiting  for  individual  students  to  deliver  their 
contributions,  and  in  particular  avoiding  loosing  too  much  time  discussing  their 
divergences  as  a  group.  Instead,  students  are  encouraged  to  engage  in  parallel 
negotiations  with  multiple  parties  to  resolve  their  differences  and  reach  consensus. 
Overall, the students assume the central role in the decision process, while the teacher 
is  sent 
their 
accomplishments, although not coordinating the assigned task.  

to  backstage,  coaching  and  encouraging  students,  assessing 

The fundamental aim of this task is to engage students in the sensemaking process. 
The sensemaking process was proposed by Weick [17] as a primary mechanism for 
organizations  to  explore  and  understand  information.  Sensemaking  is  an  ongoing 
process  aiming  to  create  order  and  make  retrospective  sense  about  some  event  or 
collection  of  events.  It  has  also  been  associated  to  preliminary  decision-making 
activities like “understanding the situation” or “getting the picture” [6]. Sensemaking 
is also inherently collaborative [12], meaning that the several mechanisms defined by 
sensemaking  (ecological  change,  enactment,  selection,  retention)  rely  on  the 
capabilities of a community of people to identify cues, update and share information, 
identify possible actions and provide feedback on those actions. 

We  argue  sensemaking  precisely  captures  the  decision  process  defined  by  our 
working  scenario.  When  students  identify  new  main  topics,  they  contribute  to  an 
ecological  change.  These  new  events  may  be  sensed  by  other  students,  who  enact 
their  responses,  looking for  similarities,  relationships, or even  misjudgments.  Then, 
collaboratively, they may try to make sense out of such events and construct a shared 
and  coherent  view.  In  summary,  this  scenario  involves  students  exchanging 
information,  moving  around  the  classroom  to  engage  in  discussions  with  the  other 
parties, negotiating common interests, and ultimately making sense of information.  

3   Context and Proximity in the Proposed Scenario 

According  to  Dey  [2],  context  is  defined  as  any  information  that  can  be  used  to 
characterize the situation of an entity. An entity is anything relevant to the interaction 
between a user and an application, such as a person, a place or an object, including the 

user and the application themselves. In general terms, context is typically the location, 
identity and state of people, groups, and computational and physical objects.  

Dix et al. [3] describe four generic forms of context that influence interaction with 
mobile  devices: 
infrastructure,  system,  domain  and  physical  context.  The 
infrastructure context addresses issues like the variability of services, user awareness 
of  available  services,  or  liveness  of  data.  The  system  context  is  related  to  the 
management  of  feedback  and  feedthrough,  support  to  distribution,  and  support  to 
emergent  behavior.  The  domain  context  considers  the  semantics  of  the  application 
domain, e.g. the definition of the relationships between the mobile devices and their 
users, and how these relationships can be used to determine the application behavior. 
Finally,  the  physical  context  is  related  with  the  possibility  that  mobile  devices  are 
likely  to  be  aware  of  their  physical  surroundings.  For  instance,  the  mobile  devices 
may know that they are proximate to other devices (if some network connectivity is 
available) or in a specific classroom (e.g. if the classroom has a router installed).  

Our approach explores two forms of context defined by Dix [3]: the domain and 
physical contexts. The domain context in our scenario is relatively complex because it 
combines  individual  and  group  work  in  a  very  fluid  way.  Students  serendipitously 
move  around  the  classroom  forming  temporary  groups  and  holding  ad-hoc 
interactions. The information about when groups were set up, who belonged to those 
groups  and  what  interactions  occurred  characterizes  the  domain  context  in  our 
scenario.  This  domain  context  should  be  maintained  by  technology  to  facilitate 
sensemaking, since it improves the retrospective understanding of the situation. The 
absence of domain context would represent an additional effort from the participants, 
who would have to search endlessly for hints about previous interactions with other 
students, the common topics that were found and decisions made.  

We thus believe that the combination of proximity and context is a key aspect for 
supporting  sensemaking  in  the  classroom  using  handheld  computing  devices.  We 
define two fundamental types of proximity contexts:  

 
•  Environmental  proximity  -  The  students  perform  their  activities  in  the 
classroom. Environmental proximity contributes to define them as a group and 
to  consolidate  their  expected  behavior  as  group.  Environmental  proximity  is 
thus  associated  to  the  production,  sharing  and  sensing  of  topics  in  the 
classroom.  

•  Close  proximity  -  The  students  engage  together  in  very  proximate  face-toface 
interactions, to avoid disturbing other students who may be engaged in 
their  own  interactions.  Close  proximity  is  associated  to  a  face-to-face 
collaborative  workspace,  where  two  or  more  students  share  information  and 
discuss about specific topics, their relevance and possible relationships.  

 

Let  us  now  discuss  these  matters  in  the  physical  context.  According  to  [16], 
proximity  is  relevant  when  users  are  close  to  each  other  and,  according  to  their 
location  handheld  computing  devices  may  support  a  differentiated  set  of  services. 
Physical proximity is based on the communications networks established by handheld 
computing  devices,  which  are  formed  dynamically  by  juxtaposition  of  wireless 
networks  created  on  demand.  Physical  proximity  defines  a  context  identifying  who 
was  physically  close  to  each  other  and  what  information  was  exchanged  between 

them. Based on these notions, we may complete our definitions of environmental and 
close proximity:  

space, 

 
•  Environmental  proximity  -  The  students  perform  their  activities  in  a 
confined  physical 
a 
communications network between all students’ handheld devices. This allows 
sensing topics in the classroom.  

establishing 

classroom, 

allowing 

•  Close proximity – When the students engage together in very proximate face-
to-face  interactions,  their  handheld  devices  will  establish  a  communications 
network.  This  network  is  distinct  from  the  one  associated  to  environmental 
proximity, and allows sharing a workspace between proximate students.  

the 

4    Proximity Model for Mobile Sensemaking 

We will first consider the implications of the physical context in our model, as it has 
direct  implications  on  the  automatic  management  of  contextual  information.  When 
two or more students are close to each other and wish to collaborate, the handheld 
computing devices will automatically activate a Close Proximity Context (CPC). The 
following rules apply to CPC management:  
 

•  The CPC is automatically activated when two or more handheld devices are 

connected together at the very proximate physical level (e.g. using IRDA).  

•  The  CPC  will  be  active  as  long  as  there  is  physical  connection  between  at 

least two devices.  

•  The students engaged in the same CPC automatically share their workspace 
and  the  information  belonging  to  the  shared  workspace  is  also  part  of  the 
CPC.  

•  The CPC evolves according to the participants and shared information. This 

allow for several students to get anytime in and out of the discussion. 

•  The CPC is automatically deactivated when physical connectivity is lost. 
•  The  deactivated  CPC  will  remain  in  the  handheld  devices  for  search  and 
navigational purposes. This functionality supports retrospective sensemaking.  

 

 
 
Fig. 1. The figure shows a possible configuration of the collaborative learning activity 

in a whole-classroom. The node labeled with T represents the teacher, the rest are 
students. All participants can move freely across the entire classroom. Hot-spots are 
known locations in the room where students can meet face-to-face in a previously 

agreed appointment. 

 
Focusing  on  the  whole  classroom,  we  also  define  an  Environmental  Proximity 
Context (EPC):  
 

•  The  EPC  is  automatically  activated  when  several  handheld  devices  are 

interconnected at the physical level (e.g. using WiFi).  

•  The students engaged in the EPC automatically receive indications about the 
topics  generated  by  other  students  that  may  be  of  interest  to  them.  This 
functionality uses similarity text matching.  

•  The students might interact with their devices to request becoming proximate 

to students for which some similarity has been indicated to them.  

 

The  handheld  are  responsible  for  getting  the  interested  parties  together.  The 
proximity  model  for  mobile  sensemaking  is  illustrated  in  Figure  1  and  further 
discussed below according to several situations.  
 

Environmental proximity situation. The students are identified with letters from 
A to Z, while T represents the teacher. They all share the same classroom, and their 
handheld  devices  share  the  same  (Wi-Fi)  network.  Therefore  they  are  potentially 
engaged in the same EPC. However, not all students are effectively engaged in the 
EPC at a specific time, because they may be engaged in a close proximity situation 
(these  are  the  cases  of,  e.g.,  RL,  GO  and  KD).  Within  the  EPC,  when  a  student 
produces a topic, it is distributed to the other students’ handheld devices. The devices 
compare  their  current  list  of  topics  with  the  distributed  topic  and,  if  there  is  some 
similarity matching, the student will be notified. Note that unrelated topics are filtered 
out, but they may become related later on, when students change their list of topics. If 

a student wishes to discuss with the student that produced the topic, she will invoke 
an engagement protocol, which is described next.  

EPC  is  useful  when  the  student  considers  that  the  face-to-face  interactions  she 
made so far are not enough and whishes to find out possible relations between her 
topics and those from other students present in the same classroom. Those students 
may also include those with whom she already had a CPC interaction. This may occur 
when after a while the students may incorporate more characterization topics to the 
initial list proposed by the teacher, which can be used again. The cases in which such 
a situation may occur are the following:  
 
•  Case EPS1. Using the WiFi network, a student X (see Fig. 1.) searches for the 
topics  other  students  have  defined  for  the  articles  they  have  read.  Once  the 
student has found the topics she is interested in decides it is not necessary to try a 
face-to-face meeting. Nevertheless, the following situations may occur: a) student 
V has more detailed information about topics X is interested which V is willing 
to share, b) X can send information to V about the topic both are interested in, c) 
X and V are only interested in exchanging information about the topic but not on 
discussing  about  why  they  use  them  to  characterize  the  article,  and  finally  d) 
there is no interest in sharing information.  

•  Case EPS2. A student Q finds using the WiFi network that Z is willing to share 
information with him. In this case, it is necessary to activate the engaging process 
(request, accept, software defines hot-spot) in order to enable Q and Z find each 
other in the Hot-Spot Y. After that a CP1 situation may arise. 

 
Engagement protocol. First, the protocol requires acceptance from the invoked party. 
In  case  of  acceptance,  the  parties  must  become  face-to-face.  Since  the  technology 
does  not  identify  the  students,  the  engagement  protocol  must  utilize  a  scheme  that 
does  not  require  identification.  The  adopted  solution  involves  Hot-Spots  (two  HotSpots 
are shown in Figure 1): the handhelds requests both parties to move towards a 
specific Hot-Spots (see Q and Z). Hot-Spots are a specific location in the environment 
(e.g.  corners  like  Hot-Spot  X  and  Y).  The  Hot-Spot  selection  may  depend  on  load 
balancing. When students come face-to-face, we have a close proximity situation.  
 
Close proximity situation. The students in this situation are face-to-face and share a 
CPC.  Their  handheld  devices  automatically  establish  a  temporal  ad-hoc  network 
connection  (IRDA).  Furthermore,  their  devices  will  provide  a  shared  workspace, 
where topics may be collaboratively edited and linked with other topics present in any 
one  of  the  participants’  handheld  devices.  This  allows  effectively  exchanging  and 
sharing  topics  and  links  across  multiple  devices  in  an  epidemic  way,  whenever 
students engage in new close proximity situations. We shall consider several possible 
scenarios within the close proximity situation:  
 
•  Case CPS1. Students R and L engage in a social face-to-face interaction in order 
to  share,  discuss,  understand  and  relate  the  topics  the  application  context  has 
found they share. After this interaction following situation may occur: a) that R 
and L could define adequate relationships between some topics specified by each 

one for the articles they have read, b) that they found no relations between the 
common topics. 

•  Case  CPS2.  Students  K  and  D  are  informed  by  their  handhelds  that  they  have 
topics  in  common  for  the  articles  they  have  read.  However,  they  decide  that  a 
social interaction is not necessary and that is enough that: a) K sends information 
to D, b) D sends information to K or c) both exchange their information. This 
information  is  sent  over  the  WiFi  network  and  may  correspond  to  the  detail 
generated by each student for a certain topic and Hill be available only if there is 
mutual consent.  

•  Case CPS3. Students C and J are informed by their handhelds that they have not 
common topics on their lists so there is no need to engage in a social interaction. 
However, it is still possible that: a) The information J has is somehow relevant to 
C, who is willing to share it, b) the information C has is relevant for J, who is 
willing to share it, c) the information J and C have is relevant for each other and 
both are willing to share it, and d) the information J and C have is not relevant for 
the other so there is no transfer of information between them.  

 
Disengagement  protocol.  The  disengagement  protocol  occurs  when  one  student 
considers  that  the  face-to-face  interaction  is  completed,  and  perhaps  other  students 
could be contacted. The disengagement occurs when the student moves away from the 
face-to-face interaction and the (IRDA) network connection is lost. Then, the student 
is  again  in  the  environmental  proximity  situation.  As  mentioned,  the  contextual 
information associated to the face-to-face interaction is preserved in the CPC.  

5   Implementation of the Mobile Sensemaking Application 

The  application  delineated  in  the  previous  sections  has  been  implemented  using  a 
rapid  development  platform  for  mobile  applications.  This  platform  offers  generic 
support  for  sketching,  pen-based  graphical  objects  manipulation,  automatic  ad-hoc 
network  establishment,  and  object  distribution  and  replication.  The  framework  has 
been used to develop several mobile applications, such as MCSketcher [19], Nomad 
[20] and Participatory Simulations [21].  

Also, as described in [21], the framework is able to recognize when to users engage 
in  a  face-to-face  encounter,  aligning  their  handheld  devices.  In  this  section  we 
describe how these features were used to build the mobile sensemaking application. 
The application offers several User Interfaces (UIs) allowing the teacher to assess the 
classroom activity, and giving the students the ability to write topics associated with 
their  assigned  papers,  link  these  topics  with  other  topics,  and  engaging  in 
collaborations with other students. Most interaction with these UIs is done with pen 
gestures, because it is the natural way for a user to control a handheld device. 

5.1 Papers distribution.  

The initial UI allows the teacher to assign papers to each student. On the left part of 
the screen, a list with student-icons represents all students attending to the activity. 
This  list  is  populated  automatically  by  recognizing  which  devices  are  running  the 
application within the wireless network range. On the right part, a list with documenticons 
represents all papers available for reading. In order to fill up this list, the teacher 
may click on the “add document” icon or the “add folder icon,” both located at the 
beginning of the file list. Clicking opens a file browser dialog or a directory browser 
dialog, loading a single selected file or all documents within selected directory into 
the list. Figure 2 shows this UI. 

 

 

 
Fig. 2. The teacher UI displays the list of students and available papers. On the left 
side the list of students is displayed (which were found by the participant discovery 
mechanism of the application based on multicasting messages). On the right side, the 
list of the papers (identified by the author’s name and publication year) is displayed. 
A  paper  is  assigned  to  a  certain  student  by  drawing  a  line  with  the  stylus  from  a 
paper’s bullet to a student’s bullet (or vice-versa).  

 
To assign a paper to a student, the teacher must drag its document-icon over the 
student-icon. Dragging a student over a document-icon would also assign a paper to a 
student. These actions may be repeated several times, assigning multiple papers to a 
student and multiple students to a paper. Every time this is done, both icons will show 
an updated count of links over their icons: the document-icon will show how many 
students have been assigned to work with that paper, and the student-icon will show 
how  many  papers  have  been  assigned  to  him/her  (figure  2).  The  teacher  can  also 
randomly assign one paper to each student by clicking on the dice-icon, at the upper 
bound of the UI. Clicking this icon repeatedly assigns multiple papers to each student, 
ensuring every paper has a similar number of students assigned. 

5.2 Paper reviewing and topics linking.  

Once a paper has been assigned, its icon appears in the students’ handheld UI. The 
student  may  double  click  any  document-icon  to  trigger  the  document  reader 
application and view the assigned paper. Document-icons appear in the lower part of 
the  UI,  so  the  rest  of  the  UI  is  empty  and  available  for  writing  or  drawing  topics 
related to the assigned papers. Once a topic is typed or sketched, the student may link 
it to one of the assigned papers by drawing a connecting line. When this happens, the 
system recognizes the gesture and establishes a link between the topic and the paper, 
represented by an arrow. A topic may be linked to several papers, and a paper may be 
linked  to  multiple  topics  (figure  3).  Repeating  the  “link  gesture”  unlinks  the  topic 
from  the  paper,  allowing  the  student  to  correct  links  created  accidentally.  Also, 
drawing a “cross gesture” can delete topics generated by the student. 

 

 

 

Fig. 3. Topics definition and linking UI. Using the stylus, students can link papers 
with related topics. Icons show the user current links’ configuration, which may be 
public, private or available only during face-to-face encounters. Topics created by the 

teacher are displayed with a different border. 

 
The teacher’s UI for topics definition is normally empty. However, it allows the 
teacher to type or draw generic topics that may help students recognize what kind of 
sentences are meant to be considered as topics. When the teacher creates such topics, 
they appear in the students’ devices along with his/her own written topics. The topics 
created  by  the  teacher  are  displayed  using  different  colors  and  borders  than  those 
created by the students. Figure 3 shows topics created by the teacher and the student. 

5.3 Sharing privileges and information sharing 

The  objective  or  this  application  is  to  support  a  highly  active  pedagogic  activity, 
allowing  the  students  to  build  common  knowledge  in  a  collaborative  way.  Hence, 
participants will eventually share their ideas with others. In this application, when a 
student  links  a  topic  to  certain  paper,  he  or  she  may  not  me  confident  about  their 
relation. Therefore, he or she may not be willing to share this idea he or she is not 
convinced with. 

The system allows students to choose in which way they want to share generated 
knowledge. In this case, each link may be configured as “public”, “face-to-face only” 
or “private”. When a connection between a paper and a topic is configured as public, 
all  students  in  the  activity  may  access  such  information  through  the  “Topic  search 
screen” or “face-to-face discussion”, both described next. If it is configured as face-
to-face only, such information will be revealed when two students engage into a face-
to-face  discussion,  allowing  the  unconfident  student  to  talk  about  the  idea  with 
another participant. When a topic link is configured as private it won’t be available to 
other students under any interaction mode until the student changes its configuration. 
Students  may  configure a  link  access by  double  clicking  it  on  the screen  using  the 
handheld  stylus.  When  this  occurs,  a  small  floating  palette  will  offer  the  three 
available states that the user can click. Each link between papers and topics displays a 
small  icon  representing  its  sharing  configuration,  as  shown  in  Figure  2.  Links  are 
created with “face-to-face only” privileges by default. 

5.4 Related topic search and environmental sharing  

As described in section 4, the activity encourages students to interact either in close 
proximity or environmentally. Students may access all knowledge generated by others 
configured as “public” by their authors. The “topics map” screen (figure 4) displays a 
diagram where every student is represented by his/her icon, including the current user 
centered  in  the  middle of  the  screen.  Each  student  icon  is  surrounded by  its  public 
topics, in a star diagram fashion.  
 

 
Fig. 4. The topics map UI. Other students’ similar topics are displayed in bold and 
darker color. Double clicking another student’s icon displays the interaction UI. 
 

 

Smart  text  matching  algorithms  simplify  the  search  process  by  organizing  the 
topics map according to the student’s interests. Topics similar to the current student’s 
ones  are  displayed  closer  to  the  center,  drawn  in  darker  color  if  their  similarity 
reaches  a  high  level.  The  participant  distribution  in  the  screen  depends  on  overall 
topics likeness: other students may be located near the center when they have a high 
number of coincidences between his/her topics and current student’s ones. 

Originally, the screen is zoomed in order to display the closest participants only. 
The user can drag the screen to navigate through the entire list of participant holding 
and  dragging  the  stylus.  Also,  the  user  may  zoom  in  or  out  clicking  the  magnifier 
icons  or  dragging  the  zoom  slider  at  the  right  of  the  screen.  Finally,  the  user  can 
double  click  another  student’s  icon  when  he/she  is  interested  in  this  particular 
student’s topics or wants to invite him/her to a face-to-face encounter. Based on these 
simple pen-based gestures each student may browse all public topics. 

5.5 Interacting with other students 

Students enter the interaction screen by double clicking another participant icon in the 
“topics  map”  screen  or  engaging  in  a  proximity  face-to-face  interaction.  The  first 
alternative  allows  a  user  to  interact  in  an  independent  and  one-way  only,  and  the 
second  one  establishes  a  two-way  interaction.  In  the  interaction  screen,  the  lower 
region  of  the  screen  belongs  to  the  current  student,  while  the  upper  region 

corresponds  to  the  other  user.  The  icons  of  papers  assigned  to  both  students  are 
displayed  beside  the  students’  icons.  These  files  icons  may  be  double  clicked 
triggering  a  secondary  reader  application,  as  mention  before.  Also,  such  icons  are 
surrounded with their topics and their links to the documents. In case the interaction is 
triggered by a face-to-face encounter, all links configured as public and as available in 
face-to-face interactions are shown. When the interaction is activated from the “topics 
map” screen and the other student is not in front of the current user, only public topic 
links will be displayed. 

The  bottom  and  the  top  of  the  interaction  screen  display  both  students’  topics 
collection. Topics from each student are horizontally sorted in order to be vertically 
aligned with topics from the other student based on text similitude. If their texts match 
exactly  or  above  a  certain  peak,  an  automatic  link  between  them  is  displayed.  A 
student  may  manually  link  his/her  topics  with  the  other  students’.  To  create  a  link 
between two topics he/she has to draw a line connecting their labels, in the same way 
as he/she linked the topics with the papers in the topics definition screen. Topic to 
topic  links  show  an  arrowhead  according  to  which  student  created  it.  In  case  both 
students agree on such relation, having the two of them drawn the same link, the line 
will have arrowheads in both ends and get highlighted. Automatically created links 
always display as a two-way link. Finally, students may link their papers directly to 
the  other  users’  topics.  Topic-paper’s  links  are  created  using  the  same  link  gesture 
available in the “topics definition” screen. By doing this, topic label will be relocated 
in the center of the screen, showing its links to papers of both students. 

5.6 Engagement invitation 

A student can invite another participant to a face-to-face interaction, in order to access 
to  his/her  “face-to-face  only”  topics  and  links.  Invitations  are  generated  in  the 
interaction  screen  drawing  a  line  between  both  students’  icons.  This  will  show  a 
dialog which allow the students to make a rendezvous appointment in a certain a hot 
spot. The invited student will get an alert in his/her device inviting him/her to meet in 
the  appointed  location.  Such  alert  has  a  “dismiss”  icon,  which  will  cancel  the 
invitation.  In  this  case,  the  first  user  will  be  notified  of  such  response.  In  case  the 
invited student accepts the proposal, both participants will meet in the assigned place 
and  start  a  face-to-face  interaction,  as  described  before,  entering  the  interaction 
screen. 

6   Discussion & Conclusions  

The use of handheld computers to support learning has attracted the attention of many 
authors. Among the earliest works we can cite is described in (Jippling, 2001). More 
works  are  described  in  [18]  and  [13].  In  all  cases,  the  reason  for  having  mobile 
devices is to support the social face-to-face interaction and to achieve high levels of 
activity in the classroom, avoiding passivity of the students.  

The importance and potential of context in general and awareness in particular was 
discovered very early in the short history of the development of collaborative mobile 

applications.  In  [10]  the  author  presents  a  works  showing  how  context  information 
can be used in different application areas, e.g. tourist guidance, exhibition guidance, 
e-mail,  shopping,  mobile  network  administration,  medical  care  and  office  visitor 
information. In these studies, the location of the user is the main attribute used in the 
context-adaptation.  In  [1]  the  authors  show  the  value  of  context  information  and 
social  awareness  for  developing  an  application  to  support  collaboration  between 
experienced and novel doctors in a hospital. In [15] a mobile application which offers 
various  services  supporting  office-type  work  which  uses  context-awareness,  mainly 
information on position of the user and available services nearby. It seems there are 
no  major  contributions  in  the  field  context-aware  applications  for  supporting 
collaborative learning except for those dealing with participatory simulations, like the 
one described in [11].  

In this work, we apply the theoretical framework proposed by Dix [3] to develop a 
model and a whole-classroom collaborative learning application. We think this model 
an application can also be applied to other scenarios beside the described in section 2 
where the common element is that the information about proximity between users can 
be  used  for  having  a  context-aware  application.  Some  of  these  scenarios  may  be 
conference  participants  using  handhelds  during  the  conference  to  ingress  a  list  of 
topics  reflecting  their  research  interests,  a  small  group  of  employees  performing 
teamwork in an ad-hoc setting (e.g. emergency management), but they do not know in 
detail the responsibilities and activities of their colleagues, or any kind of activities 
with people doing field-work having to exchange information among each other in a 
reduced surrounding.  

Acknowledgment 

This paper was funded by Fondecyt 1050601. 

References 

 1.Bardram,  J.  and  Hansen,  T.  (2004).  The  AWARE  Architecture:  Supporting  Context 
Mediated  Social  Awareness  in  Mobile  Cooperation.  Proceedings  of  the  CSCW’04, 
November 6–10, 2004, Chicago, Illinois, USA. 

 2. Dey, A. (2001). Understanding and Using Context. Personal and Ubiquitous Computing, 5, 

 3.  Dix,  A.,  Rodden,  T.,  Davies,  N.,  Trevor,  J.,  Friday,  A.  and  Palfreyman,  K.  (2000). 
Exploiting  Space  and  Location  as  a  Design  Framework  for  Interactive  Mobile  Systems 
ACM Transactions on CHI, 7. 

 4. Ernest, P. (1995) In Constructivism in education (Ed, Gale, L.) Hillsdale, NJ: Erlbaum, pp. 

4-7. 

459-486. 

 5. Gage, N. and Berliner, D. (1996) Educational Psychology., Houghton, Mifflin, Boston, MA. 
 6.  Hasan,  H.  and  Gould,  E.  (2001).  Support  for  the  Sense-Making  Activity  of  Managers. 

Decision Support Systems, 31, 71-86. 

 7. Honebein, P. (1996). Seven goals for the design of Constructivist learning environments. In 
Constructivist learning environments New Jersey: Educational Technology Publications, pp. 
17-24. 

 8. Jippling, M., Dieter, S., Krikker, J., Sandro, S. (2001). Using Handheld Computers in the 
Classroom:  Laboratories  and  Collaboration  with  Handheld  Machines.  Proceedings  of  the 
2001 SIGCSE, SIGCSE Technical Bulletin, Vol. 33, No. 1, pp. 169-173. 

 9. Kafai, Y. and Resnick, M. (1996). Constructionism in Practice: Designing, Thinking, and 
Learning in a Digital World. In Constructivist Learning Environments. Lawrence Erlbaum 
Associates, Mahwah, NJ., pp. 17-24. 

10.Kaasinen, E. (2003) User Needs for Location-Aware Mobile Devices. Personal Ubiquitous 

Computing 7: 70–79. 

11.Klopfer,  E.,  Yoon,  S,    and  Perry,  J.  (2005).  Using  Palm    Technology  in  Participatory 
Simulations  of  Complex  Systems:  A  New  Take  on    Ubiquitous  and  Accessible  Mobile 
Computing Journal of Science Education and Technology, Vol. 14, No. 3, September 2005  
12.Larsson,  A.  (2003).  Making  sense  of  collaboration:  the  challenge  of  thinking  together  in 
global design teams. Proceedings of ACM SIGGROUP Sanibel Island, Florida, pp. 153-160. 
13.Liu, T.C. Wang, H.Y., Liang, J.K., Chan, T.W., Ko, H.W. & Yang, J.C. (2003) : Wireless 
and  mobile  technologies  to  enhance  teaching  and  learning  Journal  of  Computer  Assisted 
Learning  19, 371-382 

14. Sass, E. J. (1989). Motivation in the College Classroom: What Students Tell Us. Teaching 

of Psychology, 16, 86-88. 

15.Tähti, M., Rautio, V., Arhippainen, L. (2004). Utilizing Context Awareness in Office Type 
Working Life. Proceedings of the MUM 2004 October 2729, 2004 College Park, Maryland 
USA. 

16. Thilliez, M., Delot, T., Lecomte, S. and Bennani, N. (2003). Hybrid Peer-To-Peer Model in 
Proximity Applications. In Proceedings of the 17th International Conference on Advanced 
Information Networking and Applications. 

17.Weick, K. (1993). The collapse of sense-making in organizations. The Mann-Gulch disaster 

Administrative Science Quarterly, 38, 628-652. 

18.Zurita, G, Nussbaum, M. (2004). A constructivist mobile learning environment supported 

by a wireless handheld network. Journal of Computer Assisted Learning 20, pp 235–243. 

19.Zurita, G, Baloian, N., Baytelman, F. (2006): A Face-to-Face System for Supporting Mobile 
Collaborative  Design  using  Sketches  and  Pen-based  Gestures.  In  Proceedings  of  the  10th 
International Conference on Computer supported Collaborative Work in Design, May 2006, 
Nanjing, China. IEEE press, pp. 250-255.  

20.Zurita. G.,  Baloian, N., Baytelman, F. (2005). Handheld-Based Electronic Meeting Support. 
Lecture Notes in Computer Science, Vol. 3706/2005 pp. 341-350. Proceedings of the 11th 
International Workshop, CRIWG 2005, Porto de Galinhas, Brazil, September 25-29, 2005. 

21.Zurita,  G,  Baloian,  N.,  Baytelman,  F.,  Farías,  A.  (2007).  A  Framework  for  motivating 
Participatory Simulations. To appear in the Proceedings of the 11th International Conference 
on  Computer  supported  Collaborative  Work  in  Design,  May  2007,  Melbourne,  Australia. 
IEEE press. 

 
 
 
 

