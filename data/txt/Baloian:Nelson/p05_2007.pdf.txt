Applying Sensemaking in a Mobile Learning scenario 

Gustavo Zurita1, Pedro Antunes2, Nelson Baloian3, Felipe Baytelman2 

Universidad de Chile, Santiago, Chile, 1Information Systems Department - Business 
School, 3Computer Science Department – Engineering School. 2University of Lisboa, 

gzurita@fen.uchile.cl;paa di.fc.ul.pt; nbaloian@dcc.uchile.cl; fbaytelm@dcc.uchile.cl  

Department of Informatics, Faculty of Sciencies. 

Abstract. In this work, a new type of collaborative learning activity is proposed in order to 
enable students to explore and understand information in highly mobile situations. We call 
this “mobile sensemaking” and is based on people engaged in multiple parallel, rapid and 
ad-hoc interactions, rather than structured decision processes. This activity takes place in a 
traditional classroom context, thus proposing a new way to design more participative and 
active  “lectures”.  Mobile  sensemaking  proposes  a  proximity  model  and  uses  mobile 
computing  devices  in  order  to  carry  on  collaborative  activities  according  to  the  domain 
context and physical proximity.  

1   Introduction 

With the help of appropriate mobile technology and applications, teaching and learning activities are 
expected to achieve higher levels of engagement, better adaptation to individual and group learning 
needs, higher learning rates, and better quality of time utilization and a better flexibility of teaching 
for the instructors. Over the last recent years many systems based on mobile computing technology 
have  been  developed  for supporting  collaborative  learning  of students  in  the  classroom.  Despite  of 
this  fact,  the  basic  learning  process  has  remained  largely  unchanged  throughout  this  time.  Many 
educators agree that the main drawback of the traditional classroom lecture – the one placing teachers 
as the major  focus of attention  and  most critical resources – is the reduced level  of interaction  and 
engagement  between  teachers  and  students,  and  among  the  students  themselves  thus  negatively 
affecting  the  motivation.  The  limited  interaction  possibilities  in  traditional  classroom  lectures 
originates a set of problems regarding students’ attention and motivation, reduced teachers’ awareness 
of the actual learning accomplishments, and lack of flexibility for handling the necessary adjustments 
regarding the teacher’s and students’ goals. 

Our endeavor is to improve interactivity in the classroom while still keeping the learning process 
efficient in  terms of resources and time.  We have strong reasons to believe that mobile technology 
provides a technological platform capable to support the levels of interactivity required by the active 
learning  process,  and  we  are  building  software  mechanisms  to  conserve  the  teachers’  effort  in  this 
process.  In  this  paper  we  show  how  wirelessly  interconnected  handheld  computing  devices  may 
improve interactivity in the classroom involving university students in more sophisticated interactions 
than  those  expected  in  classic  lectures,  which  in  turn  will  foster  motivating  collaborative  learning, 
[10]. The focus of this technology is to improve information sensemaking in the classroom, i.e. the 
students’ ability to collectively explore and understand information [12] while shifting the teacher’s 
role to the backstage, performing supporting  but not coordinating the assigned tasks.  

2   Learning environment 

Our learning environment considers a common classroom situation where a teacher assigns the task 
of analyzing a large collection of documents to a large group of students. These documents are related 

in  some  way,  but  the  relationships  must  be  discovered  by  the  students  through  exploration  and 
collaboration. When the task is successfully accomplished, the students should have built a coherent 
list of topics and identified their most significant relationships, thus defining a strategic view over the 
proposed research topic, without having every student to read all the documents. 

The task enfolds as follows. Each student receives one or two documents from the teacher and is 
asked  to  find  out  the  main  topics  addressed  by  those  papers.  This  individual  task  should  then 
contribute  to  the  collaborative  effort.  Students  are  expected  to  share  their  findings  with  others, 
identifying  common  topics,  establishing  relationships,  and  avoiding  misjudgments.  This  should 
follow in a paced and informal way, avoiding loosing time waiting for individual students to deliver 
their contributions, and in particular avoiding loosing too much time discussing their divergences as a 
group.  Instead,  students  are  encouraged  to  engage  in  parallel  negotiations  with  multiple  parties  to 
solve  their  differences  and  reach  consensus.  Overall,  the  students  assume  the  central  role  in  the 
decision process, while the teacher is sent to backstage, coaching and encouraging students, assessing 
their accomplishments, although not coordinating the assigned task. The fundamental aim of this task 
is to engage students in the sensemaking process. The sensemaking process was proposed by Weick 
[13] as a primary mechanism for organizations to explore and understand information. Sensemaking 
is  an  ongoing  process  aiming  to  create  order  and  make  retrospective  sense  about  some  event  or 
collection  of  events.  It  has  also  been  associated  to  preliminary  decision-making  activities  like 
“understanding  the  situation”  or  “getting  the  picture”  [4].  Sensemaking  is  also  inherently 
collaborative [8], meaning that the several mechanisms defined by sensemaking (ecological change, 
enactment,  selection,  retention)  rely  on  the  capabilities  of  a  community  of  people  to  identify  cues, 
update and share information, identify possible actions and provide feedback on those actions. 

3   Context and Proximity in the learning environment 

According  to  Dey  [2],  context  is  defined  as  any  information  that  can  be  used  to  characterize  the 
situation  of  an  entity.  An  entity  is  anything  relevant  to  the  interaction  between  a  user  and  an 
application, such as a person, a place or an object, including the user and the application themselves. 
In  general  terms,  context  is  typically  the  location,  identity  and  state  of  people,  groups,  and 
computational and physical objects.  

Dix et al. [3] describe four generic forms of context that influence interaction with mobile devices: 
infrastructure,  system,  domain  and  physical  context.  Our  approach  explores  one  form  of  context 
defined  by  Dix  [3]:  the  domain  context.  The  domain  context  in  our  scenario  is  relatively  complex 
because it combines individual and group work in a very fluid way. Students serendipitously move 
around  the  classroom  forming  temporary  groups  and  holding  ad-hoc  interactions.  The  information 
about  when  groups  were  set  up,  who  belonged  to  those  groups  and  what  interactions  occurred 
characterizes  the  domain  context  in  our  scenario.  This  domain  context  should  be  maintained  by 
technology  to  facilitate  sensemaking,  since  it  improves  the  retrospective  understanding  of  the 
situation. The absence of domain context would represent an additional effort from the participants, 
who  would  have  to  search  endlessly  for  hints  about  previous  interactions  with  other  students,  the 
common  topics  that  were  found  and  decisions  made.  We  thus  believe  that  the  combination  of 
proximity and  context is a  key  aspect for supporting sensemaking in the classroom using  handheld 
computing devices. We define two fundamental types of proximity contexts:  
•  Environmental  proximity  -  The  students  perform  their  activities  in  the  classroom. 
Environmental proximity contributes to define them as a group and to consolidate their expected 
behavior  as  group.  Environmental  proximity  is  thus  associated  to  the  production,  sharing  and 
sensing of topics in the classroom.  

•  Close proximity - The students engage together in very proximate face-to-face interactions, to 
avoid disturbing other students who may be engaged in their own interactions. Close proximity 

is  associated  to  a  face-to-face  collaborative  workspace,  where  two  or  more  students  share 
information and discuss about specific topics, their relevance and possible relationships.  

4    Proximity for Mobile Sensemaking 

When two or more students are close to each other and wish to collaborate, the handheld computing 
devices  will  automatically  activate a  Close Proximity  Context  (CPC). The  following  rules apply  to 
CPC  management:  a)  the  CPC  is  automatically  activated  when  two  or  more  handheld  devices  are 
connected together at the very proximate physical level (e.g. using IRDA); b) the students engaged in 
the  same  CPC  automatically  share  their  workspace  and  the  information  belonging  to  the  shared 
workspace  is  also  part  of  the  CPC;  and  c)  the  CPC  is  automatically  deactivated  when  physical 
connectivity  is lost.  Focusing  on the  whole classroom,  we  also  define  an  Environmental Proximity 
Context  (EPC):  a)  the  EPC  is  automatically  activated  when  several  handheld  devices  are 
interconnected at the  physical  level (e.g.  using  WiFi); and  b)  the  students  might  interact  with  their 
devices to request  becoming proximate to students  for which some similarity has  been indicated to 
them.  

Further discussed below according to several situations.  
Environmental proximity situation. Teacher and students  share the same classroom, and their 
handheld devices share the same (Wi-Fi) network. Therefore they are potentially engaged in the same 
EPC. However, not all students are effectively engaged in the EPC at a specific time, because they 
may be engaged in a close proximity situation . Within the EPC, when a student produces a topic, it is 
distributed to the other students’ handheld devices. The  devices  compare their  current list of topics 
with the distributed topic and, if there is some similarity matching, the student will be notified. Note 
that unrelated topics are filtered out, but they may become related later on, when students change their 
list of topics. If a student wishes to discuss with the student that produced the topic, she will invoke an 
engagement protocol, which is described next. EPC is useful when the student considers that the face-
to-face  interactions  he/she  made  so  far  are  not  enough  and  whishes  to  find  out  possible  relations 
between her topics and those from other students present in the same classroom. Those students may 
also include those with whom he/she already had a CPC interaction.  
     Engagement protocol. First, the protocol requires acceptance from the invoked party. In case of 
acceptance, the parties must become face-to-face. Since the technology does not identify the students, 
the  engagement  protocol  must  utilize  a  scheme  that  does  not  require  identification.  The  adopted 
solution  involves  Hot-Spots:  the  handhelds  requests  both  parties  to  move  towards  a  specific  HotSpots 
. Hot-Spots are a specific location in the environment . The Hot-Spot selection may depend on 
load balancing. When students come face-to-face, we have a close proximity situation.  
      Close proximity situation. The students in this situation are face-to-face and share a CPC. Their 
handheld  devices  automatically  establish  a  temporal  ad-hoc  network  connection  (IRDA). 
Furthermore,  their  devices  will  provide  a  shared  workspace,  where  topics  may  be  collaboratively 
edited  and  linked  with  other  topics  present  in  any  one  of  the  participants’  handheld  devices.  This 
allows  effectively  exchanging  and  sharing  topics  and  links  across  multiple  devices  in  an  epidemic 
way, whenever students engage in new close proximity situations.  
      Disengagement  protocol.  The  disengagement  protocol  occurs  when  one  student  considers  that 
the  face-to-face  interaction  is  completed,  and  perhaps  other  students  could  be  contacted.  The 
disengagement  occurs  when  the  student  moves  away  from  the  face-to-face  interaction  and  the 
(IRDA)  network  connection  is  lost.  Then,  the  student  is  again  in  the  environmental  proximity 
situation.  As  mentioned,  the  contextual  information  associated  to  the  face-to-face  interaction  is 
preserved in the CPC.  

5   Description of the Mobile Sensemaking Application 

The application delineated in the previous sections has been implemented using a rapid development 
platform  for  mobile  applications.  This  platform  offers  generic  support  for  sketching,  pen-based 
graphical objects manipulation, automatic ad-hoc network establishment, and object distribution and 
replication,  MCSketcher  [15],  Participatory  Simulations  [16].  Also,  as  described  in  [16],  the 
framework  is  able  to  recognize  when  to  users  engage  in  a  face-to-face  encounter,  aligning  their 
handheld  devices.  In  this  section  we  describe  how  these  features  were  used  to  build  the  mobile 
sensemaking application. Most interaction with these UIs is done with pen gestures, because it is the 
natural way for a user to control a handheld device. 

Paper Distribution. The initial UI allows the teacher to assign papers to each student. On the left 
part of the handheld screen, a list with student-icons represents all students attending to the activity. 
This list is populated automatically by recognizing which devices are running the application within 
the  wireless  network  range.  On  the  right  part,  a  list  with  document-icons  represents  all  documents 
available for reading. In order to fill up this list, the teacher may click on the “add document” icon or 
the  “add  folder  icon,”  both  located  at  the  beginning  of  the  file  list.  Clicking  opens  a  file  browser 
dialog  or a  directory  browser  dialog,  loading  a single selected  file or all  documents  within selected 
directory into the list. To assign a paper to a student, the teacher must drag its document-icon over the 
student-icon. These actions may be repeated several times, assigning multiple papers to a student and 
multiple students to a paper.  

Paper  reviewing  and  topics  linking.  Once  a  paper  has  been  assigned,  its  icon  appears  in  the 
students’  handheld  UI.  The  student  may  double  click  any  document-icon  to  trigger  the  document 
reader application and view the assigned paper. Document-icons appear in the lower part of the UI, so 
the rest of the UI is empty and available for writing or drawing topics related to the assigned papers. 
Once a topic is typed or sketched, the student may link it to one of the assigned papers by drawing a 
connecting line. When this happens, the system recognizes the gesture and establishes a link between 
the topic and the paper, represented by an arrow. A topic may be linked to several documents, and a 
document may be linked to multiple topics. Repeating the “link gesture” unlinks the topic from the 
document, allowing the student to correct links created accidentally. Also, drawing a “cross gesture” 
can delete topics generated by the student. 

Sharing  privileges  and  information  sharing.  The  system  allows  students  to  choose  in  which 
way they want to share generated knowledge. In this case, each link may be configured as “public”, 
“face-to-face only” or “private”. When a connection between a document and a topic is configured as 
public, all students in the activity may access such information through the “Topic search screen” or 
“face-to-face  discussion”,  both  described  next.  If  it  is  configured  as  face-to-face  only,  such 
information will be revealed when two students engage into a face-to-face discussion, allowing  the 
unconfident student to talk about the idea with another participant. When a topic link is configured as 
private it won’t be available to other students under any interaction mode until the student changes its 
configuration.  Students  may  configure  a  link  access  by  double  clicking  it  on  the  screen  using  the 
handheld stylus. When this occurs, a small floating palette will offer the three available states that the 
user can click. Each link between documents and topics displays a small icon representing its sharing 
configuration. Links are created with “face-to-face only” privileges by default. 

Related  topic  search  and  environmental  sharing.  As  described  in  section  4,  the  activity 
encourages students to interact either in close proximity or environmentally. Students may access all 
knowledge  generated  by  others  configured  as  “public”  by  their  authors.  The  “topics  map”  screen 
displays  a  diagram  where  every  student  is  represented  by  his/her  icon,  including  the  current  user 
centered in the middle of the screen.  Each student icon is surrounded by its public  topics, in a  star 
diagram fashion. Smart text matching algorithms simplify the search process by organizing the topics 
map  according  to  the  student’s  interests.  Topics  similar  to  the  current  student’s  ones  are  displayed 
closer  to  the  center,  drawn  in  darker  color  if  their  similarity  reaches  a  high  level.  The  participant 
distribution in the screen depends on overall topics likeness: other students may be located near the 

center  when  they  have  a  high  number  of  coincidences  between  his/her topics  and  current student’s 
ones.Originally, the screen is zoomed in order to display the closest participants only. The user can 
drag the screen to navigate through the entire list of participant holding and dragging the stylus. Also, 
the user may zoom in or out clicking the magnifier icons or dragging the zoom slider at the right of 
the screen. Finally, the user can double click another student’s icon when he/she is interested in this 
particular  student’s  topics  or  wants  to  invite  him/her  to  a  face-to-face  encounter.  Based  on  these 
simple pen-based gestures each student may browse all public topics. 

Interacting with other students. Students enter the interaction screen by double clicking another 
participant icon in the “topics map” screen or engaging in a proximity face-to-face interaction. The 
first  alternative  allows  a  user  to  interact  in  an  independent  and  one-way  only,  and  the  second  one 
establishes a two-way interaction. In the interaction screen, the lower region of the screen belongs to 
the  current  student,  while  the  upper  region  corresponds  to  the  other  user.  The  icons  of  documents 
assigned to both students are displayed beside the students’ icons. These files icons may be double 
clicked triggering a secondary reader application, as mention before. Also, such icons are surrounded 
with their topics and their links to the documents. In case the interaction is triggered by a face-to-face 
encounter, all links configured as public and as available in face-to-face interactions are shown. When 
the interaction is activated from the “topics map” screen and the other student is not in front of the 
current  user,  only  public  topic  links  will  be  displayed.  A  student  may  manually  link  his/her  topics 
with the other students’. To create a link between two topics he/she has to draw a line connecting their 
labels, in the same way as he/she linked the topics with the documents in the topics definition screen. 
Topic to topic links show an arrowhead according to which student created it. In case both students 
agree on such relation, having the two of them drawn the same link, the line will have arrowheads in 
both ends and get highlighted. Automatically created links always display as a two-way link. Finally, 
students  may  link  their  documents  directly  to  the  other  users’  topics.  Topic-document’s  links  are 
created  using the same link  gesture  available in the “topics  definition” screen.  By  doing this, topic 
label will be relocated in the center of the screen, showing its links to documents of both students. 
      Engagement  invitation.  A  student  can  invite  another  participant  to  take  part  in  a  face-to-face 
interaction, in order to access to his/her “face-to-face only” topics and links. Invitations are generated 
in the interaction screen drawing a line between both students’ icons. This will show a dialog which 
allow the students to make a rendezvous appointment in a certain a hot spot. The invited student will 
get  an  alert  in  his/her  device  inviting  him/her  to  meet  in  the  appointed  location.  Such  alert  has  a 
“dismiss”  icon,  which  will cancel the invitation. In  this  case, the  first user  will  be notified  of such 
response. In case the invited student accepts the proposal, both participants will meet in the assigned 
place and start a face-to-face interaction, as described before, entering the interaction screen. 

6   Discussion & Conclusions  

The  use  of  handheld  computers  to  support  learning  has  attracted  the  attention  of  many  authors. 
Among the earliest works we can cite is described in [5]. More works are described in [14] and [9]. In 
all cases, the reason for having mobile devices is to support the social face-to-face interaction and to 
achieve high levels of activity in the classroom,  avoiding passivity  of the students. The importance 
and potential of context in general and awareness in particular was discovered very early in the short 
history  of  the  development  of collaborative  mobile applications.  In [6] the author presents  a  works 
showing  how  context  information  can  be  used  in  different  application  areas,  e.g.  tourist  guidance, 
exhibition guidance, e-mail, shopping, mobile network administration, medical care and office visitor 
information.  In  these  studies,  the  location  of  the  user  is  the  main  attribute  used  in  the  contextadaptation.
  In  [1]  the  authors  show  the  value  of  context  information  and  social  awareness  for 
developing  an  application  to  support  collaboration  between  experienced  and  novel  doctors  in  a 
hospital. In [11] a mobile application which offers various services supporting office-type work which 
uses context-awareness, mainly information on position of the user and available services nearby. It 
seems  there  are  no  major  contributions  in  the  field  context-aware  applications  for  supporting 

collaborative learning except for those dealing with participatory simulations, like the one described 
in [7]. In this work, we apply the theoretical framework proposed by Dix [3] to develop a model and a 
whole-classroom  collaborative learning application. We think this model an application can also be 
applied  to  other  scenarios  beside  the  described  in  section  2  where  the  common  element  is  that  the 
information about proximity between users can be used for having a context-aware application. Some 
of these scenarios may be conference participants using handhelds during the conference to ingress a 
list of topics reflecting their research interests, a small group of employees performing teamwork in 
an  ad-hoc setting (e.g.  emergency management),  but they do not  know  in detail the responsibilities 
and  activities  of  their  colleagues,  or  any  kind  of  activities  with  people  doing  field-work  having  to 
exchange information among each other in a reduced surrounding.  

Acknowledgment: This paper was funded by Fondecyt 1050601. 

References 

 1.  Bardram,  J.  and  Hansen,  T.  (2004).  The  AWARE  Architecture:  Supporting  Context  Mediated  Social 

Awareness in Mobile Cooperation. Proceedings of the CSCW’04, Chicago, Illinois, USA. 

 2. Dey, A. (2001). Understanding and Using Context. Personal and Ubiquitous Computing, 5, 4-7. 
 3.  Dix,  A.,  Rodden,  T.,  Davies,  N.,  Trevor,  J.,  Friday,  A.  and  Palfreyman,  K.  (2000).  Exploiting  Space  and 

Location as a Design Framework for Interactive Mobile Systems ACM Transactions on CHI, 7. 

4.    Hasan,  H.  and  Gould,  E.  (2001).  Support  for  the  Sense-Making  Activity  of  Managers.  Decision  Support 

Systems, 31, 71-86. 

 5.  Jippling,  M.,  Dieter,  S.,  Krikker,  J.,  Sandro,  S.  (2001).  Using  Handheld  Computers  in  the  Classroom: 
Laboratories  and  Collaboration  with  Handheld  Machines.  Proceedings  of  the  2001  SIGCSE,  SIGCSE 
Technical Bulletin, Vol. 33, No. 1, pp. 169-173. 

6. Kaasinen, E. (2003). User Needs for Location-Aware Mobile Devices. Personal Ubiquitous Computing 7: 70–

79. 

7. Klopfer, E., Yoon, S,  and Perry, J. (2005). Using Palm Technology in Participatory Simulations of Complex 
Systems:  A New Take  on  Ubiquitous and Accessible Mobile Computing Journal of Science Education and 
Technology, Vol. 14, No. 3  

8. Larsson, A. (2003). Making sense of collaboration: the challenge of thinking together in global design teams. 

Proceedings of ACM SIGGROUP, Sanibel Island, Florida, 153-160. 

9.  Liu,  T.C.  Wang,  H.Y.,  Liang,  J.K.,  Chan,  T.W.,  Ko,  H.W.  &  Yang,  J.C.  (2003)  :  Wireless  and  mobile 

technologies to enhance teaching and learning Journal of Computer Assisted Learning  19, 371-382 

10. Sass, E. J. (1989). Motivation in the College Classroom: What Students Tell Us. Teaching of Psychology, 16, 

86-88. 

11.Tähti,  M.,  Rautio,  V.,  Arhippainen,  L.  (2004).  Utilizing  Context  Awareness  in  Office  Type  Working  Life. 

Proceedings of the MUM 2004 October 2729, 2004 College Park, Maryland USA. 

12.  Thilliez,  M.,  Delot,  T.,  Lecomte,  S.  and  Bennani,  N.  (2003).  Hybrid  Peer-To-Peer  Model  in  Proximity 
Applications. In Proceedings of the 17th International Conference on Advanced Information Networking and 
Applications. 

13.Weick,  K.  (1993).  The  collapse  of  sense-making  in  organizations.  The  Mann-Gulch  disaster  Administrative 

Science Quarterly, 38, 628-652. 

14.Zurita,  G,  Nussbaum,  M.  (2004).  A  constructivist  mobile  learning  environment  supported  by  a  wireless 

handheld network. Journal of Computer Assisted Learning 20, pp 235–243. 

15.Zurita,  G,  Baloian,  N.,  Baytelman,  F.  (2006):  A  Face-to-Face  System  for  Supporting  Mobile  Collaborative 
Design  using  Sketches  and  Pen-based  Gestures.  In  Proceedings  of  the  10th  International  Conference  on 
CSCWD, May 2006, Nanjing, China. IEEE press, 250-255.  

16.Zurita,  G,  Baloian,  N.,  Baytelman,  F.,  Farías,  A.  (2007).  A  Framework  for  motivating  Participatory 

Simulations. Proceedings of the 11th International CSCWD, Melbourne, Australia. IEEE press. 

 

