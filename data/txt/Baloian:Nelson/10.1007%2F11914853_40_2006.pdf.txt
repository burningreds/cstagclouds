A Gestures and Freehand Writing Interaction Based 
Electronic Meeting Support System with Handhelds 

Gustavo Zurita1, Nelson Baloian2, Felipe Baytelman1, and Mario Morales1 

1 Department of Information System and Management of the Economy and Businesses 

School, University of Chile, Diagonal Paraguay 257, Santiago, Chile 

gnzurita@usistemas.cl, felipe@baytex.net, mmorales@usistemas.cl 

2 Department of Computer Science of the Engineering School  of the University of Chile, 

Blanco Encalada 2120, Santiago, Chile 

nbaloian@dcc.uchile.cl 

Abstract. In this  work,  we present an Electronic Meeting Support system  for 
handhelds. The design principles applied for developing the system are aimed 
to help reduce the problems associated with having a small size screen to interact 
 with.  The  human-handheld  interaction  is  based  only  in  gestures  and  freehand 
writing, avoiding the need of widgets and virtual keyboards. The content 
of the generated documents are organized as concept maps, which gives more 
flexibility to reorganize and merge the contributions of the meeting attendees.  
Our system is based on handhelds interconnected with an ad-hoc wireless network.
 The system architecture is a peer-to-peer one, avoiding the need of central 
repositories thus allowing meetings to take place anywhere. 

1   Introduction 

In  any  organization,  small  teams  and  work  groups  undertake  a  broad  spectrum  of 
face-to-face  meeting processes, including deliberation, negotiation, consensus building,
 decision making, idea generation, problem solving, planning, [1], [9], [25], which 
are becoming increasingly important in  most business initiatives, [2]. An Electronic 
Meeting  Systems  (EMS)  is  an  interactive  computer-based  system  for  supporting 
meeting  processes.  [1].  EMS  goal  is  to  help  group  members  to  overcome  the  wellknown 
problems that arise in a meeting, thus improving its productivity, efficiency, 
and effectiveness. Since a group meeting may involve different activities, the system 
should be flexible enough to support most of them. 
    Technology  for  supporting  face-to-face  meetings  has  been  around  for  nearly  two 
decades using mainly desktop computers, networks and software implementing sophisticated 
awareness mechanisms. However, adoption statistics measuring their “accessibility 
and availability” to organizational end-users have been somewhat disappointing. 
The findings of [25] indicate that EMS systems have been adopted in organizations in 
the USA; Australia and New Zealand only to a limited extent. Several possible barriers 
to  EMS  adoption  have been  suggested  and  a  recent  survey  of  EMS  researchers  also 
identified several potential obstacles to their adoption, [25]. Some organizational issues 

R. Meersman, Z. Tari et al. (Eds.): OTM 2006, LNCS 4275, pp. 679 – 696, 2006. 
© Springer-Verlag Berlin Heidelberg 2006 

680 

G. Zurita et al. 

such as compatibility of EMS with user cognitive styles, lack of organizational incentives,
 resistance  to change  combined  with  difficulty  in  measuring  and  demonstrating 
EMS benefits are the most commonly perceived barriers. These findings also are supported 
by [19], who stated “for Groups Support software to be an organizational success,
 one must plan for and overcome extreme resistance to change”.   

It  has  been  also  mentioned  that  another  fundamental  reason  for  the  low  level  of 
adoption and use of EMS is that they still lack of fundamental functionalities supporting 
the creation of an agenda or an agenda-setting process, implementation of common 
workspace for participants, support for drawing up of minutes, procedures for supporting 
follow-up on commitments, and voting mechanisms [25]. Although some successful 
systems have been developed and tested based on desktop computers ([10], [11]) it 
has  been  demonstrated  in  [3]  and [28]  that  the EMS  interfaces on PC  and  notebook 
capture the attention and cognitive concentration of participants to such an extent that 
face-to-face  interaction is reduced.  According  to [28],  handhelds are a  more  suitable 
support tool for face-to-face meetings. In fact, handheld portable computer devices are 
non-obstructive and create a feeling of belonging because they are used in various activities 
and may be used in any place and used at any time [16], [17] and [20]. 

In this paper we propose a face-to-face EMS system based exclusively on the use 
of handhelds wirelessly connected through a peer-to-peer ad-hoc network. The aim of 
the system is to overcome in a simple way the cognitive styles, adoption, resistance to 
change, and some meeting problems (lack of common work space for members, difficulties 
while drawing up the minutes, lack of follow up commitments, and absence of 
voting mechanism among others). The system supports various processes of a meeting 
life-cycle, both individual and collaborative. The user interface is based on freehand 
input allowing: a) freehand writing and sketching over the screen of the handheld 
for taking notes; b) activation of special functionalities for, creating, managing 
and navigating through conceptual maps; c) synchronous and asynchronous coordination 
of the work and;  d) voting.  

2   Related Work 

Some analyses have been carried out of both proposed and already-developed EMS 
systems  that  use  freehand  input,  concept  maps  and  especially  handhelds,  as  well  as 
the functionalities offered by handhelds for supporting face-to-face meetings: agenda 
creation, distribution and discussion support; task and processes development support; 
distributed on-screen viewing; individual note-making; and generation of minutes.  

The  We-Met  project  [30],  supports  face-to-face  meetings  although  using  Tablet 
PCs (TPC) for each of the participants all of whom are interconnected through a TPC. 
Attendees  can  work  in  the  same  virtual  work  area  on  their  tablet  screens,  which  is 
shared  through  the  connection  with  the  TPC  and  is  freehand  input-based.  The  pro-
ject’s objectives are (a) to facilitate communication between meeting participants, and 
(b) to facilitate documentation of knowledge and information generated by the meeting 
for easy review. Users of this system found that it was necessary to have private 
work areas where they can develop ideas that are not yet ready to be presented to the 
other  attendees.  The  Pebbles  project  [18],  though  not  conceived  to  be  used  exclusively 
for meetings, can be used to provide support to collaborative groups in various 

 

A Gestures and Freehand Writing Interaction 

681 

contexts. It consists of applications that interconnect handhelds through a PC. The devices 
are used as though they were PC mice or keyboards. The project’s objective is to 
mediate  social  interaction  techniques  between  persons  through  a  shared  screen. 
RoamWare  [28],  is  a  handheld  architecture  that  supports  informal  face-to-face  reunions,
 including those held in such places as corridors. Each handheld can detect and 
interconnect to others located within a limited space, while the participants make notes 
on their devices. These notes are sent to a central computer where they are stored for 
later distribution. Costa et al. (2001) have developed the idea of combining handhelds 
and a PC to explore the relationships that may exist between a meeting and these technologies.
 They show that the use of handhelds is neither annoying nor obstructive to 
the flow of the meeting, and suggest the devices be utilized as tools to generate reports, 
a  traditional  technique  for  linking  meeting  processes to  organizational ones. The  authors 
of the study also attempt to improve meeting report generation by making use of 
the capacities handhelds can contribute to the EMS for managing individual and group 
information. [1] have studied the impact of including handhelds as a support to meetings,
 pointing out the important role they can play in managing individual information. 
The authors note the following requirements: a) creation, distribution and support for 
the  development  of  an  agenda;  b)  recording  of  decisions  taken;  c)  inclusion  of  the 
foregoing in the minutes for later distribution; d) support for typical meeting structures; 
and e) support for various agenda, issue, decision, report and logistics templates. 

We made a comparative analysis of the above-described meeting support systems. 
Antunes and Costa [5] are the only ones to propose the creation, distribution and discussion 
 of  the  agenda.  None  of  the  systems  provides  any  support  for  negotiations 
aimed at reaching agreements or for commitment follow-up. We also see that there is 
no  system  trying  to  overcome  the  typical  problems  of  handhelds  by  exploiting  the 
gesture based interaction or improving the structure of the document. This work focuses 
on incorporating those ideas in the design principles of a handheld based EMS.  

3   Design Principles 

Handhelds  are  considered  to  be  a  good  platform  for  reading  brief,  concrete  content 
because their interface is simple and insensitive to content formats, thus allowing information 
 to  be  read  quickly.  They  are  also  considered  to  be  suitable  for  providing 
support  to  diverse  collaborative  work  groups,  [23].  However,  their  reduced  screen 
size  and  use  of  virtual  keyboards  or  widgets  for  entering  and  handling  information 
introduces new complexities into the user-handheld interaction, [6]. In order to overcome 
these problems we propose the following design principles:  
• 

Interaction is based exclusively on gestures thus minimizing the number of widgets 
and virtual keyboards and maximizing the space available for entering content.
 The content will be exclusively free handwriting. Although free handwritten 
text may take more space than typed text, it allows also a flexible combination of 
sketching  and  writing.  According  to  [6]  and  [15],  sketching  and  gesturing  with 
pen-based systems are natural modes of design-task-oriented interaction. In [26] 
it  is  noted  that  a  sketch  is  a  quick  way  of  making  designs  that  a)  facilitate  the 
creator’s idea generation process, b) stimulate communication of ideas with others,
 c) stimulate the use of early ideas thanks to the accessibility and interpretation 

682 

G. Zurita et al. 

they  provide,  and  d)  gives  the  opportunity  to  see  and  get  inspired  by  other  group 
members’ ideas. 

Many systems use the metaphor of pages and/or scrolling bars for the documents 
generated in order to offer more “space” to the user. This is indeed a simple and very 
intuitive way of organizing the content of a document, but when the working area is 
extremely small, which is the case of handhelds, is seems to be better to organize the 
content as a structure which is also intuitive and may contain more information without 
having to enter more data. A structure like a concept map  will be indeed more 
suitable to order the ideas generated during the meeting since this is an intuitive yet 
flexible structure which adds more information to the content than the “list of pages” 
(which  in  fact  is  a  simple  form  of  a  concept  map)  without  having  to  input  more  
content.  

A  decision-meeting  often  follows  the  template  of  idea  generation,  idea  organization 
 and  idea  prioritization  [1].  Idea  generation  is  a  divergent  phase  where  group 
members typically engage in a kind of brainstorming activity, drawing, talking, and 
sketching. This has also been called brainsketching, [26]. This phase is characterized 
by creativity, freethinking, lack of critical analysis and lack of restrictions or controls. 
After  ideas  are  generated  or  explained  by  text  note-taking,  or  sketching,  they  need  
to be organized. This activity includes accepting/rejecting ideas, refining, rearranging, 
and  consolidating  items  representing  the  ideas.  The  final  phase  should  produce  a 
summary  of  the  ideas  as  a  list  of  the  issues  or  topics  that  are  most  important  or  
relevant. From these three phases, the organization of the different ideas contributed 
by  the  group  members  is  often  the  most  problematic.  The  output  of  an  electronic 
brainstorming  or  brainsketching  session  is  typically  extremely  “dirty”,  and  needs  to 
be  organized  in  an  easy  way  by  using  editing,  marking,  deleting  and  cutting.  
The  graph  structure  of  a  concept  map  offers  a  more  flexible  way  to  do  this  than  a  
list  of  pages.  The  use  of  concept  maps  enables  the  drafting  of  a  meeting  summary 
through the follow-up of the structure, and facilitates the determination of actions to 
be taken.  

Using  a  graph  structure  for  a  document  opens  new  challenges  which  include  the 
development of an easy gesture-based mechanism to create and fill with content this 
structure. Also the design of the document viewing options the system should provide 
is an interesting issue.  These issues will be addressed later in this paper. 
    In addition to the principles mentioned above, an EMS should provide some fundamental 
 functionality.  Because  EMS  are  mostly  aimed  at  supporting  small  group 
work in a face-to-face setting, they should provide the capability to share information, 
exchange ideas, express opinions, create solutions, develop consensus to resolve problems,
 and collaborate on tasks. This can be achieved by a shared workspace where the 
members of the meeting would write, depict or sketch their ideas simultaneously in a 
common workspace by freehand input based system.  
    According to [27], voting before discussing certainly seems to increase the sense of 
group  identity,  reduce  personality  conflicts,  and  reduce  needless  discussion.  Some 
experimental studies have shown that computer support helps to generate agreement  
among the members.  In a meeting support system voting is used as a rational choice 
tool, being usually highly formal and used once at, or towards the end of the meeting.  
 

 

A Gestures and Freehand Writing Interaction 

683 

Meeting
life-cycle

Pre-meeting

Meeting

Post-meeting

Between-meetings

Create Group

Create Meeting

Distribute
minutes

Review
meeting

Communicate
following stages

Group

Meeting

Distribution of
commitments

Set Topics
of Agenda

Schedule
Meeting

Review of

commitments

Review of

minute

Follow-up on
commitments

Proposed
agenda

Start of
meeting

Run Topics
of Agenda

End of
meeting

Review agenda

Agree agenda

Topics

Notify agenda

Agenda

Actions to be

taken

Meeting
summary

Minute

Brainstorming
Brainsketching

Organization

Discussion and

Negotiation

Voting

Individual
note-making

Creation of

minutes

Ideas

Remarks

Organized

Ideas

Prioritized

Ideas

Recorded

commitments

Assignment of
commitments

 

Fig. 1. Hierarchical diagram of the meeting system 

 

    Synchronizing the work of a group may represent a higher challenge, especially if 
we  want  to  support  the  collaborative  work  synchronous  and  asynchronously  at  the 
same time. Problems arise when it comes to merge the work of participants who have 
been  working  asynchronously  with  people  working  synchronously.  Simple  rules  
for  avoiding  inconsistencies  are  needed.  A  method  based  on  working  on  private  
notes and publishing them to the group serves to this purpose and at the same time 
allows  a  participant  to  try  sketching/writing  of  new  ideas  before  showing  them  to  
the rest.  

4   Meeting System Structure 

The  Fig.  1  shows  a  hierarchical  diagram  of  the  meeting  life-cycle,  representing  the 
stages  for  the  tasks  and  processes  that  can  be  supported  by  the  meeting  system.  A 
meeting (or a number of meetings) is triggered by a problem the group has to discuss 
and solve.  

684 

G. Zurita et al. 

    In any stage of the meeting, users record their ideas by making private remarks or 
comments about specific and ideas by individual note-taking. The brainstorming process 
is characterized by the generation of  possible  solutions,  which are registered by 
the system and distributed to all members in order to be evaluated. This process can 
be carried out by anonymous and/or nominal contributions. In a face-to-face meeting 
group members can discuss about the convenience or inconvenience of the different 
ideas. Because all processes and tasks are reflected by annotations on the handheld, 
the minute of the meeting can be created as the different possible discussion topics are 
being proposed. This generated the documentation of a meeting which could also be 
complemented with a log of actions being taken, like additions, deletions or modifications 
made to the document for a posterior analysis and evaluation. Agreed commitments 
could be registered by mean of annotations or sketches, and distributed to the 
corresponding members at the end of the meeting. The system may manage a register 
which will be used to control the fulfillment of the assignments. 

5   System Description  

The basic content of a meeting document are the notes produced by the group member 
 during  the  discussion  by  sketching  and  writing.  In  this  section  we  will  explain 
how  our  system  combines  the  input  of  all  the  members  in  a  structured  document, 
based on nodes and relations among them thus building a concept map. Also, as mentioned 
in section 2, other tools and functionalities required enhance a group meeting 
will be presented. Current implementation has been developed with Microsoft .NET 
2.0 Compact Framework’s C#, and deployed on Windows Mobile 2005. 

In order to describe how the system allows collaborative writing and content managing,
 we will first review each one of these individual functionalities in order to simplify 
the system understanding. After each feature, we will shortly describe how it has 
been implemented.  At the end of this section,  we describe the collaborative process 
and the system architecture, including the communication protocol.  

The basic action a user is allowed to do in a meeting document is to enter free hand 
writing  and  sketching.    A  free-hand  input  is  done  by  “writing”  with  the  stylus  any 
figure  which  is  not  recognized  by  the  system  as  a  special  gesture.  This  hinders  the 
user for entering a sketch with is similar to a gesture, but this is better than having to 
switch  from  a  “sketching  mode”  to  a  “writing  mode”  back  and  forth  with  a  special 
functionality. Therefore, the system must be able to recognize free-hand writing and 
sketching from special gestures. In order to achieve this, the system tries to match the 
drawn figure with each possible gesture only after the user raises the stylus tip. The 
analysis of the input is made instantly after each stroke is made, without interfering in 
the  writing/drawing  process.  In  case  a  gesture  triggers  an  action,  the  system  stops 
matching the figure with the next gestures and performs the corresponding action. In 
case  no  gesture  has  been  acknowledged,  the  system  classifies  the  stroke  as  writing 
and “writes” it in the document.  

 
 

A Gestures and Freehand Writing Interaction 

685 

a. Root page

b. Node inner page 

Mode 

icon
currently  set  to 
Work Mode 

Private notes 

 
 
 
 
 
 

 

 
 
 
 
 
 
 
 

Fig. 2. System’s screenshot during sample meeting:  Double tapping a node (2.a) displays the 
node’s inner page (2.b) 

5.1   Annotations and Sketching 

Writing  and  drawing  is  made  through  freehand  input  with  the  handheld  stylus.  The 
system  will  analyze  the  drawn  figure  and,  after  discarding  every  possible  actiongesture,
 accepts it as written symbol. Repeating this process, the user is able to write 
sentences or draw complex figures, representing his or her idea. 
    Because  the  drawings  are  shared  with  other  participants  only  when  the  pen  tip  is 
raised, other users might start drawing in the same areas where others are already writing.
 This may lead some users into confusion, because they were not aware someone 
was drawing in the same space. To address this issue, the system display a temporary 
message making other members aware that someone is already writing in a particular 
area (Fig. 3), warning other users to avoid drawing in the same space. Therefore, two 
or more users may still write in the same area, but they are aware that other partici-
pant’s drawing may interfere, encouraging agreement among users before occur. 
 
 
 
 
 
 
 
 
 
 
 
 
 

 a. Gustavo’s device 

 b. Felipe’s device 

 

 

Fig.  3.  Gustavo’s  writing  (b)  won’t  be  shared  until  he  raises  the  stylus  pen.  Meanwhile,  Felipe’s 
device shows the current received strokes and a warning saying Gustavo is still writing. 

686 

G. Zurita et al. 

    A user might need to correct or organize his or her writings. For this, methods to 
edit and manage writings and drawings are required. To allow this, we have included 
cut  and  move  actions.  When  the  user  wants  to  remove  something  written  from  the 
screen, he or she needs to draw a cross gesture. This gesture will remove every stroke 
the cross touches, as shown in Fig. 4.a. 
 

 

 

 

 

 

a

b

Fig. 4. a: A cross  gesture removes touched strokes. b: A  cross gesture removes selected elements 
only. 

    There are special situations where removing some elements might be difficult for 
the user (for example, removing a misspelling). For these cases we have included a 
second method for cutting: the user clicks one by one those lines he or her wishes to 
remove,  selecting  them;  once  all  the  strokes  selected  and  ready  to  be  removed,  the 
user  draws  the  same  cross  gesture,  removing  only  those  selected  lines,  leaving  untouched 
the rest of the writing. An example of this process can is shown in Fig. 4.b. 

Selection is an important tool to edit information in our system. We have quickly mentioned 
in the previous paragraph how to add single strokes to the selection. Clicking an 
already selected line deselects it. Also, clicking on an empty area clears the selection. In 
some cases, the user might want to select a complex group of strokes. We have included a 
method to do this with a single gesture, called double lasso gesture. This gesture consists 
in double surrounding an area with a certain closed shape. Every element included within 
the shape will be added to the selection, as illustrated in Fig. 5. 

Fig. 5. A double lasso gesture selects enclosed items 

 

   Another  way  to  manage  the  contents  in  our  system  is  by  moving  them.  The  user 
may decide to join some terms, or to separate two concepts and  write  something in 
between.  We  have  included  the  move  action  to  allow  this.  After  selecting  some 
strokes, the user can hold and drag any of the selected lines in order to move all the 
selection.  

Finally,  our  system  allows  the  user  to  paste  previously  cut  objects.  This  lets  the 
user to undo the last removal, or to move objects between pages. In order to paste, the 
user must hold the stylus pressed in the clicked point for a certain time. The removed 
elements will re-appear in the clicked point. 

 

A Gestures and Freehand Writing Interaction 

687 

5.2   Conceptual Map Building and Navigation 

As mentioned in section 2, our system allows to hierarchically organize the content of 
a meeting document in pages in order to solve the handheld limited screen size problem.
 These pages are associated to parent nodes, which is usually labelled. In order to 
create a new page, the user must write or draw some strokes, as a title. Then, he or she 
has to surround them with a rectangle or a partial rectangle. The system will recognize 
this gesture as a node creation (Fig. 6). Automatically, a new page will be associated 
to this new node. 

Fig.  6.  Surrounding  with  a  partial  rectangle  gesture  creates  a  new  node  with  the  contained 
strokes as label 

 

Once a node has been created, the user can enter into the associated page double 
clicking on the node. After this, the handheld screen will display the clicked node’s 
content page, as shown in figure 2. In order to exit the page associated with the node 
and go back to the parent page, the user can double click in any empty area. 

On every page, the user can use the same writing and drawing methods, as well as 
every gesture, including those for creating new nodes. In this way, the user builds an 
implicit  conceptual  map  of  the  information  being  represented,  through  hierarchical 
contained pages.  

 

Current 

location 
is highlighted 

Document 

tree 
view  icon  is  highlighted 

inform 
current system state 

to 

Votes are 
displayed as 
pie graphs

Attendees 
list

Group icon
with current node’s 
attendance

 

Fig.  7.  The  document  tree  view  shows  a  scaled  summary  of  the  document,  including  user’s 
current location 

 

    The user might get confused about his or her current location in the conceptual map 
if the document has too many nodes. To help the user get oriented within the document,
 we have included a document tree view button. This view shows an organized 
version of all the nodes in the document, sorted hierarchically. The node  where the 
user is currently located shows a yellow highlight. Clicking on any node will lead the 
user to its content page, just like double clicking its label. This makes the hierarchical 

688 

G. Zurita et al. 

view of the document also a powerful navigation tool. An example of the document 
tree view is shown in Fig. 7. 

By default, the document tree is scaled down in order to display all the nodes at the 
same time. When the tree is big enough, some downscaled nodes could turn difficult 
to read or understand. Therefore, a method for zooming in and scrolling through the 
tree has been added to our system. In the document tree view, the user can hold the 
stylus down over an empty area, and then drag the pen right or left to zoom in and 
zoom out respectively, and up and down to scroll. In this way, with a single gesture, 
the user can zoom and scroll through an entire complex document tree. See Fig. 8 for 
a diagram of this two-in-one innovative gesture’s functionality. 

 
 

Scroll up

Zoom out

Zoom in

Scroll down

 

Zoom in and scroll down 

 

Fig. 8. Dragging the stylus on the document tree view allows users to zoom and scroll with a 
single gesture 

5.3   Collaborative Process 

During a group meeting, the user needs to get some information about other attendees. 
The system informs the user when other users enter or leave the session, but this is not 
enough  to  follow  current  attendees  location.  Our  system  provides  two  methods  to 
retrieve some information about the participants group: the group icon displays user’s 
current  node  attendance  percentage  (how  many  of  the  total  participants  are  looking 
the same screen the user is), and the attendees’ list (Fig. 7). The group icon warns the 
user when he or she is alone, with no other user’s attention, becoming red. The more 
users  share  the  same  screen,  the  greener  the  icon  will  turn.  This  allows  the  user  to 
quickly know how many other participants are sharing the writing space.  
    The system allows users to vote for or against nodes. Thus, at a certain point of the 
meeting, attendees could agree to vote about certain ideas. In order to vote, the user 
needs to click the mode icon from the menu bar (Fig. 2). Votes are represented as a 
pie graph at the lower left corner of the node, as shown in Fig. 7. The green portion of 
the pie represents positive  votes, and  the red portion represents  negative votes. The 
black portion represents users who have not voted. 

Once  in  the  voting  mode,  the  user  can  vote  for  a  node  by  drawing  a  tick  mark, 
starting  on  the  node  (Fig.  9.a:  in  the  example,  the  pie  shows  25  percent  of  positive 
votes: 1 of 4 attendees has voted). In order to vote against an element, the user draws 
the same cross gesture used for cutting (Fig. 9.b). A user can change his or her vote 
by replacing the old one (drawing a cross will replace a previous tick and vice-versa). 
    The  full  session  tree  can  be  represented  as  an  XML  document.  During  a  meeting, 
each user can freely decide to save the current state of the document into an XML file, 
in his or her handheld’s memory. Later, a new meeting could be started from this file, in 
order to continue the same reunion based on the previous work. A user who saved such 
files could revise a previous meeting to remember discussed subjects and conclusions. 

A Gestures and Freehand Writing Interaction 

689 

 

 

 

 

 

 

a

b

Fig. 9. a: Drawing a tick gesture under vote mode adds a positive (green) vote to the node. b: 
Drawing a cross gesture under vote mode adds a negative (red) vote to the node. 

During a meeting the user might want to take some private notes, without sharing 
them with the rest of the participants. In order to allow this, our system counts with 
the private note menu (Fig. 2), which lets the user write private notes on a blank page 
associated to the user’s current location, or over the current page. Later, the user can 
share  this  note  with  the  group  by  choosing  “Publish  note”  option,  from  the  same 
menu. In the menu, the user can find his or her previous privates and published notes; 
as well as other users’ published notes. 

There are certain situations when meeting attendees could have previously worked 
by their own, developing new ideas or individually building their part of the meeting, 
based on a previous meeting, or on a brand new document. Later, during a meeting, 
the user decides to share  his  offline  work  with the other users. The system  has two 
special  options  for  this  scenario:  one  where  the  work  needs  to  be  merged  with  the 
current  session,  called  merge  versions,  and  other  where  the  user  want  to  show  as  a 
separate version the offline work, called open as version. Merge versions merges the 
saved document with the current one. All new elements (writing and nodes) will be 
added  to  the  current  session,  and  repeated  elements  will  be  updated  to  the  saved 
document  version.  On  the  other  hand,  open  as  version  creates  a  new  node  in  the 
document root page, using the file’s name as the node label. Inside this node, as its 
content  page,  the  saved  document’s  root  page  is  copied.  All  these  changes,  as  described 
in next section, are shared and updated on everyone’s handheld.  

5.4   System Achitecture 

Gesture matching and action triggering. Every concept of the system is considered 
a  gesture  object.  Some  of  these  elements  live  temporary,  executing  an  action,  and 
some persist and are represented graphically, called drawbleGestures. Some gestures 
are used in order to create another gesture. For example, a cross gesture mutates into 
a cut gesture under work mode; while under vote mode it becomes a voteAgainst gesture 
(see Fig. 10). 

Every gesture class has a analyze method, which receives the analyzed figure (the 
last user pen-based input) as a parameter, and tries to check if this stroke follows the 
internal rules to be considered such gesture. After a gesture class accepts the drawn 
shape as its own, the class triggers its internal actions (like adding the clicked shape to 
selection, creating a new node, or cutting some  writing) and returns a TRUE value, 
stopping the gesture matching chain. In case the class refuses the given shape (returning 
 a  FALSE),  the  system  will  assume  the  figure  does  not  belong  to  the  queried  
 

690 

G. Zurita et al. 

 

Fig. 10. Simplified class hierarchy with action triggering. Some gestures actions depend on the 
context. 
 
family. As mentioned, every class does this process using rules matching, instead of 
pattern matching or neural networks, because rules are easy to be described without 
need to teach the system, and they can analyze an indeterminate number of conditions 
or  parameters:  for  example,  the  double  lasso  figure  cannot  be  limited  to  a  certain 
amount of points.  

To determine what action to follow, the system starts checking the gesture against 
the  highest  priority  class  and,  in  case  it  fails,  continue  this  matching  with  the  next 
class in the priority chain. Once a gesture has replied TRUE, the system stops checking 
the gesture. In case all other classes return FALSE, the last gesture (the click ges-
ture) always returns TRUE. 

Content structure. There are some special drawbleGestures called containerOwner, 
which own two instances of another type of element called gesturesContainer: one for 
its content page, and a second one for its label. These gesturesContainers can storage 
multiple  nested  gestures.  ContainerOwners  are  referred  in  this  paper  as  nodes,  because 
their nature allows building hierarchical structures. The document root is a containerOwner 
itself. Another containerOwner subclass is the rectGesture, motioned in 
section 4.2: for rectGestures it is more clear the use of both gesturesContainers, because 
they clearly have some writing associated as a label and a whole set of nested 
elements as their content page, viewable with a double click (enter action).  

Some special gestures exploit this hierarchical structure: for example, vote gestures 
are  abstract  objects  contained  in  the  contents  gestureContainer  of  the  voted  node. 
Thus, in order to draw the vote pie, the system looks into the node content for vote 
gestures (voteFor and voteAgainst gestures), summarizing them in the round graph.  

 

A Gestures and Freehand Writing Interaction 

691 

Communication Protocol. As soon as each user launches the system, it searches the 
local  network  for  other  participants:  our  system  works  over  local  area  networks 
(wired and wireless), as well as for ad-hoc peer to peer wireless networks. Each time 
another  peer  is  discovered,  it  is  added  to  the  known  participants  list.  The  user  gets 
informed every time another user connects or disconnects from the current session.  
    When a new user is discovered, the system will send him the current state of the 
meeting: A complete version of the session tree will be transfer as an XML document. 
Also, every time the user modifies the document tree, by writing, adding or removing 
elements, or any other change, a short XML message describing the changes is sent to 
every known participant, ensuring the data consistency between peers.  

On the other side, users will receive XML information: a complete document when 
joining a session or small XML chunks when receiving changes. Both messages are 
analyzed the same way: each XML entity is used as a parameter for a gesture interpreter,
 exactly as if it would have been drawn.  

6   First Usability Testing and Analysis 

We  made  a  first  usability  analysis  of  the  system  using  think-aloud  and  heuristic 
evaluation  methods  in  order  to  detect  and  correct  possible  design  or  programming 
failures  of  the  prototype  developed.  The  evaluation  was  aimed  to  the  detection  of 
problems  in:  a)  the  collaboration  supported  by  the  system,  identifying  the  circumstances 
where the system does not provide he adequate support for or hinders the collaborative 
work among the members; b) the user interface, identifying which aspects 
difficult the understanding and learning the way it works, the user satisfaction when 
using  the  diverse  functionalities,  particularly,  when  sketching,  using  gestures,  and 
navigating; and c) combinations of both. We classified the possible problems we may 
found according to their severity, as suggested by [12], [14], [28] and [22]: a) Critical 
problems include crushes, breaks of the  working  flow, information  lose, lose of the 
focus  of  the  work;  b)  serious  problems  include  lost  of  functionality,  difficulties  but 
not break of the working flow; and c) cosmetic problems include orthographic errors, 
minor visual problems which not affect the function of the system. 

In the Think-aloud evaluation method users verbalize their thoughts about the system 
 while  using  it,  thus  avoiding  distortions,  wrong  cognitive  translations  or  omissions 
that may be introduced by a guided questionnaire [4]. This type of evaluation is 
more user-oriented than the heuristic evaluation, where experts play an important role, 
[4], [13], and [14]. The process is guarded by a monitor and observed by examiners, 
who are in charge of gathering the oral information in real time or by analysing the 
video recording of the session. According to [12], this method can be used to evaluate 
the  collaboration  inside  a  working  group  supported  by  a  computer  system.  En  each 
session, the participants acted just as they were holding a real meeting and verbalizing 
their thoughts at the same time. The monitor has to first instruct the participants about 
the usage of the system explaining the functionalities. During the meeting the monitor 
mainly observes its development and the way the participants use the system. Only if 
the participants do  not speak  any  word for 30 seconds the  monitor asks the participants 
to start thinking aloud again, [4]. The examiners observe the development of the 

692 

G. Zurita et al. 

meeting registering in real time the usability problems detected and verbalized by the 
participants. After finalizing the meeting, they are in charge of analysing the problems 
encountered. Two think-aloud test meetings were organized with 4 to 5 people each. 
In one of the sessions all participants were experts in the use and development of collaborative 
systems. The participants of the other two meetings were people who frequently 
use computers and often participate in meetings at work. The same goal and 
specific tasks were applied for both test meetings. The discussion subject was to identify 
3 benefits and 3 drawbacks of face-to-face meetings. We also asked them to perform 
specific tasks during the meeting.  The participants have to a) take all necessary 
notes  they  think  will  help  to  the  development  of  the  meeting;  b)  store  in  a  file  the 
notes taken during the meeting. Additionally, they were instructed to use the voting 
mechanism if there is any need to take decisions. During 5 to 10 minutes before starting 
the test meeting the monitor instructs the people how to use the system. Each session 
 lasted  for  35  to  45  minutes,  and  was  registered  by  video-recorder.  During  the 
meeting, the monitor and the examiners took notes about usability problems detected 
and verbally expressed by the participants. Once the  meeting  was over, the  monitor 
and the examiners discussed for about one hour the outcome of the test meeting according 
to the IDA method described in [13].  

We  also  conducted  a  heuristic  evaluation  (HE)  of  the  software.  The  heuristic 
evaluation is very popular because of its low cost and low time consumption. It is also  

 

Table 1. Compilation and classification of the problems encountered and their solutions 

Problem 

Participants do not know who was the author of 
 a certain action  
Unwanted nodes are created * 
Confusion in the collaborative writing* 

   SV     TP 

Solution 

CE  CL SZ Use different colour for user 

CE 
CR 

IU GZ Tuning gesture recognition  
IU SZ Use  mechanism  of    collaborative  writing 

awareness (Figure 3) 

Free-hand writing is not accurate or swift. * 

CR 

IU TR Modify the graphic refreshment procedure 

for nodes 

Confusion  in  the  synchronization  of  the  work,
people  add  or  delete  to  many  things  at  the  same
time + 
Unwanted explosion  (getting inside) of a node *  CR  UI GZ  Tuning gesture recognition 
Writing  becomes  slow  when  there  are  more
strokes on the screen *  

SE  UI TR Optimize synchronizing process   

SE  CL SZ Provide  flexibility  for  private  notes,  provide 
floor control policy options  

Slow distribution of the new information * 
Same strokes are not distributed* 
Some nodes are not distributed * 

SE  CL SZ Optimize synchronizing process   
SE  CL TR Optimize synchronizing process   
SE  CL GT Optimize synchronizing process   

It is difficult to tell if the current node corresponds
to a private node or not+  

CE  UI ND Provide a more evident awareness icon 

It  is  difficult  to  know  which  node  is  currently
being explored + 

CE  UI ND Label the pages with the label of the corresponding 
node. (Figure 2b) 

With the think-aloud test many critical and not so critical problems were found (those marked with *). 
These were solved before the HE testing, where those problems marked with + arose.  

 

A Gestures and Freehand Writing Interaction 

693 

proved to be a very assertive one [12]. According to [12], HE is very good at detecting 
usability problems in mobile devices and cosmetic problems, so we applied it after 
the improvements and  with experts as users. The results just confirmed those of 
the Think-Aloud evaluation. 

The table 1 compiles the most relevant information obtained during the test meetings.
 Each one of the problems encountered was classified according to first its degree 
of severity (SV): critical (CR), serious (SE), or cosmetic (CE). Then according to the 
type of problems (TP): collaboration (CL) or user interface (UI). And within the type 
of problem, related to which aspect of the system it was encountered: synchronization 
(SZ), gestures (GZ), strokes (TR), or nodes (ND). 

7    Conclusions 

After correcting the problems found in the tests and taking into account the opinion of 
the people involved  we can conclude that  we designed and developed an  electronic 
meeting support system for handhelds which is simple, easy to use, and supports effectively 
the development of a discussion, at least in the form we asked them to hold 
the meeting, which we think is general enough for validating a tool in a first stance. 
Of course, a deeper and wider study which does not only involve “laboratory condi-
tions” like the one described in the previous chapter, but in “real meeting situations” 
should  be  carried  out  in  order  to  validate  this  tool  as  a  successful  meeting  support 
system in a concluding manner.  

With the developing and first testing of this system we found evidence that the two 
most important design principles applied do really work. In fact, we can assert with a 
certain  degree  of  confidence  that  developing  a  system  for  handhelds  based  only  in 
gestures and handwriting input, avoiding the “traditional” widgets is not only feasible 
bud  very  good  accepted  by  the  user.  We  can  also  assert  that  the  structuring  of  the 
document content as a concept map gives the necessary flexibility to manage the different 
 contributions  of  the  users.  The  idea  of  structuring  a  collaborative  authored 
document as a concept map was already presented in [24] already in the year 1994, 
but the novelty of this work is to find a way to effectively manage such a structure 
with just gestures and in a reduced screen, allowing an easy  navigation through the 
document.  We  believe  that  the  contributions  of  the  work  reported  here  can  be  also 
applied in to various kinds of systems for handhelds with goals and aims for supporting 
different work as the one targeted here.   

The tests have shown that after fixing the initial critical and serious problems detected 
the system has a good acceptance. An interesting issue about the testing is that 
they  have  been  conducted  in  different  cultural  environment  (Latin  American  and 
Asian). The absence of labeled widgets and text contributed to the fact that the cultural 
background is not and obstacle to use the system. In fact the Asian people took 
notes  more easily using  Chinese characters than the  Latin  American using  Latin alphabet.
 The collaborative meeting support of the system evaluated based on gesture 
and sketch enhances the design in a natural and concordant way, enabling the share  
 

694 

G. Zurita et al. 

and exchange of information. The user interface designed is away from the rigidity of 
traditional user interfaces, supporting instead the flexibility and ambiguity inherent in 
a natural mode of communication. Therefore, member’s meeting can put their focus 
on specific meeting tasks, instead of things in low-level.  

Finally, we think that the proposed system can also be used to support undergradu-
ate/postgraduate  students  develop  skills  required  during  a  meeting.  In  this  scenario 
teachers may use the system for presenting ideas to the students and involve them in 
common  meeting  activities  like  taking  decisions,  solving  problems  collaboratively, 
etc. The students will be able to learn the diverse stages and processes of a meeting by 
doing them. This  will allow  a simulation of the real conditions of a  meeting; therefore.
 it will produce positive motivation and participation levels in the students [31]. 
According to , the anonymity supported by handhelds helps reducing evaluation apprehension 
by allowing group members to submit their ideas without having to speak 
them  in  front  of  the  group.  This,  and  the  fact  that  people  can  “express”  their  ideas 
concurrently, not having to  wait for a slot, encourages the  contribution  from people 
who  normally  would  play  a  more  passive  role  in  a  discussion  meeting.  The  system 
also helps  members to follow the agenda of the  meeting thus reducing coordination 
problems.  Furthermore,  the  system  can  also  support  a  wider  spectrum  of  activities, 
including the generation and organization of ideas, group analysis, decision making, 
group writing and action planning.  
 
Acknowledgements.  This  paper  was  partially  supported  by  Fondecyt  1050601,  and 
the DI - Universidad de Chile Nro. I2 04/01-2.  

References 

1.  Antunes, P., and Costa, C. Handheld CSCW in the Meeting Environment. Proceedings of 

the CRIWG’02, LNCS 2440 (2002) 47-60. 

2.  Bates,  S.  E.  What  is  IS’  Role  in  Re-engineering?  Business  Leaders  Should  Lead.  Computerworld 
29(39) (1995) 134. 

3.  Bergqvist, J., Dahlberg, P., Kristoffersen, S., and Ljungberg, F. Moving out of the meeting 
room: exploring support for mobile meetings. Proceedings of the Sixth European conference 
on Computer supported cooperative work. Copenghagen, Denmark (1999) 81-98. 

4.  Boren, T., and Ramey, J. Thinking Aloud: Reconciling Theory and Practice. IEEE Transactions 
on Professional Communication, 30(3) (2003) 261-278. 

5.  Costa,  C.,  Antunes, P.,  Dias,  J. The  Meeting  Report Process:  Bridging  EMS  with PDA. 
Third International Conference on Enterprise Information Systems, ICEIS 2001. Setubal, 
Portugal (2001) 821-826. 

6.  Dai, G. and Wang, H. Physical Object Icons Buttons Gesture (PIBG): A new Interaction 

Paradigm with Pen. Proceedings of CSCWD 2004, LNCS 3168,  11-20, 2005.  

7.  dos Santos, A. Vasconcelos, S., Fagundes, L. Kayo, R., Zanfolim, T., and Brunetto, C. SACE-
CSCW: A Synchronous Asynchronous Common Environment for Computer Supported Cooperative.
 Work to Aid Concurrent Engineering Processes. SCCC (1997) 218-226. 

8.  Haag,  S.,  M.  Cummings,  and  Dawkins,  J.  Management  Information  Systems  for  the  Information 
Age, 2nd Ed., Boston, MA: Irwin McGraw-Hill (2000). 

 

 

A Gestures and Freehand Writing Interaction 

695 

9.  Hayne,  S.  The  facilitators’  perspective  on  meetings  and  implications  for  group  support 

System. Database, 30(4) (1999) 72-91. 

10.  Jessup, L., and Valacich, J. Group Support Systems: A New Frontier. New York: MacMillan 
(1993). 

11.  Kjeldskov J., and Skov M. B. Evaluating the Usability of a Mobile Collaborative System: 
Exploring  Two  Different  Laboratory  Approaches.  Proceedings  of  the  4th  International 
Symposium on Collaborative Technologies and Systems, Orlando, Florida (2003) 134-141.  
12.  Kjeldskov  J.,  Skov  M.B.,  and  Stage  J.  Instant  Data  Analysis:  Evaluating  Usability  in  a 

Day. Proceedings of NordiCHI, Tampere, Finland. ACM (2004) 233-240. 

13.  Kjeldskov J., Skov M.B., and Stage J. Does Time Heal? A Longitudinal Study of Usability.
 Proceedings of OzCHI 2005, Canberra, Australia, ACM (2005). 

14.  Landay, J. and Myers, b. Sketching interfaces: Toward more human interface design, IEEE 

Computer, 2001 34(3) (2001) 56-64. 

15.  Luff,  P.,  Heath,  C.  Mobility  in  Collaboration.  Proceedings  of  Computer  Supported  Collaborative 
Work, CSCW’98. ACM Press, 1998, 305-314. 

16.  Marshall, C., Ruotolo, C. Reading-in-the-Small: A Study of Reading on Small Form Factor 
Devices. Proceedings of the JCDL’02, Portland, Oregon, USA, 2002, 13-17. 

17.  Myers, B.A., Stiel, H., and Gargiulo, R. Collaboration using multiple PDAs connected to a 
PC. Proceedings of the ACM, Conference on Computer Supported Cooperative Work. Seattle,
 WA (1998) 285-294. 

18.  Nunamaker,  J.  F.  Future  research  in  group  support  systems:  needs,  some  questions  and 
possible  directions.  International  Journal  of  Human-Computer  Studies,  47,  1997,  p  357385.
 

19.  Perry, M. O’hara, K., Sellen, A., Brown, B., and Harper, R. Dealing with mobility: understanding 
access anytime, anywhere. ACM Transactions on Computer-Human InteractionTOCHI,
 4(8) (2001) 323-347. 

20.  Po, S., Howard, S., Vetere, F., and Skov, M. B. Heuristic Evaluation and Mobile Usability. 
Bridging the Realism Gap. In Proceedings of the 6th International Conference on Human 
Computer  Interaction  with  Mobile  Devices  and  Services,  (Mobile  HCI  2004),  SpringerVerlag,
 LNCS 3160 (2004) 49-60. 

21.  Schmidt, A. Lauff, M., and Beigl, M. Handheld CSCW. Workshop on Handheld. Proceedings 

of the Computer Supported Collaborative Work - CSCW '98, November, Seattle (1998). 

22.  Streitz,  N.A.,  Geißler,  J.,  Haake,  J.M.,  Hol,  J.  DOLPHIN:  integrated  meeting  support 
across local and remote desktop environments and LiveBoards, Proceedings of the 1994 
ACM conference on Computer supported cooperative work, October 22-26, Chapel Hill, 
North Carolina, United States (1994) 345-358, 

23.  Tropman, J. E. Effective meetings: Improving Group Decision Making. Sage Publications  

(1996). 

24.  van der Lugt, R. Functions of sketching in design idea generation meetings. In TT Hewett 

& T Kavanagh (Eds.), Creativity & cognition, New York: ACM, 2002, 2002, 72-79. 

25.  Whitwort,  B.  and  McQueen,  R.  Voting  before  discussing:  Computer  voting  as  social 
communication.  Proceedings  of  the  32nd  Hawaii  International  Conference  on  Systems 
Sciences (1999) 1020-1031. 

26.  Wiberg,  M.  RoamWare:  an  integrated  architecture  for  seamless  interaction  in  between 
mobile meetings. Proceedings of the 2001 International ACM SIGGROUP - Conference 
on Supporting Group Work (2001) 288-297. 

27.  Wilson,  C.  Defining,  Categorizing,  and  Prioritizing  Usability  Problems.  UPA  2003  Idea 
Market,  July,  2003.  Available  in  http://www.upassoc.org/conferences_and_  events/ 
upa_conference/2004/call/sample/ideamarket_usability%20problems_wilson.doc  

696 

G. Zurita et al. 

28.  Wolf,  C.,  and  Rhyne,  J.  Communication  and  Information  Retrieval  with  a  Pen-Based 

Meeting Support tool. Proceedings of CSCW - ACM (1992) 322-329. 

29.  Burleson, W. Developing creativity, motivation, and self-actualization with learning systems 
International Journal of Human-Computer Studies 63(4-5) (2005) 436-451. 

30.  Tyran, G., Sherpherd, M. Collaborative Technology in the Classrom: A Review of the GSS Research 
and a Researh Framework. Information Technology and Management 2 (2001) 395-418. 

