1
1
0
2

 

b
e
F
1
2

 

 
 
]

V
C
.
s
c
[
 
 

1
v
8
5
2
4

.

2
0
1
1
:
v
i
X
r
a

Eurographics Workshop on 3D Object Retrieval (2011)
H. Laga, T. Schreck, A. Ferreira, A. Godil, and I. Pratikakis (Editors)

SHREC 2011: robust feature detection and description

benchmark

E. Boyer1, A. M. Bronstein†2, M. M. Bronstein†3, B. Bustos4, T. Darom5, R. Horaud1, I. Hotz6, Y. Keller5, J. Keustermans7,

A. Kovnatsky†8, R. Litman†2, J. Reininghaus6, I. Sipiran4, D. Smeets7, P. Suetens7, D. Vandermeulen7,

A. Zaharescu†9, V. Zobel6

1INRIA Grenoble Rhône-Alpes, France

2Department of Electrical Engineering, Tel Aviv University, Israel

4Department of Computer Science, University of Chile

5School of Engineering, Bar-Ilan University, Ramat-Gan, Israel

6Zuse Institut Berlin, Germany

3Institute of Computational Science, Faculty of Informatics, Università della Svizzera Italiana, Lugano, Switzerland

7Department of Electrical Engineering, K.U. Leuven, Belgium

8Department of Mathematics, Technion – Israel Institute of Technology, Haifa, Israel

9Aimetis Corp., Waterloo, Canada

Abstract
Feature-based approaches have recently become very popular in computer vision and image analysis applications,
and are becoming a promising direction in shape retrieval. SHREC’11 robust feature detection and description
benchmark simulates the feature detection and description stages of feature-based shape retrieval algorithms.
The benchmark tests the performance of shape feature detectors and descriptors under a wide variety of transformations.
 The benchmark allows evaluating how algorithms cope with certain classes of transformations and
strength of the transformations that can be dealt with. The present paper is a report of the SHREC’11 robust
feature detection and description benchmark results.

Categories and Subject Descriptors (according to ACM CCS): H.3.2 [Information storage and retrieval]: Information
Search and Retrieval—Retrieval models I.2.10 [Artiﬁcial intelligence]: Vision and Scene Understanding—Shape

1. Introduction

Feature-based approaches have recently become very popular 
in computer vision and image analysis applications, notably 
due to the works of Lowe [Low04], Sivic and Zisserman 
[SZ03], and Mikolajczyk and Schmid [MS05]. In these
approaches, an image is described as a collection of local
features (“visual words”) from a given vocabulary, resulting
in a representation referred to as a bag of features. The bag
of features paradigm relies heavily on the choice of the local

† Organizer of the SHREC track. All organizers and participants are
listed in alphabetical order. For any information about the benchmark,
 contact michael.bronstein@usi.ch. Authors are listed alphabetically.


c(cid:13) The Eurographics Association 2011.

feature descriptor that is used to create the visual words. A
common evaluation strategy of image feature detection and
description algorithms is the stability of the detected features
and their invariance to different transformations applied to
an image. In shape analysis, feature-based approaches have
been introduced more recently and are gaining popularity in
shape retrieval applications.

SHREC’11 invariant feature detection and description
benchmark simulates the feature detection and description 
stages of feature-based shape retrieval algorithms. The
benchmark tests the performance of shape feature detectors
and descriptors under a wide variety of different transformations.
 The benchmark allows evaluating how algorithms
cope with certain classes of transformations and what is the
strength of the transformations that can be dealt with.

Boyer et al. / SHREC’11: robust feature detection/description

This report presents a long version of

[BBB∗11].

the paper

2. Data
The dataset used in this benchmark was from the TOSCA
shapes [BBK08], available in the public domain. The shapes
were represented as triangular meshes with approximately
10,000–50,000 vertices.

The dataset includes ones shape class (human) with simulated 
transformations. Compared to the SHREC 2010 benchmark,
 there are additional transformation classes and the
transformations themselves are more challenging. For each
null shape, transformations were split into 11 classes shown
in Figure 1: isometry (non-rigid triangulationand 
distancepreserving 
almost inelastic deformations), topology (welding 
of shape vertices resulting in different triangulation),
rasterization (simulating non-pointwise topological artifacts
due to occlusions in 3D geometry acquisition), view (simulating 
missing parts due to 3D acquisition artifacts), partial 
(missing parts), micro holes and big holes, global uniform 
scaling, global afﬁne transformations, additive Gaussian 
noise, shot noise, down-sampling (less than 20% of the
original points).

In each class, the transformation appeared in ﬁve different 
versions numbered 1–5. In all shape categories except 
scale and isometry, the version number corresponded
to the transformation strength levels: the higher the number,
 the stronger the transformation (e.g., in noise transformation,
 the noise variance was proportional to the strength
number). For the isometry class, the numbers do not reﬂect 
the strength of the transformation. The total number 
of transformations was 55. The dataset is available at
http://tosca.cs.technion.ac.il/book/shrec_feat.html.

3. Evaluation methodology
The evaluation was performed separately for feature detection 
and feature description algorithms. Feature detectors
were further divided into point and region; feature descriptors 
were divided into point, region, and dense. The participants 
were asked to provide, for each shape Y in the dataset,
(i) a set of detected feature points F(Y ) = {yk ∈ Y}k or regions 
F(Y ) = {Yl ⊂ Y}l; (ii) optionally, for each detected
point yk, a descriptor vector {f(yk)}|F (Y )|
; or alternatively,
for each detected region Yl, a descriptor vector {f(Yl)}|F (Y )|
.
For dense descriptors, participants provided {f(yk)}|Y|
k=1. The
performance was measured by comparing features and feature 
descriptors computed for transformed shapes and the
corresponding null shapes.

k=1

l=1

shape Y in the dataset the groundtruth dense correspondence
to the null shape X to be given in the form of pairs of points
C0(X,Y ) = {(x(cid:48)
k=1, a feature point yk ∈ F (Y ) is said
to be repeatable if a geodesic ball of radius ρ around the corresponding 
point x(cid:48)
k,yk) ∈ C0(X,Y ) contains a detected
feature point x j ∈ F (X).† Repeatable features are
k) (cid:54)= ∅,

Fρ(Y ) = {yk ∈ F (Y ) : F(X)∩ Bρ(x(cid:48)

k,yk)}|Y|
k : (x(cid:48)

(x(cid:48)
k,yk) ∈ C0(X,Y )},

k) = {x ∈ X : dX (x,x(cid:48)
where Bρ(x(cid:48)
geodesic distance function in X.

k) ≤ ρ} and dX denotes the

Similarly, for region detectors, a region Yl ∈ F(Y ) is rel 
⊂ X has overlap

peatable if the corresponding region X(cid:48)
larger than ρ,

Fρ(Y ) = {Yl ∈ F (Y ) : |X(cid:48)

l ∩ Xl|/|X(cid:48)

l ∪ Xl| ≥ ρ}.

The repeatability of a feature detector is deﬁned as the
percentage |Fρ(Y )|/|F(Y )| of features that are repeatable,
the deﬁnition being dependent of whether a point or region
descriptor is used.

k=1

3.2. Feature description
Let {fk}|F (Y )|
, {g j)}|F (X)|
denote descriptors computed on
feature points F(X) and F(Y ), respectively. For point descriptors,
 we consider as the point corresponding to yk the
closest point x j ∈ F(X) to x(cid:48)
k,yk) ∈ C0(X,Y ),
such that rk j = dX (x j,x(cid:48)

k, where (x(cid:48)
k) < ρ for some ρ.

j=1

Descriptor quality was evaluated using the normalized L2

distance between descriptors at corresponding points,

(cid:107)fk − g j(cid:107)2

dk j =

|F (X)|2−|F (X)| ∑k, j(cid:54)=k (cid:107)fk − g j(cid:107)2

1

.

In addition, an evaluation using the ROC was performed
as follows. The corresponding feature points xk,y j are considered 
true positives if dk j ≤ τ, for some threshold τ. The
true positive rate is deﬁned as T PR = |{dk j ≤ τ}|/|{rk j ≤
ρ}|; the false positive rate is deﬁned as FPR = |{dk j ≤
τ}|/|{rk j > ρ}|. By varying the threshold τ, a set of pairs
(FPR,T PR) referred to as the receiver operation characteristic 
(ROC) curve is obtained. For a ﬁxed FPR, the higher
the TPR, the better.

For a dense descriptor, the quality is measured as the average 
normalized L2 distance between the descriptor vectors
in corresponding points,

1

|F(X)|

|F (X)|
∑
k=1

dk j.

3.1. Feature detection
The quality of the feature detection was measured using
the repeatability criterion. Assuming for each transformed

† Features without groundtruth correspondence (e.g. in regions in
the null shape corresponding to holes in the transformed shape) are
ignored.

c(cid:13) The Eurographics Association 2011.

Boyer et al. / SHREC’11: robust feature detection/description

Figure 1: Transformations of the human shape used in the tests (shown in strength 5, left to right): null, isometry, sampling,
rasterize, holes, micro holes, shot noise, noise, partial, view, scaling, afﬁne.

4. Feature detection methods
4.1. Point features
Harris 3D (Sipiran and Bustos [SB10]). The algorithm proposes 
an extension for meshes of the Harris corner detection 
method [HS88]. The algorithm suggests to determine
a neighborhood (rings or adaptive) around a vertex. Next,
this neighborhood is used to ﬁt a quadratic patch which is
considered as an image. After applying a gaussian smoothing,
 derivatives are calculated which are used to calculate
the Harris response for each vertex. In this benchmark, three
different conﬁgurations were used: adaptive neighborhoods
with δ = 0.01, 1-ring neighborhoods , and 2-ring neighborhoods.
 For details, see [SB10].

Mesh-DoG (Zaharescu et al. [ZBVH09] ). The method
considers the general setting of 2-D manifolds M embedded 
in R3 endowed in with a scalar function f : M → R,
such as colour or curvature. This represents a generalization 
of 2-D images, that can be viewed as a uniformly sampled 
square grid with vertices of valence 4. Operators, such
as the gradient and the convolution are deﬁned in this context.
 A scale-space representation of the scalar function f
is build using iterative convolutions with a Guassian kernel.
Feature detection consists of two steps. Firstly, the extrema
of the function’s Laplacian (approximated by taking the difference 
between adjacent scales - Difference of Gaussian)
are found across scales, followed by non-maximum suppression 
using a 1-ring neighbourhood both spatially and across
adjacent scales. Secondly, the detected extrema are thresholded 
(400 points). Mean and Gaussian curvature computed
using [MDSB02] were the scalar functions used for current
tests. For exact details and settings, see [ZBVH09].

Mesh SIFT (Smeets et al. [MFK∗10]). The Mesh SIFT
detector detects scale space extrema as local feature locations.
 First, a scale space is constructed containing smoothed
versions of the input mesh, which are obtained by subsequent 
convolutions of the mesh with a binomial ﬁlter. Next,
for the detection of salient points in the scale space, the mean

c(cid:13) The Eurographics Association 2011.

curvature H (Mesh SIFT-H) and the principal coordinates in
curvature space KK (Mesh SIFT-KK), which are minimal
and maximal curvature, are computed for each vertex and
at each scale in the scale space (Hi and KKi). Note that the
mesh is smoothed and not the function on the mesh (H or
KK). Scale space extrema in scale spaces of differences between 
subsequent scales (dHi = Hi+1 − Hi for Mesh SIFT-H
and dKKi = KKi+1 − KKi for Mesh SIFT-KK) are ﬁnally
selected as local feature locations.

Mesh-Scale DoG (Darom and Keller [DK11]) We follow
the work of Zaharescu et al. [ZBVH09] that presented a Difference 
of Gaussians based feature points detector for mesh
objects. We propose to deﬁne a Gaussian ﬁlter on the mesh
geometry, and compute a set of ﬁltered meshes. Consecutive 
octaves are subtracted to compute the DoG function, and
deﬁne the local maxima (both in location and scale) as our
feature points at that point and scale. In order to make the
detected features scale invariant, we suggest to set the support 
for each feature point to the width of the ﬁlter at that
scale. For details, see [DK11].

4.2. Region detectors
Shape MSER (Litman et al. [LBB10]). The algorithm ﬁnds
maximally stable components in 3D shapes, similarly to
the popular MSER method for feature analysis in images
[MCUP04]. The shape is represented as a component tree
based on vertexor 
edge-wise weighting function (VW and
EW, respectively). In this benchmark, three different weights
were used: edge weighting by inverse of commute time kernel 
(EW 1/CT) and inverse heat kernel (EW 1/HKS), and
vertex weighting by heat kernel diagonal (VW HKS). For
details, see [LBB10].

5. Feature description methods
5.1. Point descriptors
Mesh-HoG (Zaharescu et al. [ZBVH09] ). For a given interest 
point, the descriptor is computed using a geodesic supBoyer 
et al. / SHREC’11: robust feature detection/description

port region, proportional to 3% of the total surface area. For
each vertex in the neighbourhood, the 3-D gradient information 
is computed using f at the detected scale. As a ﬁrst step,
a local coordinate system is chosen, in order to make the descriptor 
rotation invariant. Then, a histogram of gradient is
computed, both spatially, at a coarse level, in order to maintain 
a certain high-level spatial ordering, and using orientations,
 at a ﬁner level. Since the gradient vectors are 3 dimensional,
 the histograms are computed in 3D. The histograms
are concatenated and normalized. A 96 dimensional descriptor 
is obtained. The gradient of the participating neighbouring 
vertices is computed at the scale of the detected interest
point. For exact details and settings, see [ZBVH09].

Scale Invariant Spin Image (Darom and Keller [DK11])
The Spin Image local descriptor was presented by Johnson
and Hebert [JH99], and has gained popularity due to its robustness 
and simplicity. Utilizing the local scale estimated
by the Mesh-Scale DoG detector, we propose to derive a
Scale Invariant Spin Image mesh descriptor, where we compute 
the Spin Image descriptor over the local scale estimated
at the interest point. This improves feature point matching,
in particular when the meshes are related signiﬁcant partial
matching. For details, see [DK11].

Local Depth SIFT (Darom and Keller [DK11]) The SIFT
algorithm, presented by D. Lowe [Low04] is a state-of-theart 
approach to computing scale and rotation invariant local
features in images. The SIFT descriptor is based on computing 
a local radial-angular histogram of the pixel value
derivatives. Inspired by Lowe’s seminal work, we propose to
compute a new local feature for 3D meshes we denote Local
Depth SIFT (LD-SIFT). Given an interest point we estimate
its tangent plane, and compute the distance from each point
on the surface to that plane to create a depth map, and set
the viewport size to match the feature scale, as detected by
the Mesh-Scale DoG detector. This makes our construction
scale invariant. We compute the PCA of the the points surrounding 
the interest point, and use their dominant direction
as the local dominant angle, and rotate the depth map to a
canonical angle based on the dominant angle. This makes the
LD-SIFT rotation invariant. We compute a SIFT feature descriptor 
on the resulting depth map to create the Local Depth
SIFT feature descriptor. For details, see [DK11].

5.2. Dense descriptors

Generalized HKS (Zobel et al. [ZRHar]). The Generalized
HKS is a generalization of the HKS [SOG09] to 1-forms
(where a 1-form can be regarded as vector ﬁeld). It is derived 
from the heat kernel for 1-forms in a similar way as
the HKS is derived from the heat kernel for functions. This
yields a symmetric tensor ﬁeld of second order with a time
parameter t. For easier comparability we consider scalar tensor 
invariants. For details see [ZRHar] or [Zob10].

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

97.75
35.50
73.50
96.50
96.50
98.00
98.25
99.25
98.25
98.25
95.50
89.75

≤2
98.13
37.75
59.50
96.88
95.75
98.00
98.75
99.13
98.00
97.25
96.38
88.68

Strength

≤3
97.92
36.17
50.67
96.83
95.50
98.00
98.50
98.50
98.00
97.17
96.33
87.60

≤4
97.94
34.19
44.72
96.88
95.38
98.00
98.13
98.25
97.87
90.06
97.00
86.22

≤5
97.70
30.85
42.06
96.65
95.20
98.00
97.45
97.95
97.75
89.50
96.70
85.44

Table 1: Repeatability (in %) at ρ = 5 of Mesh DoG (mean) feature
detection algorithm. Average number of detected points: 392.

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

99.00
29.50
76.00
98.25
94.00
99.00
98.00
99.75
98.25
98.75
92.50
89.36

≤2
99.38
30.66
61.00
98.25
92.88
99.00
98.25
99.50
98.13
96.38
92.75
87.83

Strength

≤3
98.58
31.03
50.50
98.08
92.42
99.00
98.00
99.00
98.00
95.33
92.08
86.55

≤4
98.69
29.08
43.68
97.94
92.19
99.00
97.69
98.75
97.88
85.31
92.94
84.83

≤5
97.70
26.17
39.77
97.10
91.65
99.00
96.90
98.60
97.75
82.90
94.10
83.79

Table 2: Repeatability (in %) at ρ = 5 of Mesh DoG (Gaussian)
feature detection algorithm. Average number of detected points:
391.

6. Results
6.1. Point feature detectors.

Tables 1–9 show the repeatability of different point descriptors 
at ﬁxed radius ρ = 5 (approximately 1% of the shape
diameter), broken down according to transformation classes
and strengths. Higher repeatability scores are indication of
better performance. Figures 2–3 show the repeatability of
point descriptors as function of geodesic distance varying
from 0 to 5.

6.2. Region feature detectors.

Tables 10–12 show the repeatability of different point descriptors 
at ﬁxed overlap of 0.7, broken down according to
transformation classes and strengths. Figure 4 shows the repeatability 
of region feature detectors as function of overlap
varying from 0 to 1.

c(cid:13) The Eurographics Association 2011.

Boyer et al. / SHREC’11: robust feature detection/description

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

99.75
98.25
99.62
99.75
99.25
99.92
99.73
99.94
99.74
99.91
99.97
99.62

≤2
99.83
98.28
99.61
99.76
99.29
99.92
99.83
99.92
99.75
99.88
99.89
99.63

Strength

≤3
99.85
98.23
99.52
99.70
99.26
99.92
99.83
99.92
99.74
99.90
99.88
99.61

≤4
99.87
98.26
99.40
99.67
99.25
99.92
99.83
99.92
99.71
99.82
99.84
99.59

≤5
99.87
98.17
99.52
99.61
99.20
99.92
99.83
99.91
99.71
99.85
99.84
99.58

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

50.11
34.37
41.13
51.79
51.91
51.86
52.25
52.70
51.62
62.46
41.88
49.28

≤2
51.63
35.44
40.03
51.67
52.42
51.47
52.34
52.74
52.17
67.70
47.84
50.49

Strength

≤3
51.74
34.73
38.64
52.53
52.30
51.45
52.33
52.72
51.91
64.49
46.60
49.95

≤4
51.62
34.72
38.63
52.21
52.54
51.68
52.08
52.33
51.65
56.13
48.99
49.32

≤5
51.86
34.97
38.18
51.63
52.32
51.58
52.09
52.34
51.76
49.17
49.89
48.71

Table 3: Repeatability (in %) at ρ = 5 of Mesh-Scale DoG (1) feature 
detection algorithm. Average number of detected points: 3616.

Table 6: Repeatability (in %) at ρ = 5 of Mesh SIFT (KK) feature
detection algorithm. Average number of detected points: 3786.

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

97.93
73.91
93.63
94.13
93.24
98.85
96.51
94.53
94.29
98.65
97.77
93.95

≤2
98.50
75.03
91.40
92.81
92.13
98.85
96.66
95.05
93.72
98.23
97.53
93.63

Strength

≤3
98.74
74.38
89.84
91.68
90.97
98.85
96.91
95.23
93.57
98.20
97.55
93.27

≤4
98.77
75.36
88.39
90.79
90.04
98.85
96.76
95.37
93.47
97.61
97.28
92.97

≤5
98.78
75.91
89.63
90.16
89.30
98.85
96.49
95.43
93.47
97.86
97.05
92.99

Table 4: Repeatability (in %) at ρ = 5 of Mesh-Scale DoG (2) feature 
detection algorithm. Average number of detected points: 1538.

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

49.18
31.93
40.59
53.71
50.00
49.73
51.38
53.91
50.77
62.26
42.59
48.73

≤2
50.20
31.98
40.09
51.78
50.05
51.44
51.27
53.94
53.56
67.72
48.78
50.07

Strength

≤3
50.38
32.03
37.97
52.31
50.65
51.80
51.33
53.17
52.88
63.65
47.51
49.42

≤4
50.81
31.93
36.71
52.33
51.36
51.77
51.36
52.57
52.32
54.13
49.47
48.61

≤5
51.03
31.57
35.82
52.29
51.14
51.21
51.23
52.51
51.96
47.32
49.93
47.82

Table 5: Repeatability (in %) at ρ = 5 of Mesh SIFT (H) feature
detection algorithm. Average number of detected points: 2564.

c(cid:13) The Eurographics Association 2011.

1

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

≤5
99.58
47.53
87.71
98.92
98.56
99.92
93.75
93.22
90.63
99.24
99.73
91.71
Table 7: Repeatability (in %) at ρ = 5 of Harris3D (ring 1) feature
detection algorithm. Average number of detected points: 449.

≤2
99.90
51.63
98.27
99.54
98.71
100.00
99.52
97.05
93.62
99.46
99.77
94.32

Strength
≤3
99.75
53.11
98.18
99.33
98.67
100.00
98.16
95.17
92.06
99.21
99.85
93.95

99.81
49.63
97.20
100.00
98.51
100.00
99.43
98.48
95.62
100.00
99.75
94.40

≤4
99.81
50.10
97.13
99.12
98.66
99.90
95.19
94.38
91.10
99.05
99.66
93.10

Strength

1

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

≤5
99.77
44.04
79.87
99.63
98.95
99.89
89.98
93.45
93.45
98.84
100.00
90.71
Table 8: Repeatability (in %) at ρ = 5 of Harris3D (ring 2) feature
detection algorithm. Average number of detected points: 449.

≤2
99.90
51.22
94.67
100.00
99.09
100.00
98.95
99.24
95.71
99.46
100.00
94.39

≤3
99.87
52.29
93.11
99.94
99.04
100.00
95.62
97.97
94.67
99.35
100.00
93.80

≤4
99.90
47.94
84.83
99.72
98.98
99.86
92.33
95.86
93.90
98.55
100.00
91.99

99.81
49.08
94.00
100.00
99.26
100.00
99.43
100.00
96.95
100.00
100.00
94.41

Boyer et al. / SHREC’11: robust feature detection/description

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

96.57
52.39
90.80
99.44
98.70
99.43
96.38
50.48
93.14
99.33
99.26
88.72

≤2
98.10
55.55
95.07
99.08
98.81
99.33
92.95
51.90
90.57
98.46
98.60
88.95

Strength

≤3
98.60
60.09
94.71
98.71
98.56
99.11
87.17
52.57
89.40
98.61
98.73
88.75

≤4
98.81
56.80
92.03
97.96
98.44
99.05
81.71
54.10
88.38
95.95
98.37
87.42

≤5
98.86
53.32
91.63
97.50
98.28
98.78
78.78
55.24
87.62
96.76
98.43
86.84

Table 9: Repeatability (in %) at ρ = 5 of Harris3D (Adaptive) feature 
detection algorithm. Average number of detected points: 449.

1

Strength
≤3
96.30
66.64
98.15
30.00
100.00
89.29
78.46
87.71
83.45
57.73
61.43
77.20

≤2
100.00
64.24
100.00
45.00
100.00
87.50
90.42
87.12
90.18
77.50
60.00
82.00

≤5
Transform.
Isometry
95.78
Rasterization
54.53
Sampling
58.89
Holes
24.34
Micro holes
84.07
Scaling
88.32
Afﬁne
75.21
Noise
81.47
Shot Noise
81.32
Partial
58.21
View
67.04
Average
69.92
Table 10: Repeatability (in %) at overlap ≥ 0.7 of Shape MSER
(EW 1/HKS) region detector algorithm. Average number of detected
regions: 12.36.

100.00
46.67
100.00
90.00
100.00
87.50
93.33
83.33
92.86
75.00
20.00
80.79

≤4
94.72
61.34
73.61
22.50
96.15
86.96
76.70
84.53
82.90
62.05
69.51
73.73

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1

88.89
77.78
92.31
100.00
100.00
14.29
90.91
88.89
100.00
83.33
11.11
77.05

≤2
94.44
78.17
96.15
50.00
100.00
57.14
88.31
86.11
95.83
84.52
38.89
79.05

Strength
≤3
92.13
78.78
97.44
33.33
96.30
71.43
87.08
90.74
78.17
64.68
37.83
75.26

≤4
94.10
65.91
73.08
25.00
90.97
78.57
87.81
93.06
81.13
63.10
46.55
72.66

≤5
92.78
56.36
58.46
20.00
80.78
82.86
88.03
90.44
72.90
58.48
49.74
68.26

Table 11: Repeatability (in %) at overlap ≥ 0.7 of Shape MSER
(EW 1/CT) region detector algorithm. Average number of detected
regions: 8.85.

1

Strength
≤3
95.83
57.41
95.83
29.17
100.00
87.50
76.52
87.50
81.02
59.52
55.68
75.09

≤2
100.00
61.11
100.00
43.75
100.00
87.50
87.50
87.50
82.64
75.00
56.25
80.11

≤5
Transform.
Isometry
95.00
Rasterization
45.87
Sampling
57.50
Holes
22.79
Micro holes
86.39
Scaling
85.00
Afﬁne
75.41
Noise
79.83
Shot Noise
79.72
Partial
54.05
View
60.50
Average
67.46
Table 12: Repeatability (in %) at overlap ≥ 0.7 of Shape MSER
(VW HKS) region detector algorithm. Average number of detected
regions: 9.25.

100.00
55.56
100.00
87.50
100.00
87.50
87.50
87.50
87.50
75.00
12.50
80.05

≤4
93.75
50.20
71.88
21.88
96.88
84.38
72.39
82.29
80.21
63.39
64.26
71.04

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1
0.17
1.00
0.93
0.23
0.30
0.20
0.52
1.00
0.23
0.30
0.64
0.50

≤2
0.17
1.00
0.95
0.24
0.31
0.20
0.63
0.99
0.24
0.36
0.59
0.52

Strength

≤3
0.19
0.99
0.96
0.26
0.33
0.20
0.68
0.99
0.25
0.37
0.61
0.53

≤4
0.19
0.99
0.97
0.29
0.34
0.20
0.72
0.99
0.26
0.46
0.60
0.55

≤5
0.21
0.99
0.98
0.32
0.35
0.20
0.75
0.99
0.27
0.49
0.60
0.56

Table 13: Quality of Mesh HoG feature description algorithm (average 
normalized L2 distance between descriptors at corresponding
points) on feature points detected using Mesh DoG (mean). Average
number of points: 392.

6.3. Point feature descriptors
Tables 13–18 show the performance of different point feature 
description algorithms, in terms of average normalized 
L2 distance between corresponding descriptors. Smaller
numbers correspond to better performance. Figure 5 shows
the ROC curves of different point feature descriptors, using
a ﬁxed value of ρ = 5. Higher values of the vertical axis at
a ﬁxed point on the horizontal axis are indication of better
performance.

6.4. Dense feature descriptors
Table 19 shows the performance of the GHKS dense feature 
description algorithm, in terms of normalized average
L2 distance between corresponding descriptors. Some results
could not be computed by the participants.

c(cid:13) The Eurographics Association 2011.

Boyer et al. / SHREC’11: robust feature detection/description

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1
0.15
0.98
0.95
0.21
0.29
0.19
0.58
0.98
0.22
0.32
0.69
0.51

≤2
0.15
0.98
0.97
0.23
0.30
0.19
0.66
0.99
0.23
0.40
0.62
0.52

Strength

≤3
0.17
0.99
0.97
0.27
0.32
0.19
0.71
0.99
0.24
0.40
0.65
0.54

≤4
0.17
0.99
0.98
0.30
0.34
0.19
0.74
0.99
0.25
0.48
0.65
0.55

≤5
0.19
0.99
0.98
0.34
0.35
0.19
0.78
0.99
0.26
0.51
0.63
0.56

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1
0.67
0.95
0.79
0.79
0.78
0.71
0.89
0.95
0.79
0.50
0.84
0.79

≤2
0.61
0.96
0.81
0.82
0.80
0.72
0.89
0.96
0.81
0.51
0.82
0.79

Strength

≤3
0.64
0.96
0.85
0.84
0.83
0.74
0.91
0.97
0.82
0.57
0.83
0.81

≤4
0.65
0.96
0.87
0.86
0.84
0.75
0.92
0.98
0.83
0.61
0.83
0.83

≤5
0.64
0.96
0.90
0.87
0.86
0.76
0.94
0.98
0.84
0.63
0.83
0.84

Table 14: Quality of Mesh HoG feature description algorithm (average 
normalized L2 distance between descriptors at corresponding
points) on feature points detected using Mesh DoG (Gaussian). Average 
number of points: 391.

Table 16: Quality of Local depth SIFT feature description algorithm 
(average normalized L2 distance between descriptors at
corresponding points) on feature points detected using Mesh-Scale
DoG (2). Average number of points: 1538.

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1
0.63
0.94
0.74
0.71
0.70
0.68
0.87
0.95
0.70
0.46
0.76
0.74

≤2
0.56
0.94
0.77
0.73
0.74
0.70
0.88
0.96
0.73
0.47
0.74
0.75

Strength

≤3
0.58
0.94
0.81
0.75
0.76
0.72
0.90
0.97
0.76
0.53
0.75
0.77

≤4
0.59
0.94
0.84
0.77
0.78
0.74
0.91
0.98
0.78
0.57
0.74
0.79

≤5
0.59
0.94
0.87
0.78
0.80
0.75
0.93
0.98
0.80
0.59
0.74
0.80

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1
0.26
0.88
0.62
0.36
0.84
0.24
0.60
0.96
0.41
0.78
0.50
0.58

≤2
0.52
0.87
0.66
0.39
0.85
0.24
0.74
0.97
0.48
0.77
0.45
0.63

Strength

≤3
0.61
0.87
0.70
0.42
0.86
0.24
0.75
0.98
0.52
0.78
0.46
0.65

≤4
0.52
0.87
0.75
0.45
0.87
0.24
0.76
0.98
0.56
0.69
0.46
0.65

≤5
0.57
0.87
0.79
0.47
0.87
0.24
0.79
0.99
0.60
0.62
0.45
0.66

Table 15: Quality of Local depth SIFT feature description algorithm 
(average normalized L2 distance between descriptors at
corresponding points) on feature points detected using Mesh-Scale
DoG (1). Average number of points: 3616.

Table 17: Quality of Scale invariant Spin Image feature description 
algorithm (average normalized L2 distance between descriptors 
at corresponding points) on feature points detected using MeshScale 
DoG (1). Average number of points: 3616.

c(cid:13) The Eurographics Association 2011.

Boyer et al. / SHREC’11: robust feature detection/description

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View
Average

1
0.29
0.91
0.67
0.50
0.89
0.26
0.64
0.93
0.51
0.80
0.63
0.64

≤2
0.55
0.90
0.71
0.55
0.90
0.26
0.77
0.95
0.55
0.80
0.58
0.68

Strength

≤3
0.64
0.89
0.74
0.59
0.90
0.26
0.77
0.96
0.58
0.80
0.60
0.70

≤4
0.55
0.89
0.78
0.62
0.91
0.26
0.78
0.96
0.60
0.72
0.59
0.70

≤5
0.60
0.90
0.82
0.65
0.92
0.26
0.81
0.97
0.62
0.66
0.59
0.71

Table 18: Quality of Scale invariant Spin Image feature description 
algorithm (average normalized L2 distance between descriptors 
at corresponding points) on feature points detected using MeshScale 
DoG (2). Average number of points: 1538.

Transform.
Isometry
Rasterization
Sampling
Holes
Micro holes
Scaling
Afﬁne
Noise
Shot Noise
Partial
View

1
0.57

–

0.73

–
–

0.62
1.08
3.24
0.89
0.80

–

Strength

≤3
0.62

–

0.86

–
–

0.65
1.46
3.37
1.21
1.12

–

≤4
0.62

–

0.94

–
–

0.65
1.61
3.34
1.33
1.10

–

≤5
0.65

–

0.92

–
–

0.75
1.77
3.32
1.40
1.15

–

≤2
0.58

–

0.74

–
–

0.61
1.32
3.37
1.03
0.97

–

Table 19: Quality of GHKS feature description algorithm (average 
normalized L2 distance between descriptors at corresponding
points).

References
[BBB∗11] BOYER E., BRONSTEIN A. M., BRONSTEIN M. M.,
BUSTOS B., DAROM T., HORAUD R., HOTZ I., KELLER Y.,
KEUSTERMANS J., KOVNATSKY A., LITMAN R., REININGHAUS 
J., SIPIRAN I., SMEETS D., SUETENS P., VANDERMEULEN 
D., ZAHARESCU A., ZOBEL V.: SHREC 2011: robust 
feature detection and description benchmark. In Proc. 3DOR
(20011). 2

[BBK08] BRONSTEIN A. M., BRONSTEIN M. M., KIMMEL R.:

Numerical geometry of non-rigid shapes. Springer, 2008. 2

[DK11] DAROM T., KELLER Y.: Scale invariant features for 3d

mesh models. 3, 4

[HS88] HARRIS C., STEPHENS M.: A combined corner and edge
detection. In Proc. of The Fourth Alvey Vision Conference (1988),
pp. 147–151. 3

[JH99]

JOHNSON A. E., HEBERT M.: Using spin images for efIEEE 
Trans.

ﬁcient object recognition in cluttered 3d scenes.
Pattern Anal. Mach. Intell. 21, 5 (1999), 433–449. 4

[LBB10] LITMAN R., BRONSTEIN A., BRONSTEIN M.:
Diffusion-geometric maximally stable component detection in
deformable shapes. Arxiv preprint arXiv:1012.3951 (2010). 3

[Low04] LOWE D.: Distinctive image features from scaleinvariant 
keypoints. IJCV 60, 2 (2004), 91–110. 1, 4

[MCUP04] MATAS J., CHUM O., URBAN M., PAJDLA T.: Robust 
wide-baseline stereo from maximally stable extremal reImage 
and Vision Computing 22, 10 (2004), 761–767.
gions.
3

[MDSB02] MEYER M., DESBRUN M., SCHRÖDER P., BARR
A. H.: Discrete differential geometry operators for triangulated
2-dimensional manifolds. In Proceedings of VisMath (2002). 3
[MFK∗10] MAES C., FABRY T., KEUSTERMANS J., SMEETS
D., SUETENS P., VANDERMEULEN D.: Feature detection on 3D
In Proc.
face surfaces for pose normalisation and recognition.
BTAS (2010). 3

[MS05] MIKOLAJCZYK K., SCHMID C.: A performance evaluation 
of local descriptors. Trans. PAMI (2005), 1615–1630. 1

[SB10] SIPIRAN I., BUSTOS B.: A robust 3D interest points detector 
based on Harris operator. In Proc. Eurographics Workshop
on 3D Object Retrieval (2010), Eurographics Association, pp. 7–
14. 3

[SOG09] SUN J., OVSJANIKOV M., GUIBAS L.: A concise and
provably informative multi-scale signature based on heat difIn 
Eurographics Symposium on Geometry Processing
fusion.
(SGP) (2009). 4

[SZ03] SIVIC J., ZISSERMAN A.: Video Google: A text retrieval
approach to object matching in videos. In Proc. ICCV (2003),
vol. 2, pp. 1470–1477. 1

[ZBVH09] ZAHARESCU A., BOYER E., VARANASI K., HORAUD 
R.: Surface feature detection and description with applications 
to mesh matching. 3, 4

[Zob10] ZOBEL V.: Spectral Analysis of the Hodge Laplacian on

Discrete Manifolds. Master Thesis, 2010. 4

[ZRHar] ZOBEL V., REININGHAUS J., HOTZ I.: Generalized
heat kernel signature. Journal of WSCG, International Conference 
on Computer Graphics, Visualization and Computer Vision
(2011 to appear). 4

c(cid:13) The Eurographics Association 2011.

Boyer et al. / SHREC’11: robust feature detection/description

Mesh DoG (mean)

Mesh DoG (Gaussian)

Mesh-Scale DoG (1)

IMesh-Scale DoG (2)

Mesh SIFT (H)

Mesh SIFT (KK)

Figure 2: Repeatability (%) vs distance of point feature detectors broken down according to different transformation classes.

c(cid:13) The Eurographics Association 2011.

affineholesisometrymicroholesnoisepartialrasterizesamplingscalingshotnoiseviewAVERAGE00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)Boyer et al. / SHREC’11: robust feature detection/description

3D Harris (ring 1)

3D Harris (ring 2)

Figure 3: Repeatability (%) vs distance of point feature detectors broken down according to different transformation classes.

3D Harris (adaptive)

c(cid:13) The Eurographics Association 2011.

affineholesisometrymicroholesnoisepartialrasterizesamplingscalingshotnoiseviewAVERAGE00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)00.511.522.533.544.550102030405060708090100distancerepeatability (%)Boyer et al. / SHREC’11: robust feature detection/description

Shape MSER (EW 1/CT)

Shape MSER (EW 1/HKS)

Figure 4: Repeatability (%) vs overlap of region feature detectors broken down according to different transformation classes.

Shape MSER (VW HKS)

c(cid:13) The Eurographics Association 2011.

affineholesisometrymicroholesnoisepartialrasterizesamplingscalingshotnoiseviewAVERAGE00.20.40.60.810102030405060708090100overlaprepeatability (%)  00.20.40.60.810102030405060708090100overlaprepeatability (%)  00.20.40.60.810102030405060708090100overlaprepeatability (%)  Boyer et al. / SHREC’11: robust feature detection/description

Mesh HoG (mean)

Mesh HoG (2)

Local depth SIFT (1)

Local depth SIFT (2)

Scale invariant Spin Image (1)

Scale invariant Spin Image (2)

Figure 5: ROC curves of point feature descriptors broken down according to different transformation classes.

c(cid:13) The Eurographics Association 2011.

affineholesisometrymicroholesnoisepartialrasterizesamplingscalingshotnoiseviewAVERAGE10−210−110000.10.20.30.40.50.60.70.80.91TPRFPR10−210−110000.10.20.30.40.50.60.70.80.91TPRFPR10−210−110000.10.20.30.40.50.60.70.80.91TPRFPR10−210−110000.10.20.30.40.50.60.70.80.91TPRFPR10−210−110000.10.20.30.40.50.60.70.80.91TPRFPR10−210−110000.10.20.30.40.50.60.70.80.91TPRFPR