Probabilistic Proximity Searching Algorithms

Based on Compact Partitions(cid:1)

Benjamin Bustos2 and Gonzalo Navarro1,2

2 Departamento de Ciencias de la Computaci´on, Universidad de Chile

1 Center for Web Research

Blanco Encalada 2120, Santiago, Chile
{bebustos,gnavarro}@dcc.uchile.cl

Abstract. The main bottleneck of the research in metric space searching 
is the so-called curse of dimensionality, which makes the task of
searching some metric spaces intrinsically diﬃcult, whatever algorithm
is used. A recent trend to break this bottleneck resorts to probabilistic algorithms,
 where it has been shown that one can ﬁnd 99% of the elements
at a fraction of the cost of the exact algorithm. These algorithms are welcome 
in most applications because resorting to metric space searching
already involves a fuzziness in the retrieval requirements. In this paper
we push further in this direction by developing probabilistic algorithms
on data structures whose exact versions are the best for high dimensions.
As a result, we obtain probabilistic algorithms that are better than the
previous ones. We also give new insights on the problem and propose
a novel view based on time-bounded searching.

1 Introduction

The concept of proximity searching has applications in a vast number of ﬁelds,
for example: multimedia databases, machine learning and classiﬁcation, image
quantization and compression, text retrieval, computational biology, function
prediction, etc. All those applications have in common that the elements of
the database form a metric space [6], that is, it is possible to deﬁne a positive 
real-valued function d among the elements, called distance or metric, that
satisﬁes the properties of strict positiveness (d(x, y) = 0 ⇔ x = y), symmetry
(d(x, y) = d(y, x)), and triangle inequality (d(x, z) ≤ d(x, y) + d(y, z)). For example,
 a vector space is a particular case of metric space, where the elements are
tuples of real numbers and the distance function belongs to the Ls family, deﬁned 
as Ls ((x1, . . . , xk), (y1, . . . , yk)) =
. For example, L2
is the Euclidean distance.

1≤i≤k |xi − yi|s

One of the typical queries that can be posed to retrieve similar objects from
a database is a range query, which retrieves all the elements within distance r to
a query object q. An easy way to answer range queries is to make an exhaustive

(cid:1)(cid:2)

(cid:3)1/s

(cid:1) Work supported by the Millenium Nucleus Center for Web Research, Grant P01-

029-F, Mideplan, Chile.

A.H.F. Laender and A.L. Oliveira (Eds.): SPIRE 2002, LNCS 2476, pp. 284–297, 2002.
c(cid:2) Springer-Verlag Berlin Heidelberg 2002

Probabilistic Proximity Searching Algorithms Based on Compact Partitions

285

search on the database, but this turns out to be too expensive for real-world
applications, because the distance d is considered expensive to compute. Think,
for example, of a biometric device that computes the distance between two ﬁngerprints.


Proximity searching algorithms build an index of the database and perform
range queries using this index, avoiding the exhaustive search. Many of these
algorithms are based on dividing the space in partitions or zones as compact as
possible. Each zone stores a representative point, called the center, and a few
extra data that permit quickly discarding the entire zone at query time, without
measuring the actual distance from the elements of the zone to the query object,
hence saving distance computations. Other algorithms are based in the use of
pivots, which are distinguished elements from the database and are used together
with the triangle inequality to ﬁlter out elements of the database at query time.
An inherent problem of proximity searching in metric spaces is that the
search becomes more diﬃcult when the “intrinsic” dimension of the metric space
increases, which is known as the curse of dimensionality. The intrinsic dimension
of a metric space is deﬁned in [6] as µ2/2σ2, where µ and σ2 are the mean and the
variance of the distance histogram of the metric space. This is coherent with the
usual vector space deﬁnition. Analytical lower bounds and experiments [6] show
that all proximity searching algorithms degrade their performance systematically
as the dimension of the space grows. For example, in the case of vector space
there is no technique that can reasonably cope with dimension higher than 20 [6].
This problem is due to two possible reasons: high dimensional metric spaces
have a very concentrated distance histogram, which gives less information for
discarding elements at query time; on the other hand, in order to retrieve a ﬁxed
fraction of the elements of the space it is necessary to use a larger search radius,
because in high dimensional spaces the elements are “far away” from each other.
Probabilistic algorithms are acceptable in most applications that need to
search in metric spaces, because in general the modelization as a metric space
already carries some kind of relaxation. In most cases, ﬁnding some close elements 
is as good as ﬁnding all of them.

There exists a pivot-based probabilistic proximity searching algorithm which
largely improves the search time at the cost of missing few elements [5]. On the
other hand, it is known that compact partitioning algorithms perform better
than pivot-based algorithms in high dimensional metric spaces [6] and they have
lower memory requirements.

In this paper we present several probabilistic algorithms for proximity searching 
based on compact partitions, which alleviate in some way the curse of the
dimensionality. We also present experimental results that show that these algorithms 
perform better than probabilistic algorithms based on pivots, and the
latter needs much more memory space to beat the former when the dimension
of the space is very high.

