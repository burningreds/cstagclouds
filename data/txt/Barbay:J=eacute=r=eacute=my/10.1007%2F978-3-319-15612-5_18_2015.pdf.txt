Dynamic Online Multiselection

in Internal and External Memory

J´er´emy Barbay1,(cid:2), Ankur Gupta2,(cid:2)(cid:2), Srinivasa Rao Satti3,(cid:2) (cid:2) (cid:2),

and Jonathan Sorenson2

1 Departamento de Ciencias de la Computaci´on (DCC)

Universidad de Chile
jeremy@jbarbay.cl

2 Department of Computer Science and Software Engineering

Butler University

{agupta,jsorenso}@butler.edu

3 School of Computer Science and Engineering

Seoul National University

ssrao@cse.snu.ac.kr

Abstract. We consider the dynamic version of the online multiselection
problem for internal and external memory, in which q selection queries
are requested on an unsorted array of N elements. Our internal memory
result is 1-competitive with the oﬄine result of Kaligosi et al.[ICALP
2005]. In particular, we extend the results of Barbary et al.[ESA 2013]
by supporting arbitrary insertions and deletions while supporting online
select and search queries on the array. Assuming that the insertion of
an element is immediately preceded by a search for that element, we
show that our dynamic online algorithm performs an optimal number of
comparisons, up to lower order terms and an additive O(N ) term.

For the external memory model, we describe the ﬁrst online multiselection 
algorithm that is O(1)-competitive. This result improves upon
the work of Sibeyn [Journal of Algorithms 2006] when q > m, where m is
the number of blocks that can be stored in main memory. We also extend
it to support searches, insertions, and deletions of elements eﬃciently.

1

Introduction

The multiselection problem asks for elements of rank ri from the sequence R =
(r1, r2, . . . , rq) on an unsorted array A of size N drawn from an ordered universe
of elements. We deﬁne B(Sq) as the information-theoretic lower bound on the
number of comparisons required in the comparison model to answer q queries,

(cid:2) Supported by Project Regular Fondecyt number 1120054.
(cid:2)(cid:2) Supported in part by the Butler Holcomb Awards grant and the Arete Initiative.
(cid:2) (cid:2) (cid:2) Supported by Basic Science Research Program through the National Research
Foundation of Korea (NRF) funded by the Ministry of Education, Science and
Technology (Grant number 2012-0008241).

M.S. Rahman and E. Tomita (Eds.): WALCOM 2015, LNCS 8973, pp. 199–209, 2015.
c(cid:2) Springer International Publishing Switzerland 2015

200

J. Barbay et al.

where Sq = {si} denotes the queries ordered by rank. We deﬁne Δi = si+1 − si,
where s0 = 0 and sq+1 = N . Then,
B(Sq) = log N ! − q(cid:2)

− O(N ).1

q(cid:2)

N
Δi

log (Δi!) =

Δi log

i=0

i=0

The online multiselection problem asks for elements of rank ri, where the sequence 
R is given one element at a time. The lower bound B(Sq) also applies to
search queries in the oﬄine model, as well as both types of queries in the online
model.

The dynamic online multiselection problem supports the search, insert and

delete operations, described below:
– select (r), returns the position of the r-th element in A;
– search(a), returns the position of the largest element y ≤ a from A;
– insert (a), inserts a into A; and
– delete(i), deletes the ith sorted entry from A.

1.1 Previous Work

The oﬄine multiselection problem has been well-studied for the internal memory
model [DM81, Pro95, JM10]. Kaligosi et al. [KMMS05] give an optimal oﬄine
algorithm that uses B(Sq)+o(B(Sq)+O(N ) comparisons. In the external memory
model [AV88] with parameters M and B, we deﬁne n = N/B and m = M/B.
Sibeyn [Sib06] solves external multiselection using n + nq/m1− I/Os, where  is
any positive constant. The ﬁrst term comes from creating a static index structure
using n I/Os, and the reminder nq/m1− comes from answering q searches using
that index. In addition, this result requires the condition that B ∈ Ω(logm n).
When q = m, Sibeyn’s multiselection algorithm takes O(nm) I/Os, whereas
the optimum is Θ(n) I/Os. In fact, his bounds are within ω(Bm(Sq)), for any
q ≥ m, where Bm(Sq) is the lower bound on the number of I/Os required (see
Section 4.1 for the deﬁnition of Bm(Sq)).

Motwani and Raghavan [MR86] introduced the static online multiselection
problem, where the selection and search queries arrive online, as a “Deferred
Data Structure” for sorting (i.e., the input array is sorted over time, as queries
are answered). They also described deferred data structures for some other problems 
in computational geometry. Barbay et al. [BGJ+13] described a simpler
solution and reﬁned their analysis so that it matches the oﬄine results from
Kaligosi et al. [KMMS05]. Ching et al. [YTC90] extended Motwani and Ragha-
van’s solution [MR86] to add the support of the insertion and deletion operators,
with optimal amortized complexity in the worst case over instances with a ﬁxed
number q of queries. Our solution is simpler, and our analysis ﬁner, in the worst
case over instances where the positions hit by the queries are ﬁxed. To the best
of our knowledge, there are no existing dynamic results for the multiselection
problem in the external memory model.

1 We use logb a to refer to the base b logarithm of a. By default, we let b = 2.

Dynamic Online Multiselection in Internal and External Memory

201

1.2 Our Results

log N ) comparisons.2

For the dynamic online multiselection problem in internal memory, we describe
the ﬁrst algorithm that supports a sequence R of q selection, search, insert,
are search, insert, and delete, using B(Sq) +
and delete operations, of which q(cid:3)
o(B(Sq)) + O(N + q(cid:3)
For the external memory model [AV88], we describe an online multiselection
algorithm on an unsorted array stored on disk in n blocks, using O(Bm(Sq))
I/Os, where Bm(Sq) is a lower bound on the number of I/Os required to support
the given queries. This result improves upon the work of Sibeyn [Sib06] when
q > m, where m is the number of blocks that can be stored in main memory. We
also extend it to support search, insert, and delete operations using O(Bm(Sq) +
q logB N ) I/Os.

2 Background

Our dynamic online multiselection algorithm is an extension of the static algorithm 
of Barbay et al. [BGJ+13]. To describe our algorithm, we ﬁrst start by
brieﬂy describing their algorithm in this section. For complete details, we refer
the reader to the description of the static solution [BGJ+13].

2.1 Terminology
We call an element A[i] at position i in array A a pivot if A[1 . . . i − 1] < A[i] ≤
A[i + 1 . . . n].

Query and Pivot Sets. Let R denote a sequence of q selection queries, ordered
by time of arrival. Let St = {s1, s2, . . . , st} denote the ﬁrst t queries from R,
sorted by position. We also include s0 = 1 and st+1 = n in St for convenience of
notation, since the minimum and maximum are found during preprocessing. Let
Pt = {pi} denote the set of k pivots found by the algorithm when processing St,
sorted by position. Note that p1 = 1, pk = n, V[pi] = 1 for all i, and St ⊆ Pt.

Pivot Tree and Recursion Depth. The pivots chosen by the algorithm form a
binary tree structure, deﬁned as the pivot tree T of the algorithm over time.3
Pivot pi is the parent of pivot pj if, after pi was used to partition an interval, pj
was the pivot used to partition either the right or left half of that interval. The
root pivot is the pivot used to partition A[2..n − 1] due to preprocessing. The
recursion depth, d(pi), of a pivot pi is the length of the path in the pivot tree
from pi to the root pivot. All leaves in the pivot tree are also selection queries,
but it may be the case that a query is not a leaf.
2 For the dynamic result, we make the (mild) assumption that the insertion of an
element is immediately preceded by a search for that element. In that case, we show
that our dynamic online algorithm performs an optimal number of comparisons, up
to lower order terms and an additive O(N ) term.

3 Intuitively, a pivot tree corresponds to a recursion tree, since each node represents

one recursive call made during the quickselect algorithm [Hoa61].

202

J. Barbay et al.

Intervals. Each pivot was used to partition an interval in A. Let I(pi) denote the
interval partitioned by pivot pi, and let |I(pi)| denote its length. Such intervals
form a binary tree induced by their pivots. If pi is an ancestor of pivot pj then
I(pj) ⊂ I(pi). The recursion depth of an array element is the recursion depth
of the smallest interval containing that element, which in turn is the recursion
depth of its pivot.

Gaps. Deﬁne the query gap ΔSt
pi+1 − pi. By telescoping we have

(cid:3)q

ΔSt

i =

i=1

i = si+1 − si and similarly the pivot gap ΔPt

i =

(cid:3)k

j=1

j = n − 1.
ΔPt

2.2 Description of the Static Algorithm

For the sake of completeness, we brieﬂy outline the following lemma from Barbay 
et al. [BGJ+13], which describes the optimal online multiselection algorithm
for static data:

Lemma 1 (Static Online Multiselection [BGJ+13]). Given an unsorted
array A of N elements, there exists an algorithm that supports a sequence R of q
online selection queries using B(Sq)(1+o(1))+O(N ) comparisons and O(B(Sq))
time in the worst case.

Barbay et al. [BGJ+13] describe a variant of the static algorithm from Kaligosi
et al. [KMMS05]. Both solutions consider runs, which are sorted sequences from A
of length roughly (cid:7) = 1+(cid:7)log(d(p)+1)(cid:8) in the interval I(p). They use a bitvector W
to identify the endpoints of runs within each interval. Then, they compute the
median μ of the medians of these sequences, and partition the runs based on μ.
After partitioning, they recurse on the two sets of runs, sending select queries to
the appropriate side of the recursion. To maintain the invariant on run length on
the recursions, they merge short runs of the same size optimally until all but (cid:7)
of the runs are again of length between (cid:7) and 2(cid:7).
To perform the operation A.select (s), they ﬁrst use bitvector V to identify the
interval I containing s. If |I| ≤ 4(cid:7)2, they sort the interval I (making all elements
of I pivots) and answer the query s. Otherwise, they compute the value of (cid:7) for
the current interval, and proceed as in Kaligosi et al. [KMMS05] to answer the
query s.

3 Optimal Online Dynamic Multiselection

In this section, we support insertions and deletions on the array, as well as
selection and search queries. We are originally given the unsorted list A. To
support insert and delete eﬃciently, we maintain newly-inserted elements in a
separate data structure, and mark deleted elements in A. These insert and delete
operations are occasionally merged to make the array A up-to-date. Let A(cid:3)
denote
the current array with length N(cid:3)
. We support two additional operations:
– insert (a), which inserts a into A(cid:3)
– delete(i), which deletes the ith sorted entry from A(cid:3)

, and;

.

Dynamic Online Multiselection in Internal and External Memory

203

3.1 Preliminaries

Our solution uses the dynamic bitvector of Hon et al. [HSS03]. This structure
supports the following operations on a dynamic bitvector V. The rank b(i) operation 
tells the number of b bits up to the ith position in V. The select b(i) operation
gives the position in V of the ith b bit. The insert b(i) operation inserts bit b in
the ith position. The delete(i) operation deletes the bit in the ith position. The
ﬂip(i) operation ﬂips the bit in the ith position.
Note that one can determine the ith bit of V by computing rank 1(i)−rank 1(i−
1). (For convenience, we assume that rank b(−1) = 0.) The result of Hon et
al. [HSS03, Theorem 1] can be re-stated as follows, for the case of maintaining
a dynamic bit vector (the result of [HSS03] is stated for a more general case).

Lemma 2 ([HSS03]). Given a bitvector V of length N , there exists a data
structure that takes N + o(N ) bits and supports rank b and select b in O(logt N )
time, and insert , delete and ﬂip in O(t) time, for any t where (log N )O(1) ≤
t ≤ N . This structure assumes access to a precomputed table of size N , for any
ﬁxed  > 0.

All the pivots (and their positions) generated during select , search, insert , and
delete operations on array A are maintained as in Barbay et al. [BGJ+13] using
a bitvector V. In addition, we also maintain two bitvectors, each of length N(cid:3)
:
(i) an insert bitvector I such that I[i] = 1 if and only if A(cid:3)
[i] is newly inserted,
and (ii) a delete bitvector D such that if D[i] = 1, the ith element in A has been
deleted. If a newly inserted item is deleted, it is removed from I directly. Both I
and D are implemented as instances of the data structure described in Lemma 2.
We maintain the values of the newly inserted elements in a balanced binary
search tree T . The inorder traversal of the nodes of T corresponds to the increasing 
order of their positions in A(cid:3)
. We support the following operations on
this tree: (i) given an index i, return the element corresponding to the ith node
in the inorder traversal of T , and (ii) insert/delete an element at a given inorder
position. By maintaining the subtree sizes of the nodes in T , these operations
can be performed in O(log N ) time without having to perform any comparisons
between the elements.

tors I and D are each initialized to N 0s. The tree T is initially empty.

Our preprocessing steps are the same as in the static case. In addition, bitvecAfter 
performing |A| insert and delete operations, we merge all the elements in
T with the array A, modify the bitvector B appropriately, and reset the bitvectors
I and D (with all zeroes). This increases the amortized cost of the insert and
delete operations by O(1), without requiring additional comparisons.

3.2 Dynamic Online Multiselection
We now describe how to support the operators A(cid:3).insert(a), A(cid:3).delete(i),
A(cid:3).select (i), and A(cid:3).search(a).

J. Barbay et al.

).

= j(cid:3) − D.rank 1(j(cid:3)
) and D.insert 0(j(cid:3)(cid:3)

204
A(cid:3).insert (a). First, we search for the appropriate unsorted interval [(cid:7), r] containing 
a, using a binary search on the original (unsorted) array A. Now perform
A.search(a) on interval [(cid:7), r] (choosing which subinterval to expand based on the
insertion key a) until a’s exact position j in A is determined. The original array A
must have chosen as pivots the elements immediately to its left and right (positions 
j − 1 and j in array A); hence, one never needs to consider newly-inserted
pivots when choosing subintervals. Insert a in sorted order in T at position
I.select 1(j) among all the newly-inserted elements. Calculate j(cid:3)
= I.select 0(j),
and set a’s position to j(cid:3)(cid:3)
). Finally, we update our bitvectors
by performing I.insert 1(j(cid:3)(cid:3)
). Note that, apart from the search
operation, no other operation in the insertion procedure performs comparisons
between the elements.
A(cid:3).delete(i). Compute i(cid:3)
then remove the node (element) with inorder number I.rank 1(i(cid:3)
form I.delete(i(cid:3)
In other words, we mark position i(cid:3)
element may not be in its proper place.4
A(cid:3).select (i). If I[i] = 1, return the element corresponding to the node with
= I.rank 0(i)−D.rank 1(i),
inorder number I.rank 1(i) in T . Otherwise, compute i(cid:3)
and return A.select (i(cid:3)
A(cid:3).search(a). Search for the unsorted interval [(cid:7), r] containing a using a binary
search on the original (unsorted) array A. Then perform A.search(a) on interval 
[(cid:7), r] until a’s exact position j is found. If a appears in A (which we discover
through search), we need to check whether it has been deleted. We compute
j(cid:3)
. Otherwise,
it is possible that the item has been newly-inserted. Compute p = I.rank 1(j(cid:3)
),
which is the number of newly-inserted elements that are less than or equal to a.
If T [p] = a, then return j(cid:3)(cid:3)

is newly-inserted (i.e., I[i(cid:3)
] = 1),
) from T . Peris 
an older entry, perform D.ﬂip(i(cid:3)
).
in A as deleted even though the corresponding

= D.select 0(i). If i(cid:3)
). If instead i(cid:3)

) and D.delete(i(cid:3)

= I.select 0(j) and j(cid:3)(cid:3)

= j(cid:3) − D.rank 1(j(cid:3)

). If D[j(cid:3)

] = 0, return j(cid:3)(cid:3)

; otherwise, return failure.

We now analyze the above algorithm to show that the above algorithm achieves

the comparison cost as in Theorem 1, and a running time as in Corollary 1.
Theorem 1 (Dynamic Online Multiselection). Given an unsorted array A(cid:3)
of N elements, we provide a dynamic online algorithm that can support q ∈ O(N )
select , search, insert, and delete operations, of which r are search, insert , or
delete, using at most B(Sq)(1 + o(1)) + O(N + r log N ) comparisons.
Proof. Let N(cid:3)
, after a sequence
of queries and insertions. Let Q be the sequence of q selection operations performed 
(either directly or indirectly through other operations) on A(cid:3)
, ordered by
time of arrival. Let Sq be the queries of Q, ordered by position. We now analyze

denote the current length of the dynamic array A(cid:3)

4 If a user wants to delete an item with value a, one could simply search for it ﬁrst to

discover its rank, and then delete it using this function.

Dynamic Online Multiselection in Internal and External Memory

205

the number of comparisons performed by a sequence of queries and insert and
delete operations.

We consider the case when the number of insert and delete operations is less
than N . In other words, we are between two re-buildings of our dynamic data structure.
 Recall that each of the r search, insert, and delete operations in the sequence
will perform a constant number of search operations. To execute these searches,
we require O(r log N(cid:3)
) comparisons. Note that our algorithm does not perform any
comparisons for delete(i) operations, until some other query is in the same interval
as i. The deleted element will participate in the other costs (merging, pivot-ﬁnding,
and partitioning) for these other queries, but its contribution can be bounded by
O(log N ), which we have as a credit.

Since a delete operation does not perform any additional comparisons beyond
those needed to perform a search, we assume that all the updates are insertions in
the rest of this section. Since each inserted element becomes a pivot immediately,
it does not contribute to the comparison cost of any other select operation. Also,
note that in the algorithm of Lemma 1, no pivot is part of a run and hence cannot
aﬀect the choice of any future pivot.

Since Q is essentially a set of q selection queries, we can bound its total
comparison cost for selection queries by Lemma 1, which gives a bound of
(cid:9)(cid:10)
B(Sq)(1 + o(1)) + O(N ). This proves the theorem.

By modifying Theorem 1 to account for the costs of the dynamic bit vector

from Lemma 2, we obtain the following result.
Corollary 1. Given a dynamic array A(cid:3)
of N original elements, there exists a
dynamic online data structure that can support q = O(N ) select , search, insert,
and delete operations, of which r are search, insert and delete and u of which
are insert and delete, we provide a deterministic online algorithm that uses time
within O(B(Sq) + q logt N + r log N + ut), for any t where (log N )O(1) ≤ t ≤ N .

4 External Online Multiselection

In the external memory model, we consider only two memory levels: the internal
memory of size M , and the (unbounded) disk memory, which operates by reading
and writing data in blocks of size B. We refer to the number of items of the input
by N . For convenience, we deﬁne n = N/B and m = M/B as the number of
blocks of input and memory, respectively. We make the reasonable assumption
that 1 ≤ B ≤ M/2. In this model, we assume that each I/O read or write is
charged one unit of time, and that an internal memory operation is charged no
units of time. To achieve the optimal sorting bound of SortIO(N ) ∈ Θ(n logm n)
in this setting, it is necessary to make the tall cache assumption [BF03]: M ∈
Ω(B1+), for some constant  > 0, and we will make this assumption for the
remainder of the paper.

Suppose we are given an unsorted array A of length N stored in n = N/B
blocks in the external memory. The techniques that we use in internal memory
are not immediately applicable to the external memory model: in the extreme

206

J. Barbay et al.

case where we have q = N queries, the internal memory solution would require 
O(n log2(n/m)) I/Os. This compares poorly to the optimal O(n logm n)
I/Os performed by the optimal mergesort algorithm for external memory.

4.1 A Lower Bound for Multiselect in External Memory

As in the case of internal memory, the lower bound on the number of I/Os
required to perform a given set of selection queries can be obtained by subtracting
the number of I/Os required to sort the elements between the ‘query gaps’ from
the sorting bound. More speciﬁcally, let St = {si} be the ﬁrst t queries from a
:= si+1 − si be
query sequence R, sorted by position, and for 1 ≤ i ≤ t, let ΔSt
the query gaps, as deﬁned in Section 2.1. Then the lower bound on the number
of I/Os required to support the queries in St is given by

i

Bm(St) := n logm n − t(cid:2)

(cid:5)

(cid:4)
ΔSt

i /B

logm

(cid:4)

ΔSt

i /B

(cid:5)

− O(n),

i=0

where we assume that logm
deﬁnition. Note that Bm(St) ∈ Ω(n) for all t ≥ 1.

= 0 when ΔSt

i < mB = M in the above

(cid:5)

(cid:4)
ΔSt

i /B

4.2 Partitioning in External Memory

The main diﬀerence between our algorithms for internal and external memory
is the partitioning procedure. In the internal memory algorithm, we partition
the values according to a single pivot, recursing on the half that contains the
answer. In the external memory algorithm, we modify this binary partition to a
d-way partition, for some d ∈ Θ(m), by ﬁnding a sample of d “roughly equidistant 
elements.” The next lemma describes how to ﬁnd such a sample, and then
partition the range of values into d + 1 subranges with respect to the sample.
As is usual in the external memory model [AV88], we assume that B ∈
Ω(logm n)—which allows us to store a pointer to a memory block of the input
using a constant number of blocks. This is similar to the word-size assumption
for the transdichotomous word RAM model [FW93]. In addition, the algorithm
of Sibeyn [Sib06] only works under this assumption, though this is not explicitly
mentioned.

Lemma 3. Given an unsorted array A containing N elements in external memory 
and an integer parameter d < m/2, one can perform a d-way partition in
O(n+d) I/Os, such that the size of each partition is in the range [n/(2d), 3n/(2d)].
m/4(cid:8). We perform the s-way partition described in [AV88]
to obtain s + 1 super-partitions. We reapply the s-way partitioning method to
each super-partition to obtain d < m/2 partitions in total.

Proof. Let s = (cid:7)(cid:6)

Finally, our algorithm scans the data, keeping one input block and d+1 output
blocks in main memory. An output block is written to external memory when it

Dynamic Online Multiselection in Internal and External Memory

207

is full, or when the scan is complete. The algorithm performs n I/O to read the
input, and at most (n + d + 1) I/Os to write the output into d + 1 partitions,
(cid:9)(cid:10)
thus showing the result.

4.3 Algorithm Achieving O(Bm(Sq)) I/Os

We now show that our lower bound is asymptotically tight, by describing an
O(1)-competitive algorithm.

Theorem 2 (External Static Online Multiselection). Given an unsorted
array A occupying n blocks in external memory, we provide a deterministic algorithm 
that supports a sequence R of q online selection queries using O(Bm(Sq)))
I/Os under the condition that B ∈ Ω(logm n).

Proof. Our algorithm uses the same approach as the simple internal memory
algorithm described for the static version of the problem [BGJ+13], except that
it chooses d − 1 pivots at once. In other words, each node v of the pivot tree T
containing Δv elements has a branching factor of d. We subdivide its Δv elements
into d partitions using Lemma 3. This requires O(δv +d) I/Os, where δv = Δv/B.
We also maintain the bitvector V of length N , as described before. For each
A.select (i) query, we access position V[i]. If V[i] = 1, return A[i], else scan left and
right from the ith position to ﬁnd the endpoints of this interval Ii using |Ii|/B
I/Os. The analysis of the remaining terms follows directly from the internal
memory algorithm, giving O(Bm(Sq)) + O(n) = O(Bm(Sq)) I/Os.
(cid:9)(cid:10)

To add support for the search operator, instead of taking O(log N ) time performing 
binary search on the blocks of V, we build a B-tree T maintaining all pivots 
from A. (During preprocessing, we insert A[1] and A[n] into T .) The B-tree T
will be used to support search queries in O(logB N ) I/Os instead of O(log N )
I/Os. We modify the proof of Theorem 2 to obtain the following result.

Corollary 2. Given an unsorted array A occupying n blocks in external memory,
 we provide a deterministic algorithm that supports a sequence R of q online
selection and search queries using O(Bm(Sq) + q logB N ) I/Os under the condition 
that B ∈ Ω(logm n).

Proof. The ﬁrst term follows directly from the proof of Theorem 2. Now we
explain the source of the second term, q logB N ).

We build a B-tree T maintaining all pivots from A. (During preprocessing, we
insert A[1] and A[n] into T .) Naively, for q queries, we must insert qm logm N new
pivots into T . The B-tree construction for these pivots would require O(min{qm
(logm N ), N}(logB N )) I/Os, which is prohibitive.

Instead, we notice that the pivots for an individual query z are all inserted in
some unsorted interval Iz = [l, r], where l and r are consecutive leaves of the pivot
tree T (in left-to-right level order). For z, we may spend logB(min{qm(logm N ),
N}) ∈ O(logB N ) I/Os navigating to Iz using T . Our approach is to insert all
O(m logm N ) = O((M/B) logm N ) ⊆ O(M ) pivots within Iz in a single batched

208

J. Barbay et al.

manner. This process can easily be done in a bottom-up fashion by merging
nodes in the tree T of an implicit B-tree T (cid:3)
for the O(M ) pivots using O(m)
I/Os.
Thus, we have O(min{qm logm N, N}) pivots in T , and using the batched insertion 
process above, we only need O(min{qm(logm N )/B, N/B}) = O(min{qm, n})
I/Os. We must also add O(q logB N ) I/Os to navigate to the correct interval for
each query.
For q queries, the algorithm takes O(Bm(Sq)) + O(n) + O(q logB N ) = O(Bm
(cid:9)(cid:10)

(Sq) + q logB N ) I/Os, matching the result.

Combining the ideas from Corollary 2 and Theorem 1, we can dynamize the
above algorithm. The proof follows from the fact that we can maintain the bit
vectors I and D described in the multiselection algorithms of Section 3 using a
B-tree in external memory.

Theorem 3 (External Dynamic Online Multiselection). Given an unsorted 
array A occupying n blocks in external memory, we provide a deterministic 
algorithm that supports a sequence R of q online select , search, insert , and
deleteoperations using O(Bm(Sq) + q logB N ) I/Os under the condition that B ∈
Ω(logm n).

Note that if q ∈ O(Bm(Sq)/ logB N ), then Corollary 2 and Theorem 3 require
only O(Bm(Sq)) I/Os, matching the bounds from Theorem 2. Hence, our results
are asymptotically optimal when Bm(Sq)/q = O(logB N ).

References

[AV88] Aggarwal, A., Vitter, J.S.: The input/output complexity of sorting and related

problems. Commun. ACM 31(9), 1116–1127 (1988)

[BF03] Brodal, G., Fagerberg, R.: On the limits of cache-obliviousness. In: Proceedings

of the ACM Symposium on Theory of Computing, pp. 307–315 (2003)

[BGJ+13] Barbay, J., Gupta, A., Jo, S., Rao, S.S., Sorenson, J.: Theory and implementation 
of online multiselection algorithms. In: Bodlaender, H.L., Italiano, G.F.
(eds.) ESA 2013. LNCS, vol. 8125, pp. 109–120. Springer, Heidelberg (2013)

[DM81] Dobkin, D.P., Ian Munro, J.: Optimal time minimal space selection algorithms.

J. ACM 28(3), 454–461 (1981)

[FW93] Fredman, M.L., Willard, D.E.: Surpassing the information theoretic bound

with fusion trees. J. Comput. Syst. Sci. 47(3), 424–436 (1993)

[Hoa61] Hoare, C.A.R.: Algorithm 65: ﬁnd. Commun. ACM 4(7), 321–322 (1961)
[HSS03] Hon, W.-K., Sadakane, K., Sung, W.-K.: Succinct data structures for searchable 
partial sums. In: Proceedings of the International Symposium on Algorithms
and Computation, pp. 505–516 (2003)

[JM10] Jim´enez, R.M., Mart´ınez, C.: Interval Sorting. In: Abramsky, S., Gavoille, C.,
Kirchner, C., Meyer auf der Heide, F., Spirakis, P.G. (eds.) ICALP 2010. LNCS,
vol. 6198, pp. 238–249. Springer, Heidelberg (2010)

[KMMS05] Kaligosi, K., Mehlhorn, K., Munro, J.I., Sanders, P.: Towards optimal
multiple selection. In: Caires, L., Italiano, G.F., Monteiro, L., Palamidessi, C.,
Yung, M. (eds.) ICALP 2005. LNCS, vol. 3580, pp. 103–114. Springer, Heidelberg
(2005)

Dynamic Online Multiselection in Internal and External Memory

209

[MR86] Motwani, R., Raghavan, P.: Deferred data structuring: Query-driven preprocessing 
for geometric search problems. In: Symposium on Computational Geometry,
 pp. 303–312 (1986)

[Pro95] Prodinger, H.: Multiple quickselect - Hoare’s ﬁnd algorithm for several elements.
 Inf. Process. Lett. 56(3), 123–129 (1995)

[Sib06] Sibeyn, J.F.: External selection. J. Algorithms 58(2), 104–117 (2006)
[YTC90] Ching, Y.-T., Mehlhorn, K., Smid, M.H.M.: Dynamic deferred data structuring.
 Information Processing Letters 35(1), 37–40 (1990)

