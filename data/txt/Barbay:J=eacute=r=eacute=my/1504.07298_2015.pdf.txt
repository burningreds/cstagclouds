5
1
0
2

 

n
u
J
 

8
2

 
 
]
S
D
.
s
c
[
 
 

2
v
8
9
2
7
0

.

4
0
5
1
:
v
i
X
r
a

Adaptive Computation of the

Swap-Insert Correction Distance

J´er´emy Barbay1⋆ and Pablo P´erez-Lantero2⋆

1 Departamento de Ciencias de la Computaci´on, Universidad de Chile, Chile
2 Escuela de Ingenier´ıa Civil en Inform´atica, Universidad de Valpara´ıso, Chile

Abstract. The Swap-Insert Correction distance from a string S of length
n to another string L of length m ≥ n on the alphabet [1..d] is the
minimum number of insertions, and swaps of pairs of adjacent symbols,
converting S into L. Contrarily to other correction distances, computing 
it is NP-Hard in the size d of the alphabet. We describe an algorithm 
computing this distance in time within O(d2nmgd−1), where there
are nα occurrences of α in S, mα occurrences of α in L, and where
g = maxα∈[1..d] min{nα, mα −nα} measures the diﬃculty of the instance.
The diﬃculty g is bounded by above by various terms, such as the length
of the shortest string S, and by the maximum number of occurrences of
a single character in S. Those results illustrate how, in many cases, the
correction distance between two strings can be easier to compute than
in the worst case scenario.

Keywords: Adaptive, Dynamic Programming, Edit Distance, Insert, Swap.

1

Introduction

Given two strings S and L on the alphabet Σ = [1..d] and a list of correction
operations on strings, the String-to-String Correction distance is the minimum 
number of operations required to transform the string S into the string L.
Introduced in 1974 by Wagner and Fischer [7], this concept has many applications,
 from suggesting corrections for typing mistakes, to decomposing the
changes between two consecutive versions into a minimum number of correction
steps, for example within a control version system such as cvs, svn or git.

Each distinct set of correction operators yields a distinct correction distance
on strings. For instance, Wagner and Fischer [7] showed that for the three following 
operations, the insertion of a symbol at some arbitrary position, the
deletion of a symbol at some arbitrary position, and the substitution of
a symbol at some arbitrary position, there is a dynamic program solving this
problem in time within O(nm) when S is of length n and L of length m. Similar 
complexity results, all polynomial, hold for many other diﬀerent subsets of

⋆ Partially supported by Millennium Nucleus Information and Coordination in Networks 
ICM/FIC RC130003. Part of this work was presented at the conference SPIRE
2015 [2].

the natural correction operators, with one striking exception: Wagner [6] proved
the NP-hardness of the Swap-Insert Correction distance, denoted δ(S, L)
through this paper, i.e. the correction distance when restricted to the operators
insertion and swap (or, by symmetry, to the operators deletion and swap).

The Swap-Insert Correction distance’s diﬃculty attracted special interest,
 with two results of importance: Abu-Khzam et al. [1] described an algorithm
computing δ(S, L) in time within O(1.6181δ(S,L)m), and Meister [4] described
an algorithm computing δ(S, L) in time polynomial in the input size when S
and L are strings on a ﬁnite alphabet: its running time is (m + 1)2d+1 · (n + 1)2
times some polynomial function on n and m.

The complexity of Meister’s result [4], polynomial in m of degree 2d + 1, is a
very pessimistic approximation of the computational complexity of the distance.
At one extreme, the Swap-Insert Correction distance between two strings
which are very similar (e.g. only a ﬁnite number of symbols need to be swapped
or inserted) can be computed in time linear in n and d. At the other extreme, the
Swap-Insert Correction distance of strings which are completely diﬀerent
(e.g. their eﬀective alphabets are disjoint) can also be computed in linear time
(it is then close to n + m). Even when S and L are quite diﬀerent, δ(S, L) can
be “easy” to compute: when mostly swaps are involved to transform S into L
(i.e. S and L are almost of the same length), and when mostly insertions are
involved to transform S into L (i.e. many symbols present in L are absent from
S).
Hypothesis: We consider whether the Swap-Insert Correction distance
δ(S, L) can be computed in time polynomial in the length of the input strings
for a constant alphabet size, while still taking advantage of cases such as those
described above, where the distance δ(S, L) can be computed much faster.
Our Results: After a short review of previous results and techniques in Section 
2, we present such an algorithm in Section 3, in four steps: the intuition
behind the algorithm in Section 3.1, the formal description of the dynamic program 
in Section 3.2, and the formal analysis of its complexity in Section 3.4. In
the latter, we deﬁne the local imbalance gα = min{nα, mα − nα} for each symbol
α ∈ Σ, summarized by the global imbalance measure g = maxα∈Σ gα, and prove
that our algorithm runs in time within

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1)
 ,

O
d(n + m) + d2n ·

in the worst case over all instances of ﬁxed sizes n and m, with imbalance vector
(g1, . . . , gd); where Σ+ = {α ∈ Σ : gα > 0} if gα = 0 for any α ∈ Σ, and
Σ+ = Σ \ {arg minα∈Σ gα} otherwise. This simpliﬁes to within O(d2gd−1nm) in
the worst case over instances where d, n, m and g are ﬁxed.

We discuss in Section 4 some implied results, and some questions left open,
such as when the operators are assigned asymmetric costs, when the algorithm
is required to output the sequence of corrections, when only swaps are allowed,
or when the distribution of the frequencies of the symbol is very unbalanced.

2 Background

In 1974, motivated by the problem of correcting typing and transmission errors,
Wagner and Fischer [7] introduced the String-to-String Correction problem,
 which is to compute the minimum number of corrections required to change
the source string S into the target string L. They considered the following oper-
ators: the insertion of a symbol at some arbitrary position, the deletion of a
symbol at some arbitrary position, and the substitution of a symbol at some
arbitrary position. They described a dynamic program solving this problem in
time within O(nm) when S is of length n and L of length m. The worst case
among instances of ﬁxed input size n + m is when n = m/2, which yields a
complexity within O(n2).

In 1975, Lowrance and Wagner [8] extended the String-to-String Correction 
distance to the cases where one considers not only the insertion,
deletion, and substitution operators, but also the swap operator, which exchanges 
the positions of two contiguous symbols. Not counting the identity,
ﬁfteen diﬀerent variants arise when considering any given subset of those four
correction operators. Thirteen of those variants can be computed in polynomial
time [6,7,8]. The two remaining distances, the computation of the Swap-Insert
Correction distance and its symmetric the Swap-Delete Correction distance,
 are equivalent by symmetry, and are NP-hard to compute [6], hence our
interest. All our results on the computation of the Swap-Insert Correction
distance from S to L directly imply the same results on the computation of the
Swap-Delete Correction distance from L to S.

In 2011, Abu-Khzam et al. [1] described an algorithm computing the SwapDelete 
Correction distance from a string L to a string S (and hence the
Swap-Insert Correction from S to L). Their algorithm decides if this distance 
is at most a given parameter k, in time within O(1.6181km). This indirectly
yields an algorithm computing both distances in time within O(1.6181δ(S,L)m):
testing values of k from 0 to inﬁnity in increasing order yields an algorithm com1.
6181km) ⊂ O(1.6181δ(S,L)m).
Since any correct algorithm must verify the correctness of its output, such an
algorithm implies the existence of an algorithm with the same running time
which outputs a minimum sequence of corrections from S to L. Later in 2013,
Watt [9] showed that computing the Swap-Deletion Correction distance
has a kernel size of O(k4).

puting the distance in time within O(Pδ(S,L)

k=0

In 2013, Spreen [5] observed that Wagner’s NP-hardness proof [6] was based
on unbounded alphabet sizes (i.e. the Swap-Insert Correction problem is
NP-hard when the size d of the alphabet is part of the input), and suggested
that this problem might be tractable for ﬁxed alphabet sizes. He described some
polynomial-time algorithms for various special cases when the alphabet is binary,
and some more general properties.

In 2014, Meister [4] extended Spreen’s work [5] to an algorithm computing
the Swap-Insert Correction distance from a string S of length n to another
string L of length m on any ﬁxed alphabet size d ≥ 2, in time polynomial
in n and m. The algorithm is explicitly based on ﬁnding an injective function

ϕ : [1..n] → [1..m] such that ϕ(i) = j if and only if S[i] = L[j], and the total
number of crossings is minimized. Two positions i < i′ of S deﬁne a crossing if
and only if ϕ(i) > ϕ(i′). Such a number of crossings equals the number of swaps,
and the number of insertions is always equal to m − n. Meister proved that the
time complexity of this algorithm is equal to (m + 1)2d+1 · (n + 1)2 times some
function polynomial in n and m.

We describe in the following section an algorithm computing the SwapInsert 
Correction distance in explicit polynomial time, and which running
time goes gradually down to linear for easier cases.

3 Algorithm

We describe the intuition behind our algorithm in Section 3.1, the high level
description of the dynamic program in Section 3.2, the full code of the algorithm
in Section 3.3 and the formal analysis of its complexity in Section 3.4.

3.1 High level description

The algorithm runs through S and L from left to right, building a mapping
from the characters of S to a subset of the characters of L, using the fact that,
for each distinct character, the mapping function on positions is monotone. The
Dynamic Programming matrix has size n1 × · · · × nd < nd.

For every string X ∈ {S, L}, let X[i] denote the i-th symbol of X from left to
right (i ∈ [1..|X|]), and X[i..j] denote the substring of X from the i-th symbol to
the j-th symbol (1 ≤ i ≤ j ≤ |X|). For every 1 ≤ j < i ≤ n, let X[i..j] denote the
empty string. Given any symbol α ∈ Σ, let rank(X, i, α) denote the number of
occurrences of the symbol α in the substring X[1..i], and select(X, k, α) denote
the value j ∈ [1..|X|] such that the k-th occurrence of α in X is precisely at
position j, if j exists. If j does not exist, then select(X, k, α) is null.

The algorithm runs through S and L simultaneously from left to right, skipping 
positions where the current symbol of S equals the current symbol of L, and
otherwise branching out between two options to correct the current symbol of
S: inserting a symbol equal to the current symbol of L in the current position of
S, or moving (by applying many swaps) the ﬁrst symbol of the part not scanned
of S equal to the current symbol of L, to the current position in S.

More formally, the computation of δ(S, L) can be reduced to the application

of four rules:

– if S is empty: We just return the length |L| of L, since insertions are the

only possible operations to perform in S.

– if some α ∈ Σ appears more times in S than in L: We return +∞,

since delete operations are not allowed to make S and L match.

– if S and L are not empty, S[1] = L[1]: We return δ(S[2..|S|], L[2..|L|]).
– if S and L are not empty, S[1] 6= L[1]: We compute two distances: the
distance dins = 1 + δ(S, L[2..|L|]) corresponding to an insertion of the

symbol L[1] at the ﬁrst position of S, and the distance dswaps = (r − 1) +
δ(S′, L[2..|L|]) corresponding to perform r − 1 swaps to bring to the ﬁrst
position of S the ﬁrst symbol of S equal to L[1]. In this case, r denotes the
position of such a symbol, and S′ the string resulting from S by removing
that symbol. We then return min{dins, dswaps}.

There can be several overlapping subproblems in the recursive deﬁnition of
δ(S, L) described above, which calls for dynamic programming [3] and memoization3.
 In any call δ(S′, L′) in the recursive computation of δ(S, L), the string
L′ is always a substring L[j..|J|] for some j ∈ [1..|J|], and can thus be replaced
by such an index j, but this is not always the case for the string S′. Observe
that S′ is a substring S[i..|S|] for some i ∈ [1..|S|] with (eventually) some symbols 
removed. Furthermore, if for some symbol α ∈ Σ precisely cα symbols α of
S[i..|S|] have been removed, then those symbols are precisely the ﬁrst cα symbols 
α from left to right. We can then represent S′ by the index i and a counter
cα for each symbol α ∈ Σ of how many symbols α of S[i..|S|] are removed (i.e.
ignored). In the above fourth rule, the position r is equivalent to the position of
the (cL[1] + 1)-th occurrence of the symbol L[1] in S[i..|S|]. To quickly compute
r, the functions rank and select will be used.

Let W =Qd

α=1[0..nα] denote the domain of such vectors of counters, where
for any c = (c1, c2, . . . , cd) ∈ W, cα denotes the counter for α ∈ Σ. Using
the ideas described above, the algorithm recursively computes the extension
DIST (i, j, c) of δ(S, L), deﬁned for each i ∈ [1..n + 1], j ∈ [1..m + 1], and
c = (c1, c2, . . . , cd) ∈ W, as the value of δ(S[i..n]c, L[j..m]), where S[i..n]c is the
string obtained from S[i..n] by removing (i.e. ignoring) for each α ∈ Σ the ﬁrst
cα occurrences of α from left to right.

Given this deﬁnition, δ(S, L) = DIST (1, 1, 0), where 0 denotes the vector
(0, . . . , 0) ∈ W. Given i, j, and c, DIST (i, j, c) < +∞ if and only if for each
symbol α ∈ Σ the number of considered (i.e. not removed or ignored) α symbols
in S[i..n] is at most the number of α symbols in L[j..m]. That is, count(S, i, α) −
cα ≤ count(L, j, α) for all α ∈ Σ, where count(X, i, α) = rank(X, |X|, α) −
rank(|X|, i − 1, α) is the number of symbols α in the string X[i..|X|]. In the
following, we show how to compute DIST (i, j, c) recursively for every i, j, and
c. For a given α ∈ Σ, let wα ∈ W be the vector whose components are all equal
to zero except the α-th component that is equal to 1.

3.2 Recursive computation of DIST (i, j, c)

We will use the following observation which considers the swap operations performed 
in the optimal transformation from a short string S of length n to a
larger string L of length m.

Observation 1 ([1,5]) The swap operations used in any optimal solution satisfy 
the following properties: two equal symbols cannot be swapped; each symbol is

3 Cormen et al. [3] explain that memoization comes from memo, referring to the fact

that the technique consists in recording a value so that we can look it up later.

always swapped in the same direction in the string; and if some symbol is moved
from some position to another by performing swaps operations, then no symbol
equal to it can be inserted afterwards between these two positions.

The following lemma deals with the basic case where S[i..n] and L[j..m] start
with the same symbol, i.e. S[i] = L[j]. When the beginnings of both strings are
the same, matching those two symbols seems like an obvious choice in order to
minimize the distance, but one must be careful to check ﬁrst if the ﬁrst symbol
from S[i..n] has not been scheduled to be “swapped” to an earlier position, in
which case it must be ignored and skipped:

Lemma 1. Given two strings S and L over the alphabet Σ, for any positions
i ∈ [1..n] in S and j ∈ [1..m] in L, for any vector of counters c = (c1, . . . , cd) ∈ W
and for any symbol α ∈ Σ,

S[i] = L[j] = α
cα = 0

(cid:27) =⇒ DIST (i, j, c) = DIST (i + 1, j + 1, c).

Proof. Given strings X, Y in the alphabet Σ, and an integer k, Abu-Khzam et
al. [1, Corollary 1] proved that if X[1] = Y [1], then:

δ(X, Y ) ≤ k if and only if δ(X[2..|X|], Y [2..|Y |]) ≤ k.

Given that one option to transform X into Y with the minimum number of
operations is to transform X[2..|X|] into Y [2..|Y |] with the minimum number of
operations (matching X[1] with Y [1]), we have:

δ(X, Y ) ≤ δ(X[2..|X|], Y [2..|Y |]).

By selecting k = δ(X, Y ), we obtain the equality

δ(X, Y ) = δ(X[2..|X|], Y [2..|Y |]).

Then, since the symbol α = S[i] must be considered (because cα = 0), and
S[i] = L[j], we can apply the above statement for X = S[i..n]c and Y = L[j..m]
to obtain the next equalities:

DIST (i, j, c) = δ(X, Y ) = δ(X[2..|X|], Y [2..|Y |]) = DIST (i + 1, j + 1, c).

The result thus follows.

⊓⊔

The second simplest case is when the ﬁrst available symbol of S[i..n] is already
matched (through swaps) to a symbol from L[1..j − 1]. The following lemma
shows how to simply skip such a symbol:

Lemma 2. Given S and L over the alphabet Σ, for any positions i ∈ [1..n] in
S and j ∈ [1..m] in L, and for any vector of counters c = (c1, . . . , cd) ∈ W and
for any symbol α ∈ Σ,

S[i] = α

cα > 0 (cid:27) =⇒ DIST (i, j, c) = DIST (i + 1, j, c − wα).

Proof. Since cα > 0, the ﬁrst cα symbols α of S[i..n] have been ignored, thus
S[i] is ignored. Then, DIST (i, j, c) must be equal to DIST (i + 1, j, c− wα), case
⊓⊔
in which cα − 1 symbols α of S[i + 1..n] are ignored.

The most important case is when the ﬁrst symbols of S[i..n] and L[j..m]
do not match: the minimum “path” from S to L can then start either by an
insertion or a swap operation.

Lemma 3. Given S and L over the alphabet Σ, for any positions i ∈ [1..n]
in S and j ∈ [1..m] in L, and for any vector of counters c = (c1, . . . , cd) ∈
W, note α, β ∈ Σ the symbols α = S[i] and β = L[j], r the position r =
select(S, rank(S, i, β) + cβ + 1, β) in S of the (cβ + 1)-th symbol β of S[i..n], and
θ=1 min{cθ, rank(S, r, θ) − rank(S, i − 1, θ)} of symbols ignored

∆ the number Pd

in S[i..r].

If α 6= β and cα = 0, then DIST (i, j, c) = min{dins, dswaps}, where

dins = (cid:26) DIST (i, j + 1, c) + 1 if cβ = 0

if cβ > 0

+∞

and

dswaps = (cid:26) (r − i) − ∆ + DIST (i, j + 1, c + wβ) if r 6= 0

if r = 0.

+∞

Proof. Let S′[1..n′] = S[i..n]c. Given that α 6= β and cα = 0, there are two
possibilities for DIST (i, j, c): (1) transform S′[1..n′] into L[j + 1..m] with the
minimum number of operations, and after that insert a symbol β at the ﬁrst
position of the resulting S′[1..n′]; or (2) swap the ﬁrst symbol β in S′[2..n′] from
left to right from its current position r′ to the position 1 performing r′ −1 swaps,
and then transform the resulting S′[2..n′] into L[j + 1..m] with the minimum
number of operations. Observe that option (1) can be performed if and only if
there is no symbol β ignored in S[i..n] (see Observation 1). If this is the case,
then DIST (i, j, c) = DIST (i, j + 1, c) + 1. Option (2) can be used if and only if
there is a non-ignored symbol β in S[i..n], where the ﬁrst one from left to right
is precisely at position r = select(S, rank(S, i, β) + cβ + 1, β). In such a case
θ=1 min{cθ, rank(S, r, θ) − rank(S, i − 1, θ)}
is the total number of ignored symbols in the string S[i..r]. Hence, the number
of swaps counts to r′ − 1 = (r − i) − ∆. Then, the correctness of dins, dswaps,
⊓⊔
and the result follow.

r′ = (r − i + 1) − ∆, where ∆ =Pd

The next two lemmas deal with the cases where one string is completely
processed. When L has been completely processed, either the remaining symbols
in S have all previously been matched via swaps and the distance equals zero,
or there is no sequence of operations correcting S into L:

Lemma 4. Given S and L over the alphabet Σ, for any positions i ∈ [1..n + 1]
in S and j ∈ [1..m] in L, for any vector of counters c = (c1, . . . , cd) ∈ W,

DIST (i, m + 1, c) =(cid:26) 0

+∞ otherwise.

if c1 + . . . + cd = n − i + 1 and

Proof. Note that DIST (i, m + 1, c) is the minimum number of operations to
transform the string S[i..n] into the empty string L[m + 1..m]. This number is
null if and only if all the n − i + 1 symbols of S[i..n] have been ignored, that is,
c1 + . . . + cd = n − i + 1. If not all the symbols have been ignored, then such a
transformation does not exist and DIST (i, m + 1, c) = +∞.
⊓⊔

When S has been completely processed, there are only insertions left to per-
form: the distance can be computed in constant time, and the list of corrections
in linear time.

Lemma 5. Given S and L over the alphabet Σ, for any position j ∈ [1..m + 1]
in L, and for any vector of counters c = (c1, . . . , cd) ∈ W,

DIST (n + 1, j, c) =(cid:26) m − j + 1 if c = 0 and

+∞ otherwise.

Proof. Note that DIST (i, m + 1, c) is the minimum number of operations to
transform the empty string S[n + 1..n] into the string L[j..m]. If c = 0, then
DIST (n+1, j, c) < +∞ and the transformation consists of only insertions which
⊓⊔
are m − j + 1. If c 6= 0, then DIST (n + 1, j, c) = +∞.

3.3 Complete algorithm

In the following, we describe the formal algorithm to compute DIST (i, j, 0). We
consider the worst scenario for the running time of Theorem 1, where for each
symbol α ∈ Σ we have gα > 0. The other cases in which gα > 0 is not satisﬁed for
all α ∈ Σ are easier to implement. Note that the line 3 of algorithm Compute and
line 26 of algorithm DIST 2 guarantee that DIST 2(i, j) = DIST (i, j, c) < +∞
in every call of DIST 2. Further, the counters (c1, c2, . . . , cd) are global variables
to the recursive DIST 2.

3.4 Complexity Analysis

Combining Lemmas 1 to 5, the value of DIST (1, 1, 0) can be computed recursively,
 as shown in the algorithm of Figure 1. We analyze the formal complexity
of this algorithm in Theorem 1, in the ﬁnest model that we can deﬁne, taking
into account the relation for each symbol α ∈ Σ between the number nα of
occurrences of α in S and the number mα of occurrences of α in L.

Theorem 1. Given two strings S and L over the alphabet Σ, for each symbol
α ∈ Σ, note nα the number of occurrences of α in S and mα the number of
occurrences of m in L, their sums n = n1 + · · · + nd and m = m1 + · · · + md,
and gα = min{nα, mα − nα} a measure of how far nα is from mα/2. There is an
algorithm computing the Swap-Insert Correction distance δ(S, L) in time

(* skip all symbols since they were ignored *)
return 0

else

else if j = m + 1 then

if DIST (i, j, c) = +∞ then

return +∞

else if i = n + 1 then

(* insertions *)
return m − j + 1

α ← S[i], β ← L[j]
if cα > 0 then

Algorithm DIST (i, j, c = (c1, . . . , cd))
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.

dins ← +∞, dswaps ← +∞
if cβ = 0 then

return min{dins, dswaps}

else

(* skip S[i], it was ignored *)
return DIST (i + 1, j, c − wα)

else if α = β then

(* S[i] and L[j] match *)
return DIST (i + 1, j + 1, c)

(* insert a β at index i *)
dins ← 1 + DIST (i, j + 1, c)

r ← select(S, rank(S, i, β) + cβ + 1, β)
if r 6= null then

θ=1 min{cθ, rank(S, r, θ) − rank(S, i − 1, θ)}

∆ ← Pd
(* swaps *)
dswaps ← (r − i) − ∆ + DIST (i, j + 1, c + wβ)

Fig. 1: Informal algorithm to compute DIST (i, j, c): Lemma 4 and Lemma 5
guarantee the correctness of lines 1 to 8; Lemma 2 guarantees the correctness
of lines 11 to 13; Lemma 1 guarantees the correctness of lines 14 to 16; and
Lemma 3 guarantees the correctness of lines 18 to 27.

within O(d + m) if S and L have no symbol in common, and otherwise in time
within

O
d(n + m) + d2n ·

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1)
 ,

where Σ+ = {α ∈ Σ : gα > 0} if gα = 0 for any α ∈ Σ, and Σ+ = Σ \
{arg minα∈Σ gα} otherwise.

Proof. Observe ﬁrst that there is a reordering of Σ = [1..d] such that 0 <
g1 ≤ g2 ≤ · · · ≤ gs and gs+1 = gs+2 = · · · = gd for some index s ∈ [0..d],
and we assume such an ordering from now on. Note also that given any string
X ∈ {S, L}, a simple 2-dimensional array using space within O(d · |X|) can be
computed in time within O(d · |X|), to support the queries rank(X, i, α) and

Algorithm Compute δ(S, L):
1.
2.
3.

preprocess each of S and L for rank and select
(c1, c2, . . . , cd) ← 0
return if DIST (1, 1, 0) < +∞ then DIST 2(1, 1) else +∞

Fig. 2: Calling Algorithm to compute DIST (i, j, 0), ﬁltering degenerated cases before
launching the real computation of the distance.

p ← the ﬁrst index in [1..d] so that cp = 0
for α = 1 to d do

if nα ≤ mα − nα then

xα ← rank(L, j − 1, α) − rank(S, i − 1, α) − cα

(r1, . . . , rd−1) ← (x1, . . . , xp−1, xp+1, . . . , xd)
k ← j − i − (r1 + · · · + rd−1)
if T [p, i, k, r1, . . . , rd−1] 6= undef ined then

return T [t, i, k, r1, . . . , rd−1]

if i = n + 1 then

else

else

xα ← cα

Algorithm DIST 2(i, j):
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11. else
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.
32.
33.
34.
35.

else

T [p, i, k, r1, . . . , rd−1] ← m − j + 1

else if j = m + 1 then

T [p, i, k, r1, . . . , rd−1] ← 0

α ← S[i], β ← L[j]
if cα > 0 then

cα ← cα − 1
T [p, i, k, r1, . . . , rd−1] ← DIST 2(i + 1, j)
cα ← cα + 1

else if α = β then

T [p, i, k, r1, . . . , rd−1] ← DIST 2(i + 1, j + 1)

dins ← +∞, dswaps ← +∞
if cβ = 0 and count(S, i, β) < count(L, j, β) then

dins ← 1 + DIST 2(i, j + 1)

r ← select(S, rank(S, i, β) + cβ + 1, β)
if r 6= null then

θ=1 min{cθ, rank(S, r, θ) − rank(S, i − 1, θ)}

∆ ← Pd
cβ ← cβ+1
dswaps ← (r − i) − ∆ + DIST 2(i, j + 1)
cβ ← cβ − 1

T [p, i, k, r1, . . . , rd−1] ← min{dins, dswaps}

return T [p, i, k, r1, . . . , rd−1]

Fig. 3: Formal Algorithm to compute DIST (i, j, 0), using dynamic programming with
memorization. Note that the line 26 of algorithm Compute and line 3 of algorithm
DIST 2 guarantee that DIST 2(i, j) = DIST (i, j, c) < +∞ in every call.

select(X, k, α) in constant time for all values of i ∈ [1..n], k ∈ [1..|X|], and
α ∈ Σ.

The case where the two strings S and L have no symbol in common is easy:
the distance is then +∞. The algorithm detects this case by testing if gα = 0
for all α ∈ Σ, in time within O(d + m).

Consider the algorithm of Figure 1, and let i ∈ [1..n], j ∈ [1..m], and c =

(c1, . . . , cd) be parameters such that DIST (i, j, c) < +∞.

At least one of the c1, . . . , cd is equal to zero: in the ﬁrst entry DIST (1, 1, 0)
all the counters c1, c2, . . . , cd are equal to zero, and any counter is incremented
only at line 26, in which another counter must be equal to zero because of the
lines 11 and 14.

The number of insertions counted in line 21, in previous calls to the function 
DIST in the recursion path from DIST (1, 1, 0) to DIST (i, j, c), is equal
to j − i − (c1 + · · · + cd). Let tα denote the number of such insertions for the
symbol α ∈ Σ. Then, we have

j = i + (c1 + · · · + cd) + (t1 + · · · + td),

and for all α ∈ Σ, cα ≤ nα, tα ≤ mα − nα, and

cα + tα = rank(L, j − 1, α) − rank(S, i − 1, α).

Using the above observations, we encode all entries DIST (i, j, c), for i, j and
c such that DIST (i, j, c) < +∞, into the following table T of s + 2 ≤ d + 2
dimensions. If we have s = d, then

T [p, i, k, r1, . . . , rd−1] = DIST (i, j, c = (c1, . . . , cd)),

where

cp = 0,

(r1, . . . , rd−1) = (x1, . . . , xp−1, xp+1, . . . , xd)

xα = (cid:26) cα if nα ≤ mα − nα

tα if mα − nα < nα

for every α ∈ Σ, and

k = (c1 + · · · + cd) + (t1 + · · · + td) − (r1 + · · · + rd−1).

Furthermore, given any combination of values i, j, c1, . . . , cd we can switch to
the values p, i, k, r1, . . . , rd−1, and vice versa, in time within O(d). Otherwise, if
s < d, then

T [i, k, r1, . . . , rs] = DIST (i, j, c = (c1, . . . , cd)),

where (r1, . . . , rs) = (x1, . . . , xs). Again, given the values i, j, c1, . . . , cd we can
switch to the values i, k, r1, . . . , rs, and vice versa, in O(d) time.

Since p ∈ [1..d], i ∈ [1..n + 1], k ∈ [0..Pd
every α, the table T can be as large as d × (n + 1) × (1 +Pd
1) × · · · × (gd + 1) if s = d, and as large as (n + 1) × (1 +Pd

α=1(mα − gα)], and rα ∈ [0..gα] for
α=1(mα − gα)) × (g2 +
α=1(mα − gα)) × (g1 +

1) × · · ·× (gs + 1) if 0 < s < d. For s = 0, no table is needed. The running time of
this new algorithm includes the O(d(n + m)) = O(dm) time for processing each
of S and L for rank and select, and the time to compute DIST (1, 1, 0) which
is within O(d) times n + m plus the number of cells of the table T . If s = d, the
time to compute DIST (1, 1, 0) is within

O d(n + m) + d2n ·

d

Xα=1

(mα − gα) · (g2 + 1) · · · · · (gd + 1)! .

Otherwise, if 0 ≤ s < d, the time to compute DIST (1, 1, 0) is within

O d(n + m) + dn ·

d

Xα=1

(mα − gα) · (g1 + 1) · · · · · (gs + 1)! .

The result follows by noting that: if s = d, then Σ+ = {2, . . . , d}. Otherwise, if
s < d, then Σ+ = {1, . . . , s}.
⊓⊔

The result above, about the complexity in the worst case over instances with
d, n1, . . . , nd, m1, . . . , md ﬁxed, implies results in less precise models, such as in
the worst case over instances for d, n, m ﬁxed:

Corollary 1. Given two strings S and L over the alphabet Σ, of respective
sizes n and m, the algorithm analyzed in Theorem 1 computes the Swap-Insert
Correction distance δ(S, L) in time within

O d(n + m) + d2n(m − n)(cid:18) n

d − 1

+ 1(cid:19)d−1! ,

which is within O(cid:0)n + m + nd(m − n)(cid:1) for alphabets of ﬁxed size d; and within

O d(n + m) + d2n2(cid:18) m − n

d − 1

+ 1(cid:19)d−1! ,

which is within O(cid:0)n + m + n2(m − n)d−1(cid:1) for alphabets of ﬁxed size d.

Proof. We use the following claim: If a ≥ 1 and x ≤ y, then (a + y)(x + 1) ≤
(a + x)(y + 1). It can be proved as follows:

(a − 1)x ≤ (a − 1)y

ax + y ≤ ay + x

ax + y + a + xy ≤ ay + x + a + xy

(a + y)(x + 1) ≤ (a + x)(y + 1).

Let Σ+ ⊂ Σ be as deﬁned in Theorem 1, and consider the worst scenario for the
running time, that is, let us consider w.l.o.g. that Σ+ = [2..d]. Let β ∈ Σ+ be a

symbol such that mβ − nβ < nβ, and deﬁne a and b such that:

d

d

a =

(mα − gα) − (mβ − gβ) =

(mα − gα) − nβ

Xα=1

Xα=1
= Xα∈Σ\{β}

(mα − gα) ≥ 1,

and

Note that:

b = Yα∈Σ+\{β}

(gα + 1).

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1) = (a + nβ) · b · (mβ − nβ + 1)

≤ (a + mβ − nβ) · b · (nβ + 1),

which immediately implies

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1) ≤ (m − n) Yα∈Σ+

(nα + 1).

Then,

O
d2n ·

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1)

 ⊆ O(cid:0)d2n(m − n) · (n2 + 1) · · · · · (nd + 1)(cid:1)
+ 1(cid:19)d−1!
⊆ O d2n(m − n) ·(cid:18) n2 + · · · + nd
⊆ O d2n(m − n) ·(cid:18) n

+ 1(cid:19)d−1! .

d − 1

d − 1

Using similar arguments, we can prove that

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1) ≤ n Yα∈Σ+

(mα − nα + 1),

which implies the second part of the result.

⊓⊔

4 Discussion

In 2014, Meister [4] described an algorithm computing the Swap-Insert Correction 
distance from a string S ∈ [1..d]n to another string L ∈ [1..d]m on any

ﬁxed alphabet size d ≥ 2, in time polynomial in n and m. The algorithm that we
described takes advantage of instances where for all symbols α ∈ Σ the number
nα of occurrences of α in S is either close to zero (i.e. most α symbols from L are
placed in S through insertions) or close to the number mα of occurrences of α
in L (i.e. most α symbols from L are matched to symbols in S through swaps),

while still running in time within O(m + min(cid:8)nd(m − n), n2(m − n)d−1(cid:9)) when

the alphabet size d is a constant, in the worst case over instances composed of
strings of sizes n and m. The exact running time of our algorithm is within

O
d(n + m) + d2n ·

d

Xα=1

(mα − gα) · Yα∈Σ+

(gα + 1)
 ,

where nα and mα are the respective number of occurrences of symbol α ∈ [1..d] in
S and L respectively; where the vector formed by the values gα = min{nα, mα −
nα} measures the distance between (n1, . . . , nσ) and (m1, . . . , mσ); and where
Σ+ = {α ∈ Σ : gα > 0} if gα = 0 for any α ∈ Σ, and Σ+ = Σ \ {arg minα∈Σ gα}
otherwise.

Summarizing the disequilibrium between the frequency distributions of the
symbols in the two strings via the measure g = maxα∈Σ gα ≤ n, this yields a
complexity within O(d2nmgd−1), which is polynomial in n and m, and exponential 
only in d of base g. Since this disequilibrium g is smaller than the length n
of the smallest string S, this implies a worst case complexity within O(d2mnd)
over instances formed by strings of lengths n and m over an alphabet of size d,
a result matching the state of the art [4] for this problem.

4.1 Implicit Results

The result from Theorem 1 implies the following additional results:

Weighted Operators: Wagner and Fisher [7] considered variants where the
cost cins of an insertion and the cost cswap of an swap are distinct. In the
Swap-Insert Correction problem, there are always n − m insertions,
and always δ(S, L) − n + m swaps, which implies the optimality of the algorithm 
we described in such variants.

Computing the Sequence of Corrections: Since any correct algorithm must
verify the correctness of its output, given a set C of correction operators,
any correct algorithm computing the String-to-String Correction Distance 
when limited to the operators in C implies an algorithm computing a
minimal sequence of corrections under the same constraints within the same
asymptotic running time.

Implied improvements when only swaps are needed: Abu-Khzam et al. [1]

mention an algorithm computing the Swap String-to-String Correction 
distance (i.e. only swaps are allowed) in time within O(n2). This is a
particular case of the Swap-Insert Correction distance, which happens
exactly when the two strings are of the same size n = m (and no insertion

is neither required nor allowed). In this particular case, our algorithm yields
a solution running in time within O(dm), hence improving on Abu-Khzam
et al.’s solution [1].

Eﬀective Alphabet: Let d′ be the eﬀective alphabet of the instance, i.e. the
number of symbols α of Σ = [1..d] such that the number of occurrences of
α in S is a constant fraction of the number of occurrences of α in L (i.e.
nα ∈ Θ(mα)). Our result implies that the real diﬃculty is d′ rather than d,
i.e. that even for a large alphabet size d the distance can still be computed
in reasonable time if d′ is ﬁnite.

4.2 Perspectives

Those results suggest various directions for future research:

Further improvements of the algorithm: our algorithm can be improved
further using a lazy evaluation of the min operator on line 27, so that
the computation in the second branch of the execution stops any time the
computed distance becomes larger than the distance computed in the ﬁrst
branch. This would save time in practice, but it would not improve the
worst-case complexity in our analysis, in which both branches are fully ex-
plored: one would require a ﬁner measure of diﬃculty to express how such a
modiﬁcation could improve the complexity of the algorithm

Further improvements of the analysis: The complexity of Abu-Khzam et
al.’s algorithm [1], sensitive to the distance from S to L, is an orthogonal
result to ours. An algorithm simulating both their algorithm and ours in
parallel yields a solution adaptive to both measures, but an algorithm using
both techniques in synergy would outperform both on some instances, while
never performing worse on other instances.

Adaptivity for other existing distances: Can other String-to-String Correction 
distances be computed faster when the number of occurrences of
symbols in both strings are similar for most symbols? Edit distances such
as when only insertions or only deletions are allowed are linear anyway, but
more complex combinations require further studies.

Acknowledgement.

The authors would like to thank the anonymous referees of SPIRE 2015 for
insightful comments.

References

1. F. N. Abu-Khzam, H. Fernau, M. A. Langston, S. Lee-Cultura, and U. Stege. Charge
and reduce: A ﬁxed-parameter algorithm for String-to-String Correction. Discrete
Optimization (DO), 8(1):41 – 49, 2011.

2. J. Barbay and P. P´erez-Lantero. Adaptive computation of the Swap-Insert Edition
Distance. In Proceedings of the Symposium on String Processing and Information
Retrieval (SPIRE), 2015. (to appear).

3. T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms,
 Third Edition. The MIT Press, 3rd edition, 2009.

4. Daniel Meister. Using swaps and deletes to make strings match. Theoretical Computer 
Science (TCS), 562(0):606 – 620, 2015.

5. T. D. Spreen. The Binary String-to-String Correction Problem. Master’s thesis,

University of Victoria, Canada, 2013.

6. R. A. Wagner. On the complexity of the extended String-to-String Correction Problem.
 In Proceedings of the seventh annual ACM Symposium on Theory Of Computing
(STOC), pages 218–223. ACM, 1975.

7. R. A. Wagner and M. J. Fischer. The String-to-String Correction Problem. Journal

of the ACM (JACM), 21(1):168–173, 1974.

8. R. A. Wagner and R. Lowrance. An extension of the String-to-String Correction

Problem. Journal of the ACM (JACM), 22(2):177–183, 1975.

9. N. Watt. String to String Correction kernelization. Master’s thesis, University of

Victoria, Canada, 2013.

