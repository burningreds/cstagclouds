Compact Rich-Functional Binary Relation

Representations

J´er´emy Barbay1, Francisco Claude2,(cid:2), and Gonzalo Navarro1,(cid:2)(cid:2)

1 Department of Computer Science, University of Chile

{jbarbay,gnavarro}@dcc.uchile.cl

2 David R. Cheriton School of Computer Science, University of Waterloo

fclaude@cs.uwaterloo.ca

Abstract. Binary relations are an important abstraction arising in a
number of data representation problems. Each existing data structure
specializes in the few basic operations required by one single application,
and takes only limited advantage of the inherent redundancy of binary
relations. We show how to support more general operations eﬃciently,
while taking better advantage of some forms of redundancy in practical
instances. As a basis for a more general discussion on binary relation
data structures, we list the operations of potential interest for practical
applications, and give reductions between operations. We identify a set of
operations that yield the support of all others. As a ﬁrst contribution to
the discussion, we present two data structures for binary relations, each
of which achieves a distinct tradeoﬀ between the space used to store and
index the relation, the set of operations supported in sublinear time,
and the time in which those operations are supported. The experimental
performance of our data structures shows that they not only oﬀer good
time complexities to carry out many operations, but also take advantage
of regularities that arise in practical instances to reduce space usage.

1 Introduction

Binary relations appear everywhere in Computer Science. Graphs, trees, inverted 
indexes, strings and permutations are just some examples. They have also
been used as a tool to complement existing data structures (such as trees [3] or
graphs [2]) with additional information, such as weights or labels on the nodes
or edges, that can be indexed and searched. Interestingly, the data structure
support for binary relations has not undergone a systematic study, but rather
one triggered by particular applications: we aim to remedy this fact.
Let us say that a binary relation B relates objects in [1, n] with labels in [1, σ],
containing t pairs out of the nσ possible ones. A simple entropy measure using
these parameters and ignoring any other possible regularity is H(B) = log
=
t log nσ
t +O(t) bits (log = log2 in this paper). Fig. 1 (top left) illustrates a binary
relation (identifying labels with rows and objects with columns henceforth).

(cid:2)
nσ
t

(cid:3)

(cid:2) Funded by NSERC of Canada and Go-Bell Scholarships Program.
(cid:2)(cid:2) Funded in part by Fondecyt Grant 1-080019, Chile.

A. L´opez-Ortiz (Ed.): LATIN 2010, LNCS 6034, pp. 170–183, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

Compact Rich-Functional Binary Relation Representations

171

1 2 3 4 5 6 7 8 9
A . . 1 . . . . . .
B . . . . . 1 1 . .
C . . . 1 . 1 . 1 .
D . 1 . . . . . . .
E 1 . . 1 1 . . . .
F . . . . . . . . 1
G . . . . 1 . 1 . .
H 1 1 . . . . . . .

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
E H D H A C E E G B C B G C F
1 10 1 10 10 1 10 1 10 1 10 1 10 10 10

B

A-D/E-H 1 1 0 1 0 0 1 1 1 0 0 0 1 0 1

3 5 6 10 11 12 14
D A C B C B C
A-B/C-D 1 0 1 0 1 0 1

1 2 4 7 8 9 13 15
E H H E E G G F
E-F/G-H 0 1 1 0 0 1 1 0

1 2 3 4 5 6 7 8 9
A-D 0 1 1 1 0 1 1 1 0
E-H 1 1 0 1 1 0 1 0 1

5 10 12
A B B
A/B 0 1 1

C/D 3 6 11 14
D C C C
1 0 0 0

1 7 8 15
E E E F
E/F 0 0 0 1

2 4 9 13
H H G G
G/H 1 1 0 0

2 3 4 6 7 8
A-B 0 1 0 1 1 0
C-D 1 0 1 1 0 1

1 2 4 5 7 9
E-F 1 0 1 1 0 1
G-H 1 1 0 1 1 0

3 6 7
A 1 0 0
B 0 1 1

2 4 6 8
C 0 1 1 1
D 1 0 0 0

1 4 5 9
E 1 1 1 0
F 0 0 0 1

1 2 5 7
G 0 0 1 1
H 1 1 0 0

Fig. 1. An example of binary relation (top left), its representation according to Sec. 4
(right) and according to Sec. 5 (bottom). Note that the labels and object numbers are
included in each node solely for ease of reading; in the encoding they are implicit.

Previous work focused on relatively basic primitives for binary relations: extract 
the list of all labels associated to an object or of all objects associated to
a label (an operation called access), or extracting the r-th such element (an
operation called select), or counting how many of these are there up to some
object/label value (called operation rank).

The ﬁrst representation speciﬁcally designed for binary relations [3] supports
rank, select and access on the rows (labels) of the relation, for the purpose of
supporting faster joins on labels. It was later extended to index text [13], and to
separate the content from the index [4], which in turn allows supporting labeled
operations on planar and quasi-planar labeled graphs [2].

Ad-hoc compressed representations for inverted lists [22] and Web graphs [12]
can also be considered as supporting binary relations. The idea here is to write
the objects of the pairs, in label-major order, and support extracting substrings
of the resulting string, that is, little more than access on labels. The string can
be compressed by diﬀerent means depending on the application.

In this paper we aim at describing the foundations of eﬃcient compact data
structures for binary relations. We list operations of potential interest for practical 
applications; we give various reductions between operators, thus identifying
a core set of operations which support all others; we present two data structures
for binary relations, each of which achieves a distinct tradeoﬀ between the space
used to store and index the relation and the time in which the operations are
supported; and we compare the practical performances of our data structures
with the state of the art, showing that our data structures not only oﬀer good
time complexities to carry out many operators, but also reduce the space used
by taking advantage of the redundancy of practical instances.

172

J. Barbay, F. Claude, and G. Navarro

Our ﬁrst data structure uses the reduction of binary relation operators to
string operators [3], but in conjunction with a wavelet tree [16] rather than with
Golynski et al.’s string data structure [15]. Our second data structure extends
the wavelet tree for strings to binary relations. The space used is potentially
smaller than for the previous data structure (close to H(B) bits), at the cost
of worse time for some operations, but it permits taking further advantage of
some common regularities present in real-life binary relations. For the sake of
simplicity, we aim for the simplest description of the operations, ignoring any
practical improvement that does not make a diﬀerence in terms of complexity,
or trivial extensions such as interchanging labels and objects to obtain other
space/time tradeoﬀs.

2 Basic Concepts

Given a sequence S of length n, drawn from an alphabet Σ of size σ, we want
to answer the queries: (1) ranka(S, i) counts the occurrences of symbol a ∈ Σ
in S[1, i]; (2) selecta(S, i) ﬁnds the i-th occurrence of symbol a ∈ Σ in S; and
(3) access(S, i) = S[i]. We omit S if clear from context.
For the special case Σ = {0, 1}, the problem has been solved using n + o(n)
bits of space while answering the three queries in constant time [10]. This was
later improved to use nH0(S) + o(n) bits [21]. Here H0(S) is the zero-order
entropy of sequence S, deﬁned as H0(S) =
a∈Σ #a/n log(n/#a), where #a is
the number of occurrences of symbol a in S.

(cid:4)

The wavelet tree [16] reduces the three operations on general alphabets to
those on binary sequences. It is a perfectly balanced tree that stores a bitmap of
length n at the root; every position in the bitmap is either 0 or 1 depending on
whether the symbol at this position belongs to the ﬁrst half of the alphabet or
to the second. The left child of the root will handle the subsequence of S marked
with a 0 at the root, and the right child will handle the 1s. This decomposition
into alphabet subranges continues recursively until reaching level (cid:3)log σ(cid:4), where
the leaves correspond to individual symbols. We call Bv the bitmap at node v.
The access query S[i] can be answered by following the path described for
position i. At the root v, if Bv[i] = 0/1, we descend to the left/right child,
switching to the bitmap position rank0/1(Bv, i) in the left/right child, which
then becomes the new v. This continues recursively until reaching the last level,
when we arrive at the leaf corresponding to the answer symbol. Query ranka(S, i)
can be answered similarly to access, except that we descend according to a and
not to the bit of Bv. We update position i for the child node just as before.
At the leaves, the ﬁnal bitmap position i is the answer. Query selecta(S, i)
proceeds as rank, but upwards. We start at the leaf representing a and update
i to select0/1(Bv, i) where v is the parent node, depending on whether the
current node is its left/right child. At the root, position i is the result.

Wavelet trees require n log σ + o(n) log σ bits of space, while answering all the
queries in O(log σ) time. If the bitmaps Bv are represented using the technique
of Raman et al. [21], the wavelet tree uses nH0(S)+ o(n) log σ bits. Fig. 1 (right)

Compact Rich-Functional Binary Relation Representations

173

illustrates the structure. Wavelet trees are not only used to represent strings [14],
but also grids [7], permutations [5], and many other structures.

3 Operations

3.1 Deﬁnition of Operations

Data structures for binary relations which support eﬃciently the rank and
select operations on the row (label) yield faster searches in relational databases
and text search engines [3] and, in combination with data structures for ordinal
trees, yield faster searches in multi-labeled trees, such as those featured by semistructured 
documents [3] (e.g. XML). A similar technique [2] combining various
data structures for graphs with binary relations yields a family of data structures
for edge-labeled and vertex-labeled graphs that support labeled operations on
the neighborhood of each vertex. The extension of those operations to the union
of labels in a given range allows them to handle more complex queries, such as
conjunctions of disjunctions.

As a simple example, an inverted index [22] can be seen as a relation between
vocabulary words (the labels) and the documents where they appear (the ob-
jects). Apart from the basic operation of extracting the documents where a word
appears (access on the row), we want to intersect rows (implemented on top of
row rank and select) for phrase and conjunctive queries (popular in Googlelike 
search engines). Extending these operations to a range of words allows for
stemmed and/or preﬁx searches (by properly ordering the words). Extracting a
column gives important summarization information on a document: the list of
its diﬀerent words. Intersecting columns allows for analysis of content between
documents (e.g. plagiarism or common authorship detection). Handling ranges
of documents allows for considering hierarchical document structures such as
XML or ﬁlesystems (search within a subtree or subdirectory).

As another example, a directed graph is just a binary relation between vertices.
 Extracting rows or columns supports direct and reverse navigation from a
node. In Web graphs, where the nodes (Web pages) are usually sorted by URL,
ranges of nodes correspond to domains and subdirectories. For example, counting 
the number of connections between two ranges of nodes allows estimating
the connectivity between two domains. In general, considering domain ranges
permits the analysis and navigation of the Web graph at a coarser granularity
(e.g. as a graph of hosts, or institutions).

Several text indexing data structures [8,13,17,18,20] resort to a grid, which
relates for example text suﬃxes (in lexicographical order) with their text positions,
 or phrase preﬁxes and suﬃxes in grammar compression, or two labels that
form a rule in straight-line programs, etc. The most common operation needed
is counting and returning all the points in a range.

Obviously, the case where the relation represents a geometric grid, where
objects and labels are simply coordinates, and where pairs of the relation are
points at those coordinates, is useful for GIS and other geometric applications.

174

J. Barbay, F. Claude, and G. Navarro

lab_num

lab_rnk

lab_rnk1

rel_num

rel_rnk

obj_num

lab_num

rel_num

rel_rnk

rel_rnk_lab_maj

rel_rnk_obj_maj

obj_rnk

lab_rnk

rel_rnk_lab_maj

rel_rnk_obj_maj

rel_sel_lab_maj

rel_sel_obj_maj

obj_rnk1

lab_rnk1

rel_sel_lab_maj

rel_sel_obj_maj

rel_acc_lab_maj

rel_acc_obj_maj

rel_acc_lab_maj

rel_acc_obj_maj

obj_num

obj_rnk

obj_rnk1

lab_sel

rel_min_lab_maj rel_min_obj_maj

obj_sel

lab_sel

rel_min_lab_maj rel_min_obj_maj

obj_sel

lab_sel1

lab_min

lab_acc

obj_acc

obj_min

obj_sel1

lab_sel1

lab_min

lab_acc

obj_acc

obj_min

obj_sel1

Fig. 2. Results achieved by reducing to strings (left) and by the binary-relation wavelet
tree (right). Grayed boxes are the operations we adressed directly; all the others are
supported via reductions given in Theorem 1: constant-time ones are represented by
solid arrows, and non-constant-time ones by dashed arrows. Operations supported in
time O(log σ) are in solid squares. Dashed squares represent operations supported
in higher time. We draw only the dashed arrows needed to follow the source of the
operations supported via non-constant-time reductions.

The generalization of the basic operations to ranges allows for counting the
number of points in a rectangular area, and retrieving them in diﬀerent orders.
These examples illustrate several useful ways to extend the deﬁnition of the
rank and select operations from single rows (labels) or columns (objects) to
ranges over both rows and columns. Consider for instance the extension of
select to ranges of labels: select(α, r) yields the position of the r-th 1 in
the row α of the matrix (see Fig. 1 (top left)), corresponding to the r-th object
associated to label α. On the range of rows [α, β], the expression “the r-th 1”
requires a total order on the two-dimensional area deﬁned by the range (e.g.
label-major or object-major), which yields two distinct extensions of the operation.
 Other applications require instead a select operation that retrieves the
r-th object associated to any label from a given range, regardless of how many
pairs the object participates in.

We generalize the access operation to ranges of labels and objects by supporting 
the search for the minimal (resp. maximal) label or object that participates
in a given rectangular area of the relation, and the search for the ﬁrst related pair
(in label-major or object-major order) in this area. Among other applications,
this supports the search for the highest (resp. lowest) neighbor of a point, when
the binary relation encodes the levels of points in a planar graph representing a
topography map [2].

Those examples require many distinct extensions for each of the rank, select

and access operations. Table 1 lists their formal deﬁnitions.

3.2 Reductions between Operations

The solid arrows in Fig. 2 (left) show the constant-time reductions that we identiﬁed 
among the operations; disregard the rest for now. A solid arrow op → op(cid:4)
means that solving op we also solve op(cid:4). First, rel rnk is a particular case
of rel num, whereas the latter can be supported by adding/subtracting four
rel rnk queries at the corners of the rectangle. Hence they are equivalent.

Compact Rich-Functional Binary Relation Representations

175

Table 1. Operations of interest for binary relations on [1, σ]× [1, n] (labels × objects).
x, y, z are objects (usually x ≤ z ≤ y); α, β, γ are labels (usually α ≤ γ ≤ β); r is an
integer (typically an index, parameter of select) and ‘#’ is short for ‘number of’. The
solutions for maxima are similar to those for minima. The last two columns are the
complexities we achieve in Section 4 and 5, respectively, per delivered datum.

Operation Meaning

rel num(α, β, x, y) # pairs in [α, β] × [x, y]
rel rnk(α, x) # pairs in [1, α] × [1, x]

rel rnk lab maj(x, y, α, z) # pairs in [x, y], up to (α, z) †
rel sel lab maj(α, r, x, y) r-th pair in [x, y] × [α, σ] †

rel acc lab maj(α, x, y) consecutive pairs in [α, σ] × [x, y] †
rel min lab maj(α, x, y) minimum pair in [α, σ] × [x, y] †
rel rnk obj maj(α, β, γ, x) # pairs in [α, β], up to (γ, x) ‡
rel sel obj maj(α, β, x, r) r-th pair in [α, β] × [x, n] ‡

rel acc obj maj(α, β, x) consecutive pairs in [α, β] × [x, n] ‡
rel min obj maj(α, β, x) minimum pair in [α, β] × [x, n] ‡
lab num(α, β, x, y) # distinct labels in [α, β] × [x, y]
lab rnk(α, x, y) # distinct labels in [1, α] × [x, y]
lab sel(α, r, x, y) r-th distinct label in [α, σ] × [x, y]
lab acc(α, x, y) consecutive labels in [α, σ] × [x, y]
lab min(α, x, y) minimum label in [α, σ] × [x, y]
obj num(α, β, x, y) # distinct objects in [α, β] × [x, y]
obj rnk(α, β, x) # distinct objects in [α, β] × [1, x]
obj sel(α, β, x, r) r-th distinct object in [α, β] × [x, n]
obj acc(α, β, x) consecutive objects in [α, β] × [x, n]
obj min(α, β, x) minimum object in [α, β] × [x, n]
lab rnk1(α, x) # distinct labels in [1, α] × x
lab sel1(α, r, x) r-th distinct label in [α, σ] × x
obj rnk1(α, x) # distinct objects in α × [1, x]
obj sel1(α, x, r) r-th distinct object in α × [x, n]

String
O(log σ)
O(log σ)
O(log σ)
O(log σ)
O(log σ)
O(log σ)
O(log σ)

(+)

O(log σ)
O(log σ)

O(r log σ)
O(log σ)
O(log σ)
O(r log σ)
O(r log σ)
O(r log σ)
O(log σ)
O(log σ)
O(log σ)
O(log σ)
O(log σ)
O(log σ)

O(β−α+log σ) O(β−α+log σ)
O(α + log σ)
O(α + log σ)

BRWT

O(β−α+log σ) (*)

O(α + log σ)

O(α + log σ) (*)

O(r log σ) (*)

O(log σ)
O(log σ)

O(β − α + log σ)

O(r log σ)
O(log σ)
O(log σ)

O(r log σ)
O(log σ)
O(log σ)
O(r log σ)
O(r log σ)
O(r log σ)
O(log σ)
O(log σ)
O(r log σ)
O(r log σ)
O(log σ)
O(log σ)

(+) O(min(r, log n, log r log(β − α + 1)) log σ)
(*) O(log σ) if [x, y] = [1, n]

† in label-major order
‡ in object-major order

With a constant number of any of these we also cover the areas described by
rel rnk obj maj and rel rnk lab maj, and vice versa, thus these are equivalent 
too. Obviously, obj rnk1 and lab rnk1 are particular cases of rel num. Also,
lab rnk1 is a particular case of lab rnk, itself a particular case of lab num. Note
that lab num does not reduce to lab rnk because a label could be related with
objects inside and outside the range [x, y]. Similar reductions hold for objects.
Obviously the support for the select operation rel sel lab maj implies the
support for the access operation rel acc lab maj, and accessing the ﬁrst result
of the latter gives the solution for the minimum operation rel min lab maj. In
turn this gives the minimum label in a range [α, σ] × [x, y], thus if this label
is β, we get the next label by rerunning the query on [β + 1, σ] × [x, y], this
way supporting lab acc. The latter, in turn, gives the solution to lab min in its
ﬁrst iteration, whereas successive invocations to lab min (in a fashion similar
to rel min lab maj) solves lab acc. Also analogously as before, lab sel allows
supporting lab min by asking the ﬁrst occurrence, and lab sel1 is a particular
case of lab sel. Note also that rel sel lab maj allows supporting lab sel1,
by requiring the pairs starting at the desired rows, and extracting the resulting
objects. By symmetry, analogous reductions hold for objects instead of labels.

176

J. Barbay, F. Claude, and G. Navarro

The rest of the following theorem stems from inverse-function relations between 
rank and select queries, as well as one-by-one solutions to counting and
direct-access problems.
Theorem 1. All the arrows in Figure 2 (left) represent constant-time reductions 
that hold for the operations. In addition, the pairs (lab num, lab sel)
support each other with an O(log σ) penalty factor,
(obj num, obj sel)
with an O(log n) penalty factor, and (rel rnk lab maj, rel sel lab maj)
and (rel rnk obj maj, rel sel obj maj) with an O(log(σn)) penalty factor.
 Finally, in pairs (lab acc, lab sel), (rel acc lab maj, rel sel lab maj),
(obj acc, obj sel), and (rel acc obj maj, rel sel obj maj), the ﬁrst operation 
supports the second with an O(r) penalty factor, where r is the parameter of
the select operation. Finally, the access operations support the corresponding
rank (and counting) operations in time proportional to the answer of the latter.

4 Reduction to Strings

A simple representation for binary relations [3,13] consists in a bitmap B[1, n+t]
and a string S[1, t] over the alphabet [1, σ]. The bitmap B[n+t] concatenates the
consecutive cardinalities of the n columns of the relation in unary. The string
S contains the rows (labels) of the pairs of the relation in column (object)-
major order (see Fig. 1 (right)). Barbay et al. showed [3] that an easy way to
support the rank and select operations on the rows of the binary relation is to
support the rank and select operations on B and S, using any of the several
data structures known for bitmaps and strings. We show that representing S
using a wavelet tree yields the support for more complex operations. For this
purpose, we deﬁne the mapping from a column number x to its last element in
S as map(x) = rank1(B, select0(B, x)). The inverse, from a position in S to its
column number, is unmap(m) = rank0(B, select1(B, m)) + 1. Both mappings
take constant time. Finally, let us also deﬁne for shortness rankc(B, x, y) =
rankc(B, y)−rankc(B, x−1). The following operations are supported eﬃciently,
and many others are derived with Theorem 1.
• rel rnk(α, x) in O(log σ) time. This is rank≤α(S, map(x)), where operation
rank≤α(S, m) counts the number of symbols ≤ α in S[1, m]. It can be supported
in time O(log σ) in a string wavelet tree by following the root-to-leaf branch
corresponding to α, while counting at each node the number of objects preceding
position m that are related with a label preceding α, as follows. Start at the
root v with counter c ← 0. If α corresponds to the left subtree, then enter the
left subtree with m ← rank0(Bv, m). Else enter the right subtree with c ←
c + rank0(Bv, m) and m ← rank1(Bv, m). When a leaf is reached (indeed, that
of α), the answer is c + m.
• rel sel lab maj(α, r, x, y) in O(log σ) time. We ﬁrst get rid of α by setting
r ← r + rel num(1, α − 1, x, y) and thus reduce to the case α = 1. Furthermore
we map x and y to the domain of S by x ← map(x − 1) + 1 and y ← map(y).

Compact Rich-Functional Binary Relation Representations

177

We ﬁrst ﬁnd which is the symbol β whose row contains the r-th element. For
this sake we ﬁrst ﬁnd the β such that rank≤β−1(S, x, y) < r ≤ rank≤β(S, x, y).
This is achieved in time O(log σ) as follows. Start at the root v and set r(cid:4) ← r.
If rank0(Bv, x, y) ≥ r, then continue to the left subtree with x ← rank0(Bv, x−
1) + 1 and y ← rank0(Bv, y). Else continue to the right subtree with r(cid:4) ←
r(cid:4) − rank0(Bv, x, y), x ← rank1(Bv, x − 1) + 1, and y ← rank1(Bv, y). The leaf
arrived at is β. Finally, we set r ← r − r(cid:4), and answer (β, unmap(selectβ(S, r +
rankβ(S, x − 1)))).
• rel sel obj maj(α, β, x, r) in O(min(log n, log r log(β − α + 1)) log σ) time.
Remember that the elements are written in S in object major order. First, we
note that the particular case where [α, β] = [1, σ] is easily solved in O(log σ)
time, by doing r(cid:4) ← r + rel num(1, σ, 1, x − 1) and returning (S[r(cid:4)], unmap(r(cid:4))).
In the general case, one can obtain time O(log n log σ) by binary searching the
column y such that rel num(α, β, x, y) < r ≤ rel num(α, β, x, y + 1). Then the
answer is (lab sel1(α, r − rel num(α, β, x, y), y), y). Finally, to obtain the other
complexity, we ﬁnd the O(log(β − α + 1)) wavelet tree nodes that cover the
interval [α, β]; let these be v1, v2, . . . , vk. We map position x from the root towards 
those vis, obtaining all the mapped positions xi in O(k + log σ) time.
Now the answer is within the positions [xi, xi + r − 1] of some i. We cyclically 
take each vi, choose the middle element of its interval, and map it towards 
the root, obtaining position y, corresponding to pair (S[y], unmap(y)). If
rel rnk obj maj(α, β, S[y], unmap(y)) − rel rnk(α, β, 1, x − 1) = r, the answer
is (S[y], unmap(y)). Otherwise we know whether y is before or after the answer.
So we discard the left or right interval in vi. After O(k log r) such iterations we
have reduced all the intervals of length r of all the nodes vi, ﬁnding the answer.
Each iteration costs O(log σ) time.
• rel acc obj maj(α, β, x) in O(log σ) time per pair output. Just as for the
last solution of the previous operator, we obtain the positions xi at the nodes
vi that cover [α, β]. The ﬁrst element to deliver is precisely one of those xi. We
have to merge the results, choosing always the smaller, as we return from the
recursion that identiﬁes the vi nodes. If we are in vi, we return y = xi. Else, if
the left child of v returned y, we map it to y(cid:4) ← rank0(Bv, y). Similarly, if the
right child of v returned y, we map it to y(cid:4)(cid:4) ← rank1(Bv, y). If we have only
y(cid:4) (y(cid:4)(cid:4)), we return y = y(cid:4) (y = y(cid:4)(cid:4)); if we have both we return y = min(y(cid:4), y(cid:4)(cid:4)).
The process takes O(log σ) time. When we arrive at the root we have the next
position y where a label in [α, β] occurs in S. We can then report all the pairs
(S[y + j], unmap(y)), for j = 0, 1, . . ., as long as unmap(y + j) = unmap(y) and
S[y + j] ≤ β. Once we have reported all the pairs corresponding to object
unmap(y), we can obtain those of the next objects by repeating the procedure
from rel acc obj maj(α, β, unmap(y) + 1).
• lab num(α, β, x, y) in O(β − α + log σ) time. After mapping x and y to
positions in S, we descend in the wavelet tree to ﬁnd all the leaves in [α, β] while
remapping [x, y] appropriately. We count one more label each time we arrive at
a leaf, and we stop descending from an internal node if its range [x, y] is empty.

178

J. Barbay, F. Claude, and G. Navarro

• obj sel1(α, x, r) in O(log σ) time: This is a matter of selecting the r-th
occurence of the label α in S, after the position of the pair (α, x). The formula
is unmap(selectα(S, r + obj rnk1(α, x − 1))).

The overall result is stated in the next theorem and illustrated in Fig. 2 (left).
Theorem 2. There is a representation for a binary relation B, of t pairs over
[1, σ] × [1, n], using t log σ + o(t) log σ + O(min(n, t) log( n+t
min(n,t))) bits of space.
The structure supports operations rel rnk(α, x), rel sel lab maj(α, r, x, y),
rel sel obj maj(1, σ, x, r) (note the limitation), rel acc obj maj(α, β, x), and
obj sel1(α, x, r), in time O(log σ), plus rel sel obj maj(α, β, x, r) in time
O(min(log n, log r log(β−α+1)) log σ), and lab num(α, β, x, y) in time O(β−α+
log σ). The other operations are supported via the reductions from Theorem 1.

Proof. The operations have been obtained throughout the section. For the
space, B contains n 0s out of n + t, so a compressed representation [21] re-
min(t,n)) bits. The wavelet tree for S[1, t] requires t log σ +
quires O(min(t, n) log
(cid:2)
o(t) log σ bits.

n+t

Note that the particular case rel num(1, σ, x, y) can be answered in O(1) time
using B’s succinct encoding. In general the space result is incomparable with
tH(B): if all the nσ pairs are related, then tH0(S) = nσ log σ and H(B) = 0;
but if all the pairs are within a row, then tH0(S) = 0 and H(B) > 0. In the
particular case where t ≤ n, t log σ ≤ tH(B) + O(t), while the wavelet tree for S
requires tH0(S) ≤ t log σ bits: this diﬀerence can be relevant depending on the
distribution of pairs across the rows.

5 Binary Relation Wavelet Trees (BRWT)

We propose now a special wavelet tree structure to represent binary relations.
This wavelet tree contains two bitmaps per level at each node v, Bl
v and Br
v.
At the root, Bl
v[1, n] has the x-th bit set to 1 iﬀ there exists a pair of the form
(α, x) for α ∈ [1,(cid:9)σ/2(cid:10)], and Br
v has the x-th bit set to 1 iﬀ there exists a pair
of the form (α, x) for α ∈ [(cid:9)σ/2(cid:10) + 1, σ]. Left and right subtrees are recursively
built on the positions set to 1 in Bl
v, respectively. The leaves (where no
bitmap is stored) correspond to individual rows of the relation. We store a bitmap
B[1, σ + t] recording in unary the number of elements in each row. See Fig. 1
(bottom) for an example. For ease of notation, we deﬁne the following functions
on B, trivially supported in constant-time: lab(r) = 1+rank0(B, select1(B, r))
gives the label of the r-th pair in a label-major traversal of R; while its inverse
poslab(α) = rank1(B, select0(B, α)) gives the position in the traversal where
the pairs for label α start.

v and Br

Note that, because an object x may propagate both left and right, the sizes
of the second-level bitmaps may add up to more than n bits. Indeed, the last
level contains t bits and represents all the pairs sorted in row-major order.

Compact Rich-Functional Binary Relation Representations

179

The following operations can be carried out eﬃciently on this structure.

v, y) or y ← select1(Br

• rel num(α, β, x, y) in O(β−α+log σ) time. We project the interval [x, y] from
the root to each leaf in [α, β], adding up the resulting interval sizes at leaves. Of
course we can stop earlier if the interval becomes empty. Note that we can only
count pairs at the leaves. In the case [x, y] = [1, n] we can achieve O(1) time, as
the answer is simply poslab(β) − poslab(α − 1). Note this allows solving the
restricted case rel rnk lab maj(1, n, α, z) in O(log σ) time.
• rel sel lab maj(α, r, 1, n) in O(log σ) time. Let r(cid:4) ← r + poslab(α− 1) and
β ← lab(r(cid:4)), thus β is the row where the answer is. Now we start at position
y = r(cid:4)−poslab(β−1) in leaf β and walk the wavelet tree upwards while mapping
y ← select1(Bl
v, y), depending on whether we are left
or right child of our parent v, respectively. When we reach the root, the answer
is (β, y). Note we are only solving the particular case [x, y] = [1, n].
• rel acc lab maj(α, x, y) in O(log σ) time per pair output. Map [x, y] from
the root to each leaf in [α, σ], abandoning a path when [x, y] becomes empty.
(Because left and right child cannot become simultaneously empty, the total
amount of work is proportional to the number of leaves that contain pairs to
report.) Now, for each leaf γ arrived at with interval [x(cid:4), y(cid:4)], map each z(cid:4) ∈ [x(cid:4), y(cid:4)]
up to the root, to discover the associated object z, and return (γ, z).
• rel acc obj maj(α, β, x) in O(log σ) time per pair output. Just as in Section 
4, we cover [α, β] with O(log σ) wavelet tree nodes v1, v2, . . . , and map x to
xi at each such vi, all in O(log σ) time. Now, on the way back of this recursion,
we obtain the next y ≥ x in the root associated to some label in [α, β], by following 
a process analogous to that for rel acc obj maj in Section 4. Finally, we
start from position y(cid:4) = y at the root v and report all the pairs related to y: Re-
v[y(cid:4)] = 1, remapping y(cid:4)
cursively, we descend left if Bl
appropriately at each step, and keeping within the interval [α, β]. Upon reaching
each leaf γ we report (γ, y). Then we continue from rel acc obj maj(α, β, y+1).
• lab num(α, β, x, y) in O(β − α + log σ) time. Map [x, y] from the root to each
leaf in [α, β], adding one per leaf where the interval is nonempty. Recursion can
stop when [x, y] becomes empty.
• obj sel1(α, x, r) in O(log σ) time. Map x − 1 from the root to x(cid:4) in leaf
α, then walk upwards the path from x(cid:4) + r to the root and report the position
obtained.

v[y(cid:4)] = 1, and then right if Br

We have obtained the following theorem, illustrated in Fig. 2 (right; we ignore

of

space. The

the particular cases).
Theorem 3. There is a representation for a binary relation B, of t pairs
√
2)tH(B) + o(tH(B)) + O(t + n + σ)
over [1, σ] × [1, n], using log(1 +
rel num(α, β, 1, n),
bits
structure
rel rnk lab maj(1, n, α, z),
(note
limitations 
of
these three), rel acc lab maj(α, x, y), rel acc obj maj(α, β, x),
and
and
rel num(α, β, x, y)
lab num(α, β, x, y) in time O(β − α + log σ). This yields the support
for
other operations via the reductions from Theorem 1.

operations
rel sel lab maj(α, r, 1, n)

in time O(log σ),

obj sel1(α, x, y),

supports

the

plus

180

J. Barbay, F. Claude, and G. Navarro

σ+t

v and Br

(cid:4)

x tx log σ

Proof. The operations have been obtained throughout the section. For the space,
B contains σ 0s out of σ + t, so a compressed representation [21] requires
O(min(σ, t) log
min(σ,t)) = O(max(σ, t)) bits. The space of the wavelet tree can
be counted as follows. Except for the 2n bits in the root, each other bit is induced
by the presence of a pair. Each pair has a unique representative bit in a leaf, and
also induces the presence of bits up to the root. Yet those leaf-to-root paths get
merged, so that not all those bits are diﬀerent. Consider an element x related
to tx labels. It induces tx bits at tx leaves, and their paths of bits towards the
single x at the root. At worst, all the O(tx) bits up to level log tx are created
for these elements, and from there on all the tx paths are diﬀerent, adding up a
total of O(tx) + tx log σ
tx . Adding over all x we get O(t) +
tx . This is
t = tH(B) + O(t) bits.
maximized when tx = t/n for all x, yielding O(t) + t log σn
Instead of representing two bitmaps (which would multiply the above value
by 2), we can represent a single sequence Bv with the possible values of the two
bits at each position, 00, 01, 10, 11. Only at the root 00 is possible. Except for
those 2n bits, we can represent the sequence over an alphabet of size 3 following
Ferragina et al. [14], to achieve at worst (log 3)tH(B)+o(tH(B)) bits for this part
while retaining constant-time rank and select over each Bl
v. (To achieve
√
this, we maintain the directories for the original bitmaps, of sublinear-size.)
2), we consider that the representation 
by Ferragina et al. actually achieves |Bv|H0(Bv) bits. We call (cid:7)x = |Bv| ≤ tx
and Hx = |Bv|H0(Bv). After level log tx, there is space to put all the tx bits separately,
 thus using only 01 and 10 symbols we achieve (cid:7)x = tx and Hx = tx bits.
Yet, this is not the worst that can happen. Hx can be increased by collapsing
some 01’s and 10’s into 11’s (thus reducing (cid:7)x). Note that collapsing further 01’s
or 10’s or 11’s with 11’s eﬀectively removes one symbol from Bv, which cannot
increase Hx, thus we do not consider these. Assume the tx bits are partitioned
into t01 01’s, t10 10’s, and t11 11’s, so that tx = t01+t10+2t11, (cid:7)x = t01+t10+t11,
t11 . As t11 = (tx−t01−t10)/2, the maxiand 
Hx = t01 log (cid:8)x
mum of Hx as a function of t01 and t10 yields the worst case at t01 = t10 =
tx,
2)tx bits. This
so t11 = ( 1
2
can be achieved separately at each level. Using the same distribution of 01’s,
(cid:2)
10’s, and 11’s for all x we add up to (1 +
√
2) ≈ 1.272 away of the entropy of B. On
Note that this is a factor of log(1 +
the other hand, it is actually better if the tx do not distribute uniformly.

√
4 )tx, where Hx = log(1 +

To improve the constant log 3 to log(1 +

t01 +t10 log (cid:8)x

t10 +t11 log (cid:8)x

√
2)t log σn

2

4 )tx and (cid:7)x = ( 1

2 +

t + O(t) bits.

√

√

2
4

− √

2

6 Exploiting Regularities

Real-life binary relations exhibit regularities that permit compressing them far
more than to tH(B) bits. For example, social networks, Web graphs, and inverted
indexes follow well-known properties such as clustering of the matrix, uneven
distribution of 1s, similarity across rows and/or columns, etc. [6,1,9].

The space tH0(S) achieved in Theorem 2 can indeed be improved upon certain
regularities. The wavelet tree of S, when bitmaps are compressed with local encoding 
methods [21], achieves locality in the entropy [19]. That is, if S = S1S2 . . . Sn

v and Br

(cid:4)

x tx log σ

v xor Br

The space formula in Theorem 3 can also be reﬁned: If some objects are related
tx can be smaller than tH(B).
to many labels and others to few, then
This second approach can be easily modiﬁed to exploit several other regularities.
Imagine we represent bitmaps Bl
v we store
B(cid:4)
v = Bl
v, while keeping the original sublinear structures for rank and
select. Any access to O(log n) contiguous bits in Br
v is achieved in constant
time under the RAM model by xor-ing Bl

v separately, but instead of Br

v and B(cid:4)
v.

The following regularities turn into a highly compressible B(cid:4)

v, that is, one
with few or many 0’s: (1) Row-wise similarities between nearby rows, extremely
common on Web graphs [6], yield an almost-all-zero B(cid:4)
v; (2) (sub)relations that
are actually permutations or strings, that is, with exactly one 1 per column,
yield an almost-all-one B(cid:4)
v. This second kind of (sub)relations are common in
relational databases, e.g., when objects or labels are primary keys in the table.
As there exists no widely agreed-upon notion of entropy for binary relations
(cid:3)
ﬁner than log
, we show now some experiments on the performance of these
representations on some real-life relations. We choose instances of three types of
binary relations: (1) Web graphs, (2) social networks, (3) inverted indexes.

(cid:2)
nσ
t

Compact Rich-Functional Binary Relation Representations

181

(cid:4)

x |Sx|H0(Sx) + O(n log t). In particular, if Sx correthen 
the space achieved is
sponds to the labels related to object x, then the space will beneﬁt from clustering
in the binary relation: If each object is related only to a small subset of labels, then
its Sx will have a small alphabet and thus a small entropy. Alternatively, similar
columns (albeit not rows) induce copies in string S. This is not captured by the
zero-order entropy, but it is by grammar compression methods. Some have been
exploited for graph compression [12].

For (1), we downloaded two crawls from the WebGraph project [6],
http://law.dsi.unimi.it. Crawl EU (2005) contains n = σ = 862, 664 nodes
and t = 19, 235, 140 edges. Crawl Indochina (2004) contains n = σ = 7, 414, 866
nodes and t = 194, 109, 311 edges. For (2), we downloaded a coauthorship
graph from DBLP (http://dblp.uni-trier.de/xml), which is a symmetric relation,
 and kept the upper triangle of the symmetric matrix. The result contains
n = σ = 452, 477 authors and t = 1, 481, 877 coauthorships. For (3), we consider
the relation FT, the inverted index for all of the Financial Times collections from
trec-4 (http://trec.nist.gov), converting the terms to lowercase. It relates
σ = 502, 259 terms with n = 210, 139 documents, using t = 51, 290, 320 pairs.
Table 2 shows, for these relations B, their entropy H(B), their gap complexity
(deﬁned below), the space of the string representation of Section 4, the space
of the BRWT representation of Section 5, and that using the xor-improvement
described above. All spaces are measured in bits per pair of the relation.

The gap complexity is the sum of the logarithms of the consecutive diﬀerences 
of objects associated to each label. It is upper bounded by the entropy
and gives a more reﬁned measure that accounts for clustering in the matrix. The
string representation of Section 4 already improves upon the entropy, but not
much. Although it has more functionality, this representation requires signiﬁcantly 
more space than the BRWT, which takes better advantage of regularities.
Note, however, that for example Web graphs are much more amenable than the

182

J. Barbay, F. Claude, and G. Navarro

Table 2. Entropy and space consumption, in bits per pair, of diﬀerent binary relation
representations over relations from diﬀerent applications. Ad-hoc representations have
limited functionality.

B
EU
Indochina
DBLP
FT

H(B) Gap
5.52
16.68
3.12
19.55
6.18
18.52
12.45
3.54

String BRWT +xor Best Ad-Hoc
12.57
12.81
15.97
13.91

4.38 (WebGraph)
1.47 (WebGraph)
21.9 (WebGraph)
6.20 (Rice)

7.72
4.07
13.54
9.32

6.87
3.93
11.67
7.85

social network to exploiting such regularities, while the inverted index is in between.
 The xor improvement has a noticeable additional eﬀect on the BRWT
space, reducing it by about 5%–15%. Particularly on the Web graphs, this latter
variant becomes close to the gap complexity.

The last column of the table shows the compression achieved by the best adhoc 
alternatives, which support a very restricted set of operations (namely, extracting 
all the labels associated to an object). The results for crawls Indochina
and EU are the best reported in the WebGraph Project page, and they even break
the gap complexity. For FT we measured the space required by Rice encoding of
the diﬀerential inverted lists, plus pointers from the vocabulary to the sequence.
This state-of-the-art in inverted indexes [22]. Finally, in absence of available software 
speciﬁcally targeted at compressing social networks, we tried WebGraph v.
1.7 (default parameters) on DBLP. As this is an undirected graph, we duplicate
each edge {i, j} as (i, j) and (j, i). This is not necessary on our representations,
as we can extract direct and reverse neighbors. Our representations are by far
the best in this case where no speciﬁc compressors exist.

7 Future Work

The times we have achieved for most operations is O(log σ), where σ is the
number of labels. These can probably be improved to O( log σ
log log t) by using recent 
techniques on multiary wavelet trees [7], which would reach the best results
achieved with wavelet trees for much simpler problems [14]. Our representations 
allow dynamic variants, where new pairs and/or objects can be inserted
in/deleted from the waveleet trees [19,11]. Adding/removing labels, instead, is
an open challenge, as it alters the wavelet tree shape. The space of our structures
is close but does not reach the entropy of the binary relation, H(B), in the worst
theoretical case. An ambitious goal is to support all the operations we have deﬁned 
in logarithmic time and within H(B)(1+ o(1)) bits of space. A related issue
is to deﬁne a ﬁner notion of binary relation entropy that captures regularities
that arise in real life, and express the space we achieve in those terms.
Finally, there is no reason why our list of operations should be exclusive. For
example, determining whether a pair is related in the transitive closure of B
is relevant for many applications (e.g. ancestorship in trees, paths in graphs).
Alternatively one could enrich the data itself, e.g., associating a tag to each
object/label pair, so that one can not only ask for the tag of a pair but also

Compact Rich-Functional Binary Relation Representations

183

ﬁnd pairs with some tag range within a range of the relation, and so on. This
extension has already found applications, e.g. [13]. Another extension is n-ary
relations, which would more naturally capture joins in the relational model.

References

1. Baeza-Yates, R., Navarro, G.: Modeling text databases. In: Recent Advances in

Applied Probability, pp. 1–25. Springer, Heidelberg (2004)

2. Barbay, J., Aleardi, L.C., He, M., Munro, J.I.: Succinct representation of labeled 
graphs. In: Tokuyama, T. (ed.) ISAAC 2007. LNCS, vol. 4835, pp. 316–328.
Springer, Heidelberg (2007)

3. Barbay, J., Golynski, A., Munro, I., Rao, S.S.: Adaptive searching in succinctly encoded 
binary relations and tree-structured documents. TCS 387(3), 284–297 (2007)
4. Barbay, J., He, M., Munro, I., Rao, S.S.: Succinct indexes for strings, binary relations 
and multi-labeled trees. In: SODA, pp. 680–689 (2007)

5. Barbay, J., Navarro, G.: Compressed representations of permutations, and applications.
 In: STACS. pp. 111–122 (2009)

6. Boldi, P., Vigna, S.: The WebGraph framework I: compression techniques. In:

WWW, pp. 595–602 (2004)

7. Bose, P., He, M., Maheshwari, A., Morin, P.: Succinct orthogonal range search structures 
on a grid with applications to text indexing. In: Dehne, F., Gavrilova, M.L.,
Sack, J.-R., T´oth, C.D. (eds.) WADS 2009. LNCS, vol. 5664, pp. 98–109. Springer,
Heidelberg (2009)

8. Chien, Y.F., Hon, W.K., Shah, R., Vitter, J.: Geometric Burrows-Wheeler trans-

form: Linking range searching and text indexing. In: DCC. pp. 252–261 (2008)

9. Chierichetti, F., Kumar, R., Lattanzi, S., Mitzenmacher, M., Panconesi, A., Raghavan,
 P.: On compressing social networks. In: KDD, pp. 219–228 (2009)

10. Clark, D.: Compact Pat Trees. Ph.D. thesis, Univ. of Waterloo, Canada (1996)
11. Claude, F.: Compressed Data Structures for Web Graphs. MSc. thesis, U. Chile (2008)
12. Claude, F., Navarro, G.: A fast and compact Web graph representation. In: Ziviani,
N., Baeza-Yates, R. (eds.) SPIRE 2007. LNCS, vol. 4726, pp. 105–116. Springer,
Heidelberg (2007)

13. Claude, F., Navarro, G.: Self-indexed text compression using straight-line programs.
 In: Kr´aloviˇc, R., Niwi´nski, D. (eds.) MFCS 2009. LNCS, vol. 5734, pp.
235–246. Springer, Heidelberg (2009)

14. Ferragina, P., Manzini, G., M¨akinen, V., Navarro, G.: Compressed representations

of sequences and full-text indexes. ACM TALG 3(2), article 20 (2007)

15. Golynski, A., Munro, J.I., Rao, S.S.: Rank/select operations on large alphabets: a

tool for text indexing. In: SODA, pp. 368–373 (2006)

16. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed text indexes. In:

SODA. pp. 841–850 (2003)

17. K¨arkk¨ainen, J.: Repetition-Based Text Indexing. Ph.D. thesis, U. Helsinki, Finland

(1999)

18. M¨akinen, V., Navarro, G.: Rank and select revisited and extended. TCS 387(3),

332–347 (2007)

19. M¨akinen, V., Navarro, G.: Dynamic entropy-compressed sequences and full-text

indexes. ACM TALG 4(3), article 32 (2008)

20. Navarro, G.: Indexing text using the Ziv-Lempel trie. JDA 2(1), 87–114 (2004)
21. Raman, R., Raman, V., Rao, S.S.: Succinct indexable dictionaries with applications

to encoding k-ary trees and multisets. In: SODA, pp. 233–242 (2002)

22. Witten, I., Moﬀat, A., Bell, T.: Managing Gigabytes, 2nd edn. Morgan Kaufmann

Publishers, San Francisco (1999)

