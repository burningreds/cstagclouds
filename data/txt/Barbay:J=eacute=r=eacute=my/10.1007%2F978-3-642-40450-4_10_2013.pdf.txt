Theory and Implementation of Online

Multiselection Algorithms

J´er´emy Barbay1,(cid:2), Ankur Gupta2,(cid:2)(cid:2), Seungbum Jo3,(cid:2) (cid:2) (cid:2),

Satti Srinivasa Rao3,(cid:2)(cid:2)(cid:2), and Jonathan Sorenson2

1 Departamento de Ciencias de la Computaci´on (DCC), Universidad de Chile
2 Department of Computer Science and Software Engineering, Butler University

3 School of Computer Science and Engineering, Seoul National University

Abstract. We introduce a new online algorithm for the multiselection
problem which performs a sequence of selection queries on a given unsorted 
array. We show that our online algorithm is 1-competitive in terms
of data comparisons. In particular, we match the bounds (up to lower
order terms) from the optimal oﬄine algorithm proposed by Kaligosi et
al.[ICALP 2005].

We provide experimental results comparing online and oﬄine algorithms.
 These experiments show that our online algorithms require fewer
comparisons than the best-known oﬄine algorithms. Interestingly, our
experiments suggest that our optimal online algorithm (when used to sort
the array) requires fewer comparisons than both quicksort and mergesort.

1

Introduction

Let A be an unsorted array of n elements drawn from an ordered universe. The
multiselection problem asks for elements of rank ri from the sequence R =
r1, r2, . . . , rq on A. We deﬁne B(Sq) as the information-theoretic lower bound
on the number of comparisons required in the comparison model to answer q
unique queries, where Sq = {si} denotes the queries ordered by rank. We deﬁne
i = si+1 − si, where s0 = 0 and sq+1 = n. Then,
ΔS

B(Sq) = log n! − q(cid:2)

(cid:3)
(cid:4)
ΔS
i !

=

log

q(cid:2)

ΔS

i log

− O(n).1

n
ΔS
i

i=0

i=0

As mentioned by Kaligosi et al. [10], intuitively B(Sq) follows from the fact that
any comparison-based multiselection algorithm identiﬁes the ΔS
1 smallest elements,
 ΔS
2 next smallest elements, and so on. Hence, one could sort the original
array A using

i + O(n) additional comparisons.

(cid:5)

i ΔS

i log ΔS

(cid:2) Supported in part by PROYECTO Fondecyt Regular no 1120054.
(cid:2)(cid:2) Supported in part by the Arete Initiative at the University of Chicago.

(cid:2) (cid:2) (cid:2) Supported in part by Basic Science Research Program through the National Research 
Foundation of Korea (NRF) funded by the Ministry of Education, Science
and Technology (Grant number 2012-0008241).

1 We use logb a to refer to the base b logarithm of a. By default, we let b = 2.

H.L. Bodlaender and G.F. Italiano (Eds.): ESA 2013, LNCS 8125, pp. 109–120, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

110

J. Barbay et al.

The online multiselection problem asks for elements of rank r1, r2, . . . , rq,

where the sequence R is given one element at a time (in any order).

Motivation. Online multiselection is equivalent to generalized partial sorting [9].
Variants of this problem have been studied under the names partial quicksort,
multiple quickselect, interval sort, and chunksort. Several applications, such as
computing optimal preﬁx-free codes [3] and convex hulls [11], repeatedly compute 
medians over diﬀerent ranges within an array. Online multiselection (where
queries arrive one at a time) may be a key ingredient to improved results for
these types of problems, whereas oﬄine algorithms will not suﬃce. Most recently,
Cardinal et al. [5] generalized the problem to partial order production, and they
use multiselection as a subroutine after an initial preprocessing phase.

Previous Work. Several papers [6,12,9] have analyzed the oﬄine multiselection
problem, but these approaches must all know the queries in advance. Kaligosi et
al. [10] described an algorithm performing B(Sq)+ o(B(Sq))+ O(n) comparisons.

Our Results. For the multiselection problem in internal memory, we describe
the ﬁrst online algorithm that supports a sequence R of q selection queries using
B(Sq) + o(B(Sq)) comparisons. Our algorithm is 1-competitive in the number of
comparisons performed. We match the bounds above while supporting search,
insert, and delete operations, achieve similar results in the external memory
model [1]. We invite readers to see [2] (or the upcoming journal version) for
more details on these results.

Preliminaries. Given an unsorted array A of length n, the median of A is the element 
x such that (cid:2)n/2(cid:3) elements in A are at least x. The median can be computed
in O(n) comparisons [8,4,13,7], in particular, less than 3n comparisons [7].

Outline. In the next section, we present a simple algorithm for the online multiselection 
problem, and introduce some terminology to describe its analysis. In
Section 2.2, we show that the simple algorithm has a constant competitive ratio.
Section 3 describes modiﬁcations to the simple algorithm, and shows that the
modiﬁed algorithm is optimal up to lower order terms. We describe the experimental 
results in Section 4.

2 A Simple Online Algorithm

Let A be an input array of n unsorted items. We describe a simple version of our
algorithm for handling selection queries on array A. We call an element A[i] at
position i in array A a pivot if A[1 . . . i − 1] < A[i] ≤ A[i + 1 . . . n].
Bitvector. We maintain a bitvector V of length n where V[i] = 1 if and only if
A[i] is a pivot. During preprocessing, we create V and set each bit to 0. We ﬁnd
the minimum and maximum elements in array A, swap them into A[1] and A[n]
respectively, and set V[1] = V[n] = 1.

Theory and Implementation of Online Multiselection Algorithms

111

Selection. The operation A.select (s) returns the sth smallest element of A (i.e.,
A[s] if A were sorted). To compute this result, if V[s] = 1 then return A[s] and
we are done. If V[s] = 0, ﬁnd a < s and b > s, such that V[a] = V[b] = 1 but
V[a + 1 . . . b − 1] are all 0. Perform quickselect [8] on A[a + 1 . . . b − 1], marking
pivots found along the way in V. This gives us A[s], with V[s] = 1, as desired.

As queries arrive, our algorithm performs the same steps that quicksort would
perform, although not necessarily in the same order. As a result, our recursive
subproblems mimic those from quicksort. We can show that comparisons needed
to perform q select queries on an array of n items is O(n log q). We can improve
this result to O(B(Sq)).2 We do not prove this bound directly, since our main
result is an improvement over this bound. Now, we deﬁne terminology for this
improved analysis.

2.1 Terminology

Query and Pivot Sets. Let R denote a sequence of q selection queries, ordered
by time of arrival. Let St = {s1, s2, . . . , st} denote the ﬁrst t queries from R,
sorted by position. We also include s0 = 1 and st+1 = n in St for convenience of
notation, since the minimum and maximum are found during preprocessing. Let
Pt = {pi} denote the set of k pivots found by the algorithm when processing St,
sorted by position. Note that p1 = 1, pk = n, V[pi] = 1 for all i, and St ⊆ Pt.

Pivot Tree and Recursion Depth. The pivots chosen by the algorithm form a
binary tree structure, deﬁned as the pivot tree T of the algorithm over time.3
Pivot pi is the parent of pivot pj if, after pi was used to partition an interval, pj
was the pivot used to partition either the right or left half of that interval. The
root pivot is the pivot used to partition A[2..n − 1] due to preprocessing. The
recursion depth, d(pi), of a pivot pi is the length of the path in the pivot tree
from pi to the root pivot. All leaves in the pivot tree are also selection queries,
but it may be the case that a query is not a leaf.

Intervals. Each pivot was used to partition an interval in A. Let I(pi) denote the
interval partitioned by pivot pi (which may be empty), and let |I(pi)| denote its
length. Intervals form a binary tree induced by their pivots. If pi is an ancestor
of pivot pj then I(pj) ⊂ I(pi). The recursion depth of an array element is the
recursion depth of the smallest interval containing that element, which in turn
is the recursion depth of its pivot.

St

i = si+1 − si and similarly the pivot gap Δ

Pt
i =

(cid:5)

(cid:5)

Gaps. Deﬁne the query gap Δ

pi+1 − pi. By telescoping we have
Fact 1. For all  > 0, there exists a constant c such that for all x ≥ 4,
log log log x <  log x + c.
2 B(Sq) = n log q when the q queries are evenly spaced over the input array A.
3 Intuitively, a pivot tree corresponds to a recursion tree, since each node represents

j = n − 1.

St
i =

i Δ

Pt

j Δ

one recursive call made during the quickselect algorithm [8].

112

J. Barbay et al.

Proof. Since limx→∞(log log log x)/(log x) = 0, there exists a k such that for all
x ≥ k, we know that (log log log x)/(log x) < . Also, in the interval [4, k], the
continuous function log log log x −  log x is bounded. Let c = log log log k − 2,
(cid:8)(cid:9)
which is a constant.

2.2 Analysis of the Simple Algorithm

In this section we analyze the simple online multiselect algorithm of Section 2.
We call a pivot selection method c-balanced for some constant c with 1/2 ≤
c < 1 if, for all pairs (pi, pj) where pi is an ancestor of pj in the pivot tree,
then |I(pj)| ≤ |I(pi)| · cd(pj)−d(pi)+O(1). If the median is always chosen as the
pivot, we have c = 1/2 and the O(1) term is zero. The pivot selection method
of Kaligosi et al. [10, Lemma 8] is c-balanced with c = 15/16.

Lemma 1 (Entropy Lemma). If the pivot selection method is c-balanced, then
B(Pt) = B(St) + O(n).

Proof. We sketch the proof and defer the full details to the journal version
of the paper. (Those results also appear in [2].) Consider any two consecutive
, and let Δ = s(cid:5) − s be the gap between them. Let
selection queries s and s(cid:5)
PΔ = (pl, pl+1, . . . , pr) be the pivots in this gap, where pl = s and pr = s(cid:5)
. The
lemma follows from the claim that B(PΔ) = O(Δ), since

⎞
⎠ −

(cid:10)

n log n − t(cid:2)

St
Δ
i

St
log Δ
i

(cid:11)

Pt
Δ
j

Pt
log Δ
j

i − k(cid:2)

St

j=0

Pt
Δ
j

log Δ

Pt
j =

i=0

B(P

Δ

St
i

t(cid:2)

i=0

) = O(n).

B(Pt) − B(St) =

⎛
⎝n log n − k(cid:2)
t(cid:2)

j=0

St
Δ
i

log Δ

=

i=0

We now sketch the proof of our claim, which proves the lemma. There must
be a unique pivot pm in PΔ of minimal recursion depth. We split the gap Δ
at pm. Since we use a c-balanced pivot selection method, we can bound the total
information content of the left-hand side by O(
i=l Δi) and the right-hand
(cid:8)(cid:9)
side by O(

i=m Δi), leading to the claim. The result follows.

(cid:5)m−1

(cid:5)r−1

3 Optimal Online Multiselection

In this section we prove the main result of our paper, Theorem 1.

Theorem 1 (Optimal Online Multiselection). Given an unsorted array A
of n elements, we provide an algorithm that supports a sequence R of q online
selection queries using B(Sq)(1 + o(1)) + O(n) comparisons.

Theory and Implementation of Online Multiselection Algorithms

113

Our bounds match those of the oﬄine algorithm of Kaligosi et al. [10]. In
other words, our solution is 1-competitive. We explain our proof in three main
steps. In Section 3.1, we explain our algorithm and describe how it is diﬀerent
from Kaligosi et al. [10]. We then bound the number of comparisons resulting
from merging by B(Sq)(1 + o(1)) + O(n) in Section 3.2. In Section 3.3, we bound
the complexity of pivot ﬁnding and partitioning by o(B(Sq)) + O(n).

3.1 Algorithm Description

We brieﬂy describe the deterministic algorithm from Kaligosi et al. [10]. Their
result is based on tying the number of comparisons required for merging two
sorted sequences to the information content of those sequences. This simple
observation drives their underlying approach that both ﬁnds pivots that are
“good enough” and partitions using near-optimal comparisons.
In particular, they create runs, which are sorted sequences from A of length
roughly (cid:3) = log(B/n). Then, they compute the median μ of the medians of these
sequences, and partition the runs based on μ. After partitioning, they recurse
on the two sets of runs, sending select queries to the appropriate side of the
recursion. To maintain the invariant on run length on the recursions, they merge
short runs of the same size optimally until all but (cid:3) of the runs are again of
length between (cid:3) and 2(cid:3).

We make the following modiﬁcations to the algorithm of Kaligosi et al. [10]:
– Since the value of B(Sq) is not known in advance (because R is provided
online), we cannot preset a value for (cid:3), as done in Kaligosi et al. [10]. Instead,
we locally set (cid:3) = 1 + (cid:10)log(d(p) + 1)(cid:11) in the interval I(p). Since we use only
balanced pivots, d(p) = O(log n). We keep track of the recursion depth of
pivots, from which it is easy to compute the recursion depth of an interval.
– We use a bitvector W to identify the endpoints of runs within each interval.
– The queries from R are processed online. We support online queries using
the bitvector V from Section 2. Recall that a search query incurs O(log n)
additional comparisons to ﬁnd its corresponding interval.

To perform the operation A.select (s), we ﬁrst use bitvector V to identify the interval 
I containing s. If |I| ≤ 4(cid:3)2, we sort the interval I (making all elements of I
pivots) and answer the query s. The cost for this case is bounded by Lemma 5.
Otherwise, we compute the value of (cid:3) for the current interval, and proceed as in
Kaligosi et al. [10] to answer the query s.

We can borrow much of the analysis done in [10], but it depends heavily on
the use of (cid:3), which we do not know in advance. In the rest of Section 3, we
modify their techniques to handle this complication.

3.2 Merging

Kaligosi et al. [10, Lemmas 5—10] count the comparisons resulting from merging.
Lemmas 5, 6, and 7 do not depend on the value of (cid:3) and so we can use them

114

J. Barbay et al.

in our analysis. Lemma 8 shows that the median-of-medians built on runs is a
good pivot selection method. Although its proof uses the value of (cid:3), its validity
does not depend the size of (cid:3). The proof merely requires that there are at least
4(cid:3)2 items in each interval, which also holds for our algorithm. Lemmas 9 and
10 (from Kaligosi et al. [10]) together will bound the number of comparisons by
B(Sq)(1 + o(1)) + O(n) if we can prove Lemma 2, which bounds the information
content of runs in intervals that are not yet partitioned.

Pt
i ,

(cid:5)k

(cid:5)

i=0

(cid:5)

r∈Δ

Pt
i

|r| log |r| = o(B(St)) + O(n).

Lemma 2. Let a run r be a sorted sequence of elements from A in a gap Δ
where |r| is its length. Then,
Proof. In a gap of size Δ, (cid:3) = O(log d) where d the recursion depth of the
|r| log |r| ≤ Δ log(2l) = O(Δ log log d),
elements in the gap. This gives
since each run has size at most 2(cid:3). Because we use a good pivot selection method,
we know that the recursion depth of every element in the gap is O(log(n/Δ)).
(cid:5)
i Δi log log log(n/Δi). Recall that B(St) =
Thus,
B(Pt) + O(n) =
(cid:8)(cid:9)

|r| log |r| ≤ (cid:5)
i Δi log(n/Δi) + O(n). Fact 1 completes the proof.

(cid:5)k

r∈Δ
(cid:5)

Pt
i

r∈Δ

i=0

3.3 Pivot Finding and Partitioning

Now we prove that the cost of computing medians and performing partitions
requires at most o(B(Sq)) + O(n) comparisons. The algorithm computes the median 
m of medians of each run at a node v in the pivot tree T . Then, it partitions
each run based on m. We bound the number of comparisons at each node v with
more than 4(cid:3)2 elements in Lemmas 3 and 4. We bound the comparison cost for
all nodes with fewer elements in Lemma 5.

Let d be the current depth of the pivot tree T (deﬁned in Section 2.1), and
let the root of T have depth d = 0. Each node v in T is associated with some
interval I(pv) corresponding to some pivot pv. We deﬁne Δv = |I(pv)| as the
number of elements at node v.
Recall that (cid:3) = 1 + (cid:10)log(d + 1)(cid:11), and a run is a sorted sequence of elements
in A. We deﬁne a short run as a run of length less than (cid:3). Let βn be the number
of comparisons required to compute the exact median for n elements, where β
is a constant less than three [7]. Let rs
v be the number of short runs at node v,
and let rl

v be the number of long runs (runs of length at least (cid:3)).

Lemma 3. The number of comparisons required to ﬁnd the median m of medians 
and partition all runs at m for any node v in the pivot tree T is at most
β((cid:3) − 1) + (cid:3) log (cid:3) + β(Δv/(cid:3)) + (Δv/(cid:3)) log(2(cid:3)).
Proof. We compute the cost (in comparisons) for computing the median of mev 
≤ (cid:3) − 1 short runs, we need at most β((cid:3) − 1) comparisons per
dians. For the rs
v ≤ Δv/(cid:3) long runs, we need at most β(Δv/(cid:3)).
node. For the rl

Now we compute the cost for partitioning each run based on m. We perform
(cid:5)(cid:4)−1
i=1 log i ≤
binary search in each run. For short runs, this requires at most
(cid:3) log (cid:3) comparisons per node. For long runs, we need at most (Δv/(cid:3)) log(2(cid:3))
(cid:8)(cid:9)
comparisons per node.

Theory and Implementation of Online Multiselection Algorithms

115

Since our value of (cid:3) changes at each level of the recursion tree, we will sum
the costs from Lemma 3 by level. The overall cost at level d is at most 2dβ(cid:3) +
2d(cid:3) log (cid:3) + (n/(cid:3))β + (n/(cid:3)) log(2(cid:3)) comparisons. Summing over all the levels, we
can bound the total cost of all such nodes in the pivot tree to obtain the following
lemma.

Lemma 4. The number of comparisons required to ﬁnd the median of medians
and partition over all nodes v in the pivot tree T with at least 4(cid:3)2 elements is
within o(B(St)) + O(n).
Proof. For all levels of the pivot tree up to level (cid:3)(cid:5) ≤ log(B(Pt)/n), the cost is
at most

log(B(Pt)/n)(cid:2)

2d(cid:3)(β + log (cid:3)) + (n/(cid:3))(β + log(2(cid:3))).

d=1

Since (cid:3) = (cid:10)log(d + 1)(cid:11) + 1, we can easily bound the ﬁrst term of the summation 
by (B(Pt)/n) log log(B(Pt)/n) = o(B(Pt)). The second term can be easily
upper-bounded by n log(B(Pt)/n)(log log log(B(Pt)/n)/ log log(B(Pt)/n)), which
is o(B(Pt)). Using Lemma 1, the above two bounds are o(B(St)) + O(n).
with log(B(Pt)/n) < (cid:3)(cid:5) ≤ log log n + O(1), we bound the
remaining cost. It is easy to bound each node v’s cost by o(Δv), but this is
not suﬃcient—though we have shown that the total number of comparisons for
merging is B(St) + O(n), the number of elements in nodes with Δv ≥ 4(cid:3)2 could
be ω(B(St)).

For each level (cid:3)(cid:5)

We bound the overall cost as follows, using the result of Lemma 3. Since
node v has Δv > 4(cid:3)2 elements, we can rewrite the bounds as O(Δv/(cid:3) log(2(cid:3))).
Recall that (cid:3) = log d + O(1) = log(O(log(n/Δv))) = log log(n/Δv) + O(1),
(cid:5)
v (Δv/(cid:3)) log(2(cid:3)) ≤ (cid:5)
since we use a good pivot selection method. Summing over all nodes, we get
v Δv log(2(cid:3)) = o (B(Pt)) + O(n), using Fact 1 and recall-
(cid:5)
ing that B(Pt) =
v Δv log(n/Δv). Finally, using Lemma 1, we arrive at the
(cid:8)(cid:9)
claimed bound for queries.

We now bound the comparison cost for all nodes v where Δv ≤ 4(cid:3)2.

Lemma 5. For nodes v in the pivot tree T where Δv ≤ 4(cid:3)2, the total cost in
comparisons for all operations is at most o(B(St)) + O(n).
Proof. Nodes with no more than 4(cid:3)2 elements do not incur any cost in comparisons 
for median ﬁnding and partitioning, unless there is (at least) one associated
query within the node. Hence, we focus on nodes with at least one query.
Let z be such that z = (log log n)2 log log log n + O(1). We sort the elements of
any node v with Δv ≤ 4(cid:3)2 elements using O(z) comparisons, since (cid:3) ≤ log log n+
O(1). We set each element as a pivot. The total comparison cost over all such
nodes is no more than O(tz), where t is the number of queries we have answered
so far. If t < n/z, then the above cost is O(n).
Otherwise, t ≥ n/z. Using Jensen’s inequality, we have B(Pt) ≥ (n/z) log(n/z),
which represents the cost of sorting n/z adjacent queries. Thus, tz = o(B(Pt)).
Using Lemma 1, we know that B(Pt) = B(St) + O(n), which proves the lemma.(cid:8)(cid:9)

116

J. Barbay et al.

4 Experimental Results

In this section, we present the experimental evaluation of the online and oﬄine
multiselection algorithms. Section 4.1 describes the experimental setup. Our results 
are described in Section 4.2.

4.1 Experimental Setup

Our input array consists of a random permutation of the (distinct) elements from
[1, 218]. (We also ran some experiments for larger n up to 220, and results were
similar.) Our queries are generated using the indicated distribution for each experiment.
 We allow repetitions of queries, except in the evenly-spaced case. We
only report comparisons with elements of the input array, averaged over 10 random 
experiments. In particular, we do not count comparisons between indices in
the input array. Finally, we compute the Entropy of a query sequence Sq (deﬁned
in Section 1) by
using double precision arithmetic on
a 64-bit machine.

(cid:12)
log n! − (cid:5)q

(cid:3)
ΔS
i !

i=0 log

(cid:4)(cid:13)

Now, we brieﬂy describe the algorithms we considered for choosing the pivot
in an unsorted interval I. The First Element and Random methods choose the
corresponding element as the pivot. The Medof3 method uses the median of the
ﬁrst, middle, and last elements of I as the pivot. The Median (using MedofMed)
uses Blum et al.’s linear-time algorithm [4] as the pivot. The MedofMed method
is the ﬁrst step of Blum et al.’s algorithm [4] that computes the median of every
ﬁve elements, and then uses the median of those medians as the pivot.

Pivot Selection Methods 

 
 
s
n
o
s
i
r
a
p
m
o
C
 
f
o
 
r
e
b
m
u
N

 
)
s
n
o

i
l
l
i

 

m
n
i
(

45

40

35

30

25

20

15

10

5

0

Entropy

First Element

Random

Medof3

MedofMed

Median (using
MedofMed alg)

32

128

512

2048

8192
Number of Queries 

32768

131072

524288

Fig. 1. Performance of various pivot selection methods on random input sequences

We compared the performance of these pivoting methods for random arrays
in Figure 1 for our simple online algorithm described in Section 2. We performed
similar experiments for diﬀerent algorithms. The results from Figure 1 are representative 
of all of our ﬁndings. One can clearly see that Medof3 uses the fewest

Theory and Implementation of Online Multiselection Algorithms

117

comparisons and Median requires signiﬁcantly more comparisons. The performance 
of other pivoting methods fall in between these two extremes. For the
rest of the paper, we show results only for the Medof3 pivoting method.

4.2 Results

Now, we brieﬂy describe the algorithms we considered for multiselection. All
algorithms use Medof3 as the pivoting strategy (where applicable). The Quicksort 
algorithm is the standard quicksort, augmented by q array lookups (which
require no comparisons). The Mergesort algorithm is the standard recursive
mergesort, augmented by q array lookups (which require no comparisons). The
Simple Online algorithm is described in Section 2. The Optimal Online algorithm 
is described in Section 3.1, where we set (cid:3) based on the recursion depth
of the corresponding interval. The performance of the online algorithms is independent 
of the order of the queries. (We defer the experiments supporting this
claim until the journal version of this paper.)

The Dobkin-Munro algorithm is described in [6]. The Kaligosi (sorted) algorithm 
is described in [10], which assumes that queries are given in sorted order.
The Kaligosi (unsorted) algorithm ﬁrst sorts the unsorted queries, and then
performs the Kaligosi (sorted) algorithm. In some cases, sorting queries is tantamount 
to sorting the array. Since this algorithm is oﬄine, one can assume that
the algorithm will detect this case and revert to Quicksort or Mergesort instead.
We show our results in Figures 2 and 3. For Figure 2, the queries (in the ﬁrst
graph) are evenly distributed across the input array. This query distribution
results in a worst-case entropy, and hence is a diﬃcult case for multiselection
algorithms. The second graph in Figure 2 has uniformly distributed queries. For
Figure 3, we display results for a normal query distribution with mean μ = n/2
and standard deviation σ = n/8. The second graph in Figure 3 is an exponential
query distribution with λ = 16/n.

For all query distributions, our online algorithms (Simple Online and Optimal 
Online) outperform their oﬄine counterparts (respectively, Quicksort and
Kaligosi). The Dobkin-Munro algorithm requires more comparisons than Quicksort 
for any reasonably large number of queries (based on query distribution). In
other words, it is usually better to sort than to use Dobkin-Munro. The Kaligosi
algorithm performs quite well in terms of comparisons, but is relatively slow.
The Simple Online algorithm converges to Quicksort as queries increases, highlighting 
that the online algorithm performs the same work as the Quicksort, as
intuition (and the analysis) suggests.

The Optimal Online algorithm outperforms Mergesort, Quicksort, and Kaligosi
(sorted and unsorted), and is even better than Entropy when the number of
queries is large. Having an algorithm perform fewer comparisons than Entropy
isn’t a contradiction, since Entropy is a worst-case lower bound for an arbitrary
input. Hence, the number of comparisons for an algorithm could be less than
Entropy for a given (speciﬁc) input. Even though our algorithm is similar to
Kaligosi, we can clearly see the value of online computation when comparing
these two results. The primary reason for our improved results is due to the fact

118

J. Barbay et al.

	























































































9 

8 

7 

6 

5 

4 

3 

2 

1 

0 

9 

8 

7 

6 

5 

4 

3 

2 

1 

0 

32 

64 

128 

256 

512 

1024 

2048 

4096 

8192 

16384 

32768 

65536 

131072 




	



Entropy 
Quicksort 
Mergesort 
Simple Online 
Optimal Online 
Dobkin-Munro 
Kaligosi (sorted) 
Kaligosi (unsorted) 

Entropy 
Quicksort 
Mergesort 
Simple Online 
Optimal Online 
Dobkin-Munro 
Kaligosi (sorted) 
Kaligosi (unsorted) 

32 

64 

128 

256 

512 

1024 

2048 

4096 

8192 

16384 

32768 

65536 

131072 






Fig. 2. Performance of multiselection algorithms on random input sequences using
median of three pivot selection method, when the queries are distributed as indicated

that Kaligosi will pre-process runs, even for intervals that do not contain any
queries. For the Optimal Online algorithm, since run lengths are based on the
recursion depth, the algorithm will not spend comparisons generating long runs
unless queries are in those intervals.

In fact, these results suggest that using the Optimal Online algorithm with
n/2 queries (e.g., each odd position) can sort an array in fewer comparisons than
Mergesort. The reason for this is that the runs computed at the beginning of the
algorithm save a lot of comparisons in future recursive rounds. We are currently
running experiments on tuning the length (cid:3) of the run to see if we can further
improve this performance.

Finally, we provide similar results for a decreasing input array, since this is a
best-case scenario for Mergesort. Notice that both Mergesort, Optimal Online,
and Kaligosi are better than Entropy as queries increase. However, both multiselection 
algorithms outperform Mergesort. The sudden dip in the curve corresponding 
to the Kaligosi (sorted) algorithm after 65, 536 queries corresponds
to a discrete increase in the calculated value of (cid:3) (from 4 to 5). This sort of
stair-stepping behavior is expected to continue as n increases.

Theory and Implementation of Online Multiselection Algorithms

119

			

32 

64 

128 

256 

512 

1024 

2048 

4096 

8192 

16384 

32768 

65536 

131072 

	
		



	



Entropy 
Quicksort 
Mergesort 
Simple Online 
Optimal Online 
Dobkin-Munro 
Kaligosi (sorted) 
Kaligosi (unsorted) 

Entropy 
Quicksort 
Mergesort 
Simple Online 
Optimal Online 
Dobkin-Munro 
Kaligosi (sorted) 
Kaligosi (unsorted) 

9 

8 

7 

6 

5 

4 

3 

2 

1 

0 

9 

8 

7 

6 

5 

4 

3 

2 

1 

0 




















	


































































32 

64 

128 

256 

512 

1024 

2048 

4096 

8192 

16384 

32768 

65536 

131072 






Fig. 3. Performance of multiselection algorithms on random input sequences using
median of three pivot selection method, when the queries are distributed as indicated























	






















5 

4 

3 

2 

1 

32 

64 

128 

256 

512 

1024 

2048 

4096 

8192 

16384 

32768 

65536 

131072 

	

Entropy 
Quicksort 
Mergesort 
Simple Online 
Optimal Online 
Dobkin-Munro 
Kaligosi (sorted) 
Kaligosi (unsorted) 

Fig. 4. Performance of multiselection algorithms on a decreasing input sequence using
median of three pivot selection method, when the queries are distributed as indicated

References

1. Aggarwal, A., Vitter, J.S.: The input/output complexity of sorting and related

problems. Commun. ACM 31(9), 1116–1127 (1988)

2. Barbay, J., Gupta, A., Rao, S.S., Sorenson, J.: Competitive online selection in main

and external memory. CoRR, abs/1206.5336 (2012)

120

J. Barbay et al.

3. Belal, A., Elmasry, A.: Distribution-sensitive construction of minimum-redundancy
preﬁx codes. In: Durand, B., Thomas, W. (eds.) STACS 2006. LNCS, vol. 3884,
pp. 92–103. Springer, Heidelberg (2006)

4. Blum, M., Floyd, R.W., Pratt, V.R., Rivest, R.L., Tarjan, R.E.: Time bounds for

selection. J. Comput. Syst. Sci. 7(4), 448–461 (1973)

5. Cardinal, J., Fiorini, S., Joret, G., Jungers, R.M., Munro, J.I.: An eﬃcient algorithm 
for partial order production. In: STOC, pp. 93–100 (2009)

6. Dobkin, D.P., Munro, J.I.: Optimal time minimal space selection algorithms. J.

ACM 28(3), 454–461 (1981)

7. Dor, D., Zwick, U.: Selecting the median. SICOMP 28(5), 1722–1758 (1999)
8. Hoare, C.A.R.: Algorithm 65: ﬁnd. Commun. ACM 4(7), 321–322 (1961)
9. Jim´enez, R.M., Mart´ınez, C.: Interval sorting. In: Abramsky, S., Gavoille, C.,
Kirchner, C., Meyer auf der Heide, F., Spirakis, P.G. (eds.) ICALP 2010. LNCS,
vol. 6198, pp. 238–249. Springer, Heidelberg (2010)

10. Kaligosi, K., Mehlhorn, K., Munro, J.I., Sanders, P.: Towards optimal multiple
selection. In: Caires, L., Italiano, G.F., Monteiro, L., Palamidessi, C., Yung, M.
(eds.) ICALP 2005. LNCS, vol. 3580, pp. 103–114. Springer, Heidelberg (2005)

11. Kirkpatrick, D.G., Seidel, R.: The ultimate planar convex hull algorithm. SIAM J.

Comput. 15(1), 287–299 (1986)

12. Prodinger, H.: Multiple quickselect - Hoare’s ﬁnd algorithm for several elements.

Inf. Process. Lett. 56(3), 123–129 (1995)

13. Sch¨onhage, A., Paterson, M., Pippenger, N.: Finding the median. J. Comput. Syst.

Sci. 13(2), 184–199 (1976)

