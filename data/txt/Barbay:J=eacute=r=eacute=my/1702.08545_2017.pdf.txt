Synergistic Computation

of Planar Maxima and Convex Hull

J´er´emy Barbay1 and Carlos Ochoa1(cid:63)

Departamento de Ciencias de la Computaci´on, Universidad de Chile, Chile

jeremy@barbay.cl, cochoa@dcc.uchile.cl.

7
1
0
2

 

b
e
F
7
2

 

 
 
]
S
D
.
s
c
[
 
 

1
v
5
4
5
8
0

.

2
0
7
1
:
v
i
X
r
a

Abstract. Reﬁnements of the worst case complexity over instances of ﬁxed input size
consider the input order or the input structure, but rarely both at the same time. Barbay
et al. [2016] described “synergistic” solutions on multisets, which take advantage of the
input order and the input structure, such as to asymptotically outperform any comparable
solution which takes advantage only of one of those features. We consider the extension
of their results to the computation of the Maxima Set and the Convex Hull of a set
of planar points. After revisiting and improving previous approaches taking advantage
only of the input order or of the input structure, we describe synergistic solutions taking
optimally advantage of various notions of the input order and input structure in the plane.
As intermediate results, we describe and analyze the ﬁrst adaptive algorithms for Merging
Maxima and Merging Convex Hulls.

Keywords: Convex Hull, Dominance Query, Maxima, Membership Query, Multivariate
Analysis, Synergistic.

1 Introduction

One way to close the gap between practical performance and the worst case complexity over
instances of ﬁxed input size is to reﬁne the later, considering smaller classes of instances. Such
measures of diﬃculty can be seen along two axis: some depend of the structure of the input, such
as the repetitions in a multiset [19], or the positions of the input points in the plane [1] or in
higher dimensions [13]; while some others depend on the order in which the input is given, such
as for permutations [18] but also for points in the plane [2, 16].

Barbay et al. [5] described various “synergistic” solutions on multisets, which take advantage
of both the input structure and the input order, in such a way that each of their solutions is never
asymptotically slower than other solutions taking advantage of a subset of these features, but
also so that on some family of instances, each of their solution performs an order of magnitude
faster than any solution taking advantage of only a subset of those features. They left open the
generalization of their results to higher dimensions.

In the context of the computation of the Maxima Set and of the Convex Hull, various
reﬁnements of the worst case complexity over instances of ﬁxed size have been known for some
time. Kirkpatrick and Seidel described algorithms optimal in the worst case over instances of
ﬁxed input and output size, ﬁrst in 1985 for the computation of the Maxima Set of points in
any dimension [13] and then in 1986 for the computation of the Convex Hull in the plane [14]:
such results can be classiﬁed as focused on the input structure, and were further reﬁned in
2009 by Afshani et al. [1] in 2 and 3 dimensions. Following a distinct approach, Levcopoulos et
al. [16] in 2002, and Ahn and Okamoto [2] in 2011, studied the computation of the Convex Hull

(cid:63) Corresponding author.

2

J´er´emy Barbay and Carlos Ochoa

in conjunction with various notions of input order: these results can be generalized to take
advantage of the input order when computing Maxima Sets (Section 3.1) and can be further
reﬁned using recent techniques (Section 4.1). Yet no algorithm (beyond a trivial dovetailing
combination of the solutions described above) is known to take advantage of both the input
structure and input order at the same time for the computation of the Maxima Set or of
the Convex Hull of points, in the plane or in higher dimension, nor for any other problem than
Sorting Multisets.

Hypothesis. It seems reasonable to expect that Barbay et al.’s synergistic results [5] on Sorting
Multisets should generalize to similar problems in higher dimension, such as the computation
of the Maxima Set and of the Convex Hull of a set of points in the plane. Yet these two
problems present new diﬃculties of their own: (1) while the results on multisets [5] are strongly
based on a variant of Demaine et al.’s instance optimal algorithm to Merge Multisets [10], at
this date no such results are known for Merging Maxima Sets, and the closest known result
for Merging Convex Hulls [3] (from 2008) is not adaptive to the size of the output, and hence
not adaptive to the structure of the instance; furthermore (2) whereas many input order adaptive
results are known for Sorting Multisets (with two surveys in 1992 on the topic [11, 18], and
various additional results [4, 24] since then), it seems that none are known for the computation of
the Maxima Set and that only a few are known for the computation of the Convex Hull [2,16].

Our Results. After reviewing previous results on the computation of Convex Hull taking
advantage of either the input structure (Section 2.1) or the input order (Section 2.2), and one
result on Sorting Multisets taking advantage of both (Section 2.3), we conﬁrm the hypothesis
by (1) presenting new solutions for Merging Maxima Sets (Section 3.2) and Merging Convex
Hulls (Section 4.2) in the plane, (2) deﬁning new techniques to take advantage of the input
order to compute Maxima Sets (Section 3.1), (3) improving previous techniques to analyze the
computation of Convex Hulls in function of the input order (Section 4.1), and (4) synthesizing
all those results in synergistic algorithms to compute Maxima Sets (Section 3.3) and Convex
Hulls (Section 4.3) of a set of planar points. For the sake of pedagogy, we present our results
incrementally, from the simplest to the most complex. We deﬁne formally the notions of
input order, input structure and synergistic solution in Section 2. We then describe synergistic
solutions for the computation of both the Maxima Set (Section 3) and of the Convex Hull
(Section 4) of points in the plane (the latter requiring more advance techniques). In both case,
our solution is based on an algorithm merging several partial solutions (Sections 3.2 and 4.2),
adapted from Barbay et al.’s Quick Hull Merge algorithm [5] to merge multisets1. We conclude
in Section 5 with a partial list of issues left open for improvement. Due to space constraints we
only state our results in the article and defer all the proofs to the appendix.

2 Background

Beyond the worst case complexity over instances of ﬁxed size, the adaptive analysis of algorithms
reﬁnes the scope of the analysis by considering the worst case complexity over ﬁner classes of
instances. We describe here some relevant results along two axis: results about the computation
of the Convex Hull which take advantage of the input structure (Section 2.1), results about
the computation of the Convex Hull which take advantage of the input order (Section 2.2),
and one result about Sorting Multisets which depends of both (Section 2.3).

1 Itself inspired from Demaine et al.’s algorithm solving the same problem [9].

Synergistic Computation of Planar Maxima and Convex Hull

3

2.1

Input Structure

In 1985, Kirkpatrick and Seidel [13] described an algorithm to compute the Maxima Set of points
in any dimension, which is optimal in the worst case over instances of input size n and output size
h, running in time within O(n log h). One year later, in 1986, they [14] described a slightly more
complex algorithm to compute the Convex Hull in the plane, which is similarly optimal in the
worst case over instances of input size n and output size h, running in time within O(n log h).
Both results are described as output sensitive, in the sense that the complexity depends on the
size of the output, and can be classiﬁed as adaptive to the input structure, as the position of the
points clearly determine the output (and its size), as opposed to algorithms described in the next
paragraph taking advantage of the order in which those points are given.

2.2

Input Order

A polygonal chain is a curve speciﬁed by a sequence of points p1, . . . , pn. The curve itself consists of
the line segments connecting the pairs of consecutive points. A polygonal chain C is simple if any
two edges of C that are not adjacent are disjoint, or if the intersection point is a vertex of C; and
any two adjacent edges share only their common vertex. Melkman [17] described an algorithm that
computes the Convex Hull of a simple polygonal chain in linear time, and Chazelle [8] described
an algorithm for testing whether a polygonal chain is simple in linear time. In 2002, Levcopoulos
et al. [16] combined these results to yield an algorithm for computing the Convex Hull of
polygonal chains. Their algorithm tests if the chain C is simple, using Chazelle’s algorithm [8]:
if the chain C is simple, the algorithm computes the Convex Hull of C in linear time, using
Melkman’s algorithm [17]. Otherwise, if C is not simple, the algorithm partitions C into the
subsequences C(cid:48) and C(cid:48)(cid:48), whose sizes diﬀer at most in one; recurses on each of them; and merges
the resulting Convex Hulls using Preparata and Shamos’s algorithm [22]. They measured the
complexity of this algorithm in terms of the minimum number of simple subchains κ into which the
chain C can be partitioned. Let t(n, κ) be the worst-case time complexity taken by this algorithm
for an input chain of n vertices that can be partitioned into κ simple subchains. They showed that
2(cid:101), κ1) + t((cid:98) n
2(cid:99), κ2), κ1 + κ2 ≤ κ + 1.
t(n, κ) satisﬁes the following recursion relation: t(n, κ) ≤ t((cid:100) n
The solution to this recursion gives t(n, κ) ∈ O(n(1+ log κ)) ⊆ O(n log n).
In 2011, Ahn and Okamoto [2] followed a distinct approach for the computation of the Convex
Hull, also based on some notions of input order. They considered a variant of the problem where
the output is the same size of the input, but such that the Convex Hull can be checked and
extracted in linear time from this output. In this context, they describe adaptive results directly
inspired from disorder measures introduced for the study of adaptive algorithms for Sorting
Permutations, such as Runs and Inv [11, 18].

Inspired by Ahn and Okamoto’s deﬁnition [2], we deﬁne some simple measure of input order
for the computation of Maxima Sets in Section 3.1, and we slightly reﬁne Levcopoulos et al.’s
analysis [16] for the computation of Convex Hulls in Section 4.1.

2.3 Synergistic Solutions

Inspired by previous results on sorting multisets in a way adaptive to the frequencies of the
element [19] on one hand, and on sorting permutation in a way adaptive to the distribution
of the lengths of the subsequences of consecutive positions already sorted [24] on the other
hand, Barbay et al. [5] described two “synergistic” algorithms Sorting Multisets, which take
advantage both of the input structure and of the input order, in such a way that each of their
solutions is never asymptotically slower than other solutions taking advantage of a subset of these

4

J´er´emy Barbay and Carlos Ochoa

features, but also so that on some family of instances, each of their solution performs an order of
magnitude faster than any solution taking advantage of only a subset of those features. They
left open the generalization of their results to higher dimensions. We generalize their results to
dimension 2, for the computation of the Maxima Set in Section 3, and for the computation of
the Convex Hull in Section 4.

3 Maxima Set
Given a point p ∈ R2, let px and py denote the xand 
y-coordinates of p, respectively. Given two
points p and q, p dominates q if px ≥ qx and py ≥ qy. Given a set S of points in d dimensions, a
point p from S is called maximal if none of the other points of S dominates p. The Maxima Set
of such a set S is the uniquely deﬁned set of all maximal points [15]. Kirkpatrick and Seidel [13]
described an algorithm that computes the Maxima Set running in time within O(n log h), where
n is the number of input points, and h is the number of points in the Maxima set (i.e., the
size of the output). In 2009, Afshani et al. [1] improved the results on the computation of both
the Maxima Set and Convex Hull in dimension 2 and 3 by taking the best advantage of the
relative positions of the points (while ignoring the input order).

If the points are sorted by their coordinates (say, in lexicographic order of their coordinates
for a ﬁxed order of the dimensions), the Maxima Set can be computed in time linear in the
size of the input. Reﬁning this insight, we show in Section 3.1 that one can take advantage of
the input order even if it is not as strictly sorted: this presents a result which is orthogonal to
previous input structure adaptive results [1, 13]. In order to combine these results synergistically
with previous input structure adaptive results [1, 13], we study in Section 3.2 an algorithm that
solves the problem of Merging Maxima, which asks for computing the Maxima Set of the
union of maxima sequences, in such a way that it outperforms both input structure adaptive
results by taking advantage of the number and sizes of the maxima sequences and of the relative
positions between the points in them. Last, we combine those results into a single synergistic
algorithm, which decomposes the input sequence of points into several “easy” subsequences for
which the corresponding Maxima Set can be computed in linear time, and then proceeds to
merge them. The resulting algorithm not only outperforms previous input structure adaptive
results [1, 13] in the sense that it never performs (asymptotically) worse, and performs better
when it can take advantage of the input order, it also outperforms a dovetailing combination
of previous input structure adaptive algorithms [1, 13] and the input order adaptive algorithm
described in Section 3.1.

3.1

Input Order Adaptive Maxima Set

In many cases the Maxima Set can be computed in time linear in the size of the input,
independently from the size of the Maxima Set itself. For instance, consider an order of the
input where (1) the maximal points are given in order sorted by one coordinates, and (2) for
each maximal point p, all the points dominated by p are given immediately after p in the input
order (in any relative order). The Maxima Set of a sequence of points given in this order can be
extracted and validated in linear time by a simple greedy algorithm, which throws an exception if
the input is not in such an order. Each of the various ways to deal with such exceptions directly
yields an input order adaptive algorithm [2]. For instance, if the point found to be out of order is
inserted in the partial Maxima Set computed up to this point, this yields an algorithm running
in time within O(n lg Inv) where Inv is the sum of such insertion costs.
Let’s label such a sequence “smooth”, and by extension any input subsequence of consecutive
positions which have the same property. Given an input sequence S, let σ denote the minimal

Synergistic Computation of Planar Maxima and Convex Hull

5

number of smooth subsequences into which it can be decomposed. Most interestingly for synergistic
purpose, such a decomposition can be computed in time linear in the input size. Detecting such
σ smooth subsequences and merging them two by two yields an algorithm running in time within
O(n(1 + log σ)). Such a result is orthogonal to previous input structure adaptive results [1, 13]: it
can be worse than O(n log h) when the output size h is small and the input is in a “bad” order,
as it can be much better than O(n log h) when h is large and the input is in a “good” order. We
show in the next two sections an algorithm which outperforms both.

3.2 Union of Maxima Sequences

We describe the Quick Union Maxima algorithm, which computes the Maxima Set of the union
of maxima sequences in the plane, assuming that the points in the maxima sequences are given in
sorted order by their x-coordinates (i.e., Merging Maxima). This algorithm generalizes Barbay
et al.’s [5] QuickSort inspired algorithm for Merging Multiset and is a building block towards
the synergistic algorithm for computing the Maxima Set of a set of planar points described in
Section 3.3. Given a maxima sequence Mi, let Mi[a] and Mi[b..c] denote the a-th point and the
block of consecutive c − b + 1 points corresponding to positions from b to c in Mi, respectively.
As its name indicates, the algorithm is inspired by the QuickSort algorithm.

Description of the algorithm Quick Union Maxima. The Quick Union Maxima algorithm
chooses a point p that forms part of the Maxima Set of the union, and discards all the points
dominated by p. Note that all dominated points do not belong to the maxima that contains p.
The selection of p ensures that at least half of the maxima sequences will have points dominated
by p or to the right of p and at least half of the maxima sequences will have points dominated
by p or to the left of p. The algorithm identiﬁes a block B of consecutive points in the maxima
sequence that contains p, which forms part of the output Maxima Set (p is contained in B).
All the points in B are discarded. Note that if the points of a maxima sequence in the plane are
sorted in ascending order by their x-coordinates, then their y-coordinates are sorted in decreasing
order. This algorithm takes advantage of this fact when it discards points. All discarded points
are identiﬁed by doubling searches [6] inside the maxima sequences . The algorithm then recurses
separately on the non-discarded points to the left of p and on the non-discarded points to the
right of p. (See Algorithm 1 for a more formal description.) Next, we analyze the time complexity
of the Quick Union Maxima algorithm.

Complexity Analysis of Quick Union Maxima. Every algorithm for Merging Maxima
needs to certify that blocks of consecutive points in the maxima sequences are dominated or are
in the Maxima Set of the union. In the following we formalize the notion of a certiﬁcate, that
permits to check the correctness of the output in less time than to recompute the output itself. We
deﬁne a “language” of basic “arguments” for such certiﬁcates: domination (which discards points
from the input) and maximality (which justify the presence of points in the output) arguments,
and their key positions in the instance. A certiﬁcate will be veriﬁed by checking each of its
arguments: those can be checked in time proportional to the number of blocks in them.
Deﬁnition 1. (cid:104)Mi[a] ⊃ Mj[b..c](cid:105) is an elementary domination argument if the point Mi[a]
dominates all the points in the block Mj[b..c].
Deﬁnition 2. (cid:104)Mi[a] ⊃ Mj1[b1..c1], . . . ,Mjt[bt..ct](cid:105) is a Domination Argument if the point
Mi[a] dominates all the points in the blocks Mj1[b1..c1], . . . ,Mjt[bt..ct].

6

J´er´emy Barbay and Carlos Ochoa

Algorithm 1 Quick Union Maxima
Input: A set M1, . . . ,Mρ of ρ maxima sequences
Output: The Maxima Set of the union of M1, . . . ,Mρ
1: Compute the median µ of the x-coordinates of the middle points of the maxima sequences;
2: Perform doubling searches for the value µ in the x-coordinates of the points of all maxima sequences,
3: Find the point p of maximum y-coordinate among the points q such as qx ≥ µ in all maxima sequences,

starting at both ends of the maxima sequences in parallel;
note j ∈ [1..ρ] the index of the maxima sequence containing p;
4: Discard all points dominated by p through doubling searches for the values of px and py in the xand 
y-coordinates of all maxima, respectively, except Mj (Search for px in the points q such that
qx ≥ µ and for py in the points q such that qx < µ);
5: Find the point r of maximum y-coordinate among the points q such that qx > px in all maxima
sequences except Mj and ﬁnd the point (cid:96) of maximum x-coordinate among the points q such that
qy > py in all maxima sequences except Mj;
6: Discard the block in Mj containing p that forms part of the output through doubling searches for
the values of (cid:96)x and ry in the xand 
y-coordinates of the points in Mj, respectively. (Search for (cid:96)x
in the points q such that qx < px and for ry in the points q such that qx > px.);

7: Recurse separately on the non-discarded points left and right of p.

Lemma 1. A domination argument (cid:104)Mi[a] ⊃ Mj1[b1..c1], . . . ,Mjt[bt..ct](cid:105) can be checked in
O(t) data comparisons.

It is not enough to eliminate all points that can not participate in the output. Certifying
would still require additional work: a correct algorithm must justify the optimality of its output.
To this end we deﬁne maximality arguments.
Deﬁnition 3. (cid:104)Mi[a..b] (cid:97) Mj1[a1..b1], . . . ,Mjt[at..bt](cid:105) is a Maximality Argument if either
the points Mi[b] dominates the points Mj1[a1], . . . ,Mjt[at] and the x-coordinates of the points
Mj1[a1 − 1], . . . ,Mjt[at − 1] are less than the x-coordinate of the point Mi[a] or the point
Mi[a] dominates the points Mj1 [b1], . . . ,Mjt[bt] and the y-coordinates of the points Mj1 [b1 +
1], . . . ,Mjt[bt + 1] are less than the y-coordinate of the point Mi[b].

If (cid:104)Mi[a..b] (cid:97) Mj1[a1..b1], . . . ,Mjt[at..bt](cid:105) is a valid maximality argument, then the points in

the block Mi[a..b] are maximal among the maxima sequences Mi,Mj1, . . . ,Mjt.
Lemma 2. A maximality argument (cid:104)Mi[a..b] (cid:97) Mk1[a1..b1], . . . ,Mkt[at..bt](cid:105) can be checked in
O(t) data comparisons.

The diﬃculty of ﬁnding and describing domination and maximality arguments depend on the
points they refer to in the maxima sequences, a notion captured by “argument points”:
Deﬁnition 4. Given an argument A = (cid:104)Mi[a] ⊃ Mj1 [b1..c1], . . . ,Mjt[bt..ct](cid:105) or B = (cid:104)Mi[a..b] (cid:97)
Mj1[a1..b1], . . . ,Mjt[at..bt](cid:105), the Argument Points are the points Mi[a] in A and Mi[a] and
Mi[b] in B.

Those atomic arguments combine into a general deﬁnition of a certiﬁcate that any correct

algorithm for Merging Maxima in the comparison model can be modiﬁed to output.
Deﬁnition 5. Given a set of maxima sequences and their Maxima Set M expressed as several
blocks on the maxima sequences. A certiﬁcate of M is a set of domination and maximality
arguments such that the Maxima Set of any instance satisfying those arguments is given by the
description of M. The length of a certiﬁcate is the number of distinct argument points in it.

Synergistic Computation of Planar Maxima and Convex Hull

7

We divide the analysis of the time complexity of the Quick Union Maxima algorithm into two
lemmas. We ﬁrst bound the cumulated time complexity of the doubling searches for the value of
the median µ of the x-coordinates of the middle points of the maxima (i.e., step 2 of Algorithm 1)
and the doubling searches in the points discard steps (i.e., steps 4 and 6 of Algorithm 1). The
algorithm partitions the maxima sequences into blocks of consecutive discarded points, where
each block is discarded because it is dominated, or because this block forms part of the Maxima
Set of the union. Each block forms part of some argument of the certiﬁcate computed by the
algorithm.

Lemma 3. Let s1, . . . , sβ be the sizes of the β blocks into which the algorithm Quick Union
Maxima divides the maxima sequence Mi. The cumulated time complexity of the doubling searches
for the value of the medians µ of the x-coordinates of the middle points of the maxima sequences
(i.e., step 2) and the doubling searches in the points discard steps (i.e., steps 4 and 6) of the

algorithm Quick Union Maxima in the maxima sequence Mi is within O((cid:80)β

j=1 log sj).

Proof. Every time the algorithm ﬁnds the insertion rank of one of the medians µ of the xcoordinates 
of the middle points of the maxima sequences in Mi, it ﬁnds a position d inside a
blocks whose points will be discarded. The discard points steps that search for the insertion rank
of px and py start the search in the position d. The time complexity of both discard points steps
are bounded by O(log sb), where sb is the size of the discarded block b. Both discard points steps
partition Mi in positions separating the blocks to the left of b, the block b itself and the blocks
to the right of b.
The combination of the doubling search that ﬁnds the insertion rank of µ in the x-coordinates
of Mi with the doubling searches that discard points starting in d can be represented as a tree.
Each internal node has two children, which correspond to the two subproblems into which the
recursive steps partition Mi , the blocks to the left of b and the blocks to the right of b . The
cost of this combination is bounded by O(log sb + log s), where s is the minimum between the
sum of the sizes of the blocks to the left of b and the sum of the sizes of the blocks to the right of
b, because of the two doubling searches in parallel. The size of each internal node is the size of
the block discarded in this step. The size of each leaf is the sum of the sizes of the blocks in the
child subproblem represented by this leaf.

We prove that at each combination of steps, the total cost is bounded by eight times of the
sum of the logarithms of the sizes of the nodes in the tree. This is done by induction over the
number of steps. If the number of steps is zero then there is no cost. For the inductive step, if the
number of steps increases by one, then a new combination of steps is done and a leaf subproblem
is partitioned into two new subproblems. At this step, a leaf of the tree is transformed into an
internal node and two new leaves are created. Let w and z such that w ≤ z be the sizes of the new
leaves created. Note that w and z are the sum of the sizes of the blocks to the left and to the right,
respectively, of the discarded block b in this step. The cost of this step is less than 4 log w + 4 log b.
The cost of all the steps then increases by 4 log w + 4 log b, and hence eight times the sum of the
logarithms of the nodes in the tree increases by 8(log w + log z + log b − log(w + z + b)). But if
(cid:117)(cid:116)
w ≥ 3, w ≥ b and w ≤ z then the result follows.

We bound next the time complexity of the steps that compute the median µ of the x-coordinates
of the middles points in the maxima (i.e., step 1 of Algorithm 1) and the steps that ﬁnd the points
p, (cid:96) and r (i.e., steps 3 and 5 of Algorithm 1) in the Quick Union Maxima algorithm. Note that
one execution of these steps has time complexity bounded by the number of maxima sequences
in the sub-instance. The partition of the maxima sequences by the x-coordinate of p and the
discarded points decrease the number of maxima sequences in the subinstances.

8

J´er´emy Barbay and Carlos Ochoa

Lemma 4. The cumulated number of comparison performed by the steps that compute the median
µ of the x-coordinates of the middles points in the ρ maxima sequences (i.e., step 1) and the
steps that ﬁnd the points p, (cid:96) and r (i.e., steps 3 and 5) in the Quick Union Maxima algorithm

(cid:1)), where δ is the length of the certiﬁcate C computed by the algorithm

is within O((cid:80)δ

i=1 log(cid:0) ρ

and m1, . . . , mδ is a sequence where mi is the number of maxima sequences whose blocks form the
i-th argument of C.

mi

i=1 mi log k
mi

T (δ, k) ≤(cid:80)δ

Proof. We prove this lemma by induction over δ and ρ. The time complexity of one of these steps
is linear in the number of maxima sequences in the sub-instance (i.e., ignoring all the empty
maxima sequences of this sub-instance).
Let T (δ, k) be the cumulated time complexity during the execution of the steps that compute
the medians µ of the x-coordinates of the middles points (i.e., step 1) and during the steps that ﬁnd
the points p, (cid:96) and r (i.e., steps 3 and 5) in the algorithm Quick Union Maxima. We prove that
− k, where mi is the number of maxima sequences whose blocks form
the i-th argument of C. Let µ be the ﬁrst median of the x-coordinates of the middles points of the
maxima sequences computed by the algorithm. Let c and d be the number of maxima sequences
that have non-discarded point only above of py and to the right of px, respectively. Let b be the
number of maxima sequences that have non-discarded points above py and to the right of px. Let e
be the number of maxima sequences which all their points are dominated by p. Let δc and δd be the
number of arguments computed by the algorithm to discard points in the maxima sequences above
py and to the right of px, respectively. Then, T (δ, k) = T (δc, c + b) +T (δd, d + b) + k because of the
(cid:17)
+(cid:80)δd
two recursive calls and the steps 1, 3 and 5 of the algorithm Quick Union Maxima. By Induction
−d−b. In the
,
i=1 mi ≥ d + b (the number of discarded blocks
(cid:1)x ≥ y for y ≤ x. (cid:117)(cid:116)
is greater than or equal to the number of maxima sequences); c ≤ d + b, d ≤ c + b (at least k

Hypothesis, T (δc, c+b) ≤(cid:80)δc
−c−b and T (δd, d+b) ≤(cid:80)δd
(cid:17)
worst case e = 0, and we need to prove that c + d ≤(cid:80)δc
but this is a consequence of(cid:80)δc
i=1 mi ≥ c + b,(cid:80)δd
maxima sequences are left to the left and to the right of µ); and log(cid:0)1 + y

i=1 mi log d+b
mi
i=1 mi

i=1 mi log c+b
mi

1 + c
d+b

i=1 mi log

1 + d
c+b

x

2

(cid:16)

(cid:16)

Combining Lemma 3 and Lemma 4 yields an upper bound on the number of data comparisons

mi

O((cid:80)β

performed by the algorithm Quick Union Maxima:

i=1 log(cid:0) ρ

j=1 log sj +(cid:80)δ

(cid:1)) data comparisons when it computes the Maxima Set of the

Theorem 1. Given ρ maxima sequences. The Quick Union Maxima algorithm performs within
union of these maxima sequences; where β is the number of blocks in the certiﬁcate C computed
by the algorithm; s1, . . . , sβ are the sizes of these blocks; δ is the length of C; and m1, . . . , mδ is a
sequence where mi is the number of maxima sequences whose blocks form the i-th argument of
C. This number of comparisons is optimal in the worst case over instances formed by ρ maxima
sequences that have certiﬁcates C formed by β blocks of sizes s1, . . . , sβ and length δ such that
m1, . . . , mδ is a sequence where mi is the number of maxima sequences whose blocks form the
i-th argument of C.

The optimality of this algorithm is a consequence of the fact that it checks each arguments
of any certiﬁcate using a constant number of argument points. We prove next that the Quick
Union Maxima algorithm computes a certiﬁcate which length is a constant factor of the length of
the certiﬁcate of minimal length. Consider the following algorithm for Merging Maxima. The
Left-to-Right algorithm chooses the ﬁrst points from left to right of each maxima sequence and
computes the points u and v of maximum and second maximum y-coordinate among these points,
respectively. Let Mi be the maxima sequence that contains u. Let a be the index of u in Mi.
The y-coordinates of the points in the input maxima are sorted in decreasing order from left to

Synergistic Computation of Planar Maxima and Convex Hull

9

right. The algorithm searches then for the insertion rank of vy in Mi. Let b be the index of the
rightmost point g in Mi such that gy > vy. The block Mi[a..b] form part of the Maxima Set of
the union and are discarded by the Left-to-Right algorithm. If g dominates v, the algorithm
discards all points in the input dominated by g. The algorithm restarts the computation on the
non-discarded points.

Lemma 5. The Left-to-Right algorithm computes a certiﬁcate of minimal length when it
computes the union of ρ maxima sequences.

Proof. Let u and v be the points with maximum and second maximum y-coordinate among the
ﬁrst points from left to right of the non-discarded points of the maxima sequences. Let Mi be
the maxima sequence that contains u. Then, all points in Mi with y-coordinate greater than vy
could be discarded (i.e., form part of the output) and v is the point in the maxima sequences that
allows to discard the greatest number of consecutive points including u in Mi. Let g and h be
consecutive points in Mi such that gy > vy > hy. If g dominates v, then g is the rightmost point
in Mi that dominates v. Hence, g is the point in Mi that dominates the maximum number of
consecutive points including v in the maxima sequence that contains v. These two arguments are
(cid:117)(cid:116)
enough to prove that the algorithm computes the minimum number of argument points.

Let a be the number of argument points of the certiﬁcate computed by the Left-to-Right
algorithm. The number of argument points of the certiﬁcate that the algorithm Quick Union
Maxima computes is within a constant factor of a.

Lemma 6. The algorithm Quick Union Maxima computes a certiﬁcate which length is a constant
factor of the length of the certiﬁcate of minimal length.

Proof. Suppose that there is a block b of consecutive points in a maxima sequence that the
Left-to-Right algorithm discards because it identiﬁes that the points in b are in the output.
Suppose that the algorithm Quick Union Maxima running in the same input computes a point p
(p is the point of maximum y-coordinate among the points of x-coordinate greater than µ, then p
is in the output) that is contained in b. Let r be the point of maximum y-coordinate among the
points with x-coordinate greater than px computed by the Quick Union Algorithm. Let h be
the argument point used by the Left-to-Right algorithm to identify the rightmost point in b.
Hence, ry < hy. Let (cid:96) be the point of maximum x-coordinate among the points with y-coordinate
greater than py computed by the Quick Union Maxima algorithm. Let u be the argument point
used by the Left-to-Right algorithm to discard dominated points before the identiﬁcation of
b. Hence, (cid:96) is the same point as u. So, the algorithm Quick Union Maxima discards at least the
(cid:117)(cid:116)
block b using a constant number of argument points. The result follows.

Fig. 1: A representation of a state of the
Quick Union Algorithm where the points
p, (cid:96) and r has been computed.

In the following section we describe a synergistic result that combines the results of Sections 3.1
and 3.2. This result introduces the synergistic technique also used in the computation of the
Convex Hull in Section 4.3.

‘rp10

J´er´emy Barbay and Carlos Ochoa

3.3 Synergistic Computation of Maxima Sets

algorithm that performs within 2n + O((cid:80)β

The (Smooth,Structure) Synergistic Maxima algorithm decomposes the input of planar points
into the minimal number σ of smooth subsequences of consecutive positions, computes their
maxima sequences and then merges them using the Quick Union Maxima algorithm described in
the previous section.
Theorem 2. Let S be a set of points in the plane such that S can be divided into σ smooth
maxima sequences. Let h be the number of points in the Maxima Set of S. There exists an
comparisons when it computes the Maxima Set of S; where β and s1, . . . , sβ are the number
and sizes of the blocks in the certiﬁcate C computed by the union algorithm, respectively; δ is the
length of C; and m1, . . . , mδ is a sequence where mi is the number of maxima sequences whose
blocks form the i-th argument of C. This number of comparisons is optimal in the worst case over
instances S formed by σ smooth sequences which Maxima Set have certiﬁcates C of length δ
formed by β blocks of sizes s1, . . . , sβ, such that m1, . . . , mδ is a sequence where mi is the number
of maxima sequences whose blocks form the i-th argument of C.

(cid:1)) ⊆ O(n log(min(σ, h))) 2 data

j=1 log sj +(cid:80)δ

i=1 log(cid:0) σ

mi

We prove that the number of comparisons performed by the algorithm (Smooth, Structure)
Synergistic Maxima is asymptotically optimal in the worst case over instances formed by n
points grouped in σ smooth sequences, with a ﬁnal Maxima Set of size h. The upper bound is a
consequence of the Theorem 1 and the linear time partitioning algorithm described in Section 3.1.
We describe the intuition for the lower bound below: it is a simple adversary argument, based
on the deﬁnition of a family of “hard” instances for each possible value of the parameters of the
analysis, building over each other.

First, we verify the lower bound for “easy” instances, of ﬁnite diﬃculty: general instances
formed by a single (σ = 1) smooth sequence obviously require Ω(n) comparisons (no correct
algorithm can aﬀord to ignore a single point of the input, which could dominate all others), while
general instances dominated by a single point (h = 1) also require Ω(n) comparisons (similarly
to the computation of the maximum of an unsorted sequence). Each of this lower bound yields
a distribution of instances, either of smoothness σ = 1 or of output size h = 1, such that any
deterministic algorithm performs Ω(n) comparisons on average on a uniform distribution of those
instances.

Such distributions of “elementary” instances can be duplicated so that to produce various
distributions of elementary instances; and combined so that to deﬁne a distribution of harder
instances:

Lemma 7. Given the positive integers n, σ, β, s1, . . . , sβ, δ, m1, . . . , mδ, there is a family of instances 
which can each be partitioned into σ smooth sequences such that,
– β and s1, . . . , sβ are the number and sizes of the blocks in the certiﬁcate C computed by the
– δ is the length of C;
– m1, . . . , mδ is a sequence where mi is the number of maxima sequences of the smooth sequences

union algorithm, respectively;

– on average on a uniform distribution of these instances, any algorithm computing the Maxima

whose blocks form the i-th argument of C; and

Set of S in the comparison model performs within Ω(n +(cid:80)δ
2 The quantity(cid:80)β

j=1 log sj is within O(n) but is much smaller for “easy” instances.

Finally, any such distribution with a computational lower bound on average yields a computational 
lower bound for the worst case instance complexity of any randomized algorithm, on

i=1 log(cid:0) σ

mi

(cid:1)) comparisons.

Synergistic Computation of Planar Maxima and Convex Hull

11

average on its randomness; and as a particular case a lower bound on the worst case complexity
of any deterministic algorithm:

Corollary 1. Given the positive integers σ, β, s1, . . . , sβ, δ, m1, . . . , mδ, and an algorithm A computing 
the Maxima Set of a sequence of n planar points in the comparison model (whether
deterministic or randomized), there is an instance I such that A performs a number of comparisons

(cid:1)) when it computes the Maxima Set of I.

mi

within Ω(n +(cid:80)δ

i=1 log(cid:0) σ

Proof. A direct application of Yao’s minimax principle [20, 23, 25].

(cid:117)(cid:116)

The histories of the computation of the Maxima Set and of the computation of the Convex
Hull are strongly correlated: most of the results on one problem also generalize on the other one.
Our results on the computation of the Maxima Set similarly generalize to the computation of
the Convex Hull, albeit it requires additional work and concepts, which we describe in the
next section.

4 Convex Hull
Given a set S of planar points, the Convex Hull of S is the smallest convex set containing
S [22]. Given n points in the plane, the problem of computing their Convex Hull is well studied:
the worst case complexity over instances of size n is within Θ(n lg n) in the algebraic decision tree
computational model [21]. Several reﬁnements of this analysis are known: some taking advantage
of the input structure [1, 13] and some taking advantage of the input order [2, 16].

Levcopoulos et al. [16] described how to partition a sequence of points into subsequences of
consecutive positions for which the Convex Hull can be computed in linear time. We reﬁne
their analysis to take into account the distribution of the sizes of the subsequences (Section 4.1).
This notion of input order for the computation of the Convex Hull is less restrictive than the
one seen for the computation of the Maxima Set, in the sense that it allows to consider more
sophisticated sequences as “easy” sequences.

As the computation of Convex Hulls reduces to the computation of Upper Hulls (the
computation of the Lower Hull is symmetric and completes it into the computation of the
Convex Hull), we focus on the latter. We describe an algorithm Merging Upper Hulls in
Section 4.2, which yields a synergistic algorithm taking advantage of both the input order and
the input structure in Section 4.3. This synergistic algorithm outperforms both the algorithms
described by Levcopoulos et al. [16] and Afshani et al. [1], as well as any dovetailing combination
of them.

4.1

Input Order Adaptive Convex Hull

A polygonal chain is a curve speciﬁed by a sequence of points p1, . . . , pn. The curve itself consists
of the line segments connecting the pairs of consecutive points. A polygonal chain is simple if
any two edges of P that are not adjacent are disjoint, or if the intersection point is a vertex of P ;
and any two adjacent edges share only their common vertex. Levcopoulos et al. [16] described
an algorithm that computes the Convex Hull of n planar points in time within O(n log κ),
where κ is the minimal number of simple chains into which the input sequence of points can be
partitioned. The algorithm partitions the points into simple subchains, computes their Convex
Hulls, and merges them. In their analysis the complexity of both the partitioning and merging
steps are within O(n log κ). In Section 4.3, we describe a partitioning algorithm running in linear
time, which is key to the synergistic result.

12

J´er´emy Barbay and Carlos Ochoa

For a given polygonal chain, there can be several partitions into simple subchains of minimum
size for it. We describe a reﬁned analysis which takes into account the relative imbalance between
the sizes of the subchains. The idea behind the reﬁnement is to bound the number of operations
that the algorithm executes for every simple subchain. This analysis makes it possible to identify
families of instances where the complexity of the algorithm is linear even though the number of
simple subchains into which the chain is split is logarithmic. In the recursion tree of the execution
of the algorithm described by Levcopoulos et al. [16] on an input C formed by n planar points,
every node represents a subchain of C. The cost of every node is linear in the size of the subchain
that it represents. The simplicity test and the merge process are both linear in the number of
points in the subchain. Every time this algorithm discovers that the polygonal chain is simple,
the corresponding node in the recursion tree becomes a leaf.

Theorem 3. Given a sequence S of n planar points which can be partitioned into κ simple
subchains of respective sizes n1, . . . , nκ, Levcopoulos et al.’s algorithm [16] computes the convex 
hull of S in time within O(n(1 + H(n1, . . . , nκ))) ⊆ O(n(1+ log κ)) ⊆ O(n log n), where
, which is worst-case optimal over instances of n points that can

H(n1, . . . , nκ) =(cid:80)κ

ni
n log n
ni

i=1

be partitioned into κ simple subchains of sizes n1, . . . , nκ.

ni

Proof. Fix the subchain ci of size ni. In the worst case, the algorithm considers the ni points
of ci for the simplicity test and the merging process, in all the levels of the recursion tree
from the ﬁrst level to the level (cid:100)log n
(cid:101) + 1, because the sizes of the subchains in these levels
are greater than ni. In the next level, one of the nodes (cid:96) of the recursion tree ﬁts completely
inside ci and therefore it becomes a leaf. Hence, at least ni
4 points from ci are discarded for the
following iterations. The remaining points of ci are in the left or the right ends of subchains
represented by nodes in the same level of (cid:96) in the recursion tree. In all of the following levels,
the number of operations of the algorithm involving points from ci can be bounded by the
size of the subchains in those levels. So, the sum of the number of the operations in these
levels is within O(ni). As a result, the number of operations of the algorithm involving points
from ci is within O(ni log n
+ ni). In total, the time complexity of the algorithm is within
ni

) = O(n(1 + H(n1, . . . , nκ))) ⊆ O(n(1+ log κ)) ⊆ O(n log n).

O(n +(cid:80)κ

i=1 ni log n
ni

We prove the optimality of this complexity in the worst-case over instances of n points that
can be partitioned into κ simple subchains of sizes n1, . . . , nκ by giving a tight lower bound.
Barbay and Navarro [4] showed a lower bound of Ω(n(1 + H(r1, . . . , rρ))) in the comparison
model for Sorting a sequence of n numbers, in the worst case over instances covered by ρ runs
(increasing or decreasing) of sizes r1, . . . , rρ, respectively, summing to n. The Sorting problem
can be reduced in linear time to the problem of computing the Convex Hulls of a chain of n
planar points that can be partitioned into ρ simple subchains of sizes r1, . . . , rρ, respectively. For
each real number r, this is done by producing a point with (x, y)-coordinates (r, r2). The ρ runs
(alternating increasing and decreasing) are transformed into ρ simple subchains of the same sizes.
The sorted sequence of the numbers can be obtained from the Convex Hull of the points in
(cid:117)(cid:116)
linear time.
Similarly to the computation of the Maxima Set, we deﬁne in the following section an
algorithm for Merging Upper Hulls. This algorithm is a building block towards the synergistic
algorithm that computes the Convex Hull of a set of planar points, and is more complex than
that for Merging Maxima.

4.2 Union of Upper Hulls
We describe the Quick Union Hull algorithms which computes the Upper Hull of the union
of ρ upper hull sequences in the plane assuming that the upper hull sequences are given in sorted

Synergistic Computation of Planar Maxima and Convex Hull

13

Algorithm 2 Quick Union Hull
Input: A set U1, . . . ,Uρ of ρ upper hull sequences
Output: The Upper Hull of the union of the set U1, . . . ,Uρ
1: Compute the median µ of the slopes of the middle edges of the upper hull sequences;
2: Find the point p that has a supporting line of slope µ through doubling searches for the value µ in
the slopes of the edges of all upper hull sequences, starting at both ends in parallel, note j ∈ [1..ρ]
the index of the upper hull sequence containing p;
except Uj, starting at both ends in parallel;

3: Perform doubling searches for the value px in the x-coordinates of the points of all upper hull sequences

4: Find the two tangents of p with all upper hull sequences: the one to the left of p and the one to the
right of p, through doubling searches testing for each point q the slope of the two edge that have q as
end point and the slope of the line pq and discard the points below these tangents.
5: Discard a block in Uj containing p that form part of the output by computing the tangent between
Uj and the upper hull sequences left of p of minimum slope and the tangent between Uj and the
upper hull sequences right of p of maximum slope.

6: Repeat until there is no more than one upper hull sequence of size 1: pair those left of p and pair

those right of p and apply the Step 4 to those pairs;

7: Discard all points that lie below the lines that joins p with the leftmost point and the rightmost point

of the upper hull sequences;

8: Recurse on the non-discarded points left and right of p.

order by their x-coordinates. Given an upper hull sequence Ui, let Ui[a] and Ui[b..c] denote the
a-th point and the block of c − b + 1 consecutive points corresponding to the positions from a to
b in Ui, respectively. Given two points p and q, let m(p, q) denote the slope of the straight line
that passes trough p and q.

Description of the algorithm Quick Union Hull. The Quick Union Hull algorithm is
inspired by an algorithm described by Chan et al. [7]. It chooses an edge of slope µ from the upper
hull sequences, and computes the point p that has a supporting line of slope µ. The algorithm
then splits the points in the upper hull sequences by px. It computes the two tangents of p with
all the upper hull sequences: the one to the left of p and the one to the right of p, and discards
all the points below these tangents. The algorithm also computes a block of consecutive points in
the upper hull sequence that contains p which points are part of the output, and discards the
points in this block (p is in this block). (This last step is key to the optimality of the algorithm
and is signiﬁcantly more complex than its counterpart in the Merging Maxima solution.) The
algorithm then recurses on the non-discarded points to the left of p and on the non-discarded
points to the right of p. All these steps take advantage of the fact that the points in the upper
hull sequences are sorted in increasing order of their x-coordinates and the slopes of the edges of
the upper hull sequences are monotonically decreasing from left to right. (See Algorithm 2 for a
more formal description.)
In the following we describe in more details the Step 5 of Algorithm 2. We describe only how
to compute a block of consecutive points to the right of p in Uj that form part of the output,
as the left counterpart is symmetric. Let τ be the tangent of maximum slope between Uj and
the upper hull sequences to the right of p. Let q be the point in Uj that lies in τ . Let λ be the
tangent of maximum slope among those computed at Step 4. All the points to the right of p are
below λ and λ is a separating line between the portion of Uj that contains q and the points to
the right of p. Given two upper hull sequences Ui and Uk separated by a vertical line, Barbay
and Chen [3] described an algorithm that computes the common tangent between Ui and Uk in
time within O(log a + log b), where Ui[a] and Uk[b] are the points that lie in the tangent. At each

14

J´er´emy Barbay and Carlos Ochoa

step this algorithm considers the points Ui[c] and Uk[d] and can certify at least in one upper hull
sequence if the tangent is to the right or to the left of the point considered. A minor variant
manages the case where the separating line is not vertical. Algorithm 2 executes several instances
of this algorithm in parallel between Uj and all upper hull sequences to the right of p, always
considering the same point in Uj (similarly to the Demaine et al.’s algorithm [10] to compute
the intersection of sorted set). Once all parallel decisions about the point Uj[c] are made, the
instances can be divided into two sets: (i) those whose tangents are to the left of Uj[c] and (ii)
those whose tangents are to the right of Uj[c]. Algorithm 2 stops the parallel computation of
tangents in the set of maxima sequences (ii). The Step 5 continues until there is just one instance
running and computes the tangent τ in this instance.

Analysis of the Quick Union Hull Algorithm. Similarly to the case of Merging Maxima,
every algorithm for Merging Upper Hulls needs to certify that some blocks of the upper hull
sequences can not participate in the Upper Hull of the union, and that some blocks of the
upper hull sequences are in the Upper Hull of the union. In the following we formalize the
notion of a certiﬁcate for Merging Upper Hulls problem.
Deﬁnition 6. Given the points Ui[a] and Uj[b], let (cid:96) be the straight line that passes through Ui[a]
and Uj[b] and let m(cid:96) be the slope of (cid:96). (cid:104)Ui[a],Uj[b] ⊃ Uk[c..d..e](cid:105) is an Elementary Eliminator
Argument if all the points of the block Uk[c..e] are between the vertical lines through Ui[a] and
Uj[b], m(Uk[d − 1],Uk[d]) ≥ m(cid:96) ≥ m(Uk[d],Uk[d + 1]), and the point Uk[d] lies below (cid:96).

If (cid:104)Ui[a],Uj[b] ⊃ Uk[c..d..e](cid:105) is an elementary eliminator argument then the points in the block

Uk[c..e] can not participate in the Upper Hull of the union.
Lemma 8. An elementary eliminator argument (cid:104)Ui[a],Uj[b] ⊃ Uk[c..d..e](cid:105) can be checked in
constant time.

Several blocks that are “eliminated” by the same pair of points can be combined into a single
argument, a notion captured by the block eliminator argument.
Deﬁnition 7. (cid:104)Ui[a],Uj[b] ⊃ Uk1[c1..d1..e1], . . . ,Ukt[ct..dt..et](cid:105) is a Block Eliminator Argument
if (cid:104)Ui[a],Uj[b] ⊃ Uk1[c1..d1..e1](cid:105), . . . ,(cid:104)Ui[a],Uj[b] ⊃ Ukt[ct..dt..et](cid:105) are elementary eliminator arguments.


A block eliminator argument is checked by checking each elementary eliminator argument

that form it.
Corollary 2. A block eliminator argument (cid:104)Ui[a],Uj[b] ⊃ Uk1[c1..d1..e1], . . . ,Ukt[ct..dt..et](cid:105) can
be checked in time within O(t).

As for Merging Maxima, any correct algorithm for Merging Upper Hulls must certify

that some points are part of the output.
Deﬁnition 8. (cid:104)Ui[a] (cid:97) Uj1[b1], . . . ,Ujt[bt](cid:105) is an Elementary Convex Argument if there exists
a straight line (cid:96) that passes through Ui[a] of slope m(cid:96) such that m(Uj1[b1 − 1],Uj1 [b1]) ≥ m(cid:96) ≥
m(Uj1[b1],Uj1[b1+1]), . . . , m(Ujt[bt−1],Ujt[bt]) ≥ m(cid:96) ≥ m(Ujt[bt],Ujt[bt+1]); m(Ui[a−1],Ui[a]) ≥
m(cid:96) ≥ m(Ui[a],Ui[a + 1]); and the points Uj1[b1], . . . ,Ujt[bt] lie below (cid:96).

If (cid:104)Ui[a] (cid:97) Uj1 [b1], . . . ,Ujt[bt](cid:105) is an elementary convex argument, then the point Ui[a] is in

the Upper Hull of the union of the upper hulls Ui,Uj1, . . . ,Ujt.

Synergistic Computation of Planar Maxima and Convex Hull

15

Lemma 9. An elementary convex argument (cid:104)Ui[a] (cid:97) Uj1[b1], . . . ,Ujt[bt](cid:105) can be checked in time
within O(t).

There are blocks that can be “easily” certiﬁed that form part of the output.
Deﬁnition 9. Given the points Ui[a] and Ui[b], let (cid:96) be the straight line that passes through Ui[a]
and Ui[b] and let m(cid:96) be the slope of (cid:96). (cid:104)Ui[a..b] (cid:97) Uj1[c1..d1..e1], . . . ,Ujt[ct..dt..et](cid:105) is a Block Convex
Argument if (cid:104)Ui[a] (cid:97) Uj1 [c1], . . . ,Ujt[ct](cid:105) and (cid:104)Ui[b] (cid:97) Uj1[e1], . . . ,Ujt[et](cid:105) are elementary convex
arguments; m(Uj1 [d1 − 1],Uj1[d1]) ≥ m(cid:96) ≥ m(Uj1[d1],Uj1[d1 + 1]), . . . , m(Ujt[dt − 1],Ujt[dt]) ≥
m(cid:96) ≥ m(Ujt[dt],Uj1 [dt + 1]), and the points Uj1 [d1], . . . ,Ujt[dt] lie below (cid:96).

If (cid:104)Ui[a..b] (cid:97) Uj1[c1..d1..e1], . . . ,Ujt[ct..dt..et](cid:105) is a block convex argument then the points in

the block Ui[a..b] are in the Upper Hull of the union of the upper hulls Ui,Uj1, . . . ,Ujt.
Lemma 10. A block convex argument (cid:104)Ui[a..b] (cid:97) Uj1[c1..d1..e1], . . . ,Ujt[ct..dt..et](cid:105) can be checked
in time within O(t).

Similar to the Merging Maxima, the diﬃculty of ﬁnding and describing block eliminator
and block convex arguments depend on the points they refer to in the upper hull sequences, a
notion captured by “argument points”:
Deﬁnition 10. Given an argument (cid:104)Ui[a],Uj[b] ⊃ Uk1[c1..d1..e1], . . . ,Ukt[ct..dt..et](cid:105) or (cid:104)Ui[a..b] (cid:97)
Uj1 [c1..d1..e1], . . . ,Ujt[ct..dt..et](cid:105), the Argument Points are the points Ui[a] and Ui[b].

Those atomic arguments can be checked in time proportional to the number of blocks in them,
and combine into a general deﬁnition of a certiﬁcate that any correct algorithm for Merging
Upper Hulls in the algebraic decision tree computational model can be modiﬁed to output.
Deﬁnition 11. Given a set of upper hull sequences and their Upper Hull U expressed as
several blocks on the upper hull sequences. A certiﬁcate of U is a set of block eliminator and block
convex arguments such that the Upper Hull of any instance satisfying those arguments is given
by the description of U. The length of a certiﬁcate is the number of distinct argument points in it.

Similarly to the Merging Maxima, the key of the analysis is to separate the doubling search

j=1 log sj +(cid:80)δ

i=1 log(cid:0) ρ

mi

steps from the other steps of the algorithm.

algorithm is within O((cid:80)β

Theorem 4. Given ρ upper hull sequences. The time complexity of the Quick Union Hull
union of these upper hull sequences; where β is the number of blocks in the certiﬁcate C computed
by the algorithm; s1, . . . , sβ are the sizes of these blocks; δ is the length of C; and m1, . . . , mδ is a
sequence where mi is the number of upper hull sequences whose blocks form the i-th argument of
C.

(cid:1)) when it computes the Upper Hull of the

The optimality of this algorithm is a consequence of the fact that it checks each argument of

any certiﬁcate using a constant number of argument points.

Lemma 11. The algorithm Quick Union Hull computes a certiﬁcate which length is a constant
factor of the length of the certiﬁcate of minimal length.

In the following section we describe a synergistic results that combines the results of Sections 4.1

and 4.2.

16

J´er´emy Barbay and Carlos Ochoa

4.3 Synergistic Computation of Upper Hulls

The (Simple,Structure) Synergistic Hull algorithm proceeds in two phases. It ﬁrst decomposes 
the input into simple subchains of consecutive positions using a (new) linear time doubling
search inspired partitioning algorithm, that searches for simple chains from left to right (see
Algorithm 3 for a detail description of the algorithm). It computes their upper hull sequences,
and then merges those using the Quick Union Hull algorithm described previously.

Algorithm 3 Doubling Search Partition

if i + 2t > n or the chain pi, . . . , pi+2t is not simple then

Input: A sequence of n planar points p1, . . . , pn
Output: A sequence of simple polygonal chains
1: Initialize i to 1;
2: for t = 1, 2, . . . do
3:
4:
5:
6:
7:
end if
8: end for

Add the chain pi, . . . , pi+2t−1 to the output
Update i ← i + 2t−1 + 1
Reset t ← 1

The Doubling Search Partition algorithm partitions the polygonal chain into simple subchains 
which sizes has asymptotically minimum entropy among all the partitions into simple
subchains. The following lemma formalizes this fact.

Lemma 12. Given a sequence S of n planar points. The Doubling Search Partition algorithm
computes in linear time a partition of S into k simple polygonal chain of consecutive points, of
sizes n1, . . . , nk such that n(1 + H(n1, . . . , nk)) ∈ O(n(1 + α)), where α is the minimal entropy
min{H(n1, . . . , nκ) of any partition of S into κ simple subchains of consecutive positions, of

respective sizes n1, . . . , nκ, and H(n1, . . . , nκ) =(cid:80)κ

}.

ni
n log n
ni

i=1

which time complexity is within O(n +(cid:80)δ

The proof of this lemma is similar to the proof of Theorem 3 where the number of operations
for each simple subchain of a partition into simple subchains is bounded separately. The following
theorem summarizes the synergistic result in this section.
Theorem 5. Let S be a set of points in the plane such that S can be partitioned into κ simple
subchains. Let h be the number of points in the Upper Hull of S. There exists an algorithm
Upper Hull of S, where δ is the length of the certiﬁcate C computed by the union algorithm; and
m1, . . . , mδ is a sequence where mi is the number of upper hull sequences of the simple subchains
whose blocks form the i-th argument of C. This number of comparisons is optimal in the worst
case over instances S formed by κ simple subchains which Upper Hulls have certiﬁcates C
of length δ such that m1, . . . , mδ is a sequence where mi is the number of upper hull of simple
subchains whose blocks form the i-th argument of C.

(cid:1)) ⊆ O(n log(min(κ, h))) when it computes the

i=1 log(cid:0) κ

mi

Even though the algorithms are more complex, except for some details, the proofs of Theorems 4
and 5 and Lemma 11 of Section 4 are very similar to those described in the previous section. We
describe the intuition for the lower bound below: as for the computation of Maxima Sets, it is
a simple adversary argument, based on the deﬁnition of a family of “hard” instances for each
possible value of the parameters of the analysis, building over each other, but the combination of
elementary instances requires a little bit of extra care.

Synergistic Computation of Planar Maxima and Convex Hull

17

First, we verify the lower bound for “easy” instances, of ﬁnite diﬃculty: general instances
formed by a single (κ = 1) simple sequence obviously require Ω(n) comparisons (no correct
algorithm can aﬀord to ignore a single point of the input), while general instances dominated by a
single edge (h = 1) also require Ω(n) comparisons. Each of these lower bound yields a distribution
of instances, either decomposed into κ = 1 simple chains or of output size h = 1, such that any
deterministic algorithm performs Ω(n) comparisons on average on a uniform distribution of those
instances.

Such distributions of “elementary” instances can be duplicated so that to produce various
distributions of elementary instances; and can be combined so that to deﬁne a distribution of
harder instances.

Lemma 13. Given the positive integers n, κ, β, s1, . . . , sβ, δ, m1, . . . , mδ, there is a family of
instances which can each be partitioned into κ simple subchains such that,
– β and s1, . . . , sβ are the number and sizes of the blocks in the certiﬁcate C computed by the
– δ is the length of C;
– m1, . . . , mδ is a sequence where mi is the number of upper hulls of the simple subchains whose

union algorithm, respectively;

blocks form the i-th argument of C; and

Hull of S in the comparison model performs within Ω(n +(cid:80)δ

– on average on a uniform distribution of these instances, any algorithm computing the Upper

i=1 log(cid:0) κ

mi

(cid:1)) comparisons.

Finally, any such distribution with a computational lower bound on average yields a computational 
lower bound for the worst case instance complexity of any randomized algorithm, on
average on its randomness; and as a particular case a lower bound on the worst case complexity
of any deterministic algorithm:

Corollary 3. Given the positive integers κ, β, s1, . . . , sβ, δ, m1, . . . , mδ, and an algorithm A computing 
the Upper Hull of a sequence of n planar points in the algebraic decision tree computational 
model (whether deterministic or randomized), there is an instance I such that A performs

(cid:1)) when it computes the Upper Hull of I.

a number of comparisons within Ω(n +(cid:80)δ

i=1 log(cid:0) κ

mi

Proof. A direct application of Yao’s minimax principle [20, 23, 25].

(cid:117)(cid:116)

This concludes the description of our synergistic results. In the next section, we discuss the

issues left open for improvement.

5 Discussion

Considering the computation of the Maxima Set and of the Convex Hull, we have built upon
previous results taking advantage either of some notions of input order or of some notions of
input structure, to describe solutions which take advantage of both in a synergistic way. There
are many ways in which those results can be improved further: we list only a selection here.

In the same line of thought, Ahn and Okamoto [2] described some other notion of input order
than the one we considered here, which can potentially yield another synergistic solution in
combination with a given notion of input structure. This is true for any of the many notions of
input order which could be adapted from Sorting [18].

Whereas being adaptive to as many measures of diﬃculty as possible at once is a worthy goal
in theory, it usually comes at a price of an increase in the constant factor of the running time of
the algorithm: it will become important to measure, for the various practical applications of each

18

J´er´emy Barbay and Carlos Ochoa

problem, which measures of diﬃculty take low value in practice. It will be necessary to do some
more theoretical work to identify what to look for in the practical applications, but then it will
be important to measure the practical diﬃculties of the instances.

Acknowledgments: The authors would like to thank Javiel Rojas for helping with the

bibliography on the computation of the Maxima Set of a set of points.

References

1. Afshani, P., Barbay, J., Chan, T.M.: Instance-optimal geometric algorithms. In: Proceedings of
the Annual IEEE Symposium on Foundations of Computer Science (FOCS). pp. 129–138. IEEE
Computer Society (2009)

2. Ahn, H.K., Okamoto, Y.: Adaptive algorithms for planar convex hull problems. IEICE Transactions

94-D(2), 182–189 (2011)

3. Barbay, J., Chen, E.Y.: Convex hull of the union of convex objects in the plane: an adaptive analysis.

In: Proceedings of the Annual Canadian Conference on Computational Geometry (CCCG) (2008)

4. Barbay, J., Navarro, G.: On compressing permutations and adaptive sorting. Theoretical Computer

Science (TCS) 513, 109–123 (2013)

5. Barbay, J., Ochoa, C., Rao, S.S.: Synergistic Sorting and Deferred Data Structures on MultiSets.

ArXiv e-prints (Aug 2016)

6. Bentley, J.L., Yao, A.C.C.: An almost optimal algorithm for unbounded searching. Information

Processing Letters (IPL) 5(3), 82–87 (1976)

7. Chan, T.M., Snoeyink, J., Yap, C.K.: Primal dividing and dual pruning: Output-sensitive construction
of four-dimensional polytopes and three-dimensional voronoi diagrams. Discrete & Computational
Geometry (DCG) 18(4), 433–454 (1997)

8. Chazelle, B.: Triangulating a simple polygon in linear time. Discrete & Computational Geometry

(DCG) 6(5), 485–524 (Aug 1991), http://dx.doi.org/10.1007/BF02574703

9. Demaine, E.D., Lopez-Ortiz, A.: A linear lower bound on index size for text retrieval. In: Proceedings

of the 12th Annual ACM-SIAM Symposium on Discrete algorithms (SODA). pp. 289–294 (2001)

10. Demaine, E.D., L´opez-Ortiz, A., Munro, J.I.: Adaptive set intersections, unions, and diﬀerences. In:
Proceedings of the 11th ACM-SIAM Symposium on Discrete Algorithms (SODA). pp. 743–752 (2000)
11. Estivill-Castro, V., Wood, D.: A survey of adaptive sorting algorithms. ACM Computing Surveys

(ACMCS) 24(4), 441–476 (1992)

12. Fj¨allstr¨om, P.O., Katajainen, J., Levcopoulos, C., Petersson, C.: A sublogarithmic convex hull

algorithm. BIT Numerical Mathematics 30(3), 378–384 (1990)

13. Kirkpatrick, D.G., Seidel, R.: Output-size sensitive algorithms for ﬁnding maximal vectors. In:
Proceedings of the Annual Symposium on Computational Geometry (SoCG). pp. 89–96. ACM, New
York, NY, USA (1985)

14. Kirkpatrick, D.G., Seidel, R.: The ultimate planar convex hull algorithm? SIAM Journal on Computing

(SICOMP) 15(1), 287–299 (1986)

15. Kung, H.T., Luccio, F., Preparata, F.P.: On ﬁnding the maxima of a set of vectors. Journal of the

ACM (JACM) 22(4), 469–476 (1975)

16. Levcopoulos, C., Lingas, A., Mitchell, J.S.B.: Adaptive algorithms for constructing convex hulls and
triangulations of polygonal chains. In: Proceedings of the Scandinavian Workshop on Algorithm
Theory (SWAT). pp. 80–89. Springer-Verlag, London, UK (2002)

17. Melkman, A.A.: On-line construction of the convex hull of a simple polyline. Information Processing

Letters (IPL) 25(1), 11–12 (Apr 1987), http://dx.doi.org/10.1016/0020-0190(87)90086-X

18. Moﬀat, A., Petersson, O.: An overview of adaptive sorting. Australian Computer Journal (ACJ)

24(2), 70–77 (1992)

19. Munro, J.I., Spira, P.M.: Sorting and searching in multisets. SIAM Journal on Computing (SICOMP)

5(1), 1–8 (1976)

20. Neumann, J.V., Morgenstern, O.: Theory of games and economic behavior. 1st edition, Princeton

University Press (1944)

Synergistic Computation of Planar Maxima and Convex Hull

19

21. Preparata, F.P., Hong, S.J.: Convex hulls of ﬁnite sets of points in two and three dimensions.

Communication of the ACM (CACM) 20, 87–93 (1977)

22. Preparata, F.P., Shamos, M.I.: Computational Geometry: An Introduction. Springer-Verlag (1985)
23. Sion, M.: On general minimax theorems. Paciﬁc Journal of Mathematics (PJM) 1, 171–176 (1958)
24. Takaoka, T.: Partial solution and entropy. In: Kr´aloviˇc, R., Niwi´nski, D. (eds.) Mathematical
Foundations of Computer Science (MFCS) 2009: 34th International Symposium, Novy Smokovec,
High Tatras, Slovakia, August 24-28, 2009. Proceedings. pp. 700–711. Springer Berlin Heidelberg,
Berlin, Heidelberg (2009)

25. Yao, A.C.C.: Probabilistic computations: Toward a uniﬁed measure of complexity. In: Proceedings of

the Annual IEEE Symposium on Foundations of Computer Science (FOCS). pp. 222–227 (1977)

