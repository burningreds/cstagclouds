Short Transitive Signatures for Directed Trees

Philippe Camacho and Alejandro Hevia

Dept. of Computer Science, University of Chile,
Blanco Encalada 2120, 3er piso, Santiago, Chile.

{pcamacho,ahevia}@dcc.uchile.cl

August 17, 2011

Abstract

A transitive signature scheme allows to sign a graph in such a way that, given the signatures of
edges (a, b) and (b, c), it is possible to compute the signature for the edge (or path) (a, c) without
the signer’s secret. Constructions for undirected graphs are known but the case of directed graphs
remains open. A ﬁrst solution for the case of directed trees (DT T S) was given by Yi at CT-RSA
2007.
In Yi’s construction, the signature for an edge is O(n(log(n log n))) bits long in the worst
case. A year later, Neven designed a simpler scheme where the signature size is reduced to O(n log n)
bits. Although Neven’s construction is more eﬃcient, O(n log n)-bit long signatures still remains
impractical for large n.

In this work, we propose a new DT T S scheme such that, for any value λ ≥ 1 and security

parameter κ:

• Signatures for edges are only O(κλ) bits long.

• Signing or verifying a signature for an edge requires O(λ) cryptographic operations.
• Computing a signature for an edge requires O(λn1/λ) cryptographic operations.

To the best of our knowledge this is the ﬁrst construction with such a trade oﬀ. In particular, we can
achieve O(κ log(n))-bit long signatures while taking only O(log(n)) time to generate edge signatures,
verify or even compute edge signatures.

Our construction relies on hashing with common-preﬁx proofs, a new variant of collision resistance
hashing. A family H provides hashing with common-preﬁx proofs if for any H ∈ H, given two strings
X and Y equal up to position i, a Combiner can convince a Veriﬁer that X[1..i] is a preﬁx of Y by
sending only H(X), H(Y ), and a small proof. We believe that this new primitive will lead to other
interesting applications.

Keywords: Transitive Signatures, Authenticated Data-structures, Collision-resistant Hashing,

Hashing with common-preﬁx proofs.

1

Introduction

Transitive signatures is a primitive introduced by Micali and Rivest [14] where a signer wants to authenticate 
a graph. The main property of such scheme is that, given the signatures of edges (a, b) and (b, c),
it is possible to compute - without the knowledge of the secret - a signature for the edge (a, c). In their
work, the authors propose an eﬃcient scheme for undirected graphs based on the diﬃculty of computing
discrete logarithm for large groups. They left the existence of a transitive signature scheme for directed
graph (DT S) as a challenging open question. The easier problem of building transitive signatures for
directed trees was ﬁrst addressed by Yi [19]. The construction, based on a special assumption for the

1

RSA cryptosystem, produces signatures of size O(n log(n log n)) bits, where n is the number of vertices
of the tree. Neven described in [16], a simpler solution based only on the existence of standard digital
signatures which also improves the bound on the size of the signature to O(n log n) bits.

In this work we describe a new construction for DT T S schemes that enjoys much better worst-case
complexity. Using the number of cryptographic operations as our notion of time, we obtain for any λ ≥ 1:

• Signing a new edge (or verifying the signature for any edge) can be done in O(λ) time.
• The time to compute a signature for any edge is O(λn1/λ).

Moreover, signature size is also substantially improved: our signatures require only O(κλ) bits, where κ is
a security parameter. In particular, if λ = log(n) then signatures are only O(κ log(n)) bits, while allowing
eﬃcient signature computation (O(log(n) time). Alternatively, by setting for example λ = 2, we obtain

an optimal edge signature size of O(2· κ) = O(κ) bits if we are willing to aﬀord O(√n) computation time.

Our Approach. There are two main ideas in our construction. First we use the following fact observed
by Dietz in [8]: given a tree T , if Pre and Post are the strings representing the sequences of labels
obtained by a pre-order and respectively post-order depth ﬁrst traversal, then there exists a path from a
to b if and only if a appears before b in Pre and b appears before a in Post. Armed by this result we can
reduce the problem of deciding if there is a path between vertices a and b to the one of comparing the
position of a and b in S. To do so we consider an order data structure – a concept also introduced in [8] –
where the idea is to dynamically insert elements into a sequence such that it is eﬃcient to decide whether
an element is before or after another. We implement such data structure through a binary search tree
T ′, where each node of T ′ is associated to an element of the sequence S in the following way: if a ∈ S
(bound to a′ ∈ T ′) appears before b ∈ S (bound to b′ ∈ T ′), then a′ and b′ have a common ancestor c and
a′ belongs to the left (resp. b′ belongs to the right) sub-tree of c. We then label each left (resp. right)
edge of T ′ by 0, (resp. 1). Now we assign to a the string A formed by the concatenation of 0, 1’s from
the root of T ′ to the node a′ and similarly assign the string B to node b′. From this construction we can
deﬁne a total order relation on strings ≺ such that A ≺ B, means a appears before b in the sequence S.
The advantage of this order data structure is that it allows incremental computations of new order labels:
that is, every new string V (associated to an element v of S) will share all bits except one with another
already computed label. As shown in section 4, this property is crucial to enable eﬃcient computation of
edge signatures. The problem that arises now is that large strings of O(n) bits are bound to the vertices
of T , so at ﬁrst sight we have not won too much: the signature length is now O(n) bits v/s O(n log n)
bits for Neven’s construction. That is where our second idea comes into play: we design a new kind of
collision resistant hash functions family which enables the following: Given only two hash values H(A),
H(B) and a small proof a Combiner can convince a Veriﬁer that A and B share a common preﬁx up
to a position i. We call this new primitive collision-resistant hashing with common-preﬁx proofs. We
can see that this primitive allows also to prove that A ≺ B for two strings A, B. Using this tool we
can complete our construction for DT T S. The last remaining diﬃculty is that the time to compute a
proof for strings of n bits involves a priori O(n) cryptographic operations. To overcome this drawback we
show how to balance the work between the Veriﬁer and the Combiner using the natural idea of hashing
consecutive chunks of the initial string to obtain a shorter one, and repeat this operation several times.
This technique leads to the trade oﬀ O(λn1/λ) v/s O(λ) for λ ≥ 1 between the time to compute a proof
versus the time to verify a proof. The security of our primitive is based on the n-Bilinear Diﬃe Hellman
Inversion assumption, introduced by Boneh and Boyen in [3].

Related Work. The concept of transitive signatures was introduced by Rivest and Micali [14] who also
gave constructions for undirected graphs. Bellare and Neven in [2], as well as Shahandashti et al. in [18],
introduced new schemes based on bilinear maps (but still for undirected graphs). Hohenberger [11] showed
that the existence of transitive signatures for directed graphs (DT S) implies the existence of abelian
groups where inversion is computationally infeasible except when given a trapdoor. Such groups are not

2

known to exist either. Transitive signatures are a special case of homomorphic signatures, a primitive
introduced by Rivest and explored in [12, 4, 5]. We observe that using accumulators techniques like [6, 7]
we can improve Neven’s construction [16] in order to obtain short signatures. Such a solution, however,
does not enable two key properties we seek and achieve on this paper’s construction: the computation of
edge signatures is paralellizable, and it tolerates unbounded growth for the trees (the construction can
increase the bound on the number of nodes by dynamically increasing the setup parameter, see sec. 3).
We explore a DT T S construction based on accumulators in appendix C.

Our contributions. Our contribution is twofold: ﬁrst we introduce a general and practical new
primitive, collision-resistant hashing with common-preﬁx proofs, which enables eﬃcient proofs that certain
strings share common-preﬁxes. We believe that this primitive may lead to many applications in the ﬁeld
of authenticated data structures. Our second contribution is a practical DT T S scheme which is, to the
best of our knowledge, the most eﬃcient one to the date.

Organization of the paper. In section 2 we introduce the notations, the deﬁnitions for DT T S and
the complexity assumptions that we use. Section 3 describes in details our new primitive. Then in section
4 we show how to use collision-resistant hashing with common-preﬁx proofs to obtain a practical DT T S
scheme.

2 Preliminaries

Notations and Conventions. If κ ∈ N is the security parameter then 1κ denotes the unary string
with κ ones. A function ν : N → [0, 1] is said to be negligible in κ, if for every polynomial p(·) there exists
κ0 such that ∀κ > κ0 : ν(κ) < 1/p(κ). In the following, neg will denote some negligible function in κ.
An algorithm is said to be PPT if it is probabilistic and runs in polynomial time in κ. We write x R← X
to denote an element x chosen at random from the set X. The time complexities expressed in the rest of
this work are relative to the number of cryptographic operations (signature, group exponentiation, and
application of a bilinear map).

Strings. Let n ∈ N. A string S of size |S| = n is a sequence of symbols S[1], S[2], ..., S[n] from an
alphabet Σ. We assume Σ is totally ordered, and note the order relation <. If n = 0 then S = ǫ is the
empty string. S[i..j] denotes the substring of S starting at position i and ending at position j (both S[i]
and S[j] are included). In particular if A = S[1..j] for some j ≥ 0 then we say that A is a preﬁx of S (by
convention A[1..0] for any string A is the empty string ǫ). We say a string C is a common preﬁx of A
and B if C is preﬁx of A and also of B. String C is said to be the maximum common preﬁx of A and B
if moreover C||σ is not a common preﬁx of A and B for any symbol σ ∈ Σ. The concatenation operator
on strings is denoted as ||. That is, if A, B are two strings of size n, then C = A||B is the string formed
by the sequence C[1] = A[1], C[2] = A[2], ..., C[n] = A[n], C[n + 1] = B[1], ..., C[2n] = B[n]. A symbol
σ ∈ Σ refers equivalently to the symbol or the string of length one. If A and B are strings then A ≺ B
means A appears before B w.r.t. the lexicographical order. $ is a special (and implicit) symbol that is
used only to mark the end of a string. For example the empty string is written $ and the string with
symbols a followed by b is represented by ab$.

Trees. Let T be a directed tree where each node is identiﬁed by a unique vertex-label a ∈ N. Our
construction makes use of trees which edges are associated to a symbol σ ∈ Σ. This means a node can
also be identiﬁed by a string (or path-label ) A which is the concatenation of the symbols present on the
path from the root to this node. Moreover, if α is a vertex label, we write α ∈ T to mean the node with
label α belongs to T . If we assume that each path-label A is unique then node(A) refers to the node in
T with path-label A. We say a node a ∈ T is a descendant of c if a belongs to the sub-tree rooted at c or
equivalently if there is a path from c to a. The lowest common ancestor of two nodes a, b of T is the node

3

c such that a and b belong to the sub-tree rooted at c, and for any child d of c, a or b is not a descendant
of d. If we consider a depth-ﬁrst traversal of a tree, We denote by Pre and Post the strings formed by
the successive labels of the nodes that are visited in a pre-order (the node is append to the string when
it is visited for the ﬁrst time) respectively post-order (the node is append to the string when it is visited
for the last time). The transitive closure of T is T ∗ = {(a, b) : a, b ∈ T and there is a path from a to b}.
Collision Resistance and Standard Signatures Schemes. Let H be a family of functions and
H : {0, 1}∗ → {0, 1}κ an element of H. The family H is said to be collision-resistant (CRHF ) if, for
H randomly chosen in H, any computationally bounded adversary can not ﬁnd two diﬀerent messages
M and M ′ such that H(M ) = H(M ′), except with negligible probability. Let AlgH(·) be a PPT
algorithm that computes H, then if AlgH(·) is fed with input X and returns y, we write X = H −1(y).
We denote by SSig = (SKG, SSig, SVf) a standard signature scheme. (sk, pk) ← SKG(1κ) is the pair of
private/public keys created in the setup phase. Then for a message M ∈ {0, 1}∗ its associated signature is
σM = SSig(sk, M ). The validation of a signature σ on M is done by running SVf(pk, M, σ) which returns
valid if σ is a valid signature for M under pk and ⊥ otherwise. For the security of digital signatures, we
use the standard notion of existential unforgeability under chosen message attack [9].

Transitive Signatures. In a transitive signature scheme, the Signer can sign the vertices of some
graph but also the edges. Then without the secret, given two signed edges (a, b) and (b, c) it is possible
to compute the signature of the path (or edge) (a, c). We can see that this property enables to compute
the signature for any path in the tree.

Deﬁnition 1. (Transitive Signature Scheme, [14, 16]) A transitive signature
scheme (for directed trees) is a tuple DTTS = (TSKG, TSign, TSComp, TSVf)
where:

• TSKG(1κ) : returns a pair of private/public keys (tsk, tpk).
• TSign(tsk, a, b) : returns the signature τ(a,b) of edge (a, b).
• TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk): returns the signature τ(a,c) of path (a, c). Note that the secret

key is not required.

• TSVf((a, b), τ, tpk) : returns valid if the τ is a valid signature for the path (a, b) and ⊥ otherwise.
Intuitively, a transitive signature scheme is secure if, for any PPT adversary it is infeasible to compute

a signature for a path that is outside the transitive closure of T .
Deﬁnition 2. (Security of Transitive Signature Schemes, [14, 16]) Let DTTS be a transitive signature
scheme. Consider the following experiment. The PPT adversary A is given the public key of the scheme
tpk. A asks for a polynomial number of edge signatures to the oracle OTSign(·). Finally A outputs (a, b)
and τ where a, b are nodes of the tree T formed by the successive edge insertions. The advantage of A is
deﬁned by:

Advtuf-cma(A, κ) = P r(cid:20)

TSVf((a, b), τ, tpk) = valid (cid:21)

(a, b) /∈ T ∗∧

The scheme is said to be secure if for any PPT adversary A
we have Advtuf-cma(A, κ) = neg(κ).

A trivial solution for DT T S can be implemented by simply concatenating standard edge signatures,
in which case the size of a signature grows linearly with the size of the path and may reach O(nκ) bits.
Yi’s solution [19] with O(n log(n log n)) bits signatures is clearly better than the trivial construction.
Neven’s DT T S scheme [16] reduces the size of signature to O(n log n) bits. We note that both solutions
need to maintain the state of the tree to enable new edge signature computations. As mentioned in [16]

4

the initial deﬁnition of transitive signatures is stateless in the sense that signing a new edge should only
require the knowledge of the two vertices. Our solution is also stateful and thus we make it explicit by
introducing a third participant in addition to the Signer and the Veriﬁer that we call the Combiner. His
role is to compute, without the help of the Signer, signatures for any path in the tree.

Bilinear maps. Our construction for collision resistant hashing with common-preﬁx proofs requires the
use of bilinear maps. Let G, GT , be cyclic groups of prime order p. We consider a map e : G × G → GT
which is

• bilinear : ∀a, b ∈ G, x, y ∈ Zp : e(ax, by) = e(a, b)xy.
• non-degenerate: let g be a generator of G then e(g, g) also generates GT .
• eﬃciently computable: there exists a polynomial time algorithm BMGen with parameter 1κ that
outputs (p, ˆG, ˆGT , ˆe, g) where ˆG, ˆGT refer to the representation of both groups of size p (p being a
prime number of κ bits), g is a generator of G and ˆe is an eﬃcient algorithm to compute the map.
For the sake of simplicity, in the following we will not distinguish between G, GT , e and ˆG, ˆGT , ˆe.

The security of our construction relies on the n-Billinear Diﬃe-Hellman Inversion (n-BDHI) assumption
which was introduced by Boneh and Boyen [3].

Deﬁnition 3. (n − BDHI assumption [3]) Let P = (p, G, GT , e, g) ← BMGen(1κ), s R← Zp, and T =
(g, gs, gs2
). The n-Bilinear Diﬃe-Hellman Inversion (n-BDHI) problem consists in computing
s , given P and T . We say the n − BDHI assumption holds if for any PPT adversary A we have:
e(g, g)

, ..., gsn

1

Advn-BDHI(A, κ, n) = Prh e(g, g)

1

s ← A(1κ, P, T )i = neg(κ)

3 Collision-Resistant Hashing with Common-Preﬁx Proofs

Standard collision-resistant hash functions have the property of compressing possibly large inputs strings
to small ones. In practice, hash functions are considered injective due to the collision-resistance property.
This makes them useful constructs to manipulate shorter strings without loosing much security. In that
context, proving some relations or predicates on pre-images using only the corresponding hash values
(and perhaps an additional short proof) is certainly very useful. For example, given two hash values
H(A), H(B), proving eﬃciently predicates like |A − B| ≥ 10 or A ≺ B may help to simplify some
protocols or make them more eﬃcient.
With the above goal in mind, in this paper we consider the common preﬁx predicate for strings,
CommonPrefix: given A, B ∈ Σn, CommonPrefix(A, B, i) = true if and only if A and B share a common
preﬁx up to position i. We seek collision-resistant hash function families H with the following property:
given H(A) and H(B) where A and B share a common preﬁx until position i, it should be possible to
produce a certiﬁcate π such that running some veriﬁcation algorithm on inputs i, π, H(A), H(B) one can
be convinced that CommonPrefix(A, B, i) = true. Any such scheme should be secure in the sense that if
CommonPrefix(A, B, i) = f alse then producing a forged π∗ that makes the veriﬁcation algorithm accept
should be computationally infeasible. Clearly, there exists a trivial instantiation of this primitive: just
consider H a standard (collision-resistant) hash function and π = (A, B). Of course, this is not really
useful as the size of the certiﬁcate is proportional to the size of the longest string. Thus, interesting
implementations should have short certiﬁcates. Additionally, we want hash function H to be easily
updatable: given H(A) one should be able to compute H(A||σ), without knowing A (this concept is also
known as incremental hashing [1]).
Given a CommonPrefix predicate we can now implement more interesting predicates over strings such
as Compare, where Compare(A, B) = true if A ≺ B: If A ≺ B it follows that there exists a (possibly

5

empty) common preﬁx C for A and B, such that (1) C||σ is a preﬁx of A, (2) C||σ′ is a preﬁx of B, and
(3) σ < σ′. In summary, once we know how to do proofs for Prefix, we can compare any two strings
only using their hash values and a short proof.
Collision-Resistant Hashing with common-prefix proofs (CRHwCP P ). Let κ ∈ {0, 1}∗ be the
security parameter, P K ∈ {0, 1}κ some public key, and n ∈ N a bound on the size of the input which is
a polynomial in κ. We denote by H = {HP K,n,κ} a hash function family.
Deﬁnition 4. (Collision-Resistant Hashing with common-preﬁx proofs - Syntax) A function family H of
collision-resistant hashing with common-preﬁx proofs (CRHwCP P ) is deﬁned by the tuple of algorithms
(PHGen, PHEval, PHProofGen, PHCheck) where:

• PHGen(1κ, n): given a bound n on the length of the strings to hash, this probabilistic algorithm
returns a public parameter P K. Value P K implicitly deﬁnes a hash function H = HP K,n,κ ∈ H
where H : {0, 1}n → {0, 1}κ.

• PHEval(M, P K): given M ∈ {0, 1}n, this deterministic algorithm returns a string H(M ) ∈ {0, 1}κ.
• PHProofGen(A, B, i, P K): given two messages A, B ∈ {0, 1}n, and an index 1 ≤ i ≤ n, this
deterministic algorithm computes a proof π ∈ {0, 1}κ that will be used by the PHCheck algorithm.
• PHCheck(HA, HB, π, i, P K): a deterministic algorithm that, given HA, HB ∈ {0, 1}κ, two hash

values, and a proof π ∈ {0, 1}κ, returns either valid or ⊥.

The scheme is said to be correct if for any strings A, B and i ∈ N such that CommonPrefix(A, B, i) =
true, and π = PHProofGen(A, B, i, P K), we have that PHCheck on inputs (H(A), H(B), π, i, P K) returns
valid.

The notion of security is also rather natural: for any PPT adversary A it should be diﬃcult to compute
two n-bit strings A, B, an index i ∈ {1, . . . , n}, and a proof π ∈ {0, 1}κ such that PHCheck(H(A), H(B),
π, i, P K) returns valid but A[1..i] 6= B[1..i]. Note that the adversary is required to output pre-images A
and B to win, which assures that the hash values H(A) and H(B) have been correctly computed.

Deﬁnition 5. (Collision-Resistant Hashing with Common-Preﬁx Proofs - Security) Let H be a family of
collision-resistant hash functions with common-preﬁx proofs and A a PPT adversary. The CRHwCP P
advantage of A is

AdvCRHwCP P

H

(A, κ, n) = P r


P K ← PHGen(1κ, n); A, B, π, i ← A(1κ, n, P K) :
A[1..i] 6= B[1..i] ∧ HA = H(A) ∧ HB = H(B)∧

PHCheck(HA, HB, π, i, P K) = valid




We say H is a secure preﬁx collision resistant hash function family if for every PPT A, we have
AdvCRHwCP P

H

(A, κ, n) = neg(κ).

The following proposition shows that collision resistance hashing with common-preﬁx proofs imply

(standard) collision resistance. We omit the proof.

Proposition 1. Let H be a family of collision-resistant hashing with common-preﬁx proofs. Then H is
a collision-resistant hash function family (in the standard sense).

The Construction. We assume that the description of the hash function H - which is the tuple (gs, gs2
,
..., gsn
) of the n− BDHI problem - has been computed securely by a trusted third party or using multiparty 
computations techniques. The idea is to represent a binary string M by H(M ) def= gM[1]s·gM[2]s2
···
gM[n]sn
H(M ′) will be

. Now if some message M ′ is equal to M up to position i then the value ∆ = H(M)

6

a product of gsj
j=i+1 gcjsj
j=i+1 gcjsj−(i+1)

factors for 1 ≤ j ≤ n where for all j ≤ i the exponents are equal to 0. Hence,
∆ = Qn
where cj ∈ {−1, 0, 1}. So with the knowledge of M ,M ′ and H we can compute a proof
π = Qn
. The intuition behind this is that as M and M ′ are equal up to position i then
we can represent the diﬀerence of M and M ′ using only n − i positions. Verifying that proof π is valid
then consists in using the bilinear map to “shift forward” the exponents in the proof by i positions, in
order to get back the value H(M )/H(M ′). More precisely, π will be a valid proof for H(M ), H(M ′) if
and only if e( H(M)

). Details follow.

H(M ′) , g) = e(π, gsi+1

Construction 1. (Collision-Resistant Hashing with Common-Preﬁx Proofs - Construction) Let PH be
the scheme deﬁned by the following algorithms:

).

Return H(M ).

Return P K = (P, T ).

• PHGen(1κ, n): run BMGen(1κ) to obtain P = (p, G, GT , e, g). Let s R← Zp, and T = (g, gs, gs2
• PHEval(M, P K): M ∈ {0, 1}n. Compute H(M ) = Qn
• PHProofGen(A, B, i, P K): given n-bits strings A, B, let C be the array such that ∀j ∈ {1, . . . , n} :
C[j] = A[j] − B[j]. Return π = Qn
• PHCheck(HA, HB, π, i, P K): compute ∆ = HA
return ⊥.

where bj = M [j] for j ∈ {1, . . . , n}.

, then return valid if e(∆, g) = e(π, gsi+1

j=i+1 gC[j]sj−(i+1)

j=1 gbj sj

), otherwise

, ..., gsn

HB

.

Proposition 2. Under the n-BDHI assumption the hash functions family deﬁned by the scheme PH is
a secure CRHwCP P .
Proof. Given an adversary A that breaks the security of PH, we construct an adversary B that breaks
the n − BDHI assumption as follows. Once B receives as input the parameters (P, T ) where T =
(g, gs, gs2
PHCheck(H(A), H(B), π, i, P K) = valid, that is,

), it forwards them to A. Eventually, A will output values A, B, π, i such that

, . . . , gsn

(1)
Then, B computes the array C deﬁned as C[j] = A[j]−B[j] = cj for j ∈ {1, . . . , n}. Since A[1..i] 6= B[1..i],
let k < i, be the smallest index such that ck 6= 0. Clearly i − k > 0. From (1) it follows that π = ∆
si+1 ,
and then:

)

1

e(∆, g) = e(π, gsi+1

E = e(π, gsi−k

) = e(∆

1

si+1 , gsi−k

)

= Qn

j=k e(g, g)cjsj−k−1

ck

= e(g, g)
= e(g, g)

j=k+1 e(g, g)cjsj−k−1

s Qn
ck
s D
As all the cj are known, and ck = ±1, B can compute ( E
D )1/ck = e(g, g)
Additional properties. Our construction for CRHwCP P functions family H is homomorphic in the
following sense: for any H ∈ H, any bit b, H(M||b) = H(M ) · H(0|M|||b). Moreover, since H(0|M|||b) =
gbs|M |+1
can be computed in constant time w.r.t |M|, our construction yields in fact to an incremental
hash function [1]. Furthermore, its computation can be easily parallelizable as obtaining a proof only
involves group multiplications. In particular, with O(n) processors, we can compute a proof using only
O(log n) (sequential) group multiplications. Finally note that, handling strings of length m > n can be
done dynamically, without having to recompute any proof, by simply extending the public parameter T =
(g, gs, gs2
) say by invoking the distributed procedure (or calling the trusted generator) to compute
gsn+1
. Finally, let Σ be a non binary alphabet with an eﬃcient mapping to Zp. We observe that

, . . . , gsm

, . . . , gsn

1
s .

we can adapt our construction to handle such alphabets by deﬁning H as H(S) = Q|S|

i=1 gS[i]si

.

7

4 Short Transitive Signature for Directed Trees

Our construction for DTTS is based on the following idea: handling a growing tree can be reduced
to maintaining two ordered sequences, one corresponding to the pre-order traversal and another to the
post-order traversal in a depth ﬁrst search. This was ﬁrst observed by Dietz [8].
Proposition 3. ([8]) Let T be a tree and consider a depth-ﬁrst traversal. Let Pre and Post be the strings
formed by the nodes that are visited in pre-order and post-order respectively, then for any pair of nodes
a, b in T , b is descendant of a if and only if ∃i, j : 0 < i < j and ∃i′, j′ : 0 < j′ < i′ such that:

(Pre[i] = a ∧ Pre[j] = b) ∧ (Post[i′] = a ∧ Post[j′] = b)

For example if we look at the last tree in the ﬁrst column of ﬁgure 1, we get Pre = acdbe and
Post = dcbea. We can check that as there is a path from c to d, c appears before d in Pre and D appears
before c in Post. Also note that if there is no path between two nodes x and y (recall that the tree is
directed from top to bottom) then y may appear before x in Pre or x may appear before y in Post. See
for example pairs (c, b), (e, d) or (b, a).

The challenge to use this result is that the ordered sequences are dynamic (new elements can be
inserted between any two existent elements). Such problem is addressed by the so called order data
structure [8, 15]. In such a data structure we want to compare any pair of elements and also compute a
new element such that it lies between two existing ones. A naive way - as mentioned in [8] - to implement
the proposed data structure, would be to consider the interval [0..2n − 1] for the indexes; to insert an
element between X and Y one would use index ⌊ X+Y
⌋. This way we can always ﬁnd an element between
two others and the comparison algorithm consists in comparing the numbers. Unfortunately, in this
case the Signer would have to handle indexes of length n for each new edge to sign, because the string
representation of the new index cannot be easily obtained from already computed values. So our ﬁrst
improvement is a way to design the order data structure such that, if we want to insert an element
between X and Y , the new resulting string for index Z (where X < Z < Y ) will share all bits except one
with the string representing X or or the one representing Y .

2

Before describing our construction we introduce the formal deﬁnition of an order data structure [15].

Deﬁnition 6. Let U be a totally ordered set. An order data structure consists of three algorithms:

• ODSetup() : initializes the data structure.
• ODInsert(X, Y ) : compute an element Z that will lie between the two consecutive elements X, Y ∈ U.
• ODCompare(X, Y ): returns true if X precedes Y in the total order.
Our data structure uses a binary search tree [13] to insert elements. Then comparing two elements in
the data structure reduces to ﬁnding their lowest common ancestor c and checking whether one of them is
descendant of c’s left child or whether one element is an ancestor of the other. The values (strings) from
the total order correspond to the path from the root to a node in this tree, where each edge is labelled
by 0 (left child) or 1 (right child).

Construction 2. . Let OrderDS be the data structure deﬁned by the following operations.

• ODSetup(): create a tree with two nodes, a root −∞ and its right child ∞. The label of the root is
ǫ and the label of the right child is 1. Intuitively −∞ represents the lowest element of the universe
and ∞ the greatest.

• ODInsert(X, Y ) : let X, Y be to consecutive elements, i.e.

in particular X ≺ Y . Search node(X)
and node(Y ) in the tree. If node(Y ) belongs to the right sub-tree of node(X) then add node(Z) as
the left child of node(Y ). If node(X) belongs to the left sub-tree of node(Y ) then add node(Z) as
the right child of node(X). Return Z||$, the label of node(Z) concatenated with the end marker $.

8

• ODCompare(X, Y ) : If X or Y does not end with $ return f alse. If X = Y return f alse. Obtain
the index i such that C is the maximum common preﬁx of X and Y . If X[i + 1] < Y [i + 1], return
true else return f alse.

We observe that in the worst case the largest path of the tree may be of size n + 1, and thus the
largest label will contain n + 1 = O(n) bits. Note that now the elements X, Y, Z are strings and not
integers as in the naive order data-structure. This order data-structure has an important property: for a
pair of consecutive elements (strings) X, Y the string Z returned by ODInsert(X, Y ) is equal to X||b or
Y ||b where b ∈ {0, 1}. This turns out to be crucial as these strings will be hashed using a hash function
with common-preﬁx proofs H, introduced in the previous section. As a consequence of the homomorphic
property of H it will require only a constant number of cryptographic operations in order to compute
H(Z) from H(X) or H(Y ). We remark that as we append the symbol $ at the end of all strings (i.e. we
consider the alphabet Σ = {0, 1, $} where 0 < $ < 1 and $ is the end of string marker), ODCompare(X, Y )
consists simply in comparing the strings X,Y w.r.t. the lexicographic order.

Basic Construction. Our ﬁrst construction is based only on standard digital signatures – as Neven’s
construction – but where the size of each path signature is O(n) bits instead of O(n log n) bits. The
construction works as follows. Each time an edge (and thus a vertex) is added to the tree T the pre/postorder 
lists are updated with the new vertex label. We also update two order data-structures, one for the
pre-order and one for the post-order list. More precisely, to each vertex label v we associate a value αv
(resp. βv) computed by the order data-structure for pre-order (resp. post-order) such that if v appears
before some w in Pre (resp. Post) then ODCompare(αv, αw) = true (resp. ODCompare(βv, βw) = true).

Construction 3. (DT T S from Standard Digital Signatures) Let SSig = (SKG, SSig, SVf) be a standard
digital signature scheme, and let BasicDTTS be the scheme consisting of the following algorithms.

• TSKG(1κ) : use the SKG to generate a pair of keys (sk, pk). Set tsk = sk and tpk = pk. Initialize
two order data structures OrderDSPre and OrderDSPost that will be used to maintain the sequence
for pre-order and post-order traversal respectively. Return (tsk, tpk).

• TSign(tsk, a, b) :

– Add the vertex a or b to the graph if it does not exists. Let v (either a or b) be the vertex that

was inserted.

– Update OrderDSPre, OrderDSPost data structures to reﬂect the pre-order and post-order traversal
sequence of the new tree:
let xPre and yPre be the elements in Pre such that v comes just
after xPre and lies just before yPre. Compute using OrderDSPre the label αv (that is we have
αx ≺ αv ≺ αy). Do the same for the post-order list Post and obtain βv.

– Sign using tsk the message Mv = v||αv||βv. We obtain the signature σv = SSig(tsk, Mv).
– Return τ(a,b) = (Ma, σa, Mb, σb).

• TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk): parse τ(a,b) as (Ma, σa, Mb, σb) and τ(b,c) as (Mb, σb, Mc, σc).

Return τ(a,c) = (Ma, σa, Mc, σc).

• TSVf((a, b), τ, tpk) : parse τ as (Ma, σb, Ma, σb). Verify the signatures; if any of them is invalid or
Ma (resp. Mb) is not of the form a||αa||βa (resp. b||αb||βb) then return ⊥. If not, extract from
Ma, Mb the values αa, βa, αb, βb. Verify that αa ≺ αb and βb ≺ βa, using the algorithm ODCompare.
If the veriﬁcation succeeds return valid else return ⊥.

Theorem 1. If SSig is a secure digital signature scheme under chosen message attack, then BasicDTTS
a is secure transitive signature scheme for directed trees where (a) the size of path signature is O(n) bits,
(b) the Signer generates an edge signature in time O(n/κ), and (c) the time to compute a path signature
for the Combiner is O(1).

9

Proof. Direct from proposition 3.

Combining the basic construction and collision-resistant hashing with common-preﬁx proofs we can
shrink the size of a path signature to O(κ) bits (see theorem 3 in appendix A.1). Using the trade oﬀ
technique introduced in appendix B for our hashing family we obtain the following result. (The full
construction with trade oﬀ is outlined in section A.2.)

Theorem 2. Let λ ≥ 1. If SSig is a secure digital signature scheme under chosen message attack and
H is a family of secure collision-resistant hash functions with common-preﬁx proofs, then PHDTTS with
trade oﬀ is a secure DT T S scheme and (a) the size of the signature of an edge is O(λκ) bits, (b) the
Signer has to perform O(λ) cryptographic operations (O(λ) hash computations and O(1) signature) per
edge insertion, (c) the Veriﬁer can check that there is a path between two nodes in time O(λ), and (d)
the Combiner requires O(λn1/λ) time to compute a path signature.

5 Conclusion and further work

In this work we introduced a new primitive collision resistant hashing with common-preﬁx proofs and
showed it could be used to obtain eﬃcient transitive signatures for directed trees. We recall however that
the general problem of building transitive signatures for directed graphs remains open, as the problem of
building stateless DT T S. We believe that our new hashing primitive may ﬁnd many useful applications
in particular in the design of authenticated data structures.

References

[1] Mihir Bellare, Oded Goldreich, and Shaﬁ Goldwasser.

Incremental Cryptography: The Case of
In Yvo G. Desmedt, editor, CRYPTO 1994, volume 839 of LNCS, pages

Hashing and Signing.
216–233–233. Springer-Verlag, July 1994.

[2] Mihir Bellare and Gregory Neven. Transitive Signatures: New Schemes and Proofs. IEEE Transactions 
on Information Theory, 51(6):2133–2151, June 2005.

[3] Dan Boneh and Xavier Boyen. Eﬃcient Selective-ID Secure Identity-Based Encryption Without
Random Oracles. In Christian Cachin and Jan L. Camenisch, editors, EUROCRYPT 2004, volume
3027 of LNCS, pages 223–238. Springer Berlin / Heidelberg, 2004.

[4] Dan Boneh, David Freeman, Jonathan Katz, and Brent Waters. Signing a Linear Subspace: Signature 
Schemes for Network Coding. In Stanisaw Jarecki and Gene Tsudik, editors, PKC 2009, volume
5443 of LNCS, pages 68–87–87. Springer / Berlin Heidelberg, 2009.

[5] Dan Boneh and David Mandell Freeman. Homomorphic Signatures for Polynomial Functions, 2010.

[6] Jan Camenisch, Markulf Kohlweiss, and Claudio Soriente. An Accumulator Based on Bilinear Maps
and Eﬃcient Revocation for Anonymous Credentials. In Stanisaw Jarecki and Gene Tsudik, editors,
PKC 2009, volume 5443 of Irvine, pages 481–500. Springer Berlin / Heidelberg, 2009.

[7] Jan Camenisch and Anna Lysyanskaya. Dynamic Accumulators and Application to Eﬃcient Revocation 
of Anonymous Credentials. In Moti Yung, editor, CRYPTO 2002, volume 2442 of LNCS,
pages 61–76. Springer-Verlag, 2002.

[8] Paul F. Dietz. Maintaining order in a linked list. In STOC 1982, pages 122–127. ACM Press, May

1982.

10

[9] Shaﬁ Goldwasser, Silvio Micali, and Ronald L. Rivest. A Digital Signature Scheme Secure Against

Adaptive Chosen-Message Attacks. SIAM Journal on Computing, 17(2):281, April 1988.

[10] Michael T. Goodrich, Roberto Tamassia, and Jasminka Hasic. An Eﬃcient Dynamic and Distributed
Cryptographic Accumulator. In ISC ’02 Proceedings of the 5th International Conference on Information 
Security, pages 372–388, September 2002.

[11] Susan Hohenberger.

The Cryptographic

Impact of Groups with Infeasible

Inversion.

http://groups.csail.mit.edu/cis/theses/hohenberger-masters.ps, 2003.

[12] Robert Johnson, David Molnar, Dawn Xiaodong Song, and David Wagner. Homomorphic Signature
Schemes. In Bart Preneel, editor, CT-RSA 2002, CT-RSA ’02, pages 244–262. Springer-Verlag, 2002.

[13] Donald Knuth. The Art of Computer Programming, Volume 3: Sorting and Searching. AddisonWesley,
 third edition, 1997.

[14] Silvio Micali and Ronald Rivest. Transitive Signature Schemes. In Bart Preneel, editor, CT-RSA

2002, volume 2271 of LNCS, pages 236–243. Springer / Berlin Heidelberg, February 2002.

[15] Rolf M¨ohring, Rajeev Raman, Michael Bender, Richard Cole, Erik Demaine, Martin Farach-Colton,
and Jack Zito. Two Simpliﬁed Algorithms for Maintaining Order in a List. Algorithms - ESA 2002,
2461:219–223–223, August 2002.

[16] Gregory Neven. A simple transitive signature scheme for directed trees. Theoretical Computer

Science, 396(1-3):277–282, May 2008.

[17] Lan Nguyen. Accumulators from Bilinear Pairings and Applications.

In Alfred Menezes, editor,
Topics in Cryptology CT-RSA 2005, volume 3376 of Lecture Notes in Computer Science, pages
275–292–292, Berlin, Heidelberg, 2005. Springer Berlin Heidelberg.

[18] Siamak Fayyaz Shahandashti, Mahmoud Salmasizadeh, and Javad Mohajeri. A Provably Secure
Short Transitive Signature Scheme from Bilinear Group Pairs. In Carlo Blundo and Stelvio Cimato,
editors, Security in Communication Networks, volume 3352 of LNCS, pages 60–76. Springer / Berlin
Heidelberg, 2005.

[19] Xun Yi. Directed Transitive Signature Scheme. In Masayuki Abe, editor, CT-RSA, volume 4377 of

LNCS, pages 129–144. Springer Berlin / Heidelberg, 2007.

A Full construction for DT T S with Hashing with CommonPreﬁx 
Proofs.

A.1 Full construction (without trade oﬀ)
We extend our basic construction as follows. Using the same alphabet Σ = {0, $, 1} where 0 < $ < 1,
the string comparison is now done through their hash values and corresponding proofs provided by the
scheme PH. That is, in order to prove that two strings (that correspond to paths in the order data
structures) X, Y are such that X ≺ Y through their hashes H(X), H(Y ) the Combiner must compute:
• A maximum common preﬁx C of X and Y . E.g.: (X = 10001$, Y = 1001$, C = 100) or (X =

10001$, Y=100011$, C = 1000). Note that C will never contain the symbol $.

• A proof that C is a preﬁx of X up to position i = |C|.

11

Step

Tree T

0

1

2

3

4

5

Pre/Post

order

traversal

Pre = ǫ
Post = ǫ

Pre = a
Post = a

Pre = ab
Post = ba

Pre = acb
Post = cba

Pre = acdb
Post = dcba

ǫ

a

ǫ

ǫ

a

ǫ

b

a

c

b

a

b

c

d

a

b

e

c

d

Pre = acdbe
Post = dcbea

OrderDSPre

OrderDSPost

Labels

α−∞ = $
α∞ = 1$
β−∞ = $
β∞ = 1
αa = 10$
βa = 10$

αb = 101$
βb = 100$

αc = 1010$
βc = 1000$

αd = 10101$
βd = 10000$

αe = 1011$
βe = 1001$

−∞

ǫ ∞

−∞

ǫ ∞

−∞

ǫ

∞

a

ǫ

−∞

−∞

ǫ

∞

a

ǫ

−∞

ǫ

∞

ǫ

∞

a

ǫ

a

ǫ

ǫ

b

−∞

b

ǫ

−∞

ǫ

∞

ǫ

∞

a

ǫ

a

ǫ

ǫ

b

c

ǫ

−∞

b

ǫ

c

ǫ

−∞

ǫ

ǫ

∞

ǫ

∞

a

ǫ

a

ǫ

ǫ

b

c

ǫ

ǫ

d

b

ǫ

c

ǫ

d

ǫ

−∞

−∞

∞

ǫ

∞

a

ǫ

a

ǫ

ǫ

b

c

e

ǫ

d

b

ǫ

c

e

d

ǫ

Figure 1: Example of several insertions in a directed tree and their eﬀect on the order data structures.
Step 0: The tree T to authenticate has no nodes. The sequences Pre and Post are empty as well. The order data
structure OrderDSPre and OrderDSPost contain two nodes −∞ and ∞ that are the bounds of the ordered universe.
Each edge is marked implicitly by 0 (for a left child) and 1 (for a right child).
Step 1: The ﬁrst node a of T is created. The pre/post-order lists contain only a. The order data structures are
updated in such a way they reﬂect the order −∞ ≺ a ≺ ∞. In particular we have that labels αa = βa = 10$.
The end marker $ is appended so it allows direct order label comparison through lexicographical order using that
0 < $ < 1.
Step 2: A child b is added to a. Now the pre-order sequence Pre is equal to ab and the post-order sequence is
ba. As b comes after a in Pre we have that b is the right child of a in OrderDSPre. Similarly b is the left child of a
in OrderDSPost as it comes before a in Post.
Step 3,4 and 5: We follow the same procedure and obtain for each node v its order labels αv and βv respectively.
Comparing two node labels: In step 5 we can check easily using the order labels that for example d is a
descendant of a. Indeed we have αa = 10$ and αd = 10101$ which means αa ≺ αd. Also we can check that βd =
10000$ ≺ βa = 10$. We can also observe that there is no path from b to c for example as αc = 1010$ ≺ αb = 101$
and also βc = 1000 ≺ βb = 100$.

12

• A proof that C is a preﬁx of Y up to position i = |C|.
• A proof that H(C||x) is a preﬁx of X up to position i + 1.
• A proof that H(C||y) is a preﬁx of Y up to position i + 1.

Verifying that X ≺ Y will then consists basically in checking the proofs and also verifying that x < y.
Construction 4. (DT T S from CRHwCP P )

Let PH = (PHGen, PHEval, PHProofGen, PHCheck) be a preﬁx collision-resistant hash function family,

and let PHDTTS be the scheme consistent of the following algorithms.

• TSKG(1κ) :

First, generate the public parameters for the PH scheme as well as a pair of private/public keys
(sk, pk) for the Signer running SKG. Set tsk = sk and tpk = tk. Initialize two order data structures
OrderDSPre and OrderDSPost. Return (tsk, tpk).

• TSign(tsk, a, b) :

Do the same as in BasicDTTS except that the message to be signed is now Mv = v||Hαv||Hβv , where
Hαv = H(αv) and Hβv = H(βv). Note that H(αv), H(βv) can be computed incrementally due to
the fact that H is homomorphic and that the labels αv (resp. βv), have been computed previously.

• TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk):

If τ(a,b) or τ(b,c) is invalid, then reject. To compute the signature of the edge (a, c) the Combiner
proceeds as follows. Find the lowest common ancestor in OrderDSPre for node(αa) and node(αc).
Denote it node(α′
d is a string without the terminating symbol $ but such that
H(αd) = H(α′||$) is part of an already signed message Md = d||H(αd)||H(βd). Let σd be the
signature of Md. We have that αd is the maximum common preﬁx of αa and αc. Let l = |αd|.
Compute the following values:

d). Note that α′

– π1 = PHProofGen(α′
– π2 = PHProofGen(α′
– π3 = PHProofGen(α′
– π4 = PHProofGen(α′

d, αa, l − 1, P K)
d, αc, l − 1, P K)
d||x, αa, l, P K)
d||y, αc, l, P K)

where (x, y) may be the pair of symbols (0, $) or (0, 1) or ($, 1). (Recall that 0 < $ < 1 and that all
strings are ended by $.) Finally obtain π5 = (Ma, σa, Mc, σc, Hα′
d).
Set πPre = (π1, π2, π3, π4, π5).
Compute similarly πPost and return τ(a,c) = (πPre, πPost).

, σd, l, x, y) where Hα′

= H(α′

d

d

• TSVf((a, b), τ, tpk) :

Extract πPre from τ = (πPre, πPost). Parse πPre as (π1, π2, π3, π4, π5).
, l, x, y) where Mv = v||Hαv||Hβv for v ∈ {a, c, d}. Check
Parse π5 as (Ma, σa, Mc, σc, Md, σd, Hα′
d · H(0l||$) =
that all the pairs of message-signatures are valid under public key tpk. Check that Hα′
Hαd the second component of Md. Check that x and y are symbols. If one of the veriﬁcation fails
return ⊥. Verify proofs π1, π2, π3, π4 using PHCheck, namely compute:

d

– PHCheck(Hα′
– PHCheck(Hα′

– PHCheck(Hα′

– PHCheck(Hα′

d

d

, Hαa, π1, l − 1, P K)
, Hαb , π2, l − 1, P K)
d · H(0l−1||x), Hαa , π3, l, P K)
d · H(0l−1||y)), Hαb , π4, l, P K)

13

If all these veriﬁcations pass return valid otherwise return ⊥.

Theorem 3. If SSig is a secure digital signature scheme under chosen message attack and H is a family
of secure collision-resistant hash function with common-preﬁx proofs, then PHDTTS is a secure DT T S
scheme where (a) the size of the signature is O(κ) bits, (b) the Signer generates an edge signature in
O(1) time, and (c) the time to compute a path signature for the Combiner is O(n).
Proof. Let A a PPT adversary that breaks our scheme. We build an adversary B that breaks the security
of SSig or PH. B has access to a signing oracle OSSig(·) and is given the description of the preﬁx hash
function H as described in construction 1. B forwards all the public parameters to A. A asks for edges
signing to B who replies using the signing oracle OSSig(·) and H. Finally A outputs a signature τ such
that TSVf((a, b), τ, tpk) = valid and there is no path from a to b in T . We ﬁrst consider the case where
signed messages Ma, Mb do not all correspond to edges insertion in T . This means that B has been able
to compute some signature for a message M ′ not previously requested to the oracle OSSig. So now we
assume that all signed messages reﬂects the history of edges insertions in the tree.
Let αa, αb and βa, βb be the order labels associated to vertices a, b in OrderDSPre and OrderDSPost
respectively. As there is no path from a to b, this means that (i) a appears before b in Pre and also a
appears before b in Post or (ii) b appears before a in Pre and also b appears before a in Post or (iii)
there is a path, but from b to a. Assume we are in case (i), and note that cases (ii) and (iii) are similar.
If indeed a appears before b in Pre then the adversary A managed to prove that b appears before a in
Post although the contrary is true. This means in particular that π1, π2, π3, π4 prove that there exists a
string C such that C||x is a preﬁx of βb and C||y is a preﬁx of βa and x < y. It is worth noting that,
although the proofs π1, π2, π3, π4 do not mention explicitly the strings tied to the nodes (only hash values
and lengths), these strings are present in the data structures OrderDSPre and OrderDSPost. If some hash
value is linked to two diﬀerent pre-images then B has found a collision for H. In particular this means
that B knows C. Now, as indeed βa ≺ βb, there exists no such string C, so this means that either C||x
is not a preﬁx of βa or C||y is not a preﬁx of βb, therefore B has been able to break the security of the
scheme PH.

A.2 Sketch of the full construction with trade oﬀ

Pre, a new binary search tree. We store in the node of OrderDS0

We sketch here the construction. We use a pair of order data structures for each level in the following way.
Consider the case of OrderDSPre (the case OrderDSPost can be treated similarly.) At level 0 we have the
label α that is a path in the binary search tree of OrderDS0
Pre. When a path and its associated label α of
OrderDS0
Pre becomes larger than n1/λκ then we compute H(α0) (where α0 is the n1/λκ bits long preﬁx of
α) and insert this new string in OrderDS1
Pre
with label α0 the pointer to the node of OrderDS1
Pre with label H(α0). Then if the length of the label
α continues to grow until reaching length 2n1/λκ and label α = α0||α1, we compute H(α1) and insert
this string in OrderDS1
Pre starting from node with label H(α0). We follow the procedure for each chunk
of size n1/λκ, always inserting the new string in OrderDS1
Pre to
grow. We apply the same procedure to OrderDS1
Pre as described above.
We can follow this mechanics until reaching the tree OrderDSλ−1
Pre of maximal height n1/λκ. We observe
that in each tree the common ancestor between two nodes N1, N2 will be at maximum distance n1/λκ
from both nodes. This means that computing the proof for the PH will take time O(n1/λ). The Signer
will have to compute himself the hash values for all levels but only has to sign the ﬁnal string of the last
level, so the time to compute a signature is O(λ). Finally signature for any path is O(λκ) bits long.

Pre. This process causes the tree OrderDS1

Pre by creating the tree OrderDS2

B Proof Generation and Veriﬁcation Tradeoﬀ

First, we can see that a simple optimization can be made to our scheme:
instead of working with the
binary alphabet Σ = {0, 1} it is possible to encode the string S using Σ = {0, 1, ..., 2κ − 1} and thus

14

Figure 2: Toy example of trade oﬀ data structure.

In this example, let n = 54, λ = 3, κ = 2 and the alphabet Σ = {a, b, c, d}. We have t = (54/2)1/3 = 3.
R and S are two strings that share the same preﬁx T until position i = i0 = 17 · 2 = 34. We start at
level 2. The Combiner shows that R2 and S2 are equal up to the position i2 = 1. Then he also proves
that da is a preﬁx of R2 and db is a preﬁx of S2. This means we need to ﬁnd the common preﬁx of
strings H −1(a) = cba and H −1(b) = cbc. So we move up to level 1. Now the Combiner, using H −1(a)
and H −1(b), shows that R1 and S1 share a common j1-symbol preﬁx up the relative position j1 = 2.
This means that i1 = 1 · 3 + 2 = i2 · t + j1 = 5. We move at the level 0. The Combiner then shows that
a,c are the symbols that come just after T 1 in R1 and S1 respectively. Now using H −1(a) = 001011 and
H −1(c) = 001010 the Combiner shows that R0 = R and S0 = S share a common preﬁx T 0 = T up to
the relative position j0 = 2. This means that i = i0 = 34 = (5 · 3 + 2) · 2 = (i1 · t + j0)κ.
compute H(S) = Qn/κ

where ∀i : 1 ≤ i ≤ n/κ, σi ∈ {0, 1, ..., 2κ − 1}. This observation reduces
κ ) 2. Although

the number of cryptographic operations1 required to compute a proof from O(n) to O( n
simple, this observation is crucial for the following.

i=1 gσisi

We now show how to balance the computational work between the Combiner – who generates the
hashes and the proofs – and the Veriﬁer – who checks the proofs – as follows. We obtain a CRHwCP P
scheme such that, for any λ ≥ 1, the time it takes to compute a proof is reduced to O(λn1/λ) while the
time it takes to generate a signature or verify a proof is now O(λ). Let t > 0, and S = S0 be the n-bit
string (and thus n
κ is a power of t. In order
to compute H(S), we ﬁrst cut S in chunks of size tκ. For each chunk S0, S1, ..., Sn/(tκ)−1 we compute
the hash value H(Si) and obtain a new string S1 of size n
t bits. We repeat the same procedure
with the new string S1 and obtain a string S2 of size n
t2 bits. We follow the same algorithm until

κ symbols) to hash. Assume for clarity of the exposition that n

t2κ κ = n

tκ κ = n

log(n/κ)

reaching a string S

log t −1 with at most t symbols (i.e. tκ bits) which hash is the ﬁnal output.

To be more concrete, we set t = ( n

κ )1/λ so that the new data structure has λ levels. In order to prove
that the n-bit strings R and S have a i-bit common preﬁx we do the following. Let R0, R1, ..., Rλ−1 and
S0, S1, ..., Sλ−1 be the sequences of strings obtained by following the above hashing algorithm on input
R0 = R and S0 = S, where Rℓ (resp. Sℓ) is the string processed at level ℓ. We start at level λ− 1. At this
level there is only one chunk of size t = ( n
κ )1/λ (number of symbols). Using PHProofGen, the Combiner
computes a proof πλ−1 showing that Rλ−1 and Sλ−1 share a common preﬁx T λ−1 until position iλ−1.

1For the sake of clarity we do not describe the case where the alphabet contains the special symbol $. The asymptotic

eﬃciency remains the same however.

2The proof of security remains the same, except that the symbols lie in a larger alphabet.

15

Then the Combiner computes two additional proofs: one proof πλ−1,R, showing that T λ−1||σR,λ−1 is a
preﬁx of Rλ−1, and another one (say πλ−1,S), showing that T λ−1||σS,λ−1 is a preﬁx of Sλ−1. Notice that
since the Combiner has previously computed the hash values for each level, he knows the pre-images of
σR,λ−1 and σS,λ−1 under H: the tκ-bit long strings Rλ−2
iλ−1t = H −1(σR,λ−1) (that is the chunk number
iλ−1t of Rλ−2) and similarly Sλ−2
iλ−1t = H −1(σS,λ−1). The Combiner then moves up one level and repeats
the procedure at level λ − 2 now working on the strings H −1(σR,λ−1), H −1(σS,λ−1) and generating a
proof (say πλ−2) that they have some jλ−2-symbol common preﬁx. We can see that, up to this point, the
Combiner has proven that strings Rλ−2 and Sλ−2 share a common preﬁx of length iλ−2 = iλ−1t + jλ−2.
The procedure continues iteratively going up at the levels until it reaches level 0 (see example in ﬁgure
2) where i0 = (i1t + j0)κ. The total size of the proof is O(λκ) bits.

The veriﬁcation step at each level consists in verifying that (1) the proofs computed by the Combiner
are valid, and (2) for each two consecutive levels ℓ − 1 and ℓ the proofs for level ℓ are relative to the
pre-images H −1(σR,ℓ−1) and H −1(σS,ℓ−1). These considerations lead to the following result.

Theorem 4. Let λ ≥ 1. Under the n-BDHI assumption we can build a secure CRHwCP P function
family where (a) the time to compute a hash value is O(λ), (b) the time to compute a proof is O(λn1/λ),
and (c) the time to verify a proof is O(λ).

Proof. First we observe that the mapping between each level is a collision resistant hash function family.
Assume an adversary A manages to break the trade oﬀ scheme. Then we build an adversary B that
breaks the (simple) PH by computing a forged proof or ﬁnding a collision for H. Adversary B sends the
public parameters of the scheme to A who answers with a forgery for the trade oﬀ scheme. More precisely
A returns two strings R, S and valid proofs for each level that lead to the claim that R = R0 and S = S0
are equal up to position i although there exists some index k < i such that R[k] 6= S[k].
Let i = (i1 · t + j0)· κ the decomposition of i for the ﬁrst level. If (i1 · t)κ ≤ k < (i1 · t + j0)κ this means
that Ri1·t and Si1·t will not share a common preﬁx until relative position j1, thus B has found a forgery
i2·t[k′]
for PH. If k < i1 · t we are reduced to the case where k′ = (⌈k/κ⌉)− (i1 · t) is such that R1
as otherwise B would have found a collision for H. Now if i2 · t ≤ k′ < i2 · t + j1 then again, B has broken
the security of PH. If k′ < i2 · t, we need to analyse similarly the case for the next level. Eventually we
will reach a level where B manages to break the security of PH because k < i and the decomposition of i
in base t is unique.

i2·t[k′] 6= S1

C Short DTTS using Cryptographic Accumulators

We ﬁrst recall Neven’s signature scheme for directed trees.

Construction 5. (Neven’s scheme [16])

• TSKG(1κ) : returns a pair of private/public keys (tsk, tpk) for a standard digital signature scheme.
• TSign(tsk, a, b) : the state of the tree is maintained by its description as a graph G = (V, E), the
current root r and two tables up[·] and down[·] To sign a new edge we distinguish between the
following cases:

1. V = ∅:

2. a ∈ V and b /∈ V :

r ← a; V ← V ∪ {a, b}; E ← E ∪ {(a, b)}
up[a] = down[a] = down[b] ← ǫ; up[b] ← a

V ← V ∪ {b}; E ← E ∪ {(a, b)}
up[b] ← up[a]||a; down[b] ← ǫ

16

3. a /∈ V and b = r:

r ← a; V ← V ∪ {b}; E ← E ∪ {(a, b)}
up[a] ← ǫ; down[a] ← b||down[b]
rejects because the query does not preserve the tree structure of
In all other cases the Signer
sets Ca ← (i, down[i]) and Cj ← (j, up[j]), and computes two standard
the graph. The Signer
signatures σa = SSig(tsk, Ca) and σb ← SSig(tsk, Cb). The transitive signature for the edge (a, b)
is the tuple τ(a,b) ← (Ca, σa, Cj, σj).

• TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk): Parse τ(a,b) as (Ca, σa, Cb, σb) and τ(b,c) as (Cb′ , σb′ , Cc, σc).

If b 6= b′ reject else return the composed signature for edge (a, c) as τ(a,c) ← (Ca, σa, Cc, σc).

• TSVf((a, b), τ, tpk) : Parse τ as (Ca, σa, Cb, σb), and parse Ca as (a, down) and Cb as (b, up). If
SVf(tpk, σa) = ⊥ or SVf(tpk, σb) = ⊥ return ⊥. If b occurs in down or a occurs in up or there
exists some c that occurs both in down and up then return valid else return ⊥.

Cryptographic Accumulators. An accumulator is a scheme that enables to represent a set by a
short value called accumulated value. Then given an element it is possible to prove that this elements
belongs to the set by exhibiting a proof called witness. An accumulator is dynamic if it is possible to
update the set. Two kinds of participants are involved in an accumulator scheme: the Manager that
holds the set, updates it and computes all the related values, and the User that can test for membership
of a given element. The next deﬁnition introduces the functionalities involved in a dynamic accumulator.
In our context the Manager would be the Signer
and the User takes the role of the Veriﬁer. The
Combiner is also a User that only computes witnesses for the accumulator scheme (still without knowing
the trapdoor).

Deﬁnition 7. (Syntax for Dynamic Accumulator, [7])

Let κ ∈ N be the security parameter. An accumulator scheme Acc consists of the following algorithms.
• Setup(1κ): This probabilistic algorithm takes κ in unary as input and returns a pair of public and
private keys (P K, SK), and the initial accumulated value for the empty set Acc∅. This algorithm
is run by the Manager.

• AccVal(X, Acc∅, P K, [SK]): Given a ﬁnite set of elements X (of at most polynomial size in κ),
a public key P K and the initial accumulated value Acc∅, this algorithm returns the accumulated
value AccX corresponding to the set X. This algorithm is run by the Manager. Depending on the
implementation, the secret key SK may also be given as optional parameter, often to improve the
eﬃciency3.

• Verify(x, w, AccX , P K): given an element x, a witness w, an accumulated value AccX , and a public
key P K , this deterministic algorithm returns valid if the veriﬁcation is successful, meaning that
x ∈ X, or ⊥ otherwise. This algorithm is run by a User.

• WitGen(x, AccX , P K): this algorithm returns a witness w associated to the element x of the set X

represented by AccX . We consider the case where this algorithm is run by a User.

• AddEle(x, AccX , P K, [SK]): this algorithm computes the new accumulated value AccX∪{x} obtained

after the insertion of x into set X. This algorithm is run by the Manager.

• DelEle(x, AccX , P K, [SK]): this algorithm computes the new accumulated value AccX\{x} obtained
by removing the element x from the accumulated set X. This algorithm is run by the Manager. In
our application however we do not require it.

3The secret key may also be an optional parameter in the algorithms WitGen, AddEle, DelEle.

17

Naturally, we say the scheme is correct if every valid witness leads to a successful veriﬁcation.

Deﬁnition 8. (Correctness) Let X be a set and AccX its associated accumulated value, P K a public
key, SK the corresponding private key, and y ∈ Y . Let wy a value (witness) that satisﬁes wy ←
WitGen(y, AccY , P K, SK). We say that an accumulator scheme Acc is correct if and only if
Verify(y, wy, AccX , P K) = valid, for every such y, wy, X.

The security of an accumulator scheme is captured by an experiment where the adversary plays the
role of a User and attempts to forge a witness (i.e. ﬁnding a valid witness for an element that does
not belong to the set) while having access to an oracle that implements the operations relative to the
Manager. Such adversary must succeed with at most negligible probability on the security parameter.
This experiment is very similar to the one used to deﬁne the security of digital signatures.

Deﬁnition 9. (Security for Dynamic Accumulators, [7])

Let Acc be a dynamic accumulator scheme.
We consider the notion of security denoted UF -ACC described by the following experiment: on input
the security parameter κ, the adversary A has access to an oracle O(·) that replies to queries by playing
the role of the accumulator Manager. Using the oracle, the adversary can insert and delete a polynomial
number of elements of his choice. The oracle O(·) replies with the new accumulated value. The adversary
can also ask for witness computations or update information. Finally, the adversary is required to output
a pair (x, w).

The advantage of the adversary A is deﬁned by:

AdvU F-ACC

Acc

(A) = Pr [ Verify(x, w, AccX , P K) = valid ∧ x ∈ X ]

where P K is the public key generated by Setup, and AccX is the accumulated value of the resulting
accumulated set X. The scheme Acc is said to be secure if for every probabilistic polynomial time adversary
A we have:

AdvU F-ACC

Acc

(A) = neg(κ)

Short signatures for Neven’s scheme using Accumulators. The idea to shrink the size of edge
signatures for Neven’s scheme is simply to maintain an accumulator for each list up[·] and down[·]. The
accumulated values are signed using a standard signature scheme, and the Combiner
can convince a
Veriﬁer that a vertex belongs to some list by computing the appropriate witness. Using for example one
of the scheme introduced in [7, 17, 6] the edge signature will have constant size. Note that the accumulated
values are related in the following way: if y is a child of x then the Accy = AddEle(x, Accx, P K). This
means that instead of handling an accumulator for every node which would be costly, we only need to
compute the accumulated value on the ﬂy. Then to obtain a witness, the procedure consists in recollecting
the values on the path for lists down[·] or up[·].
We can also handle the trade oﬀ (λ, λn1/λ) using accumulators with the tree technique presented for
example in [10]. Here the idea is to maintain pointers to the previous node that enables to compute a
witness / accumulated value.

To the best of our knowledge there is no way to parallelize the computation of witnesses for the
RSA accumulator [7] or NGuyen’s accumulator [17]. The accumulator presented in [6] allows parallel
computation for witnesses but the maximal size of the tree must be known before the scheme is initialized.
To summarize, our solution based on hashing with common preﬁx proof is the ﬁrst one that (1) enables
the (λ, λn1/λ) trade oﬀ between the time to compute a path signature and to verify it, (2) allows the
parallelization of the computation of a path signature and (3) does not force the size of the tree to be
known beforehand.

18

