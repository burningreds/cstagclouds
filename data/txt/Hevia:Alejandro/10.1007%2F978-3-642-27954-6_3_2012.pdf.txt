Short Transitive Signatures for Directed Trees

Philippe Camacho and Alejandro Hevia

Dept. of Computer Science, University of Chile,
Blanco Encalada 2120, 3er piso, Santiago, Chile

{pcamacho,ahevia}@dcc.uchile.cl

Abstract. A transitive signature scheme allows us to sign a graph in
such a way that, given signatures on edges (a, b) and (b, c), it is possible 
to compute the signature on edge (a, c) without the signer’s secret.
Constructions for undirected graphs are known but the case of directed
graphs remains open. A ﬁrst solution for the particular case of directed
trees (DT T S) was given by Yi at CT-RSA 2007. In Yi’s construction,
the signature for an edge is O(n log(n log n)) bits long in the worst case
where n is the number of nodes. A year later in Theoretical Computer
Science 396, Neven proposed a simpler scheme where the signature size is
reduced to O(n log n) bits. Although this construction is more eﬃcient,
O(n log n)-bit long signatures still remain impractical for large n.
In this work, we propose a new DT T S scheme such that, for any value
λ ≥ 1 and security parameter κ: (a) edge signatures are only O(κλ) bits
long, (b) signing or verifying an edge signature requires O(λ) cryptographic 
operations, and (c) computing (without the secret key) an edge
signature in the transitive closure of the tree requires O(λn1/λ) cryptographic 
operations. To the best of our knowledge this is the ﬁrst construction 
with such a trade oﬀ.
Our construction relies on hashing with common-preﬁx proofs, a new
variant of collision resistance hashing. A family H provides hashing with
common-preﬁx proofs if for any H ∈ H, given two strings X and Y equal
up to position i, a prover can convince anyone that X[1..i] is a preﬁx of
Y by sending only H(X), H(Y ), and a small proof. We believe that this
new primitive will lead to other interesting applications.

Keywords: Transitive Signatures, Collision-Resistant Hashing.

1

Introduction

Transitive signatures is a primitive introduced by Micali and Rivest [14] where a
signer wants to authenticate a graph. The main property of such scheme is that,
given the signatures of edges (a, b) and (b, c), it is possible to compute - without
the knowledge of the secret - a signature for the edge (a, c). In their work, the
authors propose an eﬃcient scheme for undirected graphs based on the diﬃculty
of computing discrete logarithm for large groups. They left the existence of a
transitive signature scheme for directed graph (DT S) as a challenging open
question.

O. Dunkelman (Ed.): CT-RSA 2012, LNCS 7178, pp. 35–50, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012

36

P. Camacho and A. Hevia

n) computation.

The easier problem of transitive signatures for directed trees (DT T S) was
ﬁrst addressed by Yi [19]. Solutions for this case, even though it is a special
kind of directed graph, are still interesting in practice. For example they allow
to implement eﬃcient military chains of command where the presence of a path
between a and b means b must execute orders of a. Yi’s construction, based
on a special assumption for the RSA cryptosystem, yields signatures of size
O(n log(n log n)) bits, where n is the number of nodes of the tree. Neven [16]
described a simpler solution based only on the existence of standard digital
signatures which also reduces signature size to O(n log n) bits.
In this work, we describe a new construction for a DT T S scheme that enjoys
much better worst-case complexity. We obtain a scheme where, for any λ ≥ 1, (a)
signing or verifying an edge signature requires O(λ) cryptographic operations,
and (b) computing (without the secret key) an edge signature in the transitive
closure of the tree requires O(λn1/λ) cryptographic operations. Also, signature
size is substantially improved: our signatures are only O(κλ) bits, where κ is
the security parameter. In particular, if λ = log(n) then signatures are only
O(κ log(n)) bits, while allowing eﬃcient signature computation (O(log(n) time).
√
Alternatively, by setting for example λ = 2, we obtain optimal signature sizes of
O(2 · κ) = O(κ) bits if we are willing to aﬀord O(
Our Approach. There are two main ideas in our construction. First, we use
the following fact observed by Dietz [9]. Let Pre and Post be the two strings
representing the sequences of nodes obtained by pre-order and post-order (re-
spectively) traversal of a given tree T . Dietz observed that there exists a path
from a to b if and only if a appears before b in Pre and b appears before a
in Post. This property captures the fact that the tree is directed (from top to
bottom) and gives us a characterization of the existence of a path between two
nodes. Armed with this result, we reduce the problem of deciding whether there
is a path between vertices a and b to comparing the position of a and b in a
string sequence S. Doing this eﬃciently is not trivial as the tree can grow, which
means the string S dynamically changes. An order data structure – a concept
also introduced in [9] – does exactly what we need: it supports element insertions
into a sequence while still providing an eﬃcient method to decide element order.
Roughly speaking, we implement such data structure via a binary search tree
B, where each pair of elements x and y in S are associated to nodes x, y ∈ B
(respectively), each with eﬃciently computable short labels (cid:4)(x) and (cid:4)(y). We
then are able to deﬁne the relation “a appears before b in the sequence S” as a
total order relation ≺ which can be eﬃciently evaluated only from (cid:4)(a) and (cid:4)(b).
To achieve this, we use a labelling technique – based on tries [10] – which
allows eﬃcient and incremental computations of labels for new elements. Any
newly inserted element v in T is mapped to a node v in B whose label (cid:4)(v) will
share all but the last bit with another already computed label (see details in
Section 4). Thus, whether an element a comes before some other element b in S
can then be eﬃciently tested by lexicographical comparison between the labels
associated to the corresponding nodes in B. With this at hand, we then use two

Short Transitive Signatures for Directed Trees

37

of these data structures to keep track of Pre and Post lists and to test Dietz’s
condition on any pair of elements.
The problem, however, is that labels of O(n) bits are now associated to vertices
of the n-node tree T , so at ﬁrst sight little has been gained: signature length
is now O(n) bits compared to O(n log n) bits in Neven’s construction. That is
when our second idea comes into play: We use a new kind of collision-resistant
hash function with an extra property. Given only two hash values H(A), H(B)
and a small proof one can convince a veriﬁer that A and B share a common
preﬁx up to a position i. We call this new primitive hashing with common-preﬁx
proofs. This tool allows us to prove Dietz’s condition using only hashed labels
(and a constant size proof), eﬀectively compressing the signature.

We further improve our construction by showing how to balance the work
between the veriﬁer and the combiner (the participant who combines edge signature 
without the help of the signer ) using the natural idea of hashing consecutive 
chunks of the initial string to obtain a shorter one, and repeat this
operation several times. This technique leads to a novel tradeoﬀ O(λn1/λ) vs.
O(λ) for λ ≥ 1 between the time to compute a proof versus the time to verify
a proof. The security of our primitive is based on the q-Bilinear Diﬃe Hellman
Inversion assumption, introduced by Boneh and Boyen [3].

Related Work. The concept of transitive signatures was introduced by Rivest
and Micali [14] who also gave constructions for undirected graphs. Bellare and
Neven in [2], as well as Shahandashti et al. in [17], introduced new schemes based
on bilinear maps (but still for undirected graphs). Hohenberger [12] showed that
the existence DT S implies the existence of abelian groups where inversion is
computationally infeasible except when given a trapdoor. Such groups are not
known to exist either. Transitive signatures are a special case of homomorphic
signatures, a primitive introduced by Rivest and explored in [13,5,4]. In [18], a
stateless DT T S scheme with constant size signature (as opposed to ours which
is constant size but stateful) is proposed but without security proof. Finally,
we observe that using accumulators techniques [7,8] we can improve Neven’s
construction [16] in order to obtain short signatures. Such a solution, however,
does not provide two key properties we achieve in this work. In particular, we
want the computation of edge signatures to be paralellizable, and a scheme that
allows unbounded growth for the trees (our construction is able to increase the
bound on the number of nodes by dynamically updating setup parameters, see
Sect. 3). We explore a DT T S construction based on accumulators in the full
version [6].

Our contributions. First, we propose a new practical DT T S scheme which,
to the best of our knowledge, is the most eﬃcient one to the date. Our scheme
also provides a ﬂexible tradeoﬀ between signature computation and veriﬁcation.
To achieve this goal, we describe a general and practical new type of collisionresistant 
hashing called hashing with common-preﬁx proofs (HCP P ). HCPP
functions enable eﬃcient proofs that certain strings share common-preﬁxes.

38

P. Camacho and A. Hevia

We believe that this primitive may lead to many applications in the ﬁeld of
authenticated data structures.

Organization of the paper. In Section 2, we introduce notations, deﬁnitions
for DT T S, and the complexity assumptions we use. Section 3 describes our new
primitive in detail. Then in Section 4, we show how to use hashing with commonpreﬁx 
proofs to obtain a practical DT T S scheme. We conclude in Section 5.

2 Preliminaries

Notations and Conventions. If κ ∈ N is the security parameter then 1κ
denotes the unary string with κ ones. A function ν : N → [0, 1] is said to be
negligible in κ if for every polynomial p(·) there exists κ0 such that ∀κ > κ0 :

ν(κ) < 1/p(κ). In the following, neg will denote some negligible function in κ.
An algorithm is called PPT if it is probabilistic and runs in polynomial time
R← X to denote an element x chosen uniformly at random
in κ. We write x
from a set X. Finally, in the rest of this work, we use the convention that time
complexities are expressed in terms of the number of cryptographic operations
(signatures, group exponentiations, and bilinear map computations).
Strings. A string S of size m = |S| is a sequence of symbols S[1], S[2], ..., S[m]
from some alphabet Σ. We assume there is a total order relation < over Σ.
If m = 0 then S =  is the empty string. S[i..j] denotes the substring of S
starting at position i and ending at position j (both S[i] and S[j] are included).
In particular if A = S[1..j] for some j ≥ 0 then we say that A is a preﬁx of S
(by convention A[1..0] for any string A is the empty string ). The concatenation
operator on strings is denoted as ||. We say a string C is a common preﬁx of
A and B if C is preﬁx of A and also of B. String C is said to be the longest
common preﬁx of A and B if C is a common-preﬁx of A and B but C||σ is not
a common preﬁx of A and B for any symbol σ ∈ Σ. Without lost of generality,
we assume < is the (standard) lexicographical order on {0, 1}∗
. We single out $
as a special symbol that is used only to mark the end of a string, and satisﬁes
0 < $ < 1. We deﬁne the extended lexicographical order ≺ on {0, 1}∗
as following:
let X, Y ∈ {0, 1}∗
= Y ||$ strings obtained by appending the
end marker to X, Y . We say that X ≺ Y ⇔ X
Trees. Let T = (V, E) be a directed tree. The transitive closure of T is T ∗
=
{(a, b) : a, b ∈ T and there is a path from a to b}. When considering depthﬁrst 
traversals of a tree, we denote by Pre and Post the strings formed by
concatenating the successive labels of the nodes visited in a pre-order (i.e. the
node is appended to the string when it is visited for the ﬁrst time) respectively
post-order (i.e. the node is appended to the string when it is visited for the last
time). Our construction also makes use of binary tries [10], a type of binary
tree, which associate labels to each node as follows. First, for each node, the
edge going to a left (resp. right) child is tagged 0 (resp. 1). Then, the label for
the node is obtained by concatenating the tags on the edges in a path from the

= X||$, Y

and X

(cid:4)

(cid:4)

(cid:4)

(cid:4)

.

< Y

Short Transitive Signatures for Directed Trees

39

root to the node. This way, any node x in the trie B can be identiﬁed by its
associated label X ∈ {0, 1}∗
. Given some label X, we denote by node(X) the
corresponding node in B if it exists. We say a node x
(cid:4) ∈ B is a descendant of x
(cid:4)
belongs to the sub-tree rooted at x or equivalently if there is a path from
if x
. The lowest common ancestor of two nodes x, y of B is the node z such
(cid:4)
x to x
that x and y belong to the sub-tree rooted at z, and for any child z
of z, x or
y is not a descendant of z

(cid:4)

(cid:4)

.

(cid:4)

Collision Resistance and Standard Signatures Schemes. The family of
functions H is said to be collision-resistant (CRHF ) if, for H:{0, 1}∗ → {0, 1}κ
uniformly chosen at random in H, any computationally bounded adversary can
not ﬁnd two diﬀerent messages M and M
) except with
negligible probability. Let AlgH(·) be a PPT algorithm that computes H, then if
AlgH(·) is fed with input X and returns y, we write X = H
−1(y). We denote by
SSig = (SKG, SSig, SVf) a standard signature scheme. A pair of private/public
keys is created by running SKG(1κ). Given a message M ∈ {0, 1}∗
, a signature
on M under pk is σM = SSig(sk, M ). A signature σ on M is deemed valid if
and only if SVf(pk, M, σ) returns valid. Regarding security, we use the standard
notion of existential unforgeability under chosen message attack [11].

such that H(M ) = H(M

(cid:4)

Transitive Signatures for Directed Trees. In a transitive signature
scheme for directed trees, the signer can dynamically sign edges in a directed
tree. Then without the secret, given two signed edges (a, b) and (b, c) it is possible 
to combine them into a signature on the edge (a, c). This property enables
the computation of signature on any path in the tree.

Deﬁnition 1. (Transitive Signature Scheme, [14,16]) A transitive signature
scheme for directed trees is a tuple DTTS = (TSKG, TSign, TSComp, TSVf) where:

– TSKG(1κ) : returns a pair of private/public keys (tsk, tpk).
– TSign(tsk, a, b) : returns the signature τ(a,b) of edge (a, b).
– TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk): returns a combined signature τ(a,c) on

– TSVf((a, b), τ, tpk) : returns valid if τ is a valid signature for the path (a, b)

edge (a, c). Note that the secret key is not required.
and ⊥ otherwise.

A transitive signature scheme is correct if both original signatures (those generated 
honestly with TSign) and combined signatures (those generated honestly
with TSComp) do verify correctly with TSVf. Intuitively, a transitive signature
scheme is secure if, for any PPT adversary it is infeasible to compute a signature
for a path outside the transitive closure of T .
Deﬁnition 2. (Security of Transitive Signature Schemes, [14,16]) Let DTTS be
a transitive signature scheme. Consider the following experiment. A PPT adversary 
A is given the public key tpk of the scheme. A may ask for a polynomial
number of edge signatures to the oracle OTSign(·). Finally A outputs (a, b) and τ
where a, b are nodes in the tree T formed by the successive validly signed edges.
The advantage of A is deﬁned by:

40

P. Camacho and A. Hevia

Advtuf-cma(A, κ) = P r

(cid:2)

(a, b) /∈ T ∗∧

TSVf((a, b), τ, tpk) = valid

(cid:3)

The scheme is said to be secure if we have Advtuf-cma(A, κ) = neg(κ) for any
PPT adversary A.
A trivial solution for DT T S can be implemented by simply concatenating
standard edge signatures, in which case the size of a signature grows linearly
with the length of the path and may reach O(nκ) bits. Yi’s solution [19] with
O(n log(n log n))-bit signatures is clearly better than the trivial construction.
Neven’s DT T S scheme [16] manages to reduce signature sizes to O(n log n) bits.
We remark that both solutions need to maintain the state of the tree to compute
new edge signatures (as opposed to the initial deﬁnition [14]).

Our solution, like previous ones, is stateful. This state is shared by the signer
and a combiner . The role of this new participant (the combiner ) is to compute,
without help from the signer , signatures for any edge in the transitive closure of
the tree.

Bilinear maps. Our construction for hashing with common-preﬁx proofs requires 
the use of bilinear maps. Let G, GT , be cyclic groups of prime order p.
We consider a map e : G × G → GT which is
– bilinear : ∀a, b ∈ G, x, y ∈ Zp : e(ax, by) = e(a, b)xy.
– non-degenerate: let g be a generator of G then e(g, g) also generates GT .
– eﬃciently computable: there exists a polynomial time algorithm BMGen with
parameter 1κ that outputs (p, ˆG, ˆGT , ˆe, g) where ˆG, ˆGT is the representation
of the corresponding groups of size p (p being a prime number of κ bits), g is
a generator of G, and ˆe is an eﬃcient algorithm to compute the map. For the
sake of simplicity, we will not distinguish between G, GT , e, and ˆG, ˆGT , ˆe.

The security of our construction relies on the q-Billinear Diﬃe-Hellman Inversion
(q-BDHI) assumption which was introduced by Boneh and Boyen [3].
Deﬁnition 3. (q-BDHI assumption [3]) Let P = (p, G, GT , e, g) ← BMGen(1κ),
R← Zp, and T = (g, gs, gs2
) for q ∈ N. The q-Bilinear Diﬃe-Hellman
s
1
Inversion (q-BDHI) problem consists in computing e(g, g)
s , given P and T .
We say the q-BDHI assumption holds if for any PPT adversary A we have:

, ..., gsq

Advq-BDHI(A, κ, q) = Pr

e(g, g)

1

s ← A(1κ, P, T )

(cid:4)

(cid:5)

= neg(κ)

3 Collision-Resistant Hashing with Common-Preﬁx

Proofs

Standard collision-resistant hash functions have the property of compressing
possibly large inputs strings to small ones. Moreover, because of collision resistance,
 in practice hash functions are considered injective. This makes them

Short Transitive Signatures for Directed Trees

41

useful constructs to manipulate shorter strings without loosing much security. In
that context, proving some relations or predicates on pre-images using only the
corresponding hash values (and perhaps an additional short proof) is certainly
very useful. For example, given two hash values H(A), H(B), proving eﬃciently
predicates like |A − B| ≥ 10 or A < B may help to simplify some protocols or
make them more eﬃcient.
With the above goal in mind, in this work we consider a predicate for strings
called CommonPrefix: given A, B ∈ Σm, for some m ∈ N, CommonPrefix(A, B, i)
= true if and only if A and B share a common preﬁx up to position i. More
concretely, we seek collision-resistant hash function families H with the following
property: given H(A) and H(B) where A and B share a common preﬁx until
position i, it should be possible to produce a certiﬁcate π such that running
a veriﬁcation algorithm on inputs H(A), H(B), i, π one can be convinced that
CommonPrefix(A, B, i) = true. Any such scheme should be secure in the sense
that if CommonPrefix(A, B, i) = f alse then forging a proof π
that makes the
veriﬁcation algorithm accept should be computationally infeasible. Clearly, there
exist trivial instantiations of this primitive: just consider H a standard (collision-
resistant) hash function and π = (A, B). Of course, this is not really useful as
the size of the certiﬁcate is proportional to the size of the longest string. Thus,
interesting implementations should have short certiﬁcates. Additionally, we want
hash function H to be eﬃciently updatable: given H(A) one should be able to
compute H(A||σ) for any string σ, without knowing A (this concept is also
known as incremental hashing [1]).

∗

(cid:4)

is a preﬁx of B, and (3) σ < σ

Given a CommonPrefix predicate we can now implement more interesting
predicates over strings such as Compare, where Compare(A, B) = true if and
only if A ≺ B (where ≺ is the extended lexicographical order): If A ≺ B it
follows that there exists a (possibly empty) common preﬁx C for A and B, such
that (1) D = C||σ is a preﬁx of A, (2) C||σ
(cid:4)
.
In summary, once we know how to do short proofs for CommonPrefix, using
incremental hashing we can compare any two strings by only their hash values.
Hashing with common-prefix proofs. Let κ ∈ {0, 1}∗
be the security parameter,
 P K ∈ {0, 1}κ some public key, and n ∈ N a bound on the size of the
input1 which is a polynomial in κ. We denote by H = {HP K,n,κ} a hash function
family.
Deﬁnition 4. (Hashing with common-preﬁx proofs - Syntax) A family H of
hash functions with common-preﬁx proofs (HCP P ) is a 4-tuple of algorithms
(HGen, HEval, HProofGen, HCheck) where:

– HGen(1κ, n): given a bound n on the length of the strings to hash, this
probabilistic algorithm returns a public parameter P K. Value P K implicitly
deﬁnes a hash function H = HP K,n,κ ∈ H where H : {0, 1}n → {0, 1}κ.

1 Here we use intentionally the same variable name n for the size of the input of the
hash function as well as the number of nodes of the tree. Indeed, our full construction
for trees of n nodes presented in section 4.2 requires hashing n-bit strings.

42

P. Camacho and A. Hevia

– HEval(M, P K): given M ∈ {0, 1}n, this deterministic algorithm eﬃciently
computes and returns the string H(M ) ∈ {0, 1}κ.
– HProofGen(A, B, i, P K): given two messages A, B ∈ {0, 1}n, and an index
1 ≤ i ≤ n, this deterministic algorithm computes a proof π ∈ {0, 1}κ that
will be used by the HCheck algorithm.
– HCheck(HA, HB, π, i, P K): a deterministic algorithm that, given HA, HB ∈
{0, 1}κ, two hash values, and a proof π ∈ {0, 1}κ, returns either valid or ⊥.
The scheme is said to be correct if for any strings A, B and i ∈ N such that
CommonPrefix(A, B, i) = true, and π = HProofGen(A, B, i, P K), we have that
HCheck on inputs (H(A), H(B), π, i, P K) returns valid.
The notion of security is also rather natural: for any PPT adversary A it
should be diﬃcult to compute two n-bit strings A, B, an index i ∈ {1, . . . , n},
and a proof π ∈ {0, 1}κ such that HCheck(H(A), H(B), π, i, P K) returns valid
but A[1..i] (cid:13)= B[1..i]. Note that the adversary is required to output pre-images
A and B to win, which guarantees that the hash values H(A) and H(B) have
been correctly computed.
Deﬁnition 5. (HCP P Security) Let H be a family of hash functions with
common-preﬁx proofs and A a PPT adversary. The HCP P advantage of A is
⎤
⎡
⎣ P K ← HGen(1κ, n); A, B, π, i ← A(1κ, n, P K) :
⎦
A[1..i] (cid:13)= B[1..i] ∧ HA = H(A) ∧ HB = H(B)∧

(A, κ, n) = P r

AdvHCP PH

We say H is a secure hash function family with common-preﬁx proofs (HCP P )
if for every PPT A, we have AdvHCP PH

(A, κ, n) = neg(κ).

HCheck(HA, HB, π, i, P K) = valid

The following proposition states that hashing with common-preﬁx proofs implies
(standard) collision resistance. We omit the proof.
Proposition 1. Let H be a family of hash functions with common-preﬁx proofs.
Then H is a collision-resistant hash function family.

, ..., gsn

(cid:4)

. Now if some message M

(cid:10)n
j=i+1 gcj sj
(cid:10)n
j=i+1 gcjsj−(i+1)

The Construction. We assume that the description of the hash function H
– i.e. the tuple (gs, gs2
) of the n-BDHI problem – has been computed
securely by a trusted third party or using multi-party computations techniques.
The basic idea is to represent a binary string M by H(M ) def= gM[1]s · gM[2]s2 ···
gM[n]sn
is equal to M up to position i then the value
, where cj ∈ {−1, 0, 1}, will be a product of powers
H(M)
Δ =
H(M(cid:2)) =
for 1 ≤ j ≤ n where for all j ≤ i the exponents are equal to 0. Yet,
of gsj
(cid:4)
can easily be computed given M ,M
the related value π =
and H. The intuition behind the proof is that as M and M
are equal up to
position i then we can represent the diﬀerence between M and M
using only
n − i positions. Thus, verifying proof π simply consists in testing if using the
bilinear map we can “shift forward” the exponents in the proof by i positions, to
obtain Δ. More precisely, π will be a valid proof for H(M ), H(M
) if and only
if e(

). Details follow.

H(M)
H(M(cid:2)) , g) = e(π, gsi+1

(cid:4)

(cid:4)

(cid:4)

Short Transitive Signatures for Directed Trees

43

Deﬁnition 6. (Hashing with Common-Preﬁx Proofs - Scheme) Let PH be the
scheme deﬁned by the following algorithms:

and T = (g, gs, gs2

– HGen(1κ, n): Run BMGen(1κ) to obtain P = (p, G, GT , e, g). Let s
). Return P K = (P, T ).
– HEval(M, P K): M ∈ {0, 1}n. Compute H(M ) =
. Return H(M ).
– HProofGen(A, B, i, P K): Given n-bits strings A, B, let C be the array such

(cid:10)n
j=1 gM[j]sj

, ..., gsn

that ∀j ∈ {1, . . . , n} : C[j] = A[j] − B[j]. Return π =

(cid:10)n
j=i+1 gC[j]sj−(i+1)

.

R← Zp,

– HCheck(HA, HB, π, i, P K): Compute Δ = HA

valid. If i < n return valid if e(Δ, g) = e(π, gsi+1

HB . If i = n and Δ = 1 return

), otherwise return ⊥.

Proposition 2. Under the n-BDHI assumption the hash functions family deﬁned 
by the scheme PH is HCP P secure.
Proof. Given an adversary A that breaks the HCP P security of PH, we construct
an adversary B that breaks the n-BDHI assumption as follows. Once B receives
)) as input, it forwards them to A.
the parameters (P, T = (g, gs, gs2
Eventually A will output values A, B, π, i such that HCheck(H(A), H(B), π, i,
P K) = valid. Then, B computes the array C deﬁned as C[j] = A[j] − B[j] = cj
for j ∈ {1, . . . , n}. Let k be the smallest index such that ck (cid:13)= 0. Clearly i− k > 0
since A[1..i] (cid:13)= B[1..i]. From the validity of π, we have that e(Δ, g) = e(π, gsi+1
),
and thus π = Δ

, . . . , gsn

1

si+1 . Then:
E = e(π, gsi−k

) = e(Δ

1

)

(cid:10)n
si+1 , gsi−k
(cid:10)n
j=k e(g, g)cjsj−k−1
j=k+1 e(g, g)cjsj−k−1

=
= e(g, g)
= e(g, g)

ck
s
ck
s D

1

s .

D )1/ck = e(g, g)

|M|||b) = gbs|M|+1

|M|||b). Moreover, since H(0

As all cj are known, and ck = ±1, B can compute ( E
Additional properties. The HCP P family H in our construction is homomorphic 
in the following sense: for any H ∈ H, and any bit b, H(M||b) =
H(M ) · H(0
can be computed in
constant time w.r.t |M|, our construction yields in fact an incremental hash
function [1]. We call such combination of properties incremental hashing with
common-preﬁx proofs and it is what we actually require in our most eﬃcient
construction. In terms of eﬃciency, both the computation of the hash function
and the proof can be easily parallelizable as they involve only group multiplications.
 In particular, with O(n) processors, we can compute a proof using only
O(log n) (sequential) group multiplications. Also, note that handling strings of
length m > n can be done dynamically, without having to recompute any proof,
by simply extending the public parameter T = (g, gs, gs2
) say by invoking 
the distributed procedure (or calling the trusted generator) to compute
gsn+1

, . . . , gsm

, . . . , gsn

.

44

P. Camacho and A. Hevia

4 Short Transitive Signatures for Directed Trees

Our construction for DTTS is based on the following idea: handling a growing
tree can be reduced to maintaining two ordered sequences, one corresponding
to the pre-order tree traversal and another to the post-order tree traversal in a
depth-ﬁrst search. This was ﬁrst observed by Dietz [9].
Proposition 3. ([9]) Let T be a tree of n nodes and consider a depth-ﬁrst
traversal. Let Pre and Post be the strings formed by the nodes that are visited
in pre-order and post-order respectively, then for any pair of nodes a, b in T , b
is descendant of a if and only if ∃i, j : 0 < i < j and ∃i
such
that:

: 0 < j

< i

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(Pre[i] = a ∧ Pre[j] = b) ∧ (Post[i

(cid:4)

, j
] = a ∧ Post[j

(cid:4)

] = b)

For example, consider the tree depicted in Fig. 1, last row, ﬁrst column. For that
tree, Pre = acdbe and Post = dcbea. Since there is a path from c to d, c appears
before d in Pre and d appears before c in Post. Also note that if there is no path
from some node x to another node y then y may appear before x in Pre or x
may appear before y in Post. See for example pairs (c, b), (e, d) or (b, a).

The challenge in using this result is that the ordered sequences are dynamic –
new elements can be inserted between any two existent elements. This problem
is addressed by the so called order data structure [9,15]. Such a data structure
allow us to compare any pair of labels and also insert a new label so that it may
lie between two existing ones. A naive way - mentioned in [9] - to implement
the proposed data structure would be to consider the interval [0..2n − 1] for the
labels; to insert an element between X and Y one would use label Z = (cid:15) X+Y
(cid:16).
This way we can always ﬁnd the label for an element between any two others
and the comparison algorithm consists in comparing the labels. Unfortunately,
this solution does not suﬃce for our application since the string representation
of a new label cannot be easily obtained from already computed labels, and the
signer must sign labels of length n for each new edge. So our ﬁrst improvement
is a new order data structure with the following property: If X and Y are two
consecutive labels,then every new computed label Z such that X ≺ Z ≺ Y will
share all bits except one with X or Y .

2

Before describing our construction we introduce the formal deﬁnition of order 
data structure [15]. Jumping ahead, we use this data structure to eﬃciently
create and update labels in U = {0, 1}∗
, as well as to compare them using extended 
lexicographical order as the relation ≺U . The particular mapping between
elements in lists Pre and Post to labels will depend on our construction.
Deﬁnition 7. Let (U,≺U ) be a totally ordered set of labels. An order data structure 
over U consists of three algorithms:

– ODSetup() : initializes the data structure.
– ODInsert(X, Y ) : Let X and Y be two consecutive labels. Compute a new
– ODCompare(X, Y ): returns true if and only if X ≺U Y .

label Z such that X ≺U Z ≺U Y .

Short Transitive Signatures for Directed Trees

45

Our construction for order data structure uses binary tries [10] to handle labels.
As mentioned before, in a trie, the label for a node is obtained by concatenating
the labels on the edges in a path from the root to the node. Comparing two
labels then reduces to comparing the labels as binary strings w.r.t. their extended
lexicographical order.

the root node is R = .

,≺) deﬁned by the following operations:

Construction 1. Let OrderDS be the order data structure over universe
({0, 1}∗
– ODSetup(): create a trie B with a single root node r. The label associated to
– ODInsert(X, Y ) : If B has only one node with label R (root) then if X = R
(thus Y can be ignored) add a node node(Z) as the right child of R. Return
Z = R||1. If Y = R then add node(Z) as the left child of R. Return Z = R||0.
If B has at least two nodes, then search node(X) and node(Y ), the nodes
associated to labels X and Y , in the binary tree. If node(Y ) belongs to the
right sub-tree of node(X) then add node(Z) as the left child of node(Y );
Return Z = Y ||0.
If node(X) belongs to the left sub-tree of node(Y ) then add node(Z) as the
right child of node(X). Return Z = X||1.

– ODCompare(X, Y ) : Return true if and only if X ≺ Y .

In terms of eﬃciency, we observe that in the worst case, the longest path of a
n-node tree is n, so labels are O(n) bits. It is also easy to see that for any pair of
consecutive labels X, Y the label Z returned by ODInsert(X, Y ) is equal to X||b
or Y ||b where b ∈ {0, 1}. Looking ahead, this property turns out to be crucial to
obtain our most eﬃcient construction as these strings will be compressed using
the hash function with common-preﬁx proofs H introduced in the previous section.
 Moreover, the homomorphic property of H will allow us to compute H(Z)
from H(X) or H(Y ) in only a constant number of cryptographic operations.

4.1 Basic Construction

Our ﬁrst construction is based only on standard digital signatures, as Neven’s
construction. The scheme is as follows. Each time an edge (and thus a vertex)
is inserted into the tree T two lists (one for pre-order Pre and another for
post-order Post) are updated with the newly inserted element. We eﬃciently
implement the latter by maintaining two order data structures OrderDSPre and
OrderDSPost, one for each list. More precisely, each element x ∈ T is associated
with a label XPre (resp. XPost) computed by the order data structure for preorder 
(resp. post-order). (As a convention, the label associated to each element
x ∈ T for list Pre is denoted by XPre, using the same symbol but in capital
letter and indexed by the list name. Same for Post.) We then use ODCompare
to evaluate if x appears before some y in Pre (resp. Post), which simply veriﬁes
that XPre ≺ YPre and YPost ≺ XPost.

46

P. Camacho and A. Hevia

Construction 2. (DT T S from Standard Digital Signatures)

Let SSig = (SKG, SSig, SVf) be a standard digital signature scheme. The

scheme BasicDTTS is as follows.
– TSKG(1κ) : Run SKG to generate a pair of keys (sk, pk). Set tsk = sk and
tpk = pk. Initialize two order data structures OrderDSPre and OrderDSPost
to maintain the sequences for pre-order and post-order tree traversal respectively.
 Set T = (V, E) as the tree with a single root r. We deﬁne two
tables (cid:4)Pre[·] and (cid:4)Post[·] that map nodes in T to their respective labels in
OrderDSPre and OrderDSPost respectively. That is, if x ∈ V , (cid:4)Pre[x] will return 
XPre and (cid:4)Post[x] will return XPost, the labels bound to x in OrderDSPre
and OrderDSPost respectively. We set (cid:4)Pre[r] = (cid:4)Post[r] = . Return (tsk, tpk).
– TSign(tsk, a, b) : If both a, b ∈ V or both a, b /∈ V or if the insertion does not
preserve the tree structure of T , return ⊥. (Recall that tree T is initialized
with a root node, so a, b should never be both not in V .)
Otherwise, let z ∈ {a, b} be the new vertex not yet in V and x ∈ {a, b} \ {z}
be the other one. Insert edge (a, b) in T , and update OrderDSPre, OrderDSPost
data structures to reﬂect the new pre-order and post-order tree traversal of T
as follows. Let y be the element in Pre such that z lies (strictly) between x and
y. Assume that x < z < y (the other case is similar). Let XPre = (cid:4)Pre[x] and
YPre = (cid:4)Pre[y]. Compute OrderDSPre.ODInsert(XPre, YPre) to obtain ZPre the
label associated to z in OrderDSPre. Similarly obtain ZPost the label associated
to z in OrderDSPost. Set (cid:4)Pre[z] = ZPre and (cid:4)Post[z] = ZPost. Then, compute
Mz = z||ZPre||ZPost and sign it to obtain σz = SSig(tsk, Mz). Now, obtain
XPost = (cid:4)Post[x], and (re)compute signature σx = SSig(tsk, Mx) on Mx =
x||XPre||XPost. Return τ(x,z) = (Mx, σx, Mz, σz).

– TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk): Parse τ(a,b) as (Ma, σa, Mb, σb) and

τ(b,c) as (Mb, σb, Mc, σc). Return τ(a,c) = (Ma, σa, Mc, σc).

– TSVf((a, b), τ, tpk) : Parse τ as (Ma, σa, Mb, σb). If Ma or Mb are not of the
form (a, APre, APost) or (b, BPre, BPost) respectively, or if any signatures is
invalid, then return ⊥. Otherwise, verify that a appears before (resp. after)
b in Pre (resp. Post) by checking that ODCompare(APre, BPre) = true and
ODCompare(BPost, APost) = true. If veriﬁcation succeeds return valid else
return ⊥.

Correctness and Security. We require that correct signatures, those honestly 
computed by the signer as well as those combined by anyone from two existent 
signatures, verify correctly, meaning the veriﬁcation algorithm on them returns 
valid. To see this holds, it suﬃces to observe ﬁrst, that the signing operation
preserves the tree structure of the graph, and second, that ODCompare(X, Y ) is
−1
Pre[Y ]
true, if and only if x = (cid:4)
−1
(resp. x = (cid:4)
Post[X]) in Pre (resp. Post) which allows correct veriﬁcation by Di-
etz’s condition (namely, proposition 3). Our scheme is secure if the underlying
standard signature scheme is secure.

−1
Post[Y ]) appears before y = (cid:4)

−1
Pre[X] (resp. y = (cid:4)

Theorem 1. If SSig is a signature scheme existentially unforgeable under chosen 
message attack then BasicDTTS a is secure transitive signature scheme for
directed trees where edge signatures are O(n + κ) bits long.

Short Transitive Signatures for Directed Trees

47

Step

Tree T

Pre/Post order

OrderDSPre

OrderDSPost

Labels

0

1

2

3

4

5

traversal

Pre = 
Post = 
Pre = a
Post = a
Pre = ab
Post = ba
Pre = acb
Post = cba

Pre = acdb
Post = dcba

Pre = acdbe
Post = dcbea



a

 

a

 b

a

c b

a

c

b

d

a

c

b e

d

r

 

a

 

a

 b

a

 b

c 

a



b

c



 d

a



b

c

e

 d

(cid:5)Pre[r] = 
(cid:5)Post[r] = 
APre = 
APost = 
BPre = 1
BPost = 0
CPre = 10
CPost = 00

DPre = 101
DPost = 000

EPre = 11
EPost = 01

r

 

a

 

a

b 

a

b



c 

a

b



c



d 

a

b



c

e

d 

Fig. 1. Example of order data structures after several insertions in a directed tree T
Step 0: The tree T to authenticate has no nodes. The sequences Pre and Post are
empty as well. The order data structure OrderDSPre and OrderDSPost contain a single
root node r. Each edge is marked implicitly by 0 (left child) and 1 (right child).
Step 1: The ﬁrst node a of T is created. The pre/post-order lists contain only a. The
order data structures are updated by setting node a to be equal to r. In particular we
have that labels APre = APost = .
Step 2: A child b is added to a. Now the pre-order sequence Pre is equal to ab and the
post-order sequence is ba. As b comes after a in Pre we have that b is the right child
of a in OrderDSPre. Similarly b is the left child of a in OrderDSPost as it comes before a
in Post.
Step 3,4 and 5: We follow the same procedure and obtain for each node x its order
labels XPre and XPost respectively.

Comparing Two Node Labels: In step 5 we can check easily using the order labels
that for example d is a descendant of a. Indeed we have APre =  and DPre = 101 which
means APre ≺ DPre. Also we can check that DPost = 000 ≺ APost = . We can also
observe that there is no path from b to c for example as CPre = 10 ≺ BPre = 1 and
also CPost = 00 ≺ BPost = 0.

4.2 Full Construction

We extend our basic construction as follows. Instead of comparing strings directly,
 we compare them by proving that labels from certain nodes contain the
labels of other nodes as preﬁxes. Such proofs are done using scheme PH. As
before, we use alphabet Σ = {0, $, 1} where 0 < $ < 1. That is, in order to
prove that two labels X, Y are such that X ≺ Y using their hashes H(X), H(Y )

48

P. Camacho and A. Hevia

instead of the strings, the combiner must compute: (1) the longest common
preﬁx C for X and Y , (2) a proof that C is a preﬁx of X up to position i = |C|,
(3) a proof that C is a preﬁx of Y up to position i = |C|, (4) a proof that C||c1
is a preﬁx of X||$ up to position i + 1 for some c1 ∈ Σ, and (5) a proof that
C||c2 is a preﬁx of Y ||$ up to position i + 1, for some c2 ∈ Σ. Then, verifying
that X ≺ Y reduces to the checking of the proofs and verifying that c1 < c2.

Construction 3. (DT T S from HCP P )
Let PH = (HGen, HEval, HProofGen, HCheck) be a family of hash functions with
common-preﬁx proofs. The scheme PHDTTS consists of following algorithms:

– TSKG(1κ) : Do as in BasicDTTS and also generate the public parameters (ie.

P K) for the PH scheme. Return (tsk, tpk, P K).
– TSign(tsk, a, b) : Do as in BasicDTTS except that the message Mz to sign is
||HZPost , where HZPre = H(ZPre) and HZPost = H(ZPost).
now Mz = z||HZPre
Store HZPre and HZPost on node z in the tree T . Notice that HZPre , HZPost can
be computed incrementally due to H’s homomorphism.

– TSComp((a, b), τ(a,b), (b, c), τ(b,c), tpk): Parse τ(a,b) as (Ma, σa, Mb, σb) and
τ(b,c) as (Mb, σb, Mc, σc). If σa, σb or σc is invalid, then reject. Parse Ma =
(a, HAPre, HAPost ) and Mc = (c, HCPre , HCPost). Compute proof πPre as follows.
First, save (HAPre, HAPost , σa) on node a in T . Do the same with the information 
for node b. Recover APre and CPre as the labels associated to a and c
respectively from OrderDSPre. Let DPre be the longest common preﬁx between
APre and CPre. Note that H(DPre) has already been computed by the signer
and thus Md = d ||H(DPre)||H(DPost), signature σd on Md are available to
the combiner. Let t = |DPre|. Compute the following values:
• π1 = HProofGen(DPre, APre, t, P K), π2 = HProofGen(DPre, CPre, t, P K)
• π3 = HProofGen(DPre||d1, APre||$, t + 1, P K), and
• π4 = HProofGen(DPre||d2, CPre||$, t + 1, P K)
where (d1, d2) ∈ {(0, $), (0, 1), ($, 1)}. Set π5 =
(Ma, σa, Mc, σc, Md, σd, t, d1, d2) and πPre = (π1, π2, π3, π4, π5). Compute
similarly πPost and return τ(a,d) = (πPre, πPost).
– TSVf((a, c), τ, tpk, P K) : If τ is of the form (Ma, σa, Mc, σc), verify that Ma
is a 3-tuple that starts with a and Mc with c, and return ⊥ if one of the signature 
σa or σc is invalid. Otherwise, extract πPre from τ = (πPre, πPost). Parse
πPre as (π1, π2, π3, π4, π5). Parse π5 as (Ma, σa, Mc, σc, Md, σd, t, d1, d2)
where Mx = x||XPre||XPost for x ∈ {a, c, d}. Check that all (standard) signatures 
are valid under public key tpk. Check that d1, d2 ∈ Σ and d1 < d2.
Verify proofs π1, π2, π3, π4 using HCheck:
• HCheck(HDPre , HAPre , π1, t, P K), and HCheck(HDPre , HCPre, π2, t, P K),
• HCheck(HDPre
• HCheck(HDPre
Perform the similar veriﬁcations relative to OrderDSPost. If all
veriﬁcations pass return valid otherwise return ⊥.

· H(0t||$), π3, t + 1, P K), and
· H(0t||$), π4, t + 1, P K)

· H(0t||d1), HAPre
· H(0t||d2), HCPre

these

Short Transitive Signatures for Directed Trees

49

This new construction combines the basic one with hashing with commonpreﬁx 
proofs so we can shrink the size of an edge signature to O(κ) bits. Furthermore,
 using a tradeoﬀ technique for our hashing family we obtain the following
result2.
Theorem 2. Let λ ≥ 1. If SSig is a signature scheme existentially unforgeable 
under chosen message attack and H is a family of secure hash functions
with common-preﬁx proofs, then PHDTTS with tradeoﬀ is a secure DT T S scheme.
Moreover, (a) an edge signature is O(λκ) bits long can veriﬁed in O(λ) cryptographic 
operations, (b) the signer has to perform O(λ) cryptographic operations
to sign an edge, and (c) computing the signature for any edge (in the transitive
closure of the tree) takes O(λn1/λ) cryptographic operations for the combiner.

5 Conclusion

In this work we propose a transitive signature scheme for directed trees which
achieves better worst-case complexity than previously known constructions, and
enables a practical trade oﬀ between the time to combine a signature, O(λn1/λ),
and the time to verify it, O(λ). However, the problem of building short and
stateless transitive signatures for directed trees remains open. Moreover, in order
to achieve the mentioned trade oﬀ, we introduce a new primitive hash functions
with common-preﬁx proofs. We believe it may ﬁnd other useful applications.

Acknowledgements. The authors would like to thank the anonymous referees
for their valuable comments and suggestions to improve the quality of this paper.

References

1. Bellare, M., Goldreich, O., Goldwasser, S.: Incremental Cryptography: The Case
of Hashing and Signing. In: Desmedt, Y.G. (ed.) CRYPTO 1994. LNCS, vol. 839,
pp. 216–233. Springer, Heidelberg (1994)

2. Bellare, M., Neven, G.: Transitive Signatures: New Schemes and Proofs. IEEE

Transactions on Information Theory 51(6), 2133–2151 (2005)

3. Boneh, D., Boyen, X.: Eﬃcient Selective-ID Secure Identity-Based Encryption
without Random Oracles. In: Cachin, C., Camenisch, J.L. (eds.) EUROCRYPT
2004. LNCS, vol. 3027, pp. 223–238. Springer, Heidelberg (2004)

4. Boneh, D., Freeman, D.: Homomorphic Signatures for Polynomial Functions. In:
Paterson, K.G. (ed.) EUROCRYPT 2011. LNCS, vol. 6632, pp. 149–168. Springer,
Heidelberg (2011)

5. Boneh, D., Freeman, D., Katz, J., Waters, B.: Signing a Linear Subspace: Signature
Schemes for Network Coding. In: Jarecki, S., Tsudik, G. (eds.) PKC 2009. LNCS,
vol. 5443, pp. 68–87. Springer, Heidelberg (2009)

2 Due to space constrainsts, the description of the trade oﬀ technique for the hash
function, its use in our signature scheme, and the security proofs are in the full
version of this paper [6].

50

P. Camacho and A. Hevia

6. Camacho, P., Hevia, A.: Short Transitive Signatures for Directed Trees. Full version

of this paper (2011), http://eprint.iacr.org/2011/438

7. Camenisch, J., Kohlweiss, M., Soriente, C.: An Accumulator Based on Bilinear 
Maps and Eﬃcient Revocation for Anonymous Credentials. In: Jarecki, S.,
Tsudik, G. (eds.) PKC 2009. LNCS, vol. 5443, pp. 481–500. Springer, Heidelberg
(2009)

8. Camenisch, J., Lysyanskaya, A.: Dynamic Accumulators and Application to Eﬃcient 
Revocation of Anonymous Credentials. In: Yung, M. (ed.) CRYPTO 2002.
LNCS, vol. 2442, pp. 61–76. Springer, Heidelberg (2002)

9. Dietz, P.F.: Maintaining order in a linked list. In: STOC, pp. 122–127. ACM Press

(1982)

10. Fredkin, E.: Trie memory. Communications of the ACM 3(9), 490–499 (1960)
11. Goldwasser, S., Micali, S., Rivest, R.L.: A Digital Signature Scheme Secure Against
Adaptive Chosen-Message Attacks. SIAM Journal on Computing 17(2), 281 (1988)
12. Hohenberger, S.: The Cryptographic Impact of Groups with Infeasible Inversion.

S.M. Thesis, MIT (May 2003)

13. Johnson, R., Molnar, D., Song, D.X., Wagner, D.: Homomorphic Signature
Schemes. In: Preneel, B. (ed.) CT-RSA 2002. LNCS, vol. 2271, pp. 244–262.
Springer, Heidelberg (2002)

14. Micali, S., Rivest, R.: Transitive Signature Schemes. In: Preneel, B. (ed.) CT-RSA

2002. LNCS, vol. 2271, pp. 236–243. Springer, Heidelberg (2002)

15. Bender, M.A., Cole, R., Demaine, E.D., Farach-Colton, M., Zito, J.: Two simpliﬁed
algorithms for maintaining order in a list. In: M¨ohring, R.H., Raman, R. (eds.) ESA
2002. LNCS, vol. 2461, pp. 152–164. Springer, Heidelberg (2002)

16. Neven, G.: A simple transitive signature scheme for directed trees. Theoretical

Computer Science 396(1-3), 277–282 (2008)

17. Shahandashti, S.F., Salmasizadeh, M., Mohajeri, J.: A Provably Secure Short Transitive 
Signature Scheme from Bilinear Group Pairs. In: Blundo, C., Cimato, S.
(eds.) SCN 2004. LNCS, vol. 3352, pp. 60–76. Springer, Heidelberg (2005)

18. Xu, J.: On Directed Transitive Signature (2009),

http://eprint.iacr.org/2009/209

19. Yi, X.: Directed Transitive Signature Scheme. In: Abe, M. (ed.) CT-RSA 2007.

LNCS, vol. 4377, pp. 129–144. Springer, Heidelberg (2006)

