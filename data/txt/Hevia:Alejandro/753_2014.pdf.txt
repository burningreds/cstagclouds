Online Deniability for Multiparty Protocols with Applications to

Externally Anonymous Authentication

Alonso Gonz´alez-Ulloa and Alejandro Hevia

Dept. of Computer Science, University of Chile
Blanco Encalada 2120, 3er piso, Santiago, Chile

alogonza@ing.uchile.cl, ahevia@dcc.uchile.cl

Abstract. In the problem of anonymous authentication (Boneh et al. CCS 1999), a sender wishes
to authenticate a message to a given recipient in a way that preserves anonymity: the recipient does
not know the identity of the sender and only is assured that the sender belongs to some authorized
set. Although solutions for the problem exist (for example, by using ring signatures, e.g. Naor, Crypto
2002), they provide no security when the anonymity set is a singleton. This work is motivated by the
question of whether there is any type of anonymity possible in this scenario. It turns out that we can
still protect the identity of all senders (authorized or not) if we shift our concern from preventing
the identity information be revealed to the recipient to preventing it could be revealed to an external
entity, other than the recipient. We deﬁne a natural functionality which provides such guarantees and
we denote it by Feaa for externally anonymous authenticated channel.
We argue that any realization of Feaa must be deniable in the sense of Dodis et al. TCC 2009. To prove
the deniability of similar primitives, previous work deﬁned ad hoc notions of deniability for each task,
and then each notion was showed equivalent to realizing the primitive in the Generalized Universal
Composability framework (GUC, Canetti et al. TCC 2007).
Instead, we put forward the question of
whether deniability can be deﬁned independently from any particular task. We answer this question in
the aﬃrmative providing a natural extension of the deﬁnition of Dodis et al. for arbitrary multiparty
protocols. Furthermore, we show that a protocol satisﬁes this deﬁnition if an only if it realizes the ideal
functionality Fden in the GUC framework. This result enables us to prove that most GUC functionalities
we are aware of (and their realizations) are deniable.
We conclude by applying our results to the construction of a deniable protocol that realizes Feaa.

1 Introduction

Consider an online forum where users can post sensitive data on a server and may be concerned
about being linked to their posts – a health forum, for example. In order to organize posts by relevance,
 the server may want to rank posts according to user reputation, which we assume is measured
by some arbitrary number. Arguably, the forum’s owners would like to implement an anonymous
authentication protocol [2], where users can be authenticated to a server while maintaining their
anonymity.

In the typical solution to the anonymous authentication problem “the authentication protocol
carried out between the user and the server does not identify the user” [2]. Instead, the server
veriﬁes that the user belongs to some authorized group, such as the group of users with the same
reputation. But what if the reputation is suﬃciently “ﬁne grained”? On the worst case, if each
user has a diﬀerent reputation level then the authorized group is of size 1. In such a case, it is
unavoidable that the server will learn the user’s identity. Even worse, any party may learn the
user’s identity since the security notion does not rule out public veriﬁcation of the authentication
process. Clearly, anonymous authentication does not suﬃce for our goal.

Can we still provide some meaningful form of anonymity for the user? It turns out that the
answer to this question is positive if we are willing to consider a diﬀerent form of anonymity.

Suppose we are no longer concerned about whether the server would identify the user but whether
an eavesdropper – or any party other than the server – can be certain that a given user indeed
participated. Moreover, we would like to preserve anonymity even in the case the server is malicious
and may use any strategy to prove to the external party that the given user indeed participated
in the protocol. We seek guarantees that no such server can succeed and call this goal externally
anonymous authentication (EAA). More precisely, an EAA protocol should satisfy the following
two requirements

Secure authentication: No user should be able to fool the server about its identity (except with

very small probability).

External anonymity: Users can not be linked to their messages by parties other than the server,

even when the server is malicious.

Yet, rigorously formalizing the above is tricky. In order to gain some intuition, it is helpful to abstract 
the desired properties using a “functionality” such as those used in secure function evaluation
deﬁnitions [29]. A good starting point is the functionality for ideally authenticated channels Fauth [4],
which allows a sender S to transmit an authenticated message to a receiver R. The functionality
is essentially Fauth(m) = (m, m), where the input is given by S, the ﬁrst output is R’s output, and
the second output is the adversary’s output. In our multiparty setting, with users P1, P2, . . . , Pn
and server S, it becomes Fauth(m1, m2, . . . , mn) = ((m1, m2, . . . , mn), (m1, m2, . . . , mn)). Certainly,
Fauth provides secure authentication but no anonymity. In order to provide anonymity, we must hide
the parties identities. We do so by setting the adversary’s output to the lexicographically sorted
list Sort(m1, m2, . . . , mn). Consequently, the semantics of the EAA primitive can be captured by

Feaa(m1, m2, . . . , mn) def= ((m1, . . . , mn), Sort(m1, . . . , mn)) .

The fact that the server’s output contains a message m in the i-th position is not a proof of the
participation of the i-th user since the server’s output can be produced without the participation of
i-th user.
This last property of Feaa is captured by the concept of deniability (originally put forward by
Dwork et al. [16] and reﬁned by Dodis et al. [11, 13]). Roughly speaking, a protocol is deniable if
the server nor any other participant can prove that a particular party participated in the protocol.
Can we realize Feaa with some protocol π while preserving deniability? Here the cryptographic
framework where security is proven becomes crucial. Indeed, it has been shown that a proper
framework needs to be used in order to preserve deniability [6, 11, 14, 22]. In fact, the Generalized
Universal Composability (GUC) framework from Canetti et al. [6] was speciﬁcally proposed to
preserve deniability, although this work does not formalize a “general” notion for this concept.

So far, it has been shown that the GUC framework captures deniability only for speciﬁc tasks,
via the following approach: Given a task T , deﬁne a deniability experiment for T and then show
that a protocol satisﬁes this experiment if and only it realizes the ideal functionality for T in the
GUC framework. This approach have been successfully done for authentication and key exchange
by Dodis et al. [11], and for zero-knowledge by Dodis et al. [13].

Defining Deniability for Arbitrary Multiparty protocols: Instead of repeating the previous 
approach for external anonymous authentication, we put forward the question of whether
deniability can be deﬁned independently from any particular task. We answer this question in the
aﬃrmative by providing a natural extension of the deﬁnition of Dodis et al. for arbitrary multiparty
protocols.

2

To gain some intuition on our deﬁnition, we recall (a simpliﬁed version of) the deniable zeroknowledge 
deﬁnition of Dodis et al. [13]. There, a prover P proves a true statement x to a veriﬁer
V in a setting where both of them are part of a network environment which includes some trusted
parties or setup (for example, PKI). Now, let π be a protocol that implements a deniable zeroknowledge 
proof from P to V . The protocol is required to be complete, sound, and zero-knowledge.
According to Dodis et al. a protocol π is an online deniable zero-knowledge protocol if, when x ∈ L,
it can be simulated only with access to the statement x and the public information of trusted parties,
but without participation of P nor V .

Interestingly, even if one abstracts out the properties which are speciﬁc to the zero-knowledge
task (completeness, soundness, and zero-knowledge), we still get a meaningful security property.
Namely: “A protocol π is deniable if and only if it can be simulated given only its inputs and public
information, but without participation of any honest party. ”

Note that neither correctness nor privacy are required from a protocol with this property, and
therefore, a protocol achieving it might be trivial to construct. But, in that case, the protocol will
probably not realize any interesting task. Deniable protocols become interesting when they also
realize some non-trivial functionality.

We formalize online deniability by proposing an experiment – similar to the one by Dodis
et al. [11, 14] – which, contrarily to those works, does not require privacy nor correctness. We show
that an arbitrary multiparty protocol satisﬁes our deniability deﬁnition if an only if it realizes a
ﬁxed ideal functionality Fden in the GUC framework. Since a functionality is a special case of a
protocol, this result also enables us to prove that most GUC functionalities we are aware of (and
their realizations) are deniable. Yet, not all the functionalities are deniable, as we discuss below.

We gain further conﬁdence in our deﬁnition by noting that a similar characterization of Bi-deniability 
in the LUC framework [9] can be captured with the LUC equivalent of Fden. In the process,
we take the opportunity to correct a small mistake in their notion, as we explain in next section.

The Non-Triviality of Our Definition of Deniability:
there are
protocols that cannot be deniable. Consider one that uses a UF-CMA public-key signature scheme
[18] where a signature for an honest user and her veriﬁcation key are public, cannot be deniable
– any simulation from the inputs only will contradict the UF-CMA property. On the other hand,
the protocols proposed in [11, 13] can be shown deniable under our deﬁnition. This provides some
support to our characterization. If we consider functionalities, on the other hand, the landscape
is not so clear. One functionality that appears to be not deniable is Fkeia [11]. Whether we can
characterize the class of meaningful non-deniable functionalities is an interesting open problem.

It is easy to see that

An external anonymous authentication protocol: We conclude applying the deﬁnitional
tools to our motivating problem. Concretely, we formulate a (not simpliﬁed) functionality for externally 
anonymous authenticated channel Feaa, and we show that there is a simple yet eﬀective
construction. Our construction combines an anonymous channel and the deniable authentication
protocol secure against static adversaries of Dodis et al. [11] with some modiﬁcations. We prove
that our construction is secure under the Decisional Diﬃe-Hellman (DDH) assumption. A technical
byproduct of this proof is an improved bound on the reduction from the so-called Multi Decisional
Diﬃe Hellman (Multi-DDH) to DDH. This result may be of independent interest.

3

1.1 Related Work

Deniability, Offline and Online: Deniable authentication was ﬁrst deﬁned by Dwork et al.
in their seminal work on Concurrent Zero-Knowledge [16]. Later, Dodis et al. reﬁned the notion,
introducing the concept of online deniability. They deﬁne and study the concept in the context of
authentication, identiﬁcation, and Key Exchange [11], and Zero Knowledge [14]. They showed that,
for each of these tasks, deniability is equivalent to GUC-realizing the corresponding ideal functionalities.
 As consequence, their deﬁnition implies security under general concurrent composition.

Several protocols that achieve deniability exist for diﬀerent tasks: deniable authentication and
identiﬁcation (e.g. [11, 15–17, 21, 23, 24]), deniable key exchange (e.g. [25, 28]), and deniable zero
knowledge [14, 22]. All of them, however, fall in one of the two categories: (oﬄine) deniable and
online-deniable. Most of the protocols proposed before [11, 14] are oﬄine deniable (with the sole
exception of HMQV [24] as noted by Dodis et al. [11]). In our work, we focus on the strictly stronger
requirement of online deniability.

Online Deniable Authentication: Dodis et al. presented an online-deniable authentication
with respect to static adversaries [11]. They also showed the impossibility of the same task with
respect to adaptive adversaries. Our paper builds on these results, ﬁrst by using a modiﬁed version
of their protocol as the underlying authentication procedure in our anonymous authentication
protocol, and second, by restricting our adversarial model to static adversaries.

Anonymous Authentication: Most work on the anonymous authentication literature relies on
ring signatures in order to make the user identify anonymously as member of an authorized group
[2, 12, 20]. Unfortunately, ring signatures cannot provide meaningful anonymity guarantees when
the ring size is one. Naor also proposed the notion of deniable ring signatures which combines
deniability and ring signatures [21]. However, as noted by Dodis et al., Naor’s protocol cannot be
online deniable as long as veriﬁers do not register public keys [11]. We also note that, in our setting,
deniable ring signature do not necessarily provide anonymity among users of diﬀerent rings (in our
example users with diﬀerent reputations).

Bi-Deniability and Deniable Encryption: Canetti and Vald [9, 10] introduced the notion of
Bi-Deniability with many similarities to the deﬁnition of deniability of Dodis et al. [11] as well as
to the one of our work. Their deﬁnition is motivated by a diﬀerent problem (capturing collusionfreeness 
and game-theoretic solution concepts) in a UC variant called Local Universal Composability

(LUC). They showed that a two-party protocol is Bi-Deniable if and only if it LUC-realizes Fauth,

the LUC authentication functionality (deﬁned in [9, 10]).

Unfortunately, there is a minor technical issue in their result that we discovered when comparing

their notion with ours. Functionality Fauth requires a speciﬁc correctness property: if the sender

provides m to the protocol, the receiver receives the same m. This is not the case in other deniable
protocols (zero-knowledge for example) so the their proposed characterization is incorrect. We

conclude that the right characterization is not Fauth but Fden, the LUC version of our Fden. A more

detailed description of the problem and a way to patch this issue is discussed in the full version of
this work.

Another meaning for deniability is that of deniable encryption (e.g. [7]). A deniable encryption
scheme must allow the receiver (or the sender) to deny that the content of a ciphertext is a given
plaintext. In contrast, in our deﬁnition an encryption scheme E is essentially deniable if a party
executing E can deny at all that the execution is taking place.

4

Simplifying Constructions: Ishai et al. [19] introduced an anonymity functionality Anon (which
provides sender and receiver anonymity) in order to construct secure channels from anonymous
channels. Interestingly, our ideal functionality for anonymous authenticated channels Feaa can be
used to signiﬁcantly simplify their construction. Due to space restrictions, we defer this discussion
to the full version of this work.

1.2 Our Contribution

In this work, we deﬁne the concept of online deniability independently of any speciﬁc task. We also
provide an alternative characterization by showing that a protocol is online deniable if and only if it
GUC realizes a given ideal functionality Fden. We note that this result also applies to Bi-deniability
in the LUC framework [9, 10].

We extend the characterization of deniable protocols (and functionalities) by showing that
most ideal functionalities are deniable. Our result implies all previous results on deniability we are
aware of: deniability for GUC-secure Zero Knowledge protocols [13, Thm.8], deniability for GUCsecure 
authentication [11, Prop.1], and deniability of GUC-secure key exchange and identiﬁcation
from [11].

Finally, we apply our results on deniability to realize the functionality that motivated this work,
which combines anonymous and authenticated channels. To prove the security of the protocol,
we use the fact that the Multi-Decisional Diﬃe-Hellman (Multi-DDH) assumption follows from the
Decisional Diﬃe-Hellman (DDH) assumption [3]. In the process, we give an improved bound on the
Multi-DDH vs. DDH relation: the tightness of our reduction is linear compared to quadratic from
the best known result [3].

1.3 Organization

We brieﬂy review UC and GUC frameworks in Section 2. We then deﬁne deniability, provide a
characterization of deniable protocols on Section 3. Finally, in Section 4, we conclude by deﬁning
an ideal functionality for externally anonymous authenticated channel Feaa, designing a protocol
for it, and formally proving it GUC realizes Feaa in the ¯Gkrk-hybrid model.

2 Preliminaries

Model: We deﬁne and prove the security guarantees of our protocol in the Generalized Universal
Composability (GUC) framework as described in [6]. We also use GUC to provide an alternative
characterization of deniability. Since GUC is a generalization of the Universal Composability (UC)
framework [5], we brieﬂy and informally outline both of them here. A more detailed exposition can
be found in [4, 5] for UC and [6, 26] for GUC.

The Universal Composability framework (UC): In the UC framework, the desired properties 
of cryptographic protocols are deﬁned in terms of tasks or functionalities. A functionality is a
“trusted third party” that obtains inputs directly from the parties, performs certain instructions on
these inputs, and provides the appropriate outputs back to the parties. A protocol securely implements 
a given cryptographic task if running the protocol against a realistic (i.e. real-life) adversary
“emulates” the execution of an ideal process. In the ideal process, the task is computed by the
trusted party directly interacting with the parties against a very limited adversary called the ideal

5

adversary. The notion of “emulation” involves a distinguisher Z which not only provides the inputs
to the parties and sees their outputs but also interacts with the adversary, with the goal of telling
whether it is interacting with a real protocol and the real-life adversary, or with the functionality
and the ideal-adversary. Good emulation means no such environment is successful. See details and
proofs in [5]. We denote EXECZ,A,π(k) the distribution of the output of environment Z when executed 
with adversary A, protocol π, and security parameter k. If the protocol assumes the presence
of some functionalities F1, . . . ,Fm, the output of the environment is denoted by EXEC
(k)
or simply EXEC
, when considering the associated family of distributions. Similarly, in the
ideal world, the output of Z executed with S and the ideal protocol with functionality F is denoted
EXECF

F1,...,Fm
Z,A,π

F1,...,Fm
Z,A,π

Z,S,IDEALF .

The main advantage of UC security is that it composes, that is, the security of any protocol is
maintained even when the protocol is being executed concurrently with other, possibly adversarially
chosen, protocols. But there is a restriction, the protocol must be subroutine respecting. This
means that the protocol itself and all its subroutines do not provide any input or output to any other
protocol. In other words, the protocol and the subroutines called by the protocol are independent
of all other protocols and cannot share state with other protocols.

The Generalized UC framework (GUC): A UC-secure protocol must be subroutine respecting,
otherwise the UC-theorem may not be true. Furthermore, a subroutine respecting protocol is
unrealistic when setup assumptions are required (which is the case of more interesting functionalities
[8]), as noted by Canetti et al.
In the GUC framework [6], subroutine respecting protocols are extended so they can be ¯Gsubroutine 
respecting: protocols can be subroutine respecting except that are allowed to call the
shared functionality ¯G. The GUC framework models ¯G-subroutine respecting protocols by allowing
the environment to impersonate dummy parties connected to the shared functionality. This small
change lets the environment simulate protocols that share state with the analyzed protocol.

[6].

The deﬁnitions of execution and emulation in GUC are almost identical to those of UC but
notation changes. From now on, we denote by EXEC both the UC-execution as well as the GUCexecution,
 and by UC-emulation we also refer to GUC-emulation. Analogously to UC, it is possible
to prove a composition theorem for ¯G-subroutine respecting protocols.

3 Online Deniability

In this section, we generalize the notions of deniability for speciﬁc tasks available in the literature,
namely online authentication deniability, online deniable key-exchange [11], and online deniable
zero-knowledge [13], to any task. We call our deﬁnition simply online deniability. Our deﬁnition
follows that in [11, 13] but it does not require correctness nor privacy.

The lack of correctness implies that, from a deﬁnitional standpoint, we do not commit to any
speciﬁc correctness property. In contrast, in deniable authentication an honest receiver is required
to output the same message sent by an honest sender. Similarly, in deniable zero-knowledge, both
completeness and soundness are required. The lack of privacy implies that we do not guarantee any
privacy property in a deniable protocol, in contrast to deniable zero-knowledge where the witness
remains hidden to any other party than the prover.
The Players: We consider a judge J , an informant I, misinformant M, and a global setup
functionality ¯G. Also, we assume there are parties P1, . . . , Pn running an arbitrary distributed

6

protocol π.1 All parties can communicate with a shared functionality ¯G (which may model, for
example, availability of a PKI) or with I. The entities J , I and M have also access to the public
interface of ¯G, and also to the secret interface but only in the case of corrupted parties.
The Real World: In the real world, the ﬁrst entity activated is the judge J . It then activates
I while providing I with the input of each party participating in π. Upon activation, party I
forwards (possibly diﬀerent) inputs to the actual parties, witnesses (monitors) the execution of
protocol π, and interact with J (possibly sending evidence that an execution of π is taking place).
The informant I can adaptively corrupt parties if instructed by J . When it does so, the entire
internal state of the corrupted party is revealed to I, who takes control of the corrupted party.
Finally, at some point of the execution J is activated, outputs a single bit and halts. Given an
J ,I,π(k) the output of J executed in the
¯G
integer k, the security parameter, we denote by RealDen
real world with informant I, shared functionality ¯G, and protocol π.
The Simulated World: In the simulated world, J is the ﬁrst party activated. Then it activates
M with the inputs of each party. Contrarily to the real world, in the simulated world honest parties
cannot be activated by M, and thus actual parties never executes the protocol π. Nonetheless, M
is also able to adaptively corrupt parties. Corruption works exactly as in the real world. Finally, at
some point of the execution J is activated, outputs a single bit and halts. Given an integer k, the
J ,M(k) the output of a judge J executed in the simulated
¯G
security parameter, we denote by SimDen
world with misinformant M, and setup functionality ¯G.
Deﬁnition 1. Let π be an arbitrary ¯G-subroutine respecting multiparty protocol. We say that protocol 
π is online deniable if for all judge J and all informant I there exists a misinformant M
such that RealDen

J ,I,π ≈ SimDen
¯G

¯G
J ,M.

3.1 Online deniability in GUC

We now show that deniability in the real world can be seen as a syntactic transformation of the
GUC real world experiment – any environment and adversary can be simulated with a judge and
an informant, and vice versa. The proof is in Appendix A.1.
Lemma 1. For each judge J and for each informant I there exists an environment ZJ and an adversary 
AI such that for all protocol π executed in the ¯G-hybrid model RealDen
¯G
ZJ ,AI ,π.
Conversely, for all environment Z and for all adversary A there exists a judge J Z and an informant
IA such that EXEC
Z,A,π ≡ RealDen
¯G

J ,I,π ≡ EXEC
¯G

¯G
J Z ,IA,π

The functionality Fden, deﬁned in ﬁgure 1, provides all the necessary information to run a
misinformant, and thus a simulator can perfectly simulate the misinformant. We now show a result
equivalent to the one in [11].
Theorem 1. A ¯G-subroutine respecting protocol π is online deniable if and only if it GUC-realizes
the ideal functionality Fden in the ¯G-hybrid model.
1 Also, we allow algorithm J to take an auxiliary input z ∈ {0, 1}∗ and to run in polynomial time with respect
to |z| and k. Similarly, due to some technicalities, we require the informant and misinformant to be probabilistic
polynomial time in the sense of UC adversaries [4, version 2013].

7

The ideal functionality Fden running with parties ˜P1, . . . , ˜Pn proceeds as follows:
1. When xi is received from party ˜Pi, send (Input, ˜Pi, x) to the adversary S.
2. When (Output, ˜Pi, y) is received from the adversary S, send y to ˜Pi.

Fig. 1. The ideal functionality Fden

Proof. We ﬁrst prove the ﬁrst implication, namely: if π is online deniable then π GUC-emulates
Fden. Let Z be an environment and A be an adversary. By lemma 1, there exists a judge J Z that
simulates Z such that RealDen
¯G
Z,A,π. By deniability of π, there exists a misinformant
M such that
SimDen
security parameter.

(cid:105)(cid:12)(cid:12)(cid:12) = , where  is negligible in the

(cid:104)
J Z ,IA,π ≡ EXEC
¯G

(cid:105)− Pr

¯G
J Z ,IA,π = 1

¯G
J Z ,M = 1

(cid:12)(cid:12)(cid:12)Pr

RealDen

(cid:104)

The ideal adversary SM with access to the ideal functionality Fden proceeds as follows:
1. Simulate M.
2. When (Input, ˜Pi, x) is received from Fden, send ( ˜Pi, x) to M.
3. When M sends ( ˜Pi, y), send (Output, ˜Pi, y) to Fden.
4. When M corrupts party Pi, party ˜Pi is corrupted and the internal state of ˜Pi is revealed to M.
5. When x is received from Z, send x to M.
6. When x is received from M, send x to Z.

Fig. 2. The ideal adversary SM

Consider now the ideal adversary SM, with (oracle) access to M, as deﬁned in ﬁgure 2. Note that
, Z is “hardwired” with M. The only diﬀerence is

¯G,Fden
Z,SM,IDEALFden

¯G
in both, SimDen
J Z ,M and EXEC
¯G,Fden
Z,SM,IDEALFden

(cid:104)

(cid:12)(cid:12)(cid:12)Pr

(cid:105) − Pr

(cid:104)

¯G
that in EXEC
J Z ,M the
inputs are forwarded from J Z to the parties by M. In both cases the input given to each party is the
¯G,Fden
same, and consequently the view of Z is the same. Therefore SimDen
,
Z,SM,IDEALFden

the inputs are directly given by Z to the parties, but in SimDen

J Z ,M ≡ EXEC
¯G

(cid:105)(cid:12)(cid:12)(cid:12) = . Therefore, π GUC-emulates

EXEC

EXEC

which implies that
Fden.
The other direction is similar. Suppose that π GUC-emulates Fden in the ¯G-hybrid model. Let
J be a judge and I be an informant, by lemma 1 there exists an environment ZJ and an adversary
ZJ ,AI . By hypothesis there exists a simulator S such that the
AI such that RealDen
¯G
advantage of ZJ distinguishing between π and Fden is negligible. Similarly to the ﬁrst implication,
a misinformant MS can simulate S for J . This is indistinguishable from I to J , and therefore π
is online deniable.

J ,I,π ≡ EXEC
¯G

¯G,Fden
Z,SM = 1

¯G
Z,A,π = 1

A Sufficient Condition for Online Deniability: It seems that deniability is a concern not
important per se, it becomes important when one wishes it to be added to some existent task,
say, GUC-realizing some functionality F. It appears that a large class of functionalities are indeed
deniable (Fauth and Fzk are examples). Indeed, this is simply a consequence of the fact that most
ideal functionalities are subroutine respecting.

8

Corollary 1. Let π be a subroutine respecting protocol, then π is online deniable. Furthermore, if
ρ is ¯G-subroutine respecting but only have access to the public interface of ¯G (that is the interface
that is accessible by the adversary), then ρ is also online deniable.

Proof. The view of a subroutine respecting protocol is completely determined by its inputs and
randomness, thus π can be perfectly simulated only with access to the inputs returned by Fden.
Thus π GUC-emulates Fden and, by Theorem 1, π must be deniable. Clearly, this simulation can
easily be extended to the case the protocol requires access to the shared functionality ¯G so the
adversary only sees the public interface.

By the transitivity of the GUC-emulation relation, we remark that a proof that a protocol GUCrealizes 
some deniable ideal functionality also implies that the protocol is deniable.

4 Externally Anonymous Authenticated Channels
4.1 The Feaa ideal functionality

An “anonymous authenticated channel” should allow parties to send authenticated messages to
any other party without revealing their identities to anyone except the receiver. Since the receiver
knows the sender identity, we call this variant external anonymity. We formally deﬁne an externallyanonymous 
authenticated channel via an ideal functionality called Feaa (ﬁg. 3) which requires the
shared functionality ¯Gkrk (ﬁg. 5). Note that the functionality Feaa reveals just the value of each
sent message to the adversary but not the identities related to those messages. This holds while
the receiver of the message is not corrupt – but even in that situation the information revealed by
Feaa is completely simulatable by any one. This holds because functionality Feaa is indeed online
deniable, guaranteed by corollary 2.

Functionality Feaa parameterized by an integer κ, running with shared functionality ¯Gkrk, parties P1, . . . , Pn, and
adversary S, proceeds as follows.
Initialization: Initialize multisets Mj ← ∅ for each j ∈ {1, . . . , n} and M ← ∅.
Message reception: Suppose (Send, m, j) is received from ˜Pi, do:

1. If ˜Pi or ˜Pj are not registered in ¯Gkrk or i = j, then send ⊥ to ˜Pi.
2. Else, send (Sent, ˜Pi) to S and (Sent, m, j) to ˜Pi, and let Mj ← Mj (cid:93) {(m, i)} and M ← M (cid:93) {m} honest.
Message delivery: Once that |M| = κ, for each j ∈ {1, . . . , n} send (Messages, Mj) to ˜Pj, and send (Messages, M )
to S.

Fig. 3. The ideal functionality Feaa

The integer κ statically ﬁxes the number of exchanged messages per session. We include this
parameter in order to deﬁne a condition that triggers the delivery of messages. In order to realize
Feaa, we will require that the underlying anonymity functionality also ﬁxes the number of exchanged
messages per session to κ.
Note that Feaa requires that senders and receivers have been registered on ¯Gkrk. This condition
means that registration on ¯Gkrk is required but not provided by Feaa.
Corollary 2. The functionality Feaa is online deniable.

9

Proof. Note that Feaa is ¯Gkrk-subroutine respecting, but all information needed from ¯Gkrk is whether
or not a party is registered. Certainly, this information is public and thus Feaa is online deniable
as consequence of Corollary 1.

4.2 Primitives and setup assumptions
In order realize Feaa, we require an anonymous channel functionality Fanon and a global PKI
modeled by the shared functionality ¯Gkrk.

Anonymous Channels: Anonymous channels allow users to exchange messages without revealing
their identities. We deﬁne an anonymous channel functionality Fanon in ﬁg. 4. We note that Fanon
can be realized, for example, using the universal composable mixnet proposed by Wikstr¨om [27].

The Ideal functionality Fanon, parameterized by an integer κ, running parties P1, . . . , Pn, and ideal adversary S
1. Initialize a list L ← ∅.
2. When (Send, m) is received from Pi, append m to the list L. Then, hand (Pi, Sent) to S.
3. Once that |L| = κ, sort the list L lexicographically to form a list L(cid:48), and hand (Output, L(cid:48)) to S and to Pi, for

i = 1 to k.

Fig. 4. The functionality Fanon.

The Key Registration with Knowledge Functionality: In this section, we recall the Φ-Key
Registration with Knowledge Functionality [11]. We require that honest parties retrieve secrets keys
only using our protocol SIGMIX, deﬁned in Sect. 4.4. In other words, Φ = {SIGMIX}.

Parameterized by a security parameter λ, a protocol (or, more generally, a list of protocols) Φ, and a (deterministic)
key generation function Gen, shared functionality ¯Gkrk proceeds as follows when running with parties P1, . . . , Pn:

Registration: When receiving a message (Register) from an honest party Pi that has not previously registered,

sample r R← {0, 1}λ then compute (P Ki, SKi) ← Genλ(r) and record the tuple (Pi, P Ki, SKi).
registered, compute (P Ki, SKi) ← Genλ(r) and record the tuple (Pi, P Ki, SKi).

Corrupt Registration: When receiving a message (Register, r) from a corrupt party Pi that has not previously

Public Key Retrieval: When receiving a message (Retrieve, Pi) from any party Pj (where i = j is allowed), if
there is a previously recorded tuple of the form (Pi, P Ki, SKi), then return (Pi, P Ki) to Pj . Otherwise return
(Pi,⊥) to Pj .

Secret Key Retrieval: When receiving a message (RetrieveSecret, Pi) from a party Pi that is either corrupt or
honestly running the protocol code for Φ, if there is a previously recorded tuple of the form (Pi, P Ki, SKi) then
return (Pi, P Ki, SKi) to Pi. In all other cases, return (Pi,⊥).

Fig. 5. The Φ-Key Registration with Knowledge shared functionality [11].

4.3 Realizing Feaa
A ﬁrst attempt to realize Feaa is to combine Fanon with the GUC-secure authentication protocol
with respect to static adversaries of Dodis et al. [11]. In their protocol, Pi sends an authenticated
message m to Pj by attaching a MAC σ = MACki,j (m). The symmetric shared secret key ki,j = kj,i

10

can be non interactively computed by Pi using Pj’s public key and Pi’s secret key (both keys
registered in ¯Gkrk), and it can be also computed by Pj with Pi’s public key and Pj’s secret key.
Note that a corrupted receiver Pj may not convince a third party about the identity of the sender
of (m, σ). Indeed, given that the key ki,j used to produce σ can also be produced by Pj, (m, σ) can
be obtained without participation of Pi when Pj is corrupted.

We will argue that this approach fails. First, note that nothing in the security deﬁnition of
a MAC (UF-CMA) prevents the existence of an algorithm Check which, given two MACs values
σ = MACk(m) and σ(cid:48) = MACk(cid:48)(m(cid:48)), returns 1 if and only if k = k(cid:48).2
Fix an execution where party P1 sends 0||σ1 = MACk1,2(0) to P2 and then P2 sends 1||σ2 =
MACk1,2(1) to P1. By anonymity, the only information leaked to the adversary should be the set of
sent messages {0, 1} and the fact that P1 sent a message and then P2 sent another message. The same
information is leaked in a similar execution with the only exception that P2 sends 1||σ2 = MACk1,3(1)
to another party P3. An adversary can distinguish these executions by executing Check(σ1, σ2); in
the ﬁrst execution it should return 1 and in the second 0.

We ﬁx this problem by attaching to the message m the evaluation of a Variable Input-Pseudo
Random Function (VI-PRF) [1] Eki,j on m. Therefore, if Pi wants to anonymously send an authenticated 
message m to Pj, Pi simply anonymously sends m||σ where σ = Eki,j (m). Note that now
the simulator is no longer concerned about the keys used to generate σ; it can generate σ by simply
picking a fresh random value. Unfortunately, this simulation procedure will be only successful if the
same message is never sent twice to the same receiver. Indeed, if the same message is sent twice to
the same receiver, the simulator can not decide whether to attach the same random value twice or
two independently chosen random values.

We can easily get rid of this assumption requiring the senders to attach a random nonce to each
message, and requiring the receivers to never accept the same message from the same receiver. 3
Note that in a real implementation, this can be also achieved by attaching, for example, the current
time to each message.

4.4 The SIGMIX protocol
The SIGMIX protocol runs in the Fanon, ¯Gkrk-hybrid model and with static adversaries. We ﬁx the
key generation algorithm Gen of ¯Gkrk with an algorithm that, using randomness r, sample a random
element x from Zq and return the pair (gx, x), where g is the generator of a cyclic group Gq of
order q. It is stressed that any other protocol using ¯Gkrk might share public keys with SIGMIX. We
consider the functionality Fanon as a traditional UC ideal functionality, meaning that each instance
of Fanon is local to each calling protocol.

The SIGMIX protocol is described in ﬁgure 6.

4.5 Proof of security

Before we prove the security of SIGMIX, we bound the relation between the hardness of the Multi
Decisional Diﬃe-Hellman assumption and the (standard) Decisional Diﬃe-Hellman assumption [3].

2 Such a scheme can be easily constructed in the Random Oracle Model. Simply attach H(k) to the MAC, i.e.
k(m) = H(k)||MACk(m). The value H(k) does not help a forger to break MAC(cid:48) as long as H(k) is a random
MAC(cid:48)
value independent from k. Given two MACs h||σ = H(k)||MACk(m) and h(cid:48)||σ(cid:48) = H(k(cid:48))||MACk(cid:48) (m(cid:48)), the algorithm
Check returns 1 if and only if h = h(cid:48).
3 In the proof of security we make a stronger requirement to simplify the proof. However, using a random nonce also

allows us to get rid of this stronger assumption.

11

The protocol SIGMIXκ, running with parties P1, . . . , Pn in the Fanon, ¯Gkrk-hybrid model, proceeds as follows:

Sender Pi: Each sender Pi and proceeds as follows:

1. Wait for input (Send, m, j).
2. If Pi or Pj are not registered on ¯Gkrk, or i = j, return ⊥. Compute ki,j ← yxi
3. Hand (Send, m||σ) to Fanon and return (Sent, m, j).

xi is Pi’s secret key and yj is Pj’s public key.

j , and compute σ ← Eki,j (m), where

Receiver Pj: Each receiver Pj proceeds as follows:
1. Wait for an input (Output, L) from Fanon.
2. Retrieve y1, . . . , yn, the public keys of all parties participating in the protocol, and retrieve xj, Pj’s secret key,
, otherwise ki,j ←⊥.
3. Let the multiset Mj ← ∅. For each i ∈ {1, . . . , n} and each (m||σ) ∈ L, if ki,j (cid:54)=⊥ and σ = Eki,j (m), then

from ¯Gkrk. For each i ∈ {1, . . . , n}, if yi (cid:54)=⊥ and xj (cid:54)=⊥ compute the shared secret ki,j ← yxj
Mj ← Mj (cid:93) {(m, i)}. Return (Messages, Mj).

i

Fig. 6. The protocol SIGMIX.

Proposition 1. Let Gq be a cyclic group where the DDH assumption holds, then the Multi-DDH
assumption also holds, that is: ({gxi}n
i=1,j>i), where xi ∈R Gq,
ri,j ∈R Gq for all i and j. Speciﬁcally, for each adversary D attacking Multi-DDH there exists an
adversary D(cid:48) attacking DDH such that n · AdvDDH

(k) ≥ AdvMDDH

i=1,{gxixj}n

i=1,j>i)

c≈ ({gxi}n

i=1,{gri,j}n

(k).

D(cid:48)

D

This linear bound on the advantages is tighter than the quadratic bound given in [3] which, to
the best of our knowledge, is the best bound known for Multi-DDH. The proof is in Appendix A.2.
The security of SIGMIX is guaranteed by the following theorem which is proven in Appendix A.3.
Theorem 2. Suppose that E : {0, 1}k × {0, 1}∗ → {0, 1}t is a VI-PRF and that DDH holds in
Gq, then SIGMIX GUC-realizes the ideal functionality Feaa in the ¯Gkrk-hybrid model with respect to
environments and adversaries that do not play replay attacks. Concretely, let n be the number of
participants and k the security parameter of an execution of SIGMIX. Then, for all environment Z
and for all adversary A there exist a simulator S, a DDH distinguisher DDDH, and a distinguisher
DPRF such that for all k large enough

EXEC

EXEC

¯Gkrk,Fanon
Z,A,SIGMIX(k) = 1
¯Gkrk,Feaa
Z,S,IDEALFeaa

(k) = 1

(cid:105)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:105)−

n · AdvDDHDDDH

(k) + (κ + 1)AdvPRF

E,DPRF

(k) +

κ

2t ≥

References

(cid:104)
(cid:104)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Pr

Pr

1. M. Bellare, R. Canetti, and H. Krawczyk. Pseudorandom functions revisited: The cascade construction and its

concrete security. In FOCS, pages 514–523. IEEE Computer Society, 1996.

2. D. Boneh and M. Franklin. Anonymous authentication with subset queries. In 6th ACM Conference on Computer

and Communications Security (CCS ’99), pages 113–119, New York, Nov. 1999. ACM Press.

3. E. Bresson, O. Chevassut, and D. Pointcheval. Dynamic group diﬃe-hellman key exchange under standard
assumptions. In Proceedings of the International Conference on the Theory and Applications of Cryptographic
Techniques: Advances in Cryptology, EUROCRYPT ’02, pages 321–336, London, UK, UK, 2002. Springer-Verlag.
4. R. Canetti. Universally composable security: A new paradigm for cryptographic protocols. Cryptology ePrint

Archive, Report 2000/067, 2000.

5. R. Canetti. Universally composable security: A new paradigm for cryptographic protocols. In B. Werner, editor,
Proceedings of the 42nd Annual Symposium on Foundations of Computer Science (FOCS-01), pages 136–147,
Los Alamitos, CA, Oct. 14–17 2001. IEEE Computer Society.

12

6. R. Canetti, Y. Dodis, R. Pass, and S. Walﬁsh. Universally composable security with global setup.

In S. P.

Vadhan, editor, TCC, volume 4392 of Lecture Notes in Computer Science, pages 61–85. Springer, 2007.

7. R. Canetti, C. Dwork, M. Naor, and R. Ostrovsky. Deniable encryption. In B. S. Kaliski Jr., editor, Advances in
Cryptology—CRYPTO ’97, volume 1294 of Lecture Notes in Computer Science, pages 90–104. Springer-Verlag,
17–21 Aug. 1997.

8. R. Canetti, E. Kushilevitz, and Y. Lindell. On the limitations of universally composable two-party computation
without set-up assumptions. In E. Biham, editor, EUROCRYPT, volume 2656 of Lecture Notes in Computer
Science, pages 68–86. Springer, 2003.

9. R. Canetti and M. Vald. Universally composable security with local adversaries. In I. Visconti and R. D. Prisco,

editors, SCN, volume 7485 of Lecture Notes in Computer Science, pages 281–301. Springer, 2012.

10. R. Canetti and M. Vald. Universally composable security with local adversaries. Cryptology ePrint Archive,

Report 2012/117, 2012. http://eprint.iacr.org/.

11. Y. Dodis, J. Katz, A. Smith, and S. Walﬁsh. Composability and on-line deniability of authentication.

In
O. Reingold, editor, Theory of Cryptography, 6th Theory of Cryptography Conference, TCC 2009, San Francisco,
CA, USA, March 15-17, 2009. Proceedings, volume 5444 of Lecture Notes in Computer Science, pages 146–162.
Springer, 2009.

12. Y. Dodis, A. Kiayias, A. Nicolosi, and V. Shoup. Anonymous identiﬁcation in ad hoc groups. In C. Cachin
and J. Camenisch, editors, EUROCRYPT, volume 3027 of Lecture Notes in Computer Science, pages 609–626.
Springer, 2004.

13. Y. Dodis, V. Shoup, and S. Walﬁsh. Eﬃcient constructions of composable commitments and zero-knowledge

proofs. 2008. http://www.shoup.net/papers/gucc.pdf.

14. Y. Dodis, V. Shoup, and S. Walﬁsh. Eﬃcient constructions of composable commitments and zero-knowledge
proofs.
In D. Wagner, editor, Advances in Cryptology - CRYPTO 2008, 28th Annual International Cryptology 
Conference, Santa Barbara, CA, USA, August 17-21, 2008. Proceedings, volume 5157 of Lecture Notes in
Computer Science, pages 515–535. Springer, 2008.

15. C. Dwork, M. Naor, and A. Sahai. Concurrent zero knowledge. In Proceedings of the 30th Annual ACM Symposium

on Theory of Computing (STOC-98), pages 409–418, New York, May 23–26 1998. ACM Press.

16. C. Dwork and A. Sahai. Concurrent zero-knowledge: Reducing the need for timing constraints. In H. Krawczyk,

editor, CRYPTO, volume 1462 of Lecture Notes in Computer Science, pages 442–457. Springer, 1998.

17. I. Goldberg, B. Ustaoglu, M. V. Gundy, and H. Chen. Multi-party oﬀ-the-record messaging. In E. Al-Shaer,
S. Jha, and A. D. Keromytis, editors, ACM Conference on Computer and Communications Security, pages 358–
368. ACM, 2009.

18. S. Goldwasser, S. Micali, and R. L. Rivest. A digital signature scheme secure against adaptive chosen-message

attacks. SIAM J. Comput., 17(2):281–308, 1988, April.

19. Y. Ishai, E. Kushilevitz, R. Ostrovsky, and A. Sahai. Cryptography from anonymity. In FOCS, pages 239–248.

IEEE Computer Society, 2006.

20. J. Kilian and E. Petrank. Identity escrow. In H. Krawczyk, editor, CRYPTO, volume 1462 of Lecture Notes in

Computer Science, pages 169–185. Springer, 1998.

21. M. Naor. Deniable ring authentication. In M. Yung, editor, CRYPTO, volume 2442 of Lecture Notes in Computer

Science, pages 481–498. Springer, 2002.

22. R. Pass. On deniability in the common reference string and random oracle model. In D. Boneh, editor, CRYPTO,

volume 2729 of Lecture Notes in Computer Science, pages 316–337. Springer, 2003.

23. M. D. Raimondo and R. Gennaro. New approaches for deniable authentication. In V. Atluri, C. Meadows, and

A. Juels, editors, ACM Conference on Computer and Communications Security, pages 112–121. ACM, 2005.

24. M. D. Raimondo, R. Gennaro, and H. Krawczyk. Secure oﬀ-the-record messaging.

In V. Atluri, S. D. C.

di Vimercati, and R. Dingledine, editors, WPES, pages 81–89. ACM, 2005.

25. M. D. Raimondo, R. Gennaro, and H. Krawczyk. Deniable authentication and key exchange. In A. Juels, R. N.
Wright, and S. D. C. di Vimercati, editors, ACM Conference on Computer and Communications Security, pages
400–409. ACM, 2006.

26. S. Walﬁsh. Enhanced security models for network protocols. PhD thesis, New York, NY, USA, 2008. AAI3310580.
27. D. Wikstr¨om. A universally composable mix-net. In M. Naor, editor, TCC, volume 2951 of Lecture Notes in

Computer Science, pages 317–335. Springer, 2004.

28. A. C. Yao and Y. Zhao. Deniable internet key exchange. In Applied Cryptography and Network Security, pages

329–348. Springer, 2010.

29. A. C.-C. Yao. Protocols for secure computations (extended abstract). In FOCS, pages 160–164. IEEE Computer

Society, 1982.

13

A Proofs

A.1 Proof of Lemma 1
Proof. Let J be a judge and I be an informant. Then we can deﬁne the environment ZJ and an
adversary AI, such that the output of ZJ is equal to the output of J .
The environment ZJ simulates J with a direct link to I. This is done by appending the
preﬁx “Judge-Inform :” to each message sent by J to I, then the new message is sent to AI.
Symmetrically, when “Inform-Judge :m” is received from AI, m is forwarded to J as coming from
I. When (Input, Pi, x) is received from AI, it activates party Pi with input x. When party Pi
produces output y, ZJ sends (Output, Pi, y) to AI.
The adversary AI simulates I with a direct link to J symmetrically as it is made by ZJ . When
I produces input x for party Pi, AI sends (Input, Pi, x) to ZJ . When (Output, Pi, y) is received
from ZJ , I is informed that Pi outputs yi. When I corrupts party Pi, AI also corrupts Pi and
reveals the internal state of Pi to I. Clearly, the simulation of J and I is perfect, and thus the
output of ZJ follows the same distribution that follows the output of J .
The other direction is similar. Let Z be a judge and A be an adversary. The judge J Z redirects
input that Z sends to the parties to the informant. The informant IA simulates the adversary A
and starts an execution of π following the instructions of J Z . The simulation of Z and A is also
perfect, and thus the output of J Z follows the same distribution that follows the output of Z.

A.2 Proof of Proposition 1

Proof. The proof is based on an hybrid argument, where in each hybrid χ(cid:96) the shared keys of
parties P1, . . . , P(cid:96) are randomly chosen and other shared keys don’t. That is

(cid:16)

def=

χ(cid:96)

({gxi}n

i=1) ,

(cid:16){gri,j}(cid:96),(cid:96)

(cid:17)

(cid:16){gxixj}n,n

,

i=1,j=i

i=1,j=(cid:96)+1

(cid:17)(cid:17)

Clearly, if z = xy then γ3 = (cid:0){gδixy}(cid:96)

Where xi ∈R Gq and ri,j ∈R Gq for all i, j ∈ 1, . . . , n. Let D be an adversary that attacks Multi-DDH.
In ﬁgure 7 we describe an adversary that chooses a random (cid:96) ∈ {1, . . . , n} and, if D(cid:48) breaks
Multi-DDH, it distinguish between hybrids χ(cid:96) and χ(cid:96)+1.
χ = χ(cid:96)+1. Then, the advantage of D(cid:48) is given by 1
D
indistinguishability between χ1 and χn is straightforward.

(cid:1) and thus χ = χ(cid:96). Otherwise, if z ∈R Gq then

(k). From the above, proving the

n AdvMDDH

i=1

A.3 Proof of Theorem 2 (sketch)

Proof. The proof proceeds through the indistinguishability of 4 games: Gamereal, Gamerand keys,
Gamerand, and Gameideal.
Let Z be an environment and A an adversary. Gamereal consist of an execution of SIGMIX
with environment Z and adversary A in the real world. Gamerand keys is the same as Gamereal
except that instead of executing SIGMIX, the protocol SIGMIXrand keys is executed. SIGMIXrand keys
is almost equal to SIGMIX, except that for each pair of honest parties Pi and Pj, i (cid:54)= j, the shared
keys ki,j and kj,i are replaced with a random ri,j ∈ Gq. Gamerand is the same as Gamerand keys
except that, instead of SIGMIXrand keys, the protocol SIGMIXrand is executed. SIGMIXrand is almost
equal to SIGMIXrand keys, except that each call to E with shared key ki,j, where both Pi and Pj are

14

On input (gx, gy , gz ) the adversary D(cid:48) does the following:

1. (cid:96)
2. Compute public keys for parties in {P1, . . . , P(cid:96)}:

R← {1, . . . , n}.
(a) δ1 ← 1.
(b) δi
(c) gxi ← (gx)δi for i = 1 to (cid:96).

R← Gq for i = 2 to (cid:96).

3. Compute the public key of party P(cid:96)+1, that is gx(cid:96)+1 ← gy .
4. Compute secret keys for parties not in {P1, . . . , P(cid:96)}, that is xi
5. Let γ1 bet the set of all public keys, γ1 ← ({gxi}n
6. Compute the shared keys for parties in {P1, . . . , P(cid:96)}:

i=1).

R← Gq for i = 1 to (cid:96) and j = i to (cid:96).

7. Compute the shared key between all parties in {P1, . . . , P(cid:96)} and P(cid:96)+1:

i=1,j=i

ri,(cid:96)+1 ← (gz )δi for i = 1 to (cid:96).

8. Compute the shared keys for which at least one exponent is known:

(a) gxixj ← (gx)δixj for i = 1 to (cid:96) and j = (cid:96) + 2 to n.

R← Gq for i = (cid:96) + 2 to n.

(cid:17)

.

(cid:17)

.

(a) g

(a) ri,j

(b) γ2 ←(cid:16){gri,j }(cid:96),(cid:96)
(b) γ3 ←(cid:16){g
(b) γ4 ←(cid:16){gxixj }(cid:96),n
(c) γ5 ←(cid:16){gxixj }n,n

ri,(cid:96)+1}(cid:96)

i=1

i=1,j=(cid:96)+2

(cid:17)
(cid:17)

.

.

9. χ ← (γ1, γ2, γ3, γ4, γ5).
10. Run D(χ) and output whatever it outputs.

i=(cid:96)+2,j=i

Fig. 7. Adversary D(cid:48) attacking DDH

(k) ≥(cid:12)(cid:12)Pr[Gamereal] − Pr[Gamerand keys](cid:12)(cid:12) .
(k) ≥(cid:12)(cid:12)Pr(cid:2)Gamerand keys = 1(cid:3) − Pr [Gamerand = 1](cid:12)(cid:12).

honest, is replaced by a call to a completely random function F . Gameideal consist of an execution
of Feaa with environment Z and the simulator S (deﬁned in ﬁgure 8) in the ideal world. We let the
output of each game be the output of the environment.
Is not hard to see that indistinguishability between Gamereal and Gamerand keys follows directly
from the hardness of Multi-DDH. Also, by proposition 1, there exist an adversary DDDH such that
n · AdvDDHDDDH
The indistinguishability between Gamerand keys and Gamerand is based on an hybrid argument.
rand such that the l-th shared key, l ≤ i, is
For each i ∈ {0, . . . , κ}, we deﬁne the hybrid Gamei
replaced by a randomly chosen key. While the l-th shared key, l > i is chosen as in Gamerand keys.
By a standard hybrid argument we get that there exist a distinguisher DPRF such that (κ + 1) ·
AdvPRF
E,DPRF
Let IA ⊆ {1, . . . , n} be the set indexes of parties corrupted by A. The ideal adversary SA is
described in ﬁgure 8, and it simulates the execution of SIGMIXrand only with access to Feaa.
Since the values of messages sent by honest senders remains unknown to SA until all messages
have been sent, when Feaa informs that a party ˜Pj (honest) sent some message, SA cheats the
simulated A making Fanon tells A that some message have been sent by ˜Pj. When the set of
messages M is revealed to SA, it silently instruct the simulated parties to send the messages to
Fanon. We will show that this seems indistinguishable from a real execution to A.
Note that the view of A consist of the lexicographically ordered list L, the responses from Fanon,
and the responses from ¯Gkrk. Also note that the responses from Fanon and the responses from ¯Gkrk
are the same and in the same order in both Gameideal and Gamerand. Therefore, the only possible
diﬀerence might be in L.

Let Lsim be the list in Gameideal and Lreal be the list in Gamerand. We distinguish ﬁve type of elements 
in both lists , (corrupt, corrupt), (corrupt, honest), (honest, corrupt), (honest, honest),
and malformed. Where (t1, t2) ∈ {corrupt, honest}2, means that the sender is of type t1 and the
receiver is of type t2, and malformed means that the element is not of the form m||Eki,j (m), for
some shared key between Pi and Pj, and i ∈ IA or j ∈ IA. Note that malformed and (corrupt, t)

15

Ideal adversary S, running with parties ˜P1, . . . , ˜Pn and executed in the Feaa, ¯Gkrk-hybrid model, proceeds as follows:

Initialization:

Initially do the following:

3.

1. Corrupt party ˜Pi, for each i ∈ IA.
2. Start a simulated execution of Gamerand with a dummy environment Z(cid:48) and a dummy functionality Fanon.

Simulation of links (Z(cid:48), A) and (Pi, ¯Gkrk), i ∈ IA:

Initialize multisets M(cid:48)
j ← ∅, for each j ∈ IA, and L ← ∅.
If m is received from Z, then instruct Z(cid:48) to send m to A.
If m is sent from A to Z(cid:48), then send m to Z.
If Pj is instructed by A to send (Register, r) to ¯Gkrk and ˜Pj has not previously registered, instruct ˜Pj to send (Register, r) to ¯Gkrk and
record the tuple (xi, yi) ← (r, gr ).

1.
2.
3.

Simulation of corrupt parties: When Pi, i ∈ IA, sends m||σ to Fanon do:

1. Let L ← L (cid:93) {m||σ} and instruct Fanon to send (Pj , Sent) to A.
2.

If σ = E

(m) for some registered public key yj , j ∈ {1, . . . , n}, and some registered secret key xi(cid:48) , i(cid:48) ∈ IA, then send (Send, m, i(cid:48), j)

i(cid:48)

x
j

y

j ← M(cid:48)
to ˜Pi(cid:48) . If j ∈ IA, then M(cid:48)
If ( ˜Pi, Sent), i /∈ IA, is received from Feaa, then instruct Fanon to send (Pi, Sent) to A.
Simulation of honest parties:
(cid:85)
End of simulation: Once that (Messages, M ) is received from Feaa and for each j ∈ IA (Messages, Mj ) is sent to ˜Pj , do:

j (cid:93) {(m, i(cid:48))}.

1. Let M(cid:48) ← M \
j∈IA
2. For each m ∈ M(cid:48), let σ
3. For each (m, i) ∈ Mj \ M(cid:48)
4. Sort L lexicographically and proceed with Fanon as if L were the ﬁnal list of received messages.

R← {0, 1}t and L ← L (cid:93) {m||σ}.
j , let ki,j ← y

and L ← L (cid:93) {m||Eki,j

(m,l)∈Mj

(cid:18)(cid:85)

(m)}.

{m}

(cid:19)

xj
i

.

Fig. 8. The ideal adversary S

are both in Lsim and Lreal, given that such elements only comes from corrupted parties. Therefore,
they must be added to Lsim in line 1 of the “Simulation of corrupt parties” stage. A message of
the type (honest, corrupt) is added to Lreal if an only if the corresponding message appears on
Mj \ M(cid:48)
j, for some j ∈ IA. Therefore, it must be added to Lsim in line 3 of the “End of simulation”
stage. Note that, given that the sender is honest, the message is exactly the same message added
in Lreal. Finally a message of the type (honest, honest) is added to Lreal if and only if the correspondent 
message can be found in M(cid:48). Therefore, it must be added to Lsim in line 2 of the “End
of simulation” stage. Note that, given that both the sender and the receiver are honest, the subset
of messages of type (honest, honest) in Lreal must be of the form {m1||F (m1), . . . , ms||F (ms)},
where s ∈ N and F is a completely random function. The assumption of environments that do
not send the same message twice implies that, if i (cid:54)= j, then mi (cid:54)= mj and thus F (mi) and F (mj)
are independent randomly chosen strings. Therefore, the messages added to Lreal in line 2 follows
exactly the same distribution of correspondent messages in Lsim. We conclude that the view of A
in Gamerand is exactly the same as in Gameideal.

The only possible diﬀerence on the view of Z is due to a diﬀerence in the output of an honest
party. Speciﬁcally, this diﬀerence is possible because, in the “Simulation of corrupted parties”
stage, some messages m||σ could not have been sent to Feaa in line 2 of the “Simulation of corrupt
parties” stage. This set of dropped messages may contain forgery, i.e. messages created by A that
are accepted by an honest Pj as coming from an honest Pi.

from another honest party. Then Pr(cid:2)Gamerand = 1|A forges(cid:3) = Pr(cid:2)Gameideal = 1|A forges(cid:3) . By

Therefore, if A does not forges, then the the output of Z in Gamerand must be the same in
Gameideal. Let “A forges” be the event where an honest party accepts a message sent by A as coming
the fundamental lemma of game playing we get that |Pr [Gamerand = 1] − Pr [Gameideal = 1]| ≤
Pr [A forges].

In the event “A forges” there is at least one m||σ such an honest Pj accept m as coming from an
honest Pi, which means that σ = F (m). By the assumption of adversaries that do not play replay
attacks, m||σ should be diﬀerent of any m(cid:48)||σ(cid:48) previously seen by A. Moreover, it must be that

16

m (cid:54)= m(cid:48) for all previously m(cid:48)||σ(cid:48) seen by A, otherwise it must be that σ (cid:54)= σ(cid:48) = F (m(cid:48)) = F (m),
because m(cid:48)||σ(cid:48) was honestly sent, and thus m||σ can not be accepted by an honest party.
Given that m (cid:54)= m(cid:48), for all previously m||σ seen by A, it must be that A have never seen F (m).
Therefore, F (m) is randomly chosen independently from σ and thus Pr [F (m) = σ] = 1/2t. Given
that A can send a most κ messages, it must hold that Pr [A forges] ≤ κ · 2−t.

Combining the results, we get that SIGMIX GUC-emulates Feaa.

17

