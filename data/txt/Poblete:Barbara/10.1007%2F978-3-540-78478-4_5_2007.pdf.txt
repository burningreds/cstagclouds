Website Privacy Preservation for

Query Log Publishing

Barbara Poblete1, Myra Spiliopoulou2, and Ricardo Baeza-Yates1,3

1 Web Research Group, University Pompeu Fabra, Barcelona, Spain

2 Otto-von-Guericke-University Magdeburg, Germany

3 Yahoo! Research, Barcelona, Spain

barbara.poblete@upf.edu,

myra@iti.cs.uni-magdeburg.de, ricardo@baeza.cl

Abstract. In this paper we study privacy preservation for the publication 
of search engine query logs. We introduce a new privacy concern,
website privacy as a special case of business privacy. We deﬁne the possible 
adversaries who could be interested in disclosing website information
and the vulnerabilities in the query log, which they could exploit. We
elaborate on anonymization techniques to protect website information,
discuss diﬀerent types of attacks that an adversary could use and propose 
an anonymization strategy for one of these attacks. We then present
a graph-based heuristic to validate the eﬀectiveness of our anonymization 
method and perform an experimental evaluation of this approach.
Our experimental results show that the query log can be appropriately
anonymized against the speciﬁc attack, while retaining a signiﬁcant volume 
of useful data.

1 Introduction

Query logs are very rich sources of information, from which the scientiﬁc community 
can beneﬁt immensely. These logs allow among other things the discovery
of interesting behavior patterns and rules. These can be used in turn for sophisticated 
user models, for improvements in ranking, for spam detection and
other useful applications. However, the publication of query logs raises serious 
and well-justiﬁed privacy concerns: It has been demonstrated that naively
anonymized query logs pose too great a risk in disclosing private information.

The awareness towards privacy threats has increased by the publication of the
American Online (AOL) query log in 2006 [1]. This dataset, which contained
20 million Web queries from 650, 000 AOL users, was subjected to a rather
rudimentary anonymization before being published. After its release, it turned
out that the users appearing in the log had issued queries that disclosed their
identity either directly or in combination with other searches [2]. Some users
even had their identities published along with their queries [3]. This increased
the awareness to the fact that query logs can be manipulated in order to reveal
private information if published without proper anonymization.

Privacy preservation in query logs is a very current scientiﬁc challenge. Some
solutions have been proposed recently [4,5]. Similarly to the general research

F. Bonchi et al. (Eds.): PinKDD 2007, LNCS 4890, pp. 80–96, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008

Website Privacy Preservation for Query Log Publishing

81

advances in privacy preserving data mining, they refer to the privacy of persons.
Little attention has been paid to another type of privacy concern, which we
consider of no less importance: website privacy or, more general, business privacy.
In this work we argue that important and conﬁdential information about websites 
and their owners can be discovered from query logs and that naive forms of
URL anonymization, as in [2], are not suﬃcient to prevent adversarial attacks.
Examples of information that can be revealed from query logs include accesses
to the site’s documents, queries posed to reach these documents and query keywords 
that reﬂect the market placement of the business that owns the site. Such
pieces of information are conﬁdential, because websites serve as channels for advertisement,
 communication with potential customers and often sales to them.
Hence, the traﬃc recorded in them delivers a picture of customer-company interaction,
 possibly for the whole product portfolio. A thorough analysis of this
traﬃc with a data mining method may then deliver information like insights on
the eﬀectiveness of advertising campaigns, popular and less popular products,
number of successful and failed sale transactions etc.

One may argue that a site’s traﬃc is only recorded at the site’s server and
therefore not public. However, the traﬃc delivered to a website by major search
engines accounts for an important part of the site’s overall traﬃc. If this part is
undisclosed, it will be a very close approximation to the complete access log of
the website.

The protection of such conﬁdential information is diﬀerent from conventional
privacy preservation. One reason for this diﬀerence is that an adversary can
reveal conﬁdential website information by aggregating a published query log
with other legally owned private data. In particular, consider an adversary which
is a company interested in disclosing information about its competitors. This
adversary could use its own background knowledge and the data of its own site
in combination to the published query log data, to infer the competitor’s private
data. This includes but is not limited to popular queries that reach both the
adversary’s site and that of the competitor. As shown in Fig. 1, the log of the
adversary can then be used to de-anonymize a part of the published query log.
Depending on the amount and quality of the information revealed, industrial
espionage or malicious intent could be argued by the aﬀected parties against the
company that published the query log.

Although query log anonymization does not look promising in the near future,
 especially from the user privacy perspective, we believe that reasonable
measures can be taken to preserve website privacy. By discussing some of the
existing threats and ways to prevent them, we can set a precedent for data mining 
applications on logs, and future query log publishing, so that the resulting
information is inspected to prevent privacy leaks. Although we focus on website
privacy, we believe that our approach also contributes to user privacy, because
much of the sensitive information about users comes from assessing the pages
they have visited.

The contributions of our work are as follows: (1) We introduce a new privacy 
issue for query logs, website privacy. (2) We describe attacks that disclose

82

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

conﬁdential information from query logs, and ways to prevent them. (3) We propose 
a heuristic graph-based method that removes those parts of the log that
may lead to information disclosure and we validate it with experiments over real
data.

In the next section, we discuss related work on privacy preserving data mining
and on query log anonymization for the protection of user privacy. In section 3,
we introduce the problem of website privacy preservation through anonymization
and describe the types of adversaries that might attack a published query log.
Section 4 describes attacks and counter-measures. In section 5, we implement
a counter-measure with an heuristic that eliminates the vulnerable parts of the
query log. We validate this heuristic experimentally and report our results in
section 6. The last section concludes the study with a summary and a short
discussion of open issues.

2 Related Work

The rapid development of advanced techniques for data collection and propagation,
 along with the fast growth of the Web, have increased the awareness to
the use of private information. This has lead to a new ﬁeld of research in the
context of analyzing private or conﬁdential information – the domain of privacy
preserving data mining [6].

Privacy preserving data mining aims at analyzing databases and data mining
algorithms, identifying potential privacy violations and devising methods that
prevent privacy breaches. Preventive measures involve the hiding or modiﬁcation 
of sensitive raw data like names, credit card numbers and addresses, and
the exclusion of any further type of sensitive knowledge that can be mined from
the database. It is important to note that many privacy preserving algorithms
are based on heuristics. This is because of the premise that selective data modiﬁcation 
or sanitization is an NP-hard problem.

The evaluation of privacy preserving algorithms [6] is usually centered on the
following features: the performance of the proposed algorithm, the data utility
after the application of the technique, the level of uncertainty which the sensitive 
information can be predicted, and the resistance to diﬀerent data mining
techniques.

Some research on privacy preservation in databases deals with privacy preserving 
data publishing that guarantees utility for data mining [7,8]. There are
studies on preventing adversarial data mining in relational databases, when data
ﬁelds are correlated [9]. Samarati and Sweeney proposed k-anonymity, in which
data is released in such a way that each query result (and each attempt for data
disclosure) returns at least k entities [10]. The principle of k-anonymity is quite
eﬀective but it cannot be directly applied to data that expands across multiple
databases, as is the case of website privacy preservation.

In the context of Web mining, one of the prominent areas for privacy preservation 
is the protection of user privacy in query logs of search engines. Among
the advances in privacy preserving Web mining, most relevant to our work are

Website Privacy Preservation for Query Log Publishing

83

the studies of Kumar et al [4] and of Adar [5]. Kumar et al propose token-based
hashing for query log anonymization [4]; The queries are tokenized and a secure
hash function is applied to each token. However, the authors show how statistical
techniques can be used to disclose private information despite the anonymization;
 they also show that there is no satisfying framework to provide privacy in
query logs [4].

In [5], Adar explains many aspects of the AOL query log problem, and shows
that traditional privacy preservation techniques cannot be applied in a straightforward 
way to protect privacy in a search log. Further, Adar argues that kanonymity 
is too costly for rapidly changing datasets like query logs. Then,
Adar proposes two user anonymization methods for query logs, which attempt
to balance log utility for research and privacy [5].

To the best of our knowledge ours is the ﬁrst paper to address the issue of
privacy preservation for websites or businesses in query logs. As we will explain
in the next section, website privacy preservation is a diﬀerent problem than
user privacy preservation. An anonymization method that preserves user privacy
would not necessarily guarantee website privacy.

3 The Website Anonymization Problem

For our analysis, we assume that a query log contains at least the same ﬁelds as
the one published by AOL [1]. Therefore we deﬁne our default query log format as:

{AnonID, Query, QueryTime, ItemRank, ClickURL}

In this signature, AnonID refers to an anonymized user ID, Query is the
search string, QueryTime is the time at which the query was issued, ItemRank
is the rank of the document clicked as a result of the query, and ClickURL is
the truncated URL of the document. In the AOL log, the URLs of documents
were truncated up to the website name ((e.g. www.example.org/somepage.html
became www.example.org). For our analysis, we also consider the hostname as a
central concept and deﬁne a website as a set of pages under the same hostname.
We use this signature as a reference basis but point out that it its vulnerability
with respect to user IDs has already been shown [5].

3.1 Challenges for Query Log Anonymization

Anonymizing query logs for data mining is very challenging for several reasons.
First, the attributes of the query log are not independent. An adversary may
use these dependencies to deduce the value of an anonymized ﬁeld. For example,
queries in search engines are known to exhibit a remarkable frequency distri-
bution: Kumar et al exploited this property to decrypt anonymized queries by
studying the frequency and co-occurrence of terms in a non-anonymized reference
log [4]. Moreover, query logs have sequential records: Rearranging or shuﬄing
them for anonymization purposes would blur or eliminate important temporal
and order-dependent information, such as user sessions.

84

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

Despite these observations, we should keep in mind that data mining focuses
mostly on extracting knowledge in pattern form and does not always require exact 
values for each attribute: Such values can be replaced by an anonymized value
that preserves their distribution. However, for Web query mining, it is diﬃcult
to determine which attributes should be anonymized or hidden: all attributes in
the log are of potential use – depending on the purpose of the analysis. Thus,
the minimization of the private information that could be disclosed by an adversary 
while maintaining enough information for data mining becomes a complex
optimization problem. We address this problem in a conservative heuristic way:
We describe possible anonymizations, show attacks that can be used to disclose
private data despite these anonymizations and then we increase the level of information 
hiding to prevent information disclosure.

3.2 Types of Adversaries for Website Privacy Preservation

It is important to recapitulate the scope of our work here: we describe and focus
only on the problem of website privacy preservation or prevention of website exposure 
(singling-out a website), when publishing or sharing search engine query
logs. This means that our goal is to prevent an adversary from obtaining conﬁdential 
information about traﬃc to websites, which have been recorded in a
search engine’s query logs. For this objective of website privacy preservation, we
identify two types of adversaries:

1. General Adversary: This type of adversary is “just” trying to discover
useful information about as many websites as possible, without any particular 
site in mind. This type of adversary might show up as a search engine
optimization company or other institution that performs market studies.

2. Adversarial Competitor: This type of adversary is a website or company
that tries to disclose information about its competitors using the query log.
In many cases, this adversary has already some information about the market 
share, portfolio and activities of the competitors, and can impute this
background knowledge upon the anonymized log to de-anonymize it. One of
the most important pieces of data that this adversary can exploit is its own
query log, which can be used to recreate pieces of the anonymized query log.

3.3 Data Sources in the Website Privacy Preservation Problem

The query log is not the sole data source available to an adversary. We enumerate
here the data sources which might be combined to assess additional information
or disclose private data. The sources are depicted in Fig. 1. Some of them may
be publicly available, while others may be private. They include:
1. An anonymized search engine query log: This is the published log.
2. Actual search results for queries from a search engine: This information is
available to each user issuing a query. The results may come from the same
search engine as the log or from a diﬀerent one, which has similar document
coverage.

Website Privacy Preservation for Query Log Publishing

85

Anonymized

Search Engine

Query Log

Website

Logs

Search Engine
Results

1.- ...
2.- ...
3.- ...
4.- ...

Fig. 1. Diﬀerent data sources involved in query log privacy preservation

3. The access log of a given site: This is private to the owner of the site. The
log contains clicks from external search engines. It is quite straightforward
to reconstruct the origin of a click from the click’s referer 1 in a conventional
access log. An adversarial competitor will have such a log for its own website.

Example 1. To illustrate the challenges of combining sites for data mining, let
us consider an on-line computer hardware store “Site A”. Site A knows that the
most popular queries used to reach it are: refurbished computer, cheap notebook,
laptop, memory and desktop computer. Site A has access to a published search
engine query log (such as the AOL log), and it wants to discover as much information 
as possible about its competitors. It ﬁrst assumes that its competitors
are reached via the same queries, which form an initial list of keywords L0. This
initial list can be expanded by searching for the URLs of Site A’s most important
competitor “Site B” in the query log. This allows Site A to obtain additional
keywords from Site B, such as electronics store, portable computers and computer
deals. The result is an enhanced list of keyword terms L1.

Next, Site A issues the queries in L1 online to a search engine and discovers
which other sites are returned in each result-set. Site A discovers that its competitors 
(next to Site B) are Site C and Site D. Having found out these additional
competitor sites, Site A can now extract all traﬃc data for each of them from
the published query log. Among other things, Site A can discover which site has
more visitors and more hits from the search engine, which queries reach other
sites but do not reach Site A etc.

1 This is a misspelling of “referrer”. It is the oﬃcial term used in HTTP speciﬁcations.

86

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

With this information, Site A can now advertise exactly on the most popular
keywords used by people reaching sites B, C and D, or it may focus on only one
of the competitors in a similar way. Most importantly, Site A can make business
decisions based on information that was not available before the disclosure of
the log.
2

4 Attacks and Measures Against Website Disclosure

In this section we discuss an incremental approach to anonymize a query log.
In each step, we show how an adversary could go about to discover information
about a certain site or site-related information (i.e. who are its competitors).
In our analysis, we consider three main types of attacks, which we deﬁne as
attacks on vulnerable queries (deﬁned in subsection 4.2 below), attacks using a
website log and attacks with user information. Although we do not attempt to
identify all possible vulnerabilities, we show that several weak points exist and
that diﬀerent techniques can be used to prevent them.

4.1 Structure of the Anonymized Query Log

As explained before, the anonymization used in the AOL log was not suﬃcient
for user and website privacy preservation. Although the clicked URLs were truncated 
at the site level, the log still provided the original Query and ItemRank
information. This is enough to do a look-up on the AOL search engine and
discover most of the actual URLs for each ClickURL ﬁeld. As a result, all site
information available on the original query log was disclosed.

A simplistic approach to prevent this kind of information disclosure would
be to hide the Rank attribute in the log and at the same time do a simple
anonymization on the ClickURL. The idea here is to replace this attribute with
a unique identiﬁer. This can be done using three methods:

1. Assign a unique ID to each URL: By doing this, the information that some

URLs belong to the same domain is lost.

2. Assign a unique ID to each URL and distinguish among URLs that belong
to the same site or domain: This can be done e.g. by using the same suﬃx
ID for all URLs of the same site. This delivers more information than the
method above, so that one can e.g. calculate the number of clicked pages in
a site and the occasions, under which many diﬀerent pages of the same site
were clicked.

3. Assign the same ID to all URLs in a website: This still allows an analysis of
the click distribution and other useful statistics for rank experiments, but it
does not allow documents inside a website to be set apart.

We opt for the second method for URL anonymization. It allows us to preserve

most information about the website and the accesses in its pages.

Website Privacy Preservation for Query Log Publishing

87

4.2 Attacks on Vulnerable Queries

We ﬁrst consider the scenario of an adversary who only has access to public
data sources, such as the anonymized query log and a public search engine.
This corresponds to the typical general adversary. In this scenario, one can
obtain information about any website by exploiting certain types of “vulnerable”
queries. We use this term for queries whose results disclose directly the identity
of the website; the adversary does not need access to additional information
sources.

A ﬁrst type of vulnerable queries are those that contain the target URL as
keyword. This is a subcategory of so-called “navigational queries” [11]: These
are queries for which the users know exactly the page they want to reach and
use the search engine to obtain the URL, using it like a bookmark on a browser.
Navigational queries become “vulnerable” from a privacy preservation point of
view when they include only the terms that later appear in the root of the selected 
URL (i.e. the website root). For example, a query with the term “amazon”
becomes vulnerable, if the user selects http://www.amazon.com among the results.
 Hence, the adversary can discover the actual website, even if the log is
anonymized. To prevent this, the query log should be checked for queries that
contain keywords matching the URL root string. Such queries should be removed
or the keywords should be hidden.

Another type of vulnerable queries are those that return fewer than k results
and thus prevent an anonymization satisfying k-anonymity. The value of k is
application-speciﬁc. Once this value is set, all queries returning less than k results
must be removed.

The last and more complex type of attack using vulnerable queries involves
pairs of queries that have non-empty intersections among the clicked results.
For this scenario, we ﬁrst assume an adversarial competitor who tries to ﬁnd
information about speciﬁc sites; later, we generalize to both types of adversary.
The attack of the adversarial competitor can go as follows:

1. The adversary deﬁnes a set of queries Q1, which are known to return URLs

of the competitor websites at highly ranked positions.

2. The adversary performs a look-up of the occurrences of the queries in Q1
in the anonymized query log L and obtains a set of AnonID values, i.e.
anonymized URLs. These IDs constitute the set of “candidate competitors”
CC, i.e. initially all sites in L that are in the result of Q1 are possible
competitors.

The task at hand is to map as many AnonIDs in CC as possible to the
corresponding URLs. Once the URLs are known, all relevant information for
them (and ultimately for the whole site containing them) can be extracted
from L.
3. For each AnonID u ∈ CC, the adversary collects all unique queries that
4. For each qi ∈ Q the adversary collects the anonymized result-set RAi.

have u as a clicked URL in L. We call this set Q.

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

88
5. For each pair of queries {qi, qj} ⊆ Q, such that |RAi∩RAj| ≥ 1, the adversary
issues both of them live to the search engine and recovers their real result-sets
Ri and Rj.
If |RAi ∩ RAj| = |Ri ∩ Rj| ≥ 1, then it is known that the URLs in
|RAi ∩ RAj| have been approximately mapped to real URLs. The match
becomes exact if |RAi ∩ RAj| = 1, or if all but one URLs in |RAi ∩ RAj| have
already been disclosed using the same methodology.
This attack can be extended for a general adversary: The complete log must
be scanned to build the intersection of clicked URLs in two result-sets. The
queries contributing to this intersection must be added to Q. Then, steps 4 and
5 are applied as above.

The process above does not guarantee that the adversary will disclose all
URLs of potential interest, but will nonetheless disclose all of the URLs from
each aﬀected website. To alleviate this vulnerability, we propose to remove one
of any two queries that share at least one clicked result. In Section 5 we present
a heuristic that modiﬁes the query log to this extent.

4.3 Attacks Using a Website Log

In the previous scenario, we assumed that the adversary had only access to the
anonymized log and to the results of a public search engine. Now we turn to a
scenario, where the adversary owns a website and can therefore use its access
log.

The access log of a website registers all requests towards the site, including
the requested URL, the time of the request, agent and IP address of the user.
In the case of combined logs, the URL where the request was performed is also
recorded (the referrer URL). If the referee is a search engine, the access log of
the website will also contain the keywords and the URL of the search engine.

Hence, if the adversary has access to a website log of the same period as the
anonymized query log, then the adversary can combine the private website log
and the public query log to disclose the anonymized information of the latter. For
example, the adversary can ﬁnd the AnonId assigned to the own website (pages).
In many cases, this information is not adequate for a privacy breach. However,
if many sites collude and share their logs, then these logs can be combined to
undisclose URLs and launch the attack described in the previous subsection.

To avoid this scenario, one more constraint should be placed in the anonymization 
process of the query log: The results displayed by the search engine for any
given query must contain URLs of at least k diﬀerent sites, so that k-anonymity
can be pursued. Since this scenario requires collusion of multiple adversaries, we
do not discuss it further but concentrate on the simpler scenario that involve
only one adversary.

4.4 Attacks with User Information

We ﬁnally consider the scenario in which the adversary can disclose the identity 
of a (single) user in the query log. Here, we assume that identity disclosure

Website Privacy Preservation for Query Log Publishing

89

q7

{u1,u2}

q6

{u2}

q2

q3

{u4}

{u5}

{u1,u2}

q8

q5

{u1,u2}

{u2}

{u2}

q1

q4

q: query
u: clicked URL

Fig. 2. Graph representation of a tiny example query log

also implies disclosure of the results clicked by the compromised user. Then,
the adversary can trace the user and the clicked URLs in the anonymized log
and map the AnonID values to complete URLs. Such an attack can be manifested 
by having a particular user or agent submit queries to the search engine
regularly and then trace back the queries and their results in a periodically released 
anonymized search log. If the queries involve pages of the adversary’s
competitors, their results can be exploited to perform the attack described in
subsection 4.2.

This scenario can be suppressed by preventing the identiﬁcation of individual
users in the query log. As pointed out in Section 2, this is a separate problem,
for which solutions start emerging.

5 Graph-Based Method

The attack presented in subsection 4.2 exploits the occurrence of the same
URL(s) among the clicked results of diﬀerent queries. We have designed a graphbased 
method to analyze the vulnerability of query logs to this attack. At the
same time we use this method to see how the number of intersections between
clicked result-sets of queries can be reduced.

This graph representation of the query log consists of modeling queries as
nodes. Two nodes are connected with an undirected edge if they share at least one
URL between their clicked result-sets. This means that two queries are connected
by an edge if there exist one or more URLs clicked from both queries, as shown
in Fig. 2.

Our graph representation also takes into account the fact that not all nodes
are of equal importance for data mining applications. To represent the “value”
of each node in the log, we assign weights to the queries. For example, the weight
can reﬂect the frequency of a particular query in the log or the number of clicked
documents for that query.

Using this graph approach we show that the solution to the attack described
in subsection 4.2 is a well-deﬁned optimization problem, namely that of disconnecting 
the graph by removing nodes while preserving the maximum weighted

90

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

graph. This corresponds to ﬁnding the maximum (weighted) independent set.
This problem is NP-Hard, so we deﬁne a heuristic approach. For this, we ﬁrst
deﬁne a measure of graph density, which reﬂects how likely it is to ﬁnd an edge
among any two nodes in the query log. The formula for this measure is:

Density =

2(# edges)

# nodes (# nodes-1)

Then, the goal of our heuristic is to reduce Density for the query log graph
to zero. The zero value of Density means that there are no intersections among
result-sets in the log. The challenge for the heuristic is to disconnect the graph
while attempting to preserve the nodes with maximum weight.

If the number of edges per node in the graph follow a power law, then this
would indicate that the number of edges can be rapidly reduced by node removal:
The graph would become disconnected very fast by only removing a few highdegree 
nodes in the graph [12]. With this in mind, we deﬁne the following greedy
heuristic to disconnect the graph:

1. Sort nodes by their degree.
2. Remove the node with the highest degree.
3. Recalculate the degree of all nodes that were adjacent to the node that was

4. Compute the value of Density.
5. If the value of Density is not equal to zero, then go to Step 1, otherwise

removed.

ﬁnish.

This heuristic can be extended to incorporate the weight of each node. This is
done by replacing the criterion used in Step 1 to sort the nodes, and use degree
weight
instead of degree.

Once the graph is disconnected, certain characteristics can be analyzed retrospectively,
 such as the speed at which the value of Density decreased and the
number of queries and of clicked documents that had to be removed to completely 
disconnect the graph.

6 Experimental Results and Discussion

6.1 The Dataset for the Evaluation

For our evaluation, we used a query log from the Yahoo! search engine. For privacy 
reasons these logs are carefully controlled and cannot be released for general
study. Even for this analysis, we do not deal with the raw query log, but only
with its graph representation. The graph representation is an application of the
graph models developed in [13] and can be computed rapidly. The computation
took approximately 2 hours on a dual core AMD OpteronT M Processor 270 with
6.7 gigabytes of RAM; it is noted though that the processing always used less
than 4 gigabytes of memory and employs only one CPU. The resulting graph

Website Privacy Preservation for Query Log Publishing

91

Fig. 3. Component size distribution in the query log sample

Fig. 4. Degree distribution in the largest graph component

contains approx. 3 million nodes and reﬂects a sample of the usage registered by
the search engine in 2005. The original Density value for this graph is equal to
0.000089, which can already be considered low in comparison to the maximum
Density = 1.

First, we computed the likelihood of ﬁnding edges, i.e. non-empty intersections
of result-sets, among pairs of queries that share a term. This corresponds to
a subgraph of particular interest, because queries sharing a term might be a
possible target for an attack. The Density value for this subgraph is 0.000045
and thus lower than the Density value of the original graph. This means that
queries sharing terms do not necessarily share more clicked results than the rest
of the queries. Thus, an adversary would not have an advantage by focusing on
this subgraph. Therefore, we continue our analysis with the original graph.

92

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

Fig. 5. Remaining edges vs. percentage of nodes removed

An attack may also start in a highly connected component of the graph. So,
we identiﬁed all connected components of the graph and computed their size
distribution (cf. Fig. 3).

We found that there is a very big connected component which includes almost
50% of all of the nodes in the graph. Without loss of generality, we study this
big connected component hereafter. We ﬁrst analyze the distribution of the node
degrees in it. If this distribution corresponds to a power law, then, by removing
the nodes with the highest degrees it would be possible to disconnect the graph
very quickly. This would indicate that this query log is very likely to be successfully 
anonymized with very little loss of information. However, as we can see in
Fig. 4, the degree distribution is not a power law. It seems that approximately
9% of the nodes have a very high degree, so we cannot disconnect the graph by
removing only a few high-degree nodes.

6.2 Three Methods for Graph Disconnection

We focus our study on the big connected component of the original graph. To
disconnect it, we used the heuristic described in Section 5. We deﬁned three
variations of the heuristic by using diﬀerent weighting schemes:

Method 1 (degree): The nodes are sorted only by their degree, the node

weight defaults to 1.

Website Privacy Preservation for Query Log Publishing

93

Fig. 6. Remaining volume of queries vs. percentage of nodes removed

Method 2 (

degree

queryFrequency ): The nodes are sorted by their degree divided with

the frequency of the query in the log.

The frequency of a query (or node) is deﬁned as the total number of times

the query was submitted to the search engine.

Method 3 (

degree

clickedDocs ): The nodes are sorted by their degree divided with

the number of clicked documents for the query in the log.

This number clickedDocs is the total number of times that documents

were clicked from the result-set for that query.

6.3 Result Overview

Figures 5, 6 and 7 show the relation among removed nodes, remaining query
volume and documents for each method. Each ﬁgure shows how the diﬀerent
log contents decrease until all edges have been removed from the query log
graph. It can be seen that the number of nodes removed to disconnect the
graph is very high for all methods. Nonetheless, the ultimate objective of retaining 
a large dataset is satisﬁed: The retained dataset still contains approx.
2,500,000 total queries (Fig. 6) and 1,200,000 clicked documents (Fig. 7). Here,
total queries is the sum of the frequencies of the remaining nodes (queries), while
clicked documents is the sum of all the clicks to documents from the remaining
queries.

94

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

Fig. 7. Remaining volume of clicked documents vs. percentage of nodes removed

6.4 Comparing the Three Methods

The best-performing variation of the heuristic is Method 2, which sorts nodes on
degree divided by query frequency: It removes less queries and clicked documents
than Method 1. It dominates Method 3, which behaves similarly to Method 2
but eliminates more nodes. Thus, Method 2 retains the largest log volume.

Method 1 scans the log by processing the node with the highest degree ﬁrst.
When we compare the curves in the three ﬁgures, we see that the disconnection
of the graph requires the removal of slightly less nodes (Fig. 5). However, the
method removes a larger number of total queries (Fig. 6) and clicked documents
(Fig. 7) than the other two methods. Therefore, it is inferior to the other methods
with respect to the objective of retaining a large dataset.

In Fig. 6 and Fig. 7, we can see that Method 1 follows a diﬀerent curve than
the other two methods: The slope drops smoother and the drop starts earlier.
This observation indicates that the connectivity of the graph drops earlier under
this Method. We want to study extensions of this heuristic that will allow us to
shift the end-point of the curve to the left, i.e. eliminate less nodes.

7 Conclusions and Future Work

In this paper we have presented a new issue on privacy preserving data analysis
in the Web, the preservation of website privacy. We have shown that website
information can be extracted from naively anonymized query logs. We have also
deﬁned diﬀerent types of adversaries encountered when dealing with website

Website Privacy Preservation for Query Log Publishing

95

information, as well as general types of vulnerabilities, which can be used to disclose 
information. We have presented speciﬁc attacks and techniques to prevent
them.

We have described a graph representation for query log privacy preservation
analysis and have deﬁned a heuristic for log anonymization through graph disconnection.
 We have derived three methods upon this heuristic by considering
diﬀerent ways of sorting the nodes in the graph and then removing the highest
rank nodes.

One of the methods, which sorts and the nodes (queries) on their degree
divided by the query frequency, is experimentally shown to be the best in preserving 
the most amount of log volume, i.e. total number of queries and clicked
documents. The complete disconnection of the graph requires removing most of
the queries, but the statistical properties of the remaining ones still allow for
knowledge discovery tasks. Also, the disconnection of the graph can be achieved
by removing infrequent queries. Infrequent queries are those most likely to point
to individuals (persons or institutions), so it is intuitively desirable to remove
them.

The graph statistics described in [13] and the fact that query logs usually
follow stable distributions indicate that the results obtained from this log can
scale to logs of longer time periods and to query logs from other search engines.
 Queries that are removed by our anonymization technique are infrequent,
minimizing the loss of potentially useful information in the remaining data.

Another important characteristic of the heuristic presented in this work is
that the graph representation of the query log can be computed relatively fast.
This makes the our anonymization approach suitable for rapidly changing data,
such as query logs.

Future work on this topic includes studying the possibility of making infrequent 
queries frequent by generalization. This would imply replacing queries
with their keywords. It is worth studying whether query generalization reduces
the vulnerability posed by infrequent non-disconnected queries.

Acknowledgments

The authors thank Alessandro Tiberi from the University of Rome “La Sapienza”
for providing the graph representation of the query log and help to understand
this data. Also we thank the following people from Yahoo! Research: Aristides
Gionis for many valuable discussions and feedback, and Vanessa Murdock and
Bo Pang for their corrections for this ﬁnal version.

References

1. AOL research website, no longer online, http://research.aol.com
2. Arrington, M.: AOL proudly releases massive amounts of private data (2006),
http://www.techcrunch.com/2006/08/06/aol-proudly-releases-massive-
amounts-of-user-search-data/

96

B. Poblete, M. Spiliopoulou, and R. Baeza-Yates

3. Barbaro, M., Zeller, T.: A face is exposed for AOL searcher no. 4417749, New York

Times (2006)

4. Kumar, R., Novak, J., Pang, B., Tomkins, A.: On anonymizing query logs via tokenbased 
hashing. In: WWW 2007: Proceedings of the 16th international conference
on World Wide Web, pp. 629–638. ACM Press, New York (2007)

5. Adar, E.: User 4xxxxx9: Anonymizing query logs. In: Query Log Analysis: Social

and Technological Challenges, Workshop in WWW 2007 (2007)

6. Verykios, V., Bertino, E., Fovino, I., Provenza, L., Saygin, Y., Theodoridis, Y.:
State-of-the-art in privacy preserving data mining. SIGMOD Record 33(1), 50–57
(2004)

7. Chawla, S., Dwork, C., McSherry, F., Smith, A., Wee, H.: Toward privacy in public

databases. In: Theory of Cryptography Conference, pp. 363–385 (2005)

8. Kifer, D., Gehrke, J.: Injecting utility into anonymized datasets. In: Proceedings
of the 2006 ACM SIGMOD international conference on Management of data, pp.
217–228 (2006)

9. Aggarwal, C., Pei, J., Zhang, B.: On privacy preservation against adversarial data
mining. In: Proceedings of the 12th ACM SIGKDD international conference on
Knowledge discovery and data mining, pp. 510–516 (2006)

10. Samarati, P., Sweeney, L.: Protecting privacy when disclosing information: kanonymity 
and its enforcement through generalization and suppression. Technical
report (1998)

11. Broder, A.: A taxonomy of web search. ACM SIGIR Forum 36(2), 3–10 (2002)
12. Albert, R., Jeong, H., Barabasi, A.L.: Error and attack tolerance of complex networks.
 Nature 406(6794), 378–382 (2000)

13. Baeza-Yates, R., Tiberi, A.: Extracting semantic relations from query logs. In:
ACM SIGKDD international conference on Knowledge discovery and data mining
(to appear, 2007)

