7
1
0
2

 

n
u
J
 

4
1

 
 
]

C
D
.
s
c
[
 
 

1
v
2
5
5
4
0

.

6
0
7
1
:
v
i
X
r
a

Block-space GPU Mapping for Embedded Sierpi´nski

Gasket Fractals

Crist´obal A. Navarro
Institute of Informatics,

Benjam´ın Bustos

Raimundo Vega

Department of Computer Science (DCC)

Institute of Informatics,

Universidad Austral de Chile,

University of Chile, Santiago, Chile

Universidad Austral de Chile,

Valdivia, Chile

Email: bbustos@dcc.uchile.cl

Email: cnavarro@inf.uach.cl

Valdivia, Chile

Email: rvega@inf.uach.cl

Nancy Hitschfeld

Department of Computer Science (DCC)

University of Chile, Santiago, Chile

Email: nancy@dcc.uchile.cl

E 7→ Z2

Abstract—This work studies the problem of GPU thread
mapping for a Sierpi ´nski gasket fractal embedded in a discrete
Euclidean space of n × n. A block-space map λ : Z2
F is
proposed, from Euclidean parallel space E to embedded fractal
space F, that maps in O(log2 log2(n)) time and uses no more
than O(nH) threads with H ≈ 1.58... being the Hausdorff
dimension, making it parallel space efﬁcient. When compared to
a bounding-box map, λ(ω) offers a sub-exponential improvement
in parallel space and a monotonically increasing speedup once
n > n0. Experimental performance tests show that in practice
λ(ω) can produce performance improvement at any block-size
once n > n0 = 28, reaching approximately 10× of speedup for
n = 216 under optimal block conﬁgurations.

Keywords—GPU computing; thread mapping; block-space fractal 
domains; Sierpinski gasket;

I.

INTRODUCTION

Fractals can be described as self-similar structures [14]
where a similar1 geometrical pattern is found at all scales.
Several natural phenomena produce fractal patterns that obey
a self-similar structure [13]. Phenomena such as plant and
tree growth [21], [22], terrain formation [15], [23], molecular
dynamics [26], snowﬂake crystallization [9], blood vessels [5],
morphological features of living organisms [27], among many
others, display a fractal design where self-similarity is a critical
feature for modeling its geometrical structure.

One well known fractal

is the Sierpi´nski Gasket, or
Sierpi´nski Triangle, described by Waclaw Sierpi´nski in 1915.
Despite being over than a century old, the Sierpi´nski gasket
remains a relevant subject as it is present in different ﬁelds
such as the construction of antennas [2], [24], cellular automata
[20], [28], molecular DNA self-organization [10], [26], selfassembly 
theory [4], [12] and phase transitions on fractal spin
lattices [6], [7], [16], among others, because of its special
properties. For fractal simulations such as in Cellular Automata
or Monte Carlo simulation on spin models, the Sierpi´nski
gasket is usually discretized. Is this form, the fractal is deﬁned
as a self-similar structure where level r + 1 is composed of

three repetitions of level r at 1/2 the scale, as shown in Figure
1.

Fig. 1: Construction of the discrete Sierpi´nski gasket.

Applications that involve graphical representations or dataparallel 
simulations with nearest neighbors interactions may
beneﬁt if the storage of the structure preserves spatial locality
in memory space, i.e, the memory locations (x ± 1, y ± 1)
deﬁne a neighborhood in the actual fractal as well. One way
to achieve this is to embed the fractal in a Euclidean space of
n × n as shown in Figure 2.

Fig. 2: A discrete Sierpi´nski gasket embedded in a n × n Euclidean space.

1Depending on which fractal, the term similar can refer to exactly similar

or quasi similar.

For applications that can operate in an embedded fractal
domain, computations will usually consist of accessing all the

elements of the fractal and eventually perform arithmetic/logic
operations that involve the data-element itself and possibly its
nearest neighbors. Eventually, when the fractal is large enough
to the point of containing hundreds of thousands of elements,
a sequential computation can take an excessive amount of time
for the practical requirements of the ﬁeld. In these situations
GPU computing becomes an attractive tool for accelerating the
task [19].

For every GPU computation there is a stage where threads
to data space. A map, deﬁned
are mapped from parallel
as f : Zk → Zm,
transforms each k-dimensional point
x = (x1, x2, ..., xk) in parallel space P k into a unique mdimensional 
point f (x) = (y1, y2, · · · , ym) in data space Dm.
GPU parallel spaces are deﬁned as orthotopes Πk ∈ P k in
k = 1, 2, 3 dimensions. A known way of mapping threads
is to use the bounding-box (BB) approach, that builds an
orthotope Πk sufﬁciently large to cover the whole data space
and threads are mapped using the identity f (ω) = ω. Such map
is highly convenient and efﬁcient for the class of problems
where data space is also deﬁned by an orthotope; such as
vectors, tables, matrices and box-shaped volumes. But for an
embedded fractal such as the Sierpi´nski gasket, this approach
is no longer efﬁcient in terms of parallel space as many threads
fall outside the domain, introducing a performance penalty to
the execution time (see Figure 3).

Fig. 3: In the bounding-box approach the threads that fall outside the fractal
have to be discarded at run time.

Two research questions arise from this GPU efﬁciency
problem on the embedded Sierpi´nski gasket; The ﬁrst question:
Is there any parallel-space efﬁcient function, namely λ(ω),
that can use asymptotically the same number of threads as
data elements in the fractal and map blocks properly onto the
embedded Sierpi´nski gasket? (see Figure 4).

Fig. 4: A λ(ω) map would use asymptotically the same number of threads
as data elements.

It is important to note that Question 1 asks for a blockspace 
map and not a thread-space one. The change from
thread-space to block-space allows coalesced memory to be
preserved throughout the entire domain as thread organization
is not compromised inside a block.

The second question relates to performance: Will

the
parallel-space improvement translate into a signiﬁcant GPU
performance improvement?

The present work focuses on these two questions and provides 
positive answers for both of them. A dedicated analysis is
devoted to show that an alternating unrolling strategy allows to
deﬁne a parallel-space efﬁcient λ(ω) that only requires O(nH)
threads, with H ≈ 1.58... being the Hausdorff dimension of
the Sierpi´nski fractal. It addition, it is shown that by taking
advantage of block-parallelism, λ(ω) becomes computable
in O(log2 log2(n)) time which is fast enough to produce
monotonically increasing speedup once n > n0 with n0 being
a constant threshold value.

The rest of the manuscript presents related work (Section
II), a formal deﬁnition and analysis of λ(ω) (Section III) and
Section (IV) presents performance results. A discussion and
comments on future work is found in Section V.

II. RELATED WORK

The following related works can be classiﬁed into two
categories; (1) studies on efﬁcient GPU mapping for triangular
domains and (2) general studies on the structure of the discrete
Sierpi´nski fractal.

One of the ﬁrst works that explored the possibilities of
improving the GPU mapping and stage was the research of
Jung et. al. [11] whom proposed packed data structures for
representing triangular and symmetric matrices with applications 
to LU and Cholesky decomposition [8]. The strategy is
based on building a rectangular box strategy for accessing and
storing a triangular matrix (upper or lower). Data structures
become practically half the size with respect
to classical
methods based on the full matrix. The strategy was originally
intended to modify the data space (i.e., the matrix), however
one can apply the concept analogously to the parallel space.

Ries et. al. contributed with a parallel GPU method for the
triangular matrix inversion [25]. The authors identiﬁed that the
parallel space indeed can be improved by using a recursive
partition of the grid, based on a divide and conquer strategy.
The approach takes O(log2(n)) time by doing a balanced
partition of the structure, from the orthogonal point to the
diagonal.

Q. Avril et. al. proposed a GPU mapping function for collision 
detection based on the properties of the upper-triangular
map [1]. The map is a thread-space function u(x) → (a, b),
where x is the linear index of a thread tx and the pair (a, b) is
a unique two-dimensional coordinate in the upper triangular
matrix. Since the map works in thread space, the map is
accurate only in the range n ∈ [0, 3000] of linear problem
size.

Navarro, Hitschfeld and Bustos have proposed a blockspace 
map function for 2-simplices and 3-simplices [18], [17],
based on the solution of an m order equation that is formulated

from the linear enumeration of the discrete elements. The authors 
report performance improvement for 2-simplices, and for
the 3-simplex case, the mapping technique is extended to the
discrete orthogonal tetrahedron, where the parallel space usage
can be 6× more efﬁcient. However the authors clarify that it is
difﬁcult to translate such space improvement into performance
improvement, as the map requires the computation of several
square and cubic roots that introduce a signiﬁcant amount
of overhead to the process. From the point of view of datareorganization,
 a succinct blocked approach can be combined
along with the block-space thread map, producing additional
performance beneﬁts with a sacriﬁce of o(n3) extra memory.

Exploring the beneﬁts of efﬁcient GPU mapping onto the
embedded Sierpi´nski gasket becomes an interesting topic of
research since its geometry is no longer Euclidean as in the
related works, but instead it is embedded in an Euclidean one.
Finding a proper efﬁcient λ(ω) would produce an asymptotic
improvement in parallel space and a potential performance
improvement that could eventually be exploited.

III. ANALYSIS AND FORMULATION OF λ(ω)

where the exponent H = log2(3) ≈ 1.5849... is the Hausdorff
dimension of the original inﬁnite Sierpi´nski gasket.

Lemma 2: A discrete Sierpi´nski gasket of level r packs

into a 2-orthotope Π2 of dimensions 3⌈ r

2 ⌉ × 3⌊ r

2 ⌋.

Proof: Proof by induction on r:

•

•

Base case: At scale r = 0 the fractal has a space
of V(F
) = 1 element that packs into a regular 2orthotope 
of 1×1 = 3⌈ 0
2 ⌋.

2 ⌋ satisfying 3⌈ r

2 ⌉×3⌊ r

2 ⌉×3⌊ 0

3, 1
1

2

Induction step: It is assumed that the orthotope for
r = k is quasi-regular. If k is even, the packing for
k + 1 will triple the horizontal dimension of the 2orthotope.
 If k is odd, the packing for k + 1 will triple
the vertical dimension of the 2-orthotope. Since even
and odd must alternate, the dimensions of the packed
2-orthotope for k + 1 can only be 3 · 3⌈ k
2 ⌋ or
3 · 3⌈ k
2 ⌋, which is regular or quasi-regular,
respectively.

2 ⌉ × 3 · 3⌊ k

2 ⌉ × 3⌊ k

This Section ﬁrst analyzes two important properties of the
discrete embedded Sierpi´nski gasket, which are helpful in the
formulation of the map λ(ω).

The packing process of Lemma (2) is illustrated in Figure
5, where the packing steps are in correspondence with the scale
levels shown in Figure 5.

A. Analysis of the Space and Packing of F k,s

n

The discrete Sierpi´nski gasket belongs to a category of
discrete fractals where its structure can be built by replicating
k instances of itself at a scale s and placed with an arbitrary
spatial organization. The notation F k,s
is introduced to denote
such fractal, where n ∈ N is the linear size, k ∈ N the
replication factor and 0 < s < 1 ∈ R the scaling factor in
terms of reduction. Since fractals have a recursive self-similar
structure, their volume V(F k,s

n ) may be expressed as

n

V(F k,s

n ) =

k

X

i=1

V(F k,s
sn )

(1)

with V(F k,s
) = 1 being the limit condition of the recursion.
Given that the replication factor k is ﬁxed, and n scales by
factors of s, the volume may be simpliﬁed into

1

V(F k,s

n ) = kr

(2)

where r = log1/s(n) is deﬁned as the scale level.

The Sierpi´nski gasket is a particular case where k = 3,
s = 1/2 and r = log2(n). Successive steps of the fractal
produce the pattern early depicted in Figure 2. The following
two lemmas are introduced to support the formulation of a
map λ(ω).

Lemma 1: The space occupied by a discrete embedded
Sierpi´nski gasket is in correspondence with the Hausdorff
dimension of the inﬁnite Sierpi´nski gasket.

Proof: The space occupied by a Sierpi´nski gasket of linear
3, 1
n ) = 3r. Given that r = log2(n) and 3log2(x) =

size n is V(F
2log2(3) log2(x), the space expression can be rearranged into

2

V(F

3, 1
n ) = nH=log2(3)

2

(3)

Fig. 5: Each scale of the Sierpi´nski fractal packs into a 2-orthotope Π2 of
dimensions 3⌈ r

2 ⌉ × 3⌊ r

2 ⌋.

B. Changing from Thread-space to Block-space

An important aspect

to consider is at which level

the
parallel space will be mapped. Two approaches are possible;
(1) thread-space mapping and (2) block-space mapping. For
ﬁrst one, λ(ω) deﬁnes ω as a unique thread location in parallel
space. For the second approach, λ(ω) deﬁnes ω as a block
coordinate in which several threads are contained. The blockspace 
approach has three important advantages over threadspace 
mapping. First, in block-space, the fractal becomes a
simpliﬁed version of the original, requiring less elements to
be mapped. Second, since the fractal is a simpliﬁed version
of itself, it is possible to work on higher sizes of n before
the CUDA grid maximum dimensions are reached. Third, the

block-space approach allows the possibility for threads inside
a block to preserve locality, which is essential for coalesced
memory accesses on data.

the fractal does block ω belongs to. For even µ, βµ(ω) acts on
ωx. For odd µ, it acts on ωy. Regions are sorted as 0 for top, 1
for middle and 2 for right (see Figure 1 for visual reference).

The block-space map λ(ω) is now introduced, where
ω = (ωx, ωy) denotes a two-dimensional coordinate of a block
of constant size |B| = ρx × ρy threads. The change from
thread-space to block-space means that blocks are mapped to
a simpliﬁed version of the fractal of linear size nb = n/b, as
shown in Figure 6.

Fig. 6: In thread-space mapping, threads are directly mapped one-to-one to
the elements of the fractal of linear size n = 64. In block-space mapping,
|B| = 8 × 8 and blocks of threads are mapped onto a simpliﬁed version of
the fractal of linear size nb = 64/8 = 8.

It is important to clarify that the extra green regions visible
in Figure 6 do not necessarily mean unused threads. The stage
of local thread mapping is detailed later in this Section, where
three approaches can be used.

The formulation of λ(ω) continues in block-space with
ρx = ρy to simplify the analysis, with nb the new simpliﬁed
linear size of the fractal with the origin (0, 0) located at the topleft 
corner for both the parallel and embedded fractal spaces,
and with y increasing downwards.

C. Formulation of λ(ω)
The function λ : Z2

E 7→ Z2

F is introduced as a mapping of
block coordinates ω in parallel-space onto block coordinates
in the embedded space. The intuition behind is an unrolling
process applied in parallel to each ω ∈ Π2 through all the scale
levels. At each level, different x, y offsets are accumulated to
form the ﬁnal (λx(ω), λy(ω)) coordinate in the fractal.

Theorem 1: There exists a block-space parallel-space efﬁcient 
λ(ω) that can map blocks in O(log2 log2(nb)) time using
|B| = θ(

log2 log2(nb) ) threads per block.

log2(nb)

Proof: By construction: let rb = 2nb be the block-space
scale level of the fractal, Π2 the 2-orthotope of 3⌈ rb
2 ⌉ × 3⌊ rb
2 ⌋
3, 1
blocks that maps onto the discrete Sierpi´nski gasket F
nb , with
each block having ρx × ρy threads. By Lemma (1), Π2 is
parallel-space efﬁcient in block-space.

2

A helper index function βµ(ω) is deﬁned as

βµ(ω) = (cid:16) ωx((µ + 1) mod 2) + ωy(µ mod 2)

(cid:17) mod 3
(4)
to produce an index in the range βµ(ω) = 0, 1, 2 that identiﬁes,
within scale level µ ∈ [0..rb], which of the three regions of

3⌈ µ

2 ⌉−1

Having the βµ(ω) index, the weight functions
µ = βµ − j βµ
2 k

µ = j βµ
∆x

2 k, ∆y

(5)

compute the offset weights, 0 or 1, for each of the x and y
directions at scale level µ. The value of the offset corresponds
to 2µ−1, which is the linear size of each region at scale level
µ. For a given µ, the combination of the weight functions with
the offset produce partial coordinates of the form

τ µ
x = ∆x
τ µ
y = ∆y

µ2µ−1,
µ2µ−1

(6)

(7)

that contribute to the ﬁnal mapped coordinate. The summation
of all partial coordinates produce the map

λ(ω) = (λx(ω), λy(ω)),

λx(ω) =

λy(ω) =

log2(nb)

X

µ=1

log2(nb)

X

µ=1

τ x
µ

τ y
µ

(8)

(9)

(10)

which can be computed in O(log2 log2(n)) time (i.e., nb ∈
θ(n)) using a parallel reduction with the threads contained
in the ω block. Finally, by Brent’s Theorem [3],
|B| =
θ(
log2 log2(n) ) threads are sufﬁcient for a block of threads to
reduce efﬁciently in parallel.

log2(n)

Theorem 2: λ(ω) requires asymptotically less work than

the bounding-box approach.

Proof: The asymptotic work improvement factor of λ(ω)
with respect to the bounding-box approach is the quotient of
the costs of mapping all blocks using their corresponding Π2
structures with the consideration nb ∈ θ(n)

Sλ(ω) =

O(1)V(Π2

BB)

O(log2 log2(n))V(Π2

λ(ω))

(11)

(12)

BB and Π2

λ(ω) are the parallel-spaces for

where Π2
the
bounding-box and λ(ω) approaches, respectively. The parallelspace 
of Π2
BB corresponds to the Euclidean box of nb × nb
λ(ω) is O(nH) by Lemma
blocks, and the parallel-space of Π2
(1). Applying the limit n → ∞

lim
n→∞

Sλ(ω) = lim
n→∞

= lim
n→∞

= ∞

∂

∂n (n2−H)

∂
∂n (log2 log2(n))
(2 − H)n1−H

1

n log2(n))

(13)

(14)

(15)

The importance of Theorem (2) is that
it guarantees the
existence of a n > n0 where λ(ω) will start becoming each
time faster than the bounding box approach. A theoretical

Asymptotical Improvement Factors of λ(ω)

Map Time

Parallel Space

number of extra threads. Choosing one or another can depend
on the speciﬁc application, i.e., to avoid competing with the
application in the use of memory bandwidth or arithmetic
operations.

 100

 10

 1

 1

 10

 100

n

 1000

 10000

Fig. 7: The theoretical improvement for parallel-space and mapping time.

curve is presented in Figure 7. From the plot, one can note
that space improvement is clear in the log-log scale. For the
time improvement, the improvement decreases until n0 ∼ 7,
which is the point where it becomes a monotonically increasing
function. In practice, constants could have an effect that would
push n0 further to the right.

D. Intra-Block Mapping

Once λ(ω) maps a block ω, all

the ρx × ρy threads
contained have a shared reference coordinate that is available
to use for computing their individual location in the fractal.
This phase of organizing the threads within a block is referred
here as Intra-Block Mapping, and this subsection describes
three possible approaches to accomplish this.

1) Further Unrolling: In this approach threads inside their
mapped block use the same λ(ω) map but applied to each
thread. By Theorem (1), the Intra-block map is parallel-space
efﬁcient and the mapping time becomes O(log2 log2(|B|)) ∈
O(1) as ρx, ρy are constant and do not grow with n.

2) Shared Lookup Table: The second approach is to use
a shared lookup table of ρx × ρy = O(1) offset coordinates,
available to any thread in any block. Mapping each thread
would cost O(1) memory accesses and the extra memory
introduced by the shared table is O(ρx × ρy) ∈ O(1).

3) Bounding Sub-boxes: The third approach consists of
using small bounding-boxes in each block. This approach
introduces a constant number of extra threads in each block,
but allows each thread to be mapped just with f (x) = x which
costs O(1). In order to know if it is in the fractal or not,
each thread evaluates if tx&(n − 1 − ty) == 0 is true or not,
respectively, with & being the bitwise AND operator.

the ﬁnal mapping time will not

Regardless of which Intra-block mapping approach is
the
chosen,
O(log2 log2(n)) time, as the blocks have a constant size of
threads. Nevertheless, it is worth considering that Further Unrolling 
introduces a constant cost in mapping time. The Shared
Lookup Table approach introduces a constant cost in memory
and ﬁnally the Bounding Sub-boxes introduce a constant in the

surpass

IV.

IMPLEMENTATION AND PERFORMANCE RESULTS

A CUDA implementation of λ(ω) is put under test to
obtain the actual speedup for different values of n. The
implementation uses the Bounding Sub-boxes approach to
arrange threads inside each block, as it is the simplest in terms
of implementation time. The parallel reduction per-block is
performed using the shufﬂe instruction of CUDA, which allows
efﬁcient register-level communication among threads within
the same warp.

The performance test consists of measuring the average
time taken to write a constant value on all the elements of
a Sierpi´nski gasket of scale level r, which is embedded in
a Mn×n matrix ﬁlled with zeros. The conﬁguration space is
explored in the ranges r = 0..16 and ρ = 1, 2, 4, 8, 16, 32 for
the scale level and block-size respectively, in order to ﬁnd the
optimal setting that provides the best performance for both the
bounding-box and λ(ω) approaches. The average performance
measures are taken by averaging 100 sub-averages, each one
being an average time of 10 consecutive synchronized kernel
calls. The standard error for each mean was below 1%. The
hardware for performance test is listed in Table I.

TABLE I: Hardware used for performance tests.

Device
GPU
CPU
RAM

Model
Titan-X Pascal, GP102, 3584 cores, 12GB
Intel i7-6950X 10-core Broadwell
128GB DDR4 2400MHz

Figure 8 presents the speedup of λ(ω) over the boundingbox 
approach, as well as the running times for the two mapping
techniques. For values of n < 28, one can note that only some
curves offer speedup. Once n > 28, the speedup begins to
increase for all block-size conﬁgurations, reaching the higher
values at n = 216 = 65536, which was the highest problem
size that ﬁt in the GPU memory. An important aspect to
note from the speedup curve is that for the largest possible
block size, |B| = ρ × ρ = 32 × 32, the λ(ω) map runs the
test approximately 6× faster than the bounding-box approach.
Furthermore, as blocks become smaller in ρ, the improvement
increases dramatically, reaching up to 55× of speedup.

The plot of the running times provides further insights on
what conﬁguration is the best suited for each mapping technique.
 By looking at the running times of the small block conﬁgurations,
 one can note that regardless of their high speedup,
their running times are the slowest ones. For the boundingbox 
approach (BB) the best performance is obtained when
the block-size is maximum. For λ(ω) the best performance is
found when using a block of |B| = 16 × 16 threads. If the
curves of the best conﬁguration for each implementation are
considered, i.e., the ones with marked points on Figure 8, right,
then the speedup provided by λ(ω) increasing further more
reaching almost an order of magnitude. The other running

λ(ω) Speedup over Bounding-Box

Mapping Running Times, Bounding-box vs λ(ω)

ρ=1
ρ=2
ρ=4
ρ=8
ρ=16
ρ=32

 55
 50
 45
 40
 35
 30
 25
 20
 15
 10
 5

Sλ(ω)

BBρ=1
BBρ=2
BBρ=4
BBρ=8
BBρ=16
BBρ=32
λ(ω)ρ=1
λ(ω)ρ=2
λ(ω)ρ=4
λ(ω)ρ=8
λ(ω)ρ=16
λ(ω)ρ=32

100

10-1

10-2

10-3

10-4

10-5

T[s]

20

22

24

26

28
n

210

212

214

216

20

22

24

26

210

212

214

216

28
n

Fig. 8: On the left, the speedup of λ(ω) with respect to the bounding-box approach at different block-size conﬁgurations. On the right, their absolute running
times at different block-size conﬁgurations.

time curves are still useful to visualize that as blocks become
smaller, the value of n0 where λ(ω) is more convenient moves
closer to the origin, and vice versa, however the GPU with its
current organization and architecture is not fully utilized by
such small block conﬁgurations, thus leading to an inferior
performance. Therefore, in practice large blocks should be
utilized and by Theorem (2), beyond n = 216 the speedup
would keep increasing in favor of λ(ω).

V. DISCUSSION

The results obtained in this work have shown that a
parallel-space efﬁcient mapping function can lead to signiﬁcant
performance gains in applications that require processing an
embedded Sierpi´nski gasket. The analysis and formulation of
λ(ω) has provided three important results; (1) There exists a
correspondence between a quasi-regular 2-orthotope of discrete
elements and the elements of the embedded Sierpi´nski gasket
fractal. (2) Such correspondence from parallel to data space
can be computed in O(log2 log2(n)) time using a block-space
map that is based on efﬁcient parallel reductions. (3) The total
work of mapping the 2-orthotope with λ(ω) is asymptotically
smaller than the work generated by the bounding box approach,
leading to a monotonically increasing speedup that is guaranteed 
to occur once a n0 value is reached.

The experimental performance results conﬁrm the theory
as once the fractal reaches the linear size n0 = 28, the speedup
begins to increase monotonically for all block-sizes. Using
the maximum block size of 32 × 32 threads, λ(ω) reached
up to 6× of speedup. The maximum speedup obtained was
approximately 55× with blocks of 1 thread, however such
block conﬁguration is not practical for the GPU architecture.
Still, having measured the running times with different block
conﬁgurations helped in understanding that reducing the block
size only brings the n0 value closer to the origin and increasing
the block-size pushes it forward. Eventually, all block conﬁgurations 
can reach up to 55× of speedup and beyond if the
fractal is large enough.

The GPU map found for the embedded Sierpi´nski gasket
may be adapted to work for other types of embedded fractals

that follow a similar building scheme applying modiﬁcations
to the helper, weight and offset functions. In order to obtain
speedup, it is crucial to check if the overall work will be
asymptotically smaller than the bounding-box approach.

Two important questions may be formulated from the
results obtained in this work. The ﬁrst one is: Can there exist
a general λ(ω) that maps a family of embedded fractals who
share the same building principle?, and the second question:
can there exist a λ(ω) that maps in O(1) time using no more
than O(1) extra memory?. Future research in these directions
can provide important insights on the limits of efﬁcient GPU
computing for embedded fractal domains.

ACKNOWLEDGMENT

This project was

supported by the research project
FONDECYT No 3160182 from CONICYT, as well as by the
Nvidia CUDA Research Center at the Department of Computer
Science (DCC) from University of Chile.

REFERENCES

[1] Quentin Avril, Val´erie Gouranton, and Bruno Arnaldi. Fast collision
In

culling in large-scale environments using gpu mapping function.
EGPGV, pages 71–80, 2012.

[2] C. P. Baliarda, C. B. Borau, M. N. Rodero, and J. R. Robert. An iterative
model for fractal antennas: application to the sierpinski gasket antenna.
IEEE Transactions on Antennas and Propagation, 48(5):713–719, May
2000.

[3] Richard P. Brent. The parallel evaluation of general arithmetic expressions.
 J. ACM, 21(2):201–206, April 1974.

[4] David Doty. Theory of algorithmic self-assembly. Commun. ACM,

55(12):78–88, December 2012.

[5] A. Gamba, D. Ambrosi, A. Coniglio, A. de Candia, S. Di Talia,
E. Giraudo, G. Serini, L. Preziosi, and F. Bussolino. Percolation,
morphogenesis, and burgers dynamics in blood vessels formation. Phys.
Rev. Lett., 90:118101, Mar 2003.

[6] Y Gefen, A Aharony, Y Shapir, and B B Mandelbrot. Phase transitions
on fractals. ii. sierpinski gaskets. Journal of Physics A: Mathematical
and General, 17(2):435, 1984.

[7] Yuval Gefen, Benoit B. Mandelbrot, and Amnon Aharony. Critical
phenomena on fractal lattices. Phys. Rev. Lett., 45:855–858, Sep 1980.

[8] Fred Gustavson. New generalized data structures for matrices lead to a
variety of high performance algorithms. In Roman Wyrzykowski, Jack
Dongarra, Marcin Paprzycki, and Jerzy Wasniewski, editors, Parallel
Processing and Applied Mathematics, volume 2328 of Lecture Notes in
Computer Science, pages 418–436. Springer Berlin / Heidelberg, 2006.

[9] Kai He, Cheng-Yan Xu, Liang Zhen, and Wen-Zhu Shao. Fractal growth
-fe2o3: From dendritic micro-pines to hexagonal

of single-crystal
micro-snowﬂakes. Materials Letters, 62(45):739 – 742, 2008.

[10] Min Chen Jian Shang, Wang Yongfeng et al. Assembling molecular

Sierpi´nski triangle fractals. Nat Chem, 7(5):389–393, May 2015.

[11]

[12]

Jin Hyuk Jung and Dianne P. OLeary. Exploiting structure of symmetric
or triangular matrices on a gpu.
Technical report, University of
Maryland, 2008.

James I. Lathrop, Jack H. Lutz, and Scott M. Summers. Strict selfassembly 
of discrete sierpinski triangles. Theoretical Computer Science,
410(4):384 – 405, 2009.

[13] Benoit B Mandelbrot. The fractal geometry of nature. 1982. San

Francisco, CA, 1982.

[14] Benoit B. Mandelbrot. Fractals. John Wiley & Sons, Inc., 2004.

[15] Bruce T. Milne. Measuring the fractal geometry of landscapes. Applied

Mathematics and Computation, 27(1):67 – 79, 1988.

[16] Klauko P. Mota and Paulo Murilo C. de Oliveira. Monte carlo
simulations for the slow relaxation of crumpled surfaces. Physica A:
Statistical Mechanics and its Applications, 387(24):6095 – 6104, 2008.

[17] Crist´obal A. Navarro, Benjam´ın Bustos, and Nancy Hitschfeld. Potential 
beneﬁts of a block-space GPU approach for discrete tetrahedral 
domains.
In CLEI-2016, XLII Conferencia Latinoamericana de
Inform´atica, Valparaiso, Chile, October 10-14, 2016, 2016.

[18] Cristobal A. Navarro and Nancy Hitschfeld. GPU maps for the space of
computation in triangular domain problems. In 2014 IEEE International
Conference on High Performance Computing and Communications, 6th
IEEE International Symposium on Cyberspace Safety and Security, 11th
IEEE International Conference on Embedded Software and Systems,
HPCC/CSS/ICESS 2014, Paris, France, August 20-22, 2014, pages 375–
382, 2014.

[19] Cristobal A. Navarro, Nancy Hitschfeld-Kahler, and Luis Mateu. A
survey on parallel computing and its applications in data-parallel
problems using GPU architectures. Commun. Comput. Phys., 15:285–
329, 2014.

[20] Fumio Ohi and Yoshikazu Takamatsu. Time-space pattern and periodic
property of elementary cellular automata — sierpinski gasket and
partially sierpinski gasket —. Japan Journal of Industrial and Applied
Mathematics, 18(1):59, 2001.

[21] Peter E. Oppenheimer. Real time design and animation of fractal plants

and trees. SIGGRAPH Comput. Graph., 20(4):55–64, August 1986.

[22] Michael W. Palmer. Fractal geometry: a tool for describing spatial

patterns of plant communities. Vegetatio, 75(1):91–102, 1988.

[23] A. P. Pentland. Fractal-based description of natural scenes.

IEEE
Transactions on Pattern Analysis and Machine Intelligence, PAMI-
6(6):661–674, Nov 1984.

[24] C. Puente-Baliarda, J. Romeu, R. Pous, and A. Cardama. On the
behavior of the sierpinski multiband fractal antenna. IEEE Transactions
on Antennas and Propagation, 46(4):517–524, Apr 1998.

[25] Florian Ries, Tommaso De Marco, Matteo Zivieri, and Roberto Guerrieri.
 Triangular matrix inversion on graphics processing unit. In Proceedings 
of the Conference on High Performance Computing Networking,
Storage and Analysis, SC ’09, pages 9:1–9:10, New York, NY, USA,
2009. ACM.

[26] Winfree E Rothemund PWK, Papadakis N. Algorithmic self-assembly

of dna sierpinski triangles. PLoS Biol, 2(12):e424, 2004.

[27] E. R. Weibel. Fractal geometry: a design principle for living organisms.
 American Journal of Physiology - Lung Cellular and Molecular
Physiology, 261(6):L361–L369, 1991.

[28] Stephen Wolfram. Statistical mechanics of cellular automata. Rev. Mod.

Phys., 55(3):601–644, July 1983.

