Evaluating Design Concepts to Support Informal 

Communication in Hospitals through the Development of 

a Tool Based on an Iterative Evaluation 

David A. Mejia1, Alberto L. Morán2, Jesus Favela1, Sergio F. Ochoa3, and José Pino3 

1 Departamento de Ciencias de la Computacion, CICESE, Ensenada, Mexico 

2 Facultad de Ciencias, UABC, Ensenada, Mexico 

3 Departamento de Ciencias de la Computación, Universidad de Chile, Santiago, Chile 

{mejiam,favela}@cicese.mx, alberto_moran@uabc.mx, 

{sochoa,jpino}@dcc.uchile.cl 

Abstract. The evaluation of groupware systems is considered a complex activity,
  mainly due to the impact that this kind of tools could have in work practices,
 the multiples variables that influences the use and evaluation of them, as 
well as the expensive cost of time and resources required for an in situ evaluation.
  These  reasons  have  complicated  the  generation  of  a  generic  guide  for 
evaluating  this  type  of  tools.  Some  researchers  in  groupware  evaluation  have 
highlighted the need to evaluate groupware tools, according to the context and 
characteristics of those organizations in which these tools would be deployed. 
Thus, in this paper we present a process to evaluate a tool that supports informal 
collaboration in hospital.  Due  to  nature  of  hospital  work  and  the  difficulty  of 
performing an in situ evaluation, our proposal implies a multi-phase evaluation 
process through the development lifecycle of the tool.   

Keywords: Groupware evaluation, design concepts, informal communication. 

1   Introduction 

Software  evaluation  is  considered  a  very  complex  activity,  especially  when  these 
systems could have direct impact on the work practices in a set of potential users. In 
other words, groupware is traditionally considered to be difficult to evaluate because 
of the effects of multiple people and the social and organizational context [6].  

The understanding of these effects could be expensive in time and human efforts, 
since the software must be deployed in the place of the organization and used by the 
intended user during a period of time. In hospitals, it is not recommended to deploy a 
groupware application without a preliminary evaluation of the possible effects on the 
medical staff, since it can impact negatively in communication or work patterns and, 
consequently,  in  patient  care.  By  improving  the  techniques  used  prior  to  workplace 
evaluations, many problems can be eliminated early on, thus improving the efficiency 
of evaluation as it progresses into the workplace [6].  

To this date there is not a generic guide for evaluating groupware in organizations, 
mainly due to the broad range of organizations and users that must be dealt with [2]. 

M. Kurosu (Ed.): Human Centered Design, HCII 2009, LNCS 5619, pp. 1013–1022, 2009. 
© Springer-Verlag Berlin Heidelberg 2009 

1014 

D.A. Mejia et al. 

Thus,  what  is  recommended  is  to  select  an  evaluation  approach  appropriate  for  the 
actual problem or research question under consideration [1]. For this reason, in this 
paper  we  present  an  approach  to  evaluate  a  groupware  application  for  supporting 
collaboration  in  hospitals.  It  is  based  on  an  iterative  software  development  and 
evaluation cycle with multiple phases, allowing understanding the user needs from the 
early stages of the development process. 

The  remainder  of  the  paper  is  organized  as  follows.  Section  2  presents  a  brief 
background about collaboration in hospitals. Section 3 presents our proposed procedure 
to assess the intention of adoption of these tools at development time. In Section 
4 we illustrate an instance of a groupware evaluation using the proposed approach and 
finally, Section 5 concludes this paper. 

2   A Process for Evaluating Groupware throughout the 

Development Lifecycle 

As a way to evaluate the possible impact of a groupware tool in an organization without 
 having  to  deploy  it,  we  are  proposing  an  approach  that  involves  obtaining  and 
taking  into  account  the  needs  of  the  users  throughout  the  design  and  development 
process. Based on this approach, the design of a groupware tool, therefore, progresses 
in iterative cycles of design, evaluation and redesign. Thus, the procedure used consists 
in the evaluation of three main phases (see Figure 1): i) the understanding of the 
problem, ii) the design of the tool, and iii) the usability of the tool. A brief description 
of these phases follows. 

2.1   Phase 1: Evaluating the Understanding of the Problem 

The first phase consists in determining if the researchers’ perception of the problem 
corresponds to the users’ perception of the problem. This requires evaluating whether 
the users perceive as a problem the breakdowns that researchers identify in the field 
study.  A  set  of  interviews  and  a  focus  group  session  with  potential  users  could  be 
used to validate the field study findings.  

In this phase it is recommended to show the identified breakdowns through the use of 
scenarios  illustrating  real  instances  of  observed  collaboration  [in  the  hospital].  In  this 
stage the discussion must be elaborated around the perceptions of the users concerning 
the presented scenarios. Some of the following questions could help to this purpose: 
•  Have you seen or experimented similar situations? 
•  How frequently does this occur [in hospitals]? 
•  Do you consider this situation as an inconvenience during the performance of your 

daily work tasks? 

•  What do you do when this situation occurs? 
•  Do you have some proposal for addressing this situation? 

After the focus group session ends, the researchers must do a qualitative analysis to 
identify those misunderstandings during the analysis of the problem. This analysis is 
very useful, because it could help to avoid spending resources in the development of 
tools that will not address real breakdowns, according to the users’ perception.  

 

Evaluating Design Concepts to Support Informal Communication in Hospitals 

1015 

Fig. 1. Proposed iterative design and evaluation lifecycle 

 

2.2   Phase 2: Evaluating the Design 

The  second  phase  consists  in  validating  whether  the  designed  functionality  for  the 
tool might help to achieve the goal of the system [augment informal communication] 
as  identified  in  the  field  study  (tool  design),  as  well  as  evaluating  (from  the  design 
perspective) if potential users would be interested on using the proposed tool. As in 
the previous phase, the use of scenarios could be very helpful to show users the envisioned 
support for the identified breakdown [in the hospital]. In this phase it is recommended 
to show two types of scenarios: the first type is aimed at showing users the 
problem  or  breakdown  that  is  addressed.  These  scenarios  could  be  very  similar  to 
those used in the previous phase. The second type instead of illustrating the problem, 
must envision how the proposed tool could address the specific problem. 

The main focus in this phase must be to identify those weaknesses in the design of 
the proposed tool that could interfere with the user’s intention of use. Thus, some of 
the following questions could help to accomplish this purpose: 
•  Does the tool address the problem adequately? 
•  Which are the advantages of this tool in comparison with the way in which users 

currently address this situation? 

•  Which are the disadvantages of this tool in comparison with the way in which users 

currently address this situation? 

•  What changes do users suggest for the tool to be useful in this situation? 
•  Do users intend to use this tool? 

1016 

D.A. Mejia et al. 

After the session, a qualitative analysis of the  gathered data could help to understand 
why users would intend or not to use the tool, as well as to avoid researchers to 
work in a tool that would not be used due to errors during its design. 

2.3   Phase 3: Evaluating the Usability 

The third phase consists in evaluating whether the tool helps to address the identified 
problems in an easy and seamless way. In other words, in this phase the tool is evaluated 
from a usability perspective. For this reason, it is recommended to recreate real 
instances  of  collaboration  in  order  to  allow  users  to  interact  among  them  using  the 
tool. Thus, instead of a focus group session such as in the previous phases, it is recommended 
to conduct a set of controlled activities in a laboratory. The users must be 
asked  to  perform  some  activities  using  the  tool  and  at  the  end  of  this  session,  they 
must be asked to comment about their perception of the use of the tool. Additionally, 
researchers could measure the activities that users perform using the tool (i.e. number 
of clicks in a determined button, time spent to accomplish a task, etc.). After the session 
finalizes, the researches could make an analysis using qualitative and quantitative 
techniques of the collected data to identify weaknesses in the usability of the tool. 

The main purpose of this phase is to avoid releasing a tool that would not fulfill the 
usability and functional requirements established by the users, and as a consequence, 
that has a significant risk of not being adopted by potential users. 

After each phase, researchers must determine whether users found inconveniences 
or  errors  in  the  design  or  development  of  the  tool.  When  it  happens,  the  researcher 
must  address  these  findings  and  restart  the  evaluation  process  on  the  current  phase. 
Thus,  at  the  end  of  this  design  and  evaluation  process,  researchers  will  be  able  to 
provide a set of design insights and a tool informed with requirements that emerged 
directly from observations of the real [hospital work] situations, and validated by the 
potential users. 

3   Illustrating the Evaluation Process through the Development   of 

SOLAR 

To illustrate the use of the proposed evaluation process, in this section we report the 
main  results  of  the  evaluation  of  SOLAR  during  its  development,  a  tool  to  support 
informal  communication  in  hospitals  that  integrates  an  ensemble  of  five  specialized 
services that includes i) location estimation of workers in the hospital displayed on the 
floor plan on the Smartphone, ii) awareness of relevant events and nearby colleagues 
and their social context, that allows them to select an appropriate moment to initiate 
an  interaction  with  others,  iii)  transfer  of  files  and  URLs  among  heterogeneous  devices 
just by clicking the right mouse button and choosing the target device, iv) screen 
sharing of any device in the vicinity (e.g. PDA,  PC or public display) on a handheld 
computer, and remotely sharing the control of the device with its owner and/or other 
users,  and  v)  notification  of  creation  or  modification  of  information,  and  storage  of 
this information in a user’s mobile device during a collaboration episode (capture of 
collaboration outcomes). [4, 5]. 

 

Evaluating Design Concepts to Support Informal Communication in Hospitals 

1017 

According to [7], the deployment of groupware tools without an adequate evaluation 
is not recommended, mainly because unevaluated systems tend to be unsuccessful 
and may fail to consider the context, stakeholders and contain errors after deployment. 
However, the evaluation of tools like SOLAR represents a challenge, since the evaluation 
process is dependent on several variables such as those imposed by the application 
domain  (i.e.  the  hospital),  its  multiple  users  (i.e.  physicians,  medical  interns  and 
nurses), and their interaction with the provided services (i.e. how the tools affects work 
practices) [5]. For this reason, we decided to evaluate SOLAR through its development 
lifecycle as proposed previously. 

3.1   Phase 1 Evaluation Results: Understanding the Problem 

During the analysis of the results of the field study, we identified some breakdowns 
before, after and during communication that include lack of awareness of the presence 
of mobile colleagues, waste of opportunities for collaboration, interruption of interactions 
in order to gather information artifacts necessary for collaboration, and loss of 
information generated during collaboration.  

We exemplify these breakdowns through the use of scenarios like the following:  

A physician is in the Internal Medicine office when a medical specialist arrives and 
asks him about an X-Ray image he is consulting.  

      [Physician] What do you think about this? 

 [Medical Specialist]  (Looking the X-Ray results) Mmm, I think that he has (dis-

ease’s name). 

         [Physician]  Are  you  sure?  Because  he  has  (medical  specialist  explains  the 

symptoms of patient). 

  [Medical Specialist] Yes, I do. I had a patient with similar symptoms. 
         [Physician]Are you sure? I think (there) could be some differences between 

 [Medical Specialist] Well, let me review the health record of my patient and I will 

the symptoms of these patients. 

get back to you later. 

Later,  the  physician  and  the  medical  specialist  met  opportunistically  in  the  hallway 
and they restart their previous discussion. 

  [Medical Specialist] (Showing the physician a health record) Look, these are the     

symptoms  of  the  patient  I  mentioned.  His  disease  has  the 
same features as those of your patient. 

        [Physician] Ok, you are right. But, which is the treatment for this type of dis-

ease? 

   [Medical  Specialist]  (Medical  specialist  explains  the  treatment  for  the  patient).  I 
have a book in my consulting room. Please go there later, I 
can lend it to you. 

 

In this phase we perform the evaluation with four physicians in a focus group session.
  We  exemplified  the  breakdowns  through  three  scenarios  that  we  showed  to 
them. It  was  not necessary to iterate in this first phase evaluating session,  since  the 
comments  and  recommendations  of  these  physicians  where  only  aimed  at  changing 
the medical terminology used in the scenarios.  

1018 

D.A. Mejia et al. 

3.2   Phase 2 Evaluation Results: Validating design 

Based on the breakdowns identified in  hospital collaboration, as  well as on a  set of 
design insights identified during the analysis of the data collected in the field study, 
we designed the functionality of SOLAR. Then, aimed to estimating the users’ intention 
to use SOLAR through the evaluation of its functionality,  we verified that SOLAR 
does provide support for each of these breakdowns. 

The design insights that inspired SOLAR functionality include: 

Use  of  devices  that  allow  workers  to  initiate  collaboration  while  on-the-move. 
Medical workers are not only constantly moving from one operation center to another, 
but they actually have meaningful encounters and perform work while in the hallway or 
bed ward. Thus, SOLAR was designed to provide support for hospital workers to allow 
them to collaborate when they are on the move as required by the actual situation. 

Use  of  devices  that  allow  workers  getting  into  collaboration  while  on-the-base. 
Hospital  workers  fill  administrative  forms,  write  medical  notes  or  analyze  medical 
evidence in specific places that we have called “base locations” (e.g. nurse pavilion, 
consulting room, etc.). Furthermore, we found that hospital workers have meaningful 
interactions and collaborate with others colleagues when they are at those base locations.
  For  this  reason,  SOLAR  should  be  executed  in  devices  that  allow  workers  to 
collaborate while they are in their base location. 

Easy access to information sources. Physicians and medical interns need to share or 
exchange  information  to  accomplish  the  objective  of  their  interactions.  Currently, 
they use physical artifacts to do this, like medical records and X-Ray images, among 
others. For this reason, SOLAR allows them to have easy access to digital information 
sources anytime, anywhere. 

Use  of  devices  and  services  that  allow  interactions  based  on  medical  evidence. 
Physicians and medical interns often discuss clinical cases. Sometimes, they use and 
share information stored in physical artifacts (e.g. medical records, X-Ray images and 
books) and/or in electronic devices (e.g. document stored on PC, PDA or digital  li-
brary) in order to explain their opinions to others. For this reason, SOLAR  was designed 
 to  provide  mechanisms  that  allow  the  use  and  manipulation  of  devices  and 
information that help to enrich discussions anyplace-anytime medical workers need it. 

Tracking of People. Hospital workers often interrupt their work and also walk more 
than 60 feet in order to locate a particular colleague. For this reason, SOLAR allows 
hospital workers to be aware of the presence of others, their identity and location, as 
well as suggesting an adequate moment for initiating collaboration with them.  

Awareness of the opportunities for collaboration. In informal interactions there are 
two main elements that trigger people to initiate collaboration with others: the availability 
 of  a  communication  or  interaction  channel  (e.g.  physical  proximity)  and  the 
interest or need of at least one of the participants to collaborate with the other [20]. 
For these reasons, SOLAR allows  hospital  workers to be aware of  the other’s presence,
 identity and location, as well as of an adequate moment for getting into collaboration 
with them.  

 

Evaluating Design Concepts to Support Informal Communication in Hospitals 

1019 

Seamless information access and sharing. One of the purposes of informal interactions 
 is  sharing  or  transferring  documents  to  others.  Thus,  SOLAR  allows  hospital 
workers to easily share and exchange information among them.  

Capture  of  collaboration  outcomes.  Information  generated  during  collaboration  is 
rarely  recorded  in  persistent  artifacts.  Since  information  could  be  useful  in  future 
activities or interactions, SOLAR provides mechanisms that allow users to capture the 
collaboration outcomes, in order to facilitate the reuse of information generated while 
they are collaborating. 

Based on these design insights, we designed and developed five main services that 
conform the functionality of SOLAR: i) location estimation, ii) awareness for potential 
collaboration, iii) seamless information transfer, iv) remote control of heterogeneous 
devices and v) capture of collaboration outcomes  

In  order  to  better  illustrate  the  features  of  our  identified  design  insights,  we  presented 
the next scenario to five medical interns. This scenario projects how the situation 
represented in the scenario of the previous phase could be performed using a tool 
conceived based on the identified design insights: 

A physician is in a patient’s room when she realizes through a location estimation 
mechanism  in  her  PDA  that  the  medical  specialist  is  walking  down  the  corridor  –
which is close to her position and decides to ask him about an X-Ray image she was 
consulting in a public display.  

              [Physician]   What do you think about this? 

  [Medical Specialist]  (Looking  at  the  X-Ray  results)  Mmm,  I  think  that  he  has 

(disease’s name). 

               [Physician]   Are you sure? Because he has (medical specialist explains 

the symptoms of patient). 

 [Medical Specialist]  Yes, I do. I had a patient with similar symptoms. 
                [Physician]   Are you sure? I think (there) could be some differences be-

[Medical Specialist]  Let me show you the health record of my patient. 

tween the symptoms of these patients. 

The medical specialist access the patient’s health record through his PDA and transfers 
(seamlessly) the document to a public display. 

[Medical Specialist] 

(From their PDA, using a tool for remotely controlling the 
public  display,  he  explain  the  physician  an  X-Ray  of  the 
patient) Look, these are the symptoms of the patient I mentioned.
 His disease has the same features as those of your 
patient. 

      [Physician]      Ok,  you  are  right.  But,  which  is  the  appropriate  treatment  for 

[Medical Specialist] 

this type of disease? 
(After explaining the treatment for the patient the medical 
specialist accesses his office’s computer through his PDA 
to retrieve information from a medical guide related to the 
medication and to the patient’s condition, and transfers it 
to the physicians’ PDA). I have this information that could 
be useful to you. 

1020 

D.A. Mejia et al. 

During  the  course  of  this  interaction,  the  voice  and  textual  comments  are  stored  in 
order to be accessed when the hospital workers require it. 

So, in this scenario we show how the services designed into SOLAR (i.e. location 
estimation; the use of devices that allow workers to initiate collaborations while on-
the-move;  the  use  of  devices  and  services  that  allow  interactions  based  on  medical 
evidence;  tracking  people;  seamless  information  access  and  sharing;  and  capture  of 
collaboration outcomes) synergically work in order to augment a co-located informal 
interaction. 

During this phase, medical workers suggested some changes in the capture of collaboration 
outcomes.  According  to our process,  we  made the changes to the system 
and conducted an additional second phase evaluation session. 

3.3   Phase 3 Evaluation Results: Validating Usability  

To  illustrate  the  third  phase  of  the  evaluation,  in  this  section  we  report  the  results  
of the usability evaluation of one of SOLAR services, the Remote Control of Heterogeneous 
 Devices.  This  evaluation  session  was  conducted  in  a  meeting  room  with  a 
public  display  and  several  personal  computers.  The  subjects  of  the  study  were  six 
graduate students, some of them having already used a PDA and others not. Before 
we  started  the  evaluation  we  gave  each  user  a  PDA,  simulating  indeed,  a  real  colocated 
 meeting  environment  saturated  with  heterogeneous  devices.  The  complete 
results of this evaluation are discussed elsewhere [3].  

The  evaluation  required  two  subjects  to  collaborate  in  performing  three  different 
tasks, including i) checking email and filling a survey with/without the echo functionality 
 (completed  individually),  ii)  creating  a  picture  slideshow  accompanied  with  a 
soundtrack with the aim of making a promotional clip for a city (two users, each subject 
played a particular role: as a sound designer, choosing one song among ten that 
were available; or as a graphic designer choosing eight pictures from the thirty pictures 
 available),  and  iii)  following  a  red  spot  in  synchronization  with  the  tick  of  a 
metronome set at a very low speed (the priority was to follow the metronome instead 
of the precision, aimed at estimating the precision and the speed of the application). 
Thus,  we  randomly  grouped  our  subjects  in  pairs  conducting  an  evaluation  session 
with each group. 

We wanted to capture qualitative data and quantitative measurements of the users’ 
inputs. Therefore, we videotaped each evaluation session capturing the users’ interaction 
with the PDA and the verbal communication exchanges they were having while 
performing each task. In addition, the screen of the public display was captured using 
the Morae1 software which registers all user inputs for statistics and analysis. 

After the end of this session, we identified that subjects were positive about the application.
  The  main  advantages  the  subjects  highlighted  were  all  related  to  the  collaborative 
features (pointer and control services) allowed by the application.  

Additionally, we provided a list of seven improvements and we asked the subjects 
to choose three of them which, in their opinion, need to be attended with higher priority 
(see table 1).  

                                                           
1 Available at http://www.techsmith.com/morae.asp 

 

Evaluating Design Concepts to Support Informal Communication in Hospitals 

1021 

Table 1. Improvements for the Remote Control of Heterogeneous Devices’ service of SOLAR 

Improvement 
A less jerky movement 
Improved speed 
Higher precision 
Right click ability 
Click and hold ability (to move a window for example) 
New pointer shape 

Choices 

5 
2 
6 
1 
3 
0 

 

The results of the preliminary evaluation of the system show that the users experienced 
 some  difficulty  moving  the  cursor  in  the  remote  screen,  yet,  they  found  the 
application  to  be  useful  in  facilitating  co-located  collaborations.  In  addition,  users 
seemed  to  require  additional  experience  with  the  tool  as  we  observed  that  they  improved 
their precision and speed towards the end of the exercises.  According to the 
proposed  approach,  these  improvements  must  be  introduced  before  repeating  third 
phase evaluation one more time. 

4   Conclusions 

The evaluation of groupware tools is not a simple task, because of the multiple factors 
and  variables  that  influence  and  define  the  organizations  where  these  tools  are  deployed.
  The  main  mechanism  to  evaluate  these  tools  would  be  through  the  deployment 
of the tool in the organization, followed by an in situ evaluation. This kind of 
evaluation is expensive in terms of time and human resources; perhaps its main disadvantage 
is that errors during the design stage would be detected very late (deployment 
time). Moreover, even with the deployment of the tool, there is not a specific process 
to evaluate a groupware tool in situ,  

In this paper we present a process for evaluating groupware applications throughout 
the development lifecycle. This procedure consists of three phases that evaluate i) 
the understanding of the problem, ii) the design of the tool, and iii) the usability of the 
tool. We illustrate the use of this approach through the evaluation of SOLAR, a tool 
developed for supporting informal communication in hospitals. We found this procedure 
very  useful, because it  helped us to  identify specific  errors during the analysis 
and design phases. Also, based on the techniques used, this approach might help predicting 
how users would use and accept the proposed tool.  

Acknowledgements 

This work was partially supported by LACCIR under grant No. RFP0012007. 

References 

1.  Greenberg, S., Buxton, B.: Usability Evaluation Considered Harmful (Some of the Time). 
In: Proceedings of the SIGCHI conference on Human Factors in computing systems, Florence,
 Italy, April 5-10 (2008) 

1022 

D.A. Mejia et al. 

2.  Grudin, J.: Why CSCW applications fail: problems in the design and evaluation of organization 
of organizational interfaces. In: CSCW 1988, pp. 85–93. ACM Press, New York (1988) 
3.  Markarian, A., Favela, J., Tentori, M., Castro, L.A.: Seamless Interaction among Heterogeneous 
 Devices  in  Support  for  Co-located  Collaboration.  In:  Dimitriadis,  Y.A.,  Zigurs,  I., 
Gómez-Sánchez, E. (eds.) CRIWG 2006. LNCS, vol. 4154, pp. 389–404. Springer, Heidelberg 
(2006) 

4.  Mejia,  D.A.,  Morán,  A.L.,  Favela,  J.:  Supporting  Informal  Co-located  Collaboration  in 
Hospital  Work.  In:  Haake,  J.M.,  Ochoa,  S.F.,  Cechich,  A.  (eds.)  CRIWG  2007.  LNCS, 
vol. 4715, pp. 255–270. Springer, Heidelberg (2007) 

5.  Mejia,  D.A.,  Morán,  A.L.,  Favela,  J.,  Tentori,  M.,  Markarian,  A.,  Castro,  L.A.:  On  the 
Move  Collaborative  Environments:  Augmenting  Face  to  Face  Informal  Collaboration  in 
Hospitals. e-Services Journal 6(1) 

6.  Pinelle, D., Gutwin, C.: A review of groupware evaluations. In: WETICE 2000: 9th International 
 Workshop  on  Enabling  Technologies,  pp.  86–91.  IEEE  Computer  Society,  Los 
Alamitos (2000) 

7.  Herskovic,  V.,  Pino,  J.,  Ochoa,  S.,  Antunes,  P.:  Evaluation  Methods  for  Groupware  Systems.
 In: Haake, J.M., Ochoa, S.F., Cechich, A. (eds.) CRIWG 2007. LNCS, vol. 4715, pp. 
328–336. Springer, Heidelberg (2007) 

