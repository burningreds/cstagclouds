Enhancing Educational-Material Retrieval Using

Authored-Lesson Metadata

Olivier Motelet1, Benjamin Piwowarski2, Georges Dupret2, Jose A. Pino1,

and Nelson Baloian1

1 DCC - Universidad de Chile

2 Yahoo! Research Latin America

Abstract. Many authors believe that in order to achieve coherence and
ﬂexibility at the same time in multimedia-based learning units, it is
highly recommendable to structure the diﬀerent components as a graph.
In a lesson graph, educational resources are encapsulated into learning
objects (LO) along with their respective metadata and are interconnected
through diﬀerent kind of rhetorical and semantical relationships. The
LOs of these graphs are stored within repositories, where their metadata
are used to ease their retrieval. In this paper we propose to integrate
the processes of searching LOs and editing the lesson graph. This new
framework extends traditional keyword and metadata search to take advantage 
of the information stored implicitly in the lesson graph structure,
making LOs retrieval more eﬀective and the expression of queries more
intuitive. The retrieval of the learning material consists of two processes:
(1) The user ﬁrst deﬁnes the topological location of a required piece of
educational material within the lesson graph, this is, its relationships
with other pieces. (2) Then, the user issues a traditional keyword query,
which is processed by an IR system modiﬁed to take the graph structure
into account. Experiments show the advantages of this approach.

1 Introduction

The last ten years have witnessed the emergence of various repositories dedicated
to store and share educational resources under the form of learning objects,
or LO in short. Although LOs have diﬀerent deﬁnitions in the literature, this
article considers a LO as a piece of educational material (a slide, a web page,
a simulation, etc.) associated with some metadata. The main goal of LOs is to
enable the re-usability of learning/teaching material. International organizations
have worked towards supporting that purpose by deﬁning characterization and
interoperability standards for LOs [1].

One of the main ongoing eﬀorts in this direction is the speciﬁcation of the
Learning Object Metadata (LOM) standard for the metadata characterizing a
LO [2]. Unlike most standards that mainly describe physical attributes of the
digital resources, LOM oﬀers a large set of educational attributes designed to
help teachers and learners to retrieve existing educational material and activities.
In practice, however, most users issue simple keyword queries and neglect the
use of the metadata in spite of the diﬃculties they face while retrieving the

N. Ziviani and R. Baeza-Yates (Eds.): SPIRE 2007, LNCS 4726, pp. 254–263, 2007.
c(cid:2) Springer-Verlag Berlin Heidelberg 2007

Enhancing Educational-Material Retrieval Using Authored-Lesson Metadata

255

material they expect to obtain [3]. In this paper, we present a user-oriented way
of taking advantage of the metadata: The user tells the system the location in
the lesson graph where to ﬁnd the LO he needs and what type of relations this
object should hold with its neighbors. We then make use of this information to
improve retrieval.

The graph representation is an intuitive way of visualizing the course structure 
and is amenable to last minute modiﬁcations during the lecture delivery
itself. Many course authoring tools designed to create adaptive and ﬂexible lesson 
units use a graph for the course structure [4]. Typically, a teacher starts the
authoring of a course by building a graph of LOs connected by semantic and/or
rhetoric relationships and ﬁlls the nodes with teaching material. The new search
paradigm for learning material we propose comes into play naturally when the
teacher introduces a new, empty node, i.e., not yet referring concrete material,
into the graph and links it to other nodes. These nodes, the links and the associated 
metadata provide a context to the search that we use to improve retrieval.
The main challenge we face is the transformation of the information contained
implicitly in the graph into a form that can be used to search the LO database.
The following section introduces the notion of lesson graph based on LOs.
Next querying a LO repository from within a lesson graph is presented. Section 4
describes our method for taking advantage of the lesson graph associated with
the query in order to enhance LO retrieval. The results of experiments in a smallscale 
but realistic setting are reported and support our approach: We show in
the experiment section how our method improves over simple keyword queries.
Finally, related work is reviewed and conclusions are obtained.

2 Authoring a Course as a Graph

Metadata for Learning Objects (LOM) has two purposes, to describe the LOs
and to interconnect LOs. The LOM speciﬁcation concerns about 60 metadata
attributes describing mostly technical, educational and general aspects of educational 
resources. Attributes are identiﬁed by a series of names separated by
slashes, e.g., general/title, where “general” is the category and “title” the attribute 
name. Attributes can be classiﬁed in three sets: (1) Predeﬁned vocabulary
values (e.g., easy and diﬃcult are vocabulary values for the educational/diﬃculty
attribute). The speciﬁcation proposes values for the vocabulary but this is generally 
tailored towards the needs of particular teaching communities. (2) Free
text that can be associated with a given language. Several texts corresponding
to several languages can be proposed. (3) Primitive types, such as identiﬁer,
date, time, or integer. Most attributes have a value deﬁned on a set, e.g., a set
of strings for the general/keywords attribute.

Links between LOs are deﬁned by a special kind of attribute called a relation.
Links are typed, such as introducesTo or exempliﬁedBy. The set of links deﬁnes
the structure of the graph. Figure 1 illustrates such a LO graph where six LOs,
labeled from L1 to L6, describe a part of a programming course for an object

256

O. Motelet et al.

Object
Instantiation

L6

"Traffic Light" 
Problem

L1

Introduces To

Resolved By

"Traffic Light" 
Implementation

L2

Abstracted By

Constructors

Constructors
Overloading

?

L5

Object
Instantiation

L3

Background For

L4

Exampliﬁed By

Fig. 1. Start of a lesson graph about “object instantiation”

oriented language. L1 (problem deﬁnition) and L2 (Java code) introduce the
problem of how to organize a crossroad with two traﬃc lights. The topic of this
exercise is object instantiation in a program. L3 and L4 refer to slides deﬁning
respectively object instantiation and the concept of constructors. L5 is an example 
of a query within a LO graph and will be described in the next section.
L6 is a LO of coarser granularity and acts as a container for L1 to L5. Practically,
 lesson graphs such as the one presented in Figure 1 can be authored with
LessonMapper2, a graph authoring tool of LOs characterized with LOM [5].

Several authors argue that the LOM relation types speciﬁcation is insuﬃcient
for lesson authoring and needs to be extended [6,7]. We focus on the work of
Trigg [8], which deﬁnes an extensive set of relations for supporting narration.
According to our institution teachers’ needs, we empirically selected a subset
of these relations, emphasizing the semantical, rhetorical and organizational aspects 
of course authoring: introducesTo, assessedBy, supportedBy, abstractedBy,
exempliﬁedBy, comparableWith, backgroundFor, summarizedBy, explainedBy, resolvedBy,
 refutedBy, isPartOf. Each of these relations has an opposite: a relation
from a LO a to another LO b implies an inverse relation from b to a. It is important 
to note that the suggested relations do not apply to all teaching contexts,
but are easily complemented to suit other situations.

3 Querying a Repository from Inside the Lesson Graph

Standard querying is done by searching matching metadata and keywords. To
describe L5, we could for example choose “constructors overloading” and retrieve
the LOs with metadata related to it. This is the approach taken by the Lucene
search engine [9] that we use in our experiments (Section 5).

Querying a LO repository can be done using a purely graphical approach.
For instance, consider node L5 of Figure 1. This node is not associated with an
existing document, instead it is a query node: A query reﬂecting the need for a
learning object with certain characteristics is thus expressed as a position in the
lesson graph. In Figure 1, the LOs satisfying the query node L5 are examples of
the concepts introduced by L4.

Enhancing Educational-Material Retrieval Using Authored-Lesson Metadata

257

Since authoring a lesson consists of adding nodes to the lesson graph, it is
natural to integrate this task with retrieval and to use the implicit information
associated with the new node position. This can be seen as associating a context
extracted from the graph to the traditional term or metadata search. In this
work, we will modify the ranking of retrieved objects as produced by a Lucene
search process with the results of classiﬁers designed to take the neighbor graph
into account.

4 Using the Lesson Graph to Evaluate Potential Results

Motelet et al. [10] propose a system that takes advantage of the semantics of a
lesson graph in order to infer information about the LOM semantics of the LOs
of a lesson graph. Unlike other models (e.g., [11]), this system suggests metadata
where they are missing using an exhaustive-diﬀusion process of the node characteristics 
along the graph edges. This characteristic is particularly interesting in
the context of the lesson graph authoring process where metadata are typically
incomplete. Two types of metadata information are generated: value suggestions
and value restrictions. We propose to generate this additional information for
the query nodes and to use it when querying a LO repository from within a
lesson graph.

This section ﬁrst describes the use of value restrictions and value suggestions
as classiﬁers. Then the combination of the generated classiﬁers with a machine
learning algorithm is discussed.

4.1 Using Value Restrictions as Classiﬁers
Value restrictions are deduced from graph consistency analysis. In Figure 1 for
instance, we expect L1 to be simpler than L2 because it introduces it. While
the diﬃculty of a LO is a relative notion that may be hard to standardize, it is
possible to compare diﬃculty levels of two LOs inside the same lesson graph. In
terms of value restrictions, it means that the value of the LOM attribute edu-
cational/diﬃculty of L1 should be as low or lower than the educational/diﬃculty
of L3. If L1 introduces more than one resource, its level of educational/diﬃculty
should be compatible with each element it introduces. Rules about graph consistency 
may be deﬁned for any LOM attribute and any relation as far as it is
meaningful. In [10], the authors propose that such an assumption about graph
consistency be tailored to suit other teacher requirements if necessary.

When searching a repository, the LOs that comply with the value restrictions 
associated with the query should be promoted. To implement this idea, a
score is computed for each LO as #CompliedRestrictions
. If there are no generated
restrictions for a certain LOM attribute, the scores are set to 1.

#Restrictions

4.2 Using Value Suggestions as Classiﬁers
Value suggestions are generated based on a set of assumptions about attribute
similarities between related LOs. In our example, since L1 introduces L3 we

258

O. Motelet et al.

expect that both share a similar value for the attribute general/keyword. We
evaluate this similarity based on probabilities observed in the repository over
the same attributes. For instance, analyzing the repository on which we conducted 
the experiments of Section 5, we observe that a keyword of the attribute
general/keyword of a LO has 54% chance to appear in the same attribute ﬁeld of
the LOs it introduces.

Formally, if we deﬁne Vatt as the set of possible values for an attribute att, a
value suggestion for a LOM attribute of a given LO is a set of weighted values
{(v, w(v)) : v ∈ Vatt} where w(v) is the probability that the v value suits the
LO. We can compute suggestions for elements in the repository in the same way
as we compute them for queries based on the neighboring nodes. To estimate
the similarity between a query node q and a node e from the repository, we need
to measure how similar the nodes’ suggestions are. We propose to adapt the
traditional cosine measure for this task:
(cid:2)

v wq(v) × we(v)

v wq(v)2 × (cid:3)(cid:2)

simatt(q, e) =

(cid:3)(cid:2)

v we(v)2

where v scans the values of att and wq(v) and we(v) are the weights associated
with v in the suggestions of q and e, respectively. This measure quantiﬁes the
intuition that the value suggestions represent the relation of the node q and
e with their neighbors in their respective graphs. In other words, these values
summarize the context of the nodes.

Note that the original attribute values from node e are discarded and only the
suggestions extracted from its neighbors are considered for evaluating the cosine
measure. There are two reasons for this. First, because we are attempting to
match the lesson graph and the repository graph, it is natural to simulate what
would be the state of e if it were the currently introduced node. Setting e as a new
node in its environment with the same kind of information as the teacher provides
for q has the eﬀect of making the two associated LOs representations more
homogeneous, and improves retrieval as shown by our numerical experiments.
The second reason for discarding the original attribute values of the node e
is more pragmatic and is related to the keyword search: Lucene indexes the
LOs in the repository according to the original attributes and thus there is an
information redundancy if we re-introduce these values in the classiﬁers. Instead,
using only the value suggestions originating from the node neighbors, the context
is better taken into account. To distinguish the case where we discard the original
attribute values from the case where they are preserved, we refer to the ﬁrst as
context-only diﬀusion and the second as full diﬀusion. Section 5.2 shows
the beneﬁt of context-only diﬀusion over full diﬀusion.

4.3 Combining Classiﬁers

As explained above, graph consistency and context similarity can be used to
evaluate the relevance of repository LOs for each metadata attribute. In our
implementation, we suppose the attributes are independent and have a total of
17 classiﬁers based on value restrictions and 17 classiﬁers based on the value

Enhancing Educational-Material Retrieval Using Authored-Lesson Metadata

259

suggestions. These classiﬁers are called graph-based classiﬁers. Combination
of these classiﬁers is done by RankBoost [12].

RankBoost is a machine learning algorithm that searches for an optimal combination 
of several weak or uncertain classiﬁers. In preliminary experiments not
reported in this paper, we ﬁrst evaluated separately each graph-based classiﬁer.
As the Lucene and graph-based classiﬁers operate on almost distinct variable
sets, we opted for a series of new classiﬁers whose score is the score of one graphbased 
classiﬁer multiplied by the Lucene score. We call them mixed classiﬁers.
Each of these classiﬁers orders repository LOs: The corresponding ranks are the
input to the RankBoost algorithm.

Thanks to the fact that the relevance can be considered binary, we used the
simplest version of the RankBoost algorithm: At each iteration of the algorithm,
a base classiﬁer is chosen, along with a threshold rank and a weight α. The result
of learning is a set of step functions fi, one for each base classiﬁer. The ﬁnal score
i fi(ri(q, L)) where ri(q, L) is the rank of
of a LO L for a query q is given by
L according to the ith classiﬁer and fi is the function learned by RankBoost for
this classiﬁer. We furthermore required that each function fi is decreasing with
respect to the rank ri, in order to avoid over-ﬁtting (as suggested in [12]).

(cid:2)

5 Experiments

5.1 Description

A learning object repository was implemented within our institution and populated 
with 170 learning objects about a single topic: An introductory Java
course. This repository contains ﬁne grained LOs, each corresponding to teach-
ing/learning material for about 5 minutes. In contrast with the available repositories,
 relation semantics linking repository LOs are based on the proposal made
in Section 2 (see [13] for getting access to a repository snapshot). Eleven teachers
of Java Programming, not involved in the project presented in this article, were
asked to complete a lesson graph about object instantiation and method call. We
informed them that the lesson should tackle the following topics: constructor,
new, method call, ’.’ , constructors with arguments, method overloading, delegation,
 object design, separation of concern. They were also informed that topic
ordering was ﬂexible. Topics were purposely deﬁned for various granularities and
without apparent coherency so that each teacher felt free to create a new course.
The lesson was presented as a graph built in LessonMapper2. The tool was
previously introduced to the teachers, along with examples of lesson graphs and
available relation types. Each teacher was confronted with 4 diﬀerent situations:
(1) A graph with one LO, (2) a graph with 5 LOs (including the ﬁrst graph), (3)
a graph with 9 LOs (including the second), and (4) a graph with 13 resources
(including the third). The content of the presented graphs were not previously
known to teachers: The presented LOs were original and not similar to the teach-
ers’ own courses. The repository did not contain any LOs used in the presented
graphs.

260

O. Motelet et al.

The proposed graphs were purposely incomplete in order to motivate the
teacher to complete them. For each situation, teachers were asked to complete
the corresponding lesson graph with 2 new LOs of their choice. The teachers had
to thoroughly describe the required LOs so that the interviewer could identify
which repository LO matched the teacher’s intent. The matching LOs were not
communicated to the teachers. Instead of that, they were asked to search for
them in the repository using common keyword queries and locating the expected 
material inside the graphs, i.e., by deﬁning query nodes. Teachers knew
that keyword queries were used to search the metadata of the available LOs of
the repository and not their content. Eventually, query terms referring to some
special vocabulary values were deﬁned in natural language and then replaced by
the interviewer with the proper vocabulary value.

The four situations gave rise to respectively 23, 21, 22 and 22 test cases,
including keyword query and position in lesson graph along with the relevant
results (see [13] for getting access to the test cases). In the ﬁrst situation, one
teacher formulated 3 queries instead of two. In the second situation, one query
had no answer in the repository and was subsequently ignored.

5.2 Result Analysis

Using the queries (composed of a graph with a query node and of a set of key-
words), we evaluated three diﬀerent systems: First, we used only keywords and
the Lucene IR system. Lucene indexed the metadata of the LOs contained in
the repository. During the preprocessing, metadata values were stemmed and
tags were removed. Only metadata were indexed since most of the educational

i

i

n
o
s
c
e
r
P

RankBoost for context−only diffusion
RankBoost for full context diffusion 
Lucene
Mean for context−only diffusion
Mean for full context diffusion

%
0
5

%
0
4

%
0
3

%
0
2

0%

5%

10%

15%

20%

25%

30%

35%

40%

45%

50%

55%

60%

Recall

Fig. 2. Precision recall results of mixed classiﬁers combined with RankBoost and
Lucene. We also plotted the average precision of the mixed classiﬁers for both full
and context-only diﬀusions.

Enhancing Educational-Material Retrieval Using Authored-Lesson Metadata

261

resources of the used repository were multimedia documents with proprietary format 
where relevant information is diﬃcult to access. Similarly, keyword queries
are stemmed.

In the next step, we used the mixed classiﬁers combined with RankBoost and
each of the two diﬀusion mechanisms in turn (full diﬀusion and context-only
diﬀusion) described in Section 4. We trained and tested RankBoost using a 4fold 
cross-validation. Each fold corresponded to one of the diﬀerent situations of
the experiment. When testing one fold, the data of the three others were used
for training.

Figure 2 shows the standard precision-recall [14] curves for the data of the
experience described above. Lucene outperforms the mean of the mixed classiﬁers 
taken individually. Nevertheless, the RankBoost combination of the mixed
classiﬁers outperforms signiﬁcantly Lucene alone, especially when graph-based
classiﬁers use the context-only diﬀusion algorithm. Table 1 summarizes tests
conﬁrming the statistical signiﬁcance of this diﬀerence.

Table 1. T-tests on precision diﬀerences between RankBoost (context-only diﬀusion)
and Lucene

Recall interval Mean

95% conﬁdence interval p-value
0% – 25% 0.05226301 0.01948787 – 0.08503815 0.002109
0% – 50% 0.05020075 0.02076609 – 0.07963540 0.001053
0% – 75% 0.04613934 0.01865014 – 0.07362853 0.001251
0% – 100% 0.04106811 0.01429855 – 0.06783768 0.003039

To gain insight on these results, we studied the mean proportional diﬀerences
between the RankBoost-based evaluation and Lucene alone using 100 samples
taken randomly with repetition into the 88 test cases (Bootstrap sampling).
The Rankboost combination of the mixed classiﬁers using context-only diﬀusion
presents a constantly positive gain of over 10% over Lucene alone.

Analyzing the way the various classiﬁers are combined, it is possible to identify 
which LOM attributes contribute to enhance retrieval: We observe that
the interactivityLevel, interactivityType and semanticDensity classiﬁers 
have been singled out by Rankboost as operating on the most helpful
attributes.

We could not experiment with other publicly available repositories because
they lack semantically rich relations between LOs. Therefore, future work will
consist in developing a bigger and more heterogeneous repository in order to
prove that our approach is scalable.

6 Discussion

This paper described how a graph structure can be used as an additional source
of evidence when searching in LO repositories during lesson authoring. We show
that a query can be deﬁned topologically, i.e., according to the location of the

262

O. Motelet et al.

node within the lesson graph and semantically by a set of keywords. The keyword
search is processed by a standard IR system (in our case Lucene) while the
topological information is used to compare the graph surrounding the query
node with the surrounding graphs of each LO in the repository. Information
from both sources is then combined in order to enhance the retrieval of LOs
to be reused by lesson authors. The idea of deﬁning a query as a graph is also
present in approaches related to concept maps [15,16] but those works ignore the
semantics of the links between concept nodes and characteristics other than node
titles. Experiments show that our system makes successful use of this information
even though we focused on a reduced teacher community and a repository about
a very speciﬁc topic.

Most existing works attempting to enhance LO retrieval are based on user
proﬁles [17,18]. In contrast, our approach requires the teacher to author her
lesson as a graph of LOs but does not need any personal or historical data.
Nevertheless, generating a lesson as a graph imposes on the teacher the tedious
task of generating the metadata [19]. Consequently, various research eﬀorts focus
on automatic and semi-automatic generation of such metadata ([20,21,22]). Such
support systems are necessary to make the authoring of a lesson as a graph of
LOs a reasonable requirement in the context of a teacher community trying to
systematically share teaching/learning material among its members.

The diﬃcult use of metadata makes the extension of a query with contextual 
information extracted from the graph –like we propose in this work– a
promising approach. It integrates nicely and intuitively into the lesson authoring 
process. One can even argue that the necessity of locating the LOs being
edited or searched helps the teacher to clarify her aims. Our interaction with the
teachers that participated in the experiments tends to conﬁrm this hypothesis.
Moreover, while for now metadata are exclusively used when the LO is retrieved,
our approach directly takes advantage of them when they are created because
they help retrieval, generating a positive insentive for lesson authors to produce
high quality metadata.

References

1. IMS: IMS global learning consortium (2007), http://www.imsglobal.org
2. LOM: IEEE LTSC p1484.12.1 learning object metadata speciﬁcation ﬁnal draft

(2002), http://ieeeltsc.org/wg12LOM/

3. Najjar, J., Klerkx, J., Vuoikari, R., Duval, E.: Finding appropriate learning ob-
jects: An empirical evaluation. In: World Conference on Educational Multimedia,
Hypermedia and Telecommunications ED-MEDIA 2005, Montreal, Canada, pp.
1407–1414 (2005)

4. McCalla, G.: The search for adaptability, ﬂexibility, and individualization: Approaches 
to curriculum in intelligent tutoring systems. In: Foundations and Frontiers 
of Adaptive Learning Environments, pp. 91–122. Springer, Heidelberg (1992)

5. LessonMapper2: Web site (2007),

http://www.dcc.uchile.cl/∼omotelet/LessonMapper2.xhtml

Enhancing Educational-Material Retrieval Using Authored-Lesson Metadata

263

6. Engelhardt, M., Hildebrand, A., Lange, D., Schmidt, T.C.: Reasoning about elearning 
multimedia objects. In: SWAMM. Proc. of WWW 2006, Intern. Workshop on
Semantic Web Annotations for Multimedia (2006)

7. Fischer, S.: Course and exercise sequencing using metadata in adaptive hypermedia

learning systems. J. Educ. Resour. Comput. 1, 5 (2001)

8. Trigg, R.: A Network-Based Approach to Text Handling for the Online Scientiﬁc

Community. PhD thesis, University of Maryland (1983)

9. Lucene: Full-featured text search engine library in java (2007), http://lucene.

apache.org

10. Motelet, O., Baloian, N., Piwowarsky, B., Pino, J.A.: Taking advantage of the semantics 
of a lesson graph based on learning objects. In: The 13th International
Conference on Artiﬁcial Intelligence in Education (AIED 2007), IOS Press, Amsterdam 
(2007) (to be published)

11. Hatala, M., Richards, G.: Value-added metatagging: Ontology and rule based methods 
for smarter metadata. In: Schroeder, M., Wagner, G. (eds.) RuleML 2003.
LNCS, vol. 2876, pp. 65–80. Springer, Heidelberg (2003)

12. Freund, Y., Iyer, R.D., Schapire, R.E., Singer, Y.: An eﬃcient boosting algorithm
for combining preferences. Journal of Machine Learning Research 4, 933–969 (2003)
13. Motelet, O.: Experiment data (repository snapshot and test cases) (2007), http://

reflex.dcc.uchile.cl/lm/lessonMapper2/IRTests.zip

14. Baeza-Yates, R., Ribeiro-Neto, B.: Modern Information Retrieval. Addison-Wesley,

Reading (1999)

15. Carvalho, M., Hewett, R., Canas, A.: Enhancing web searches from concept mapbased 
knowledge models. In: Proceedings of the SCI Conference, AAAI Press,
Stanford, California, USA (2001)

16. Leake, D., Maguitman, A., Reichherzer, T., Canas, A.J., Carvalho, M., Arguedas,
M., Eskridge, T.: ”googling” from a concept map: Towards automatic concept-
map-based query formation. In: Canas, A.J., Novak, J.D., Gonzalez, F.M. (eds.)
Concept Maps: Theory, Methodology, Technology Proc. of the First Int. Conference
on Concept Mapping (2004)

17. Murray, T.: Authoring intelligent tutoring systems: an analysis of state of the art.

International Journal of Artiﬁcial Intelligence in Education 10, 98–129 (1999)

18. Rafaeli, S., Dan-Gur, Y., Barak, M.: Social recommender systems: Recommendations 
in support of e-learning. J. of Dist. Educ. Tech. 3, 29–45 (2005)

19. Recker, M.: Perspectives on teachers as digital library users. D-Lib Magazine 12

(2006)

20. Ochoa, X., Cardinaels, K., Meire, M., Duval, E.: Frameworks for the automatic indexation 
of learning management systems content into learning object repositories.
In: World Conference on Educational Multimedia, Hypermedia and Telecommunications 
EDMEDIA,
 pp. 1407–1414 (2005)

21. Saini, P.S., Ronchetti, M., Sona, D.: Automatic generation of metadata for learning

22. Motelet, O., Baloian, N.A.: Hybrid system for generating learning object metadata.

objects. [23] 275–279

[23] 563–567

23. Kinshuk, Koper, R. (eds.): ICALT 2006. Proceedings of the 6th IEEE International
Conference on Advanced Learning Technologies, Kerkrade, The Netherlands, 5-7
July 2006. IEEE Computer Society Press, Los Alamitos (2006)

