 

Implementing Shared Displays: A Tool for Smooth 
Integration of Large-Screen TVs and Mobile Devices 

Christian Berkhoff1, Sergio F. Ochoa1, José A. Pino1, Jesús Favela2, Jonice Oliveira3, 

and Luis A. Guerrero4 

1 Department of Computer Science, Universidad de Chile, Santiago, Chile 

{berkhoff,sochoa,jpino}@dcc.uchile.cl 

2 Department of Computer Science, CICESE, Ensenada, Mexico 

favela@cicese.mx 

3 Universidade Federal do Rio de Janeiro, Rio de Janeiro, Brazil 

jonice@ufrj.br 

4 CITIC Research Group, School of Computer Science and Informatics,  

Universidad de Costa Rica  

luis.guerrero@ecci.ucr.ac.cr 

Abstract.  One  of  the  keystones  of  vision  of  AmI  is  the  ability  of  multiple 
devices to seamlessly communicate within themselves. To this end, this article 
presents a mobile computer application which is able to smoothly connect via 
WiFi  to  large-screen  TVs  and  mobile  computer  devices.  Thus  the  application 
allows  implementing  shared  displays  with  minimal  effort  and  cost.  These 
shared  displays  have  shown  to  be  useful  to  support  meetings  and  informal 
encounters in various scenarios, such as at home, hospitals or business settings. 
The application was tested in real scenarios with encouraging results.    

Keywords:  Shared  displays,  resource  sharing,  encounters,  meetings,  largescreen 
TV, mobile computing devices.  

1 

Introduction 

The  recent  widespread  availability  of  mobile  devices  (such  as  smartphones,  slate 
devices  and  notebooks)  has  energized  the  development  of  novel  mobile  and 
ubiquitous applications. Although these devices have improved their computing and 
storage  capacity  and  also  their  power  autonomy,  their  small  screen  constrains  their 
use  in  several  scenarios,  particularly  in  meetings  where  information  needs  to  be 
shared by multiple participants.  

Typically,  connecting  a  smartphone  or  laptop  to  a  projector  or  a  LSTV  involves 
connecting  and  disconnecting  cables  which  usually  interrupts  the  fluidity  of  the 
meeting, distracts participants and reduces the meeting’s effectiveness. In some cases 
it is possible to count on meeting rooms equipped for such purpose, which eases the 
meeting activity but they are not always available and their cost may be high. 

If we take into account that many meetings are not necessarily formal activities, we 
realize  that  many  meeting  types  (such  as  the  social  encounters)  have  little  or  no 

J. Bravo, R. Hervás, and M. Rodríguez (Eds.): IWAAL 2012, LNCS 7657, pp. 278–286, 2012. 
© Springer-Verlag Berlin Heidelberg 2012 

 

Implementing Shared Displays: A Tool for Smooth Integration 

279 

support;  e.g.  an  encounter  of  grandsons  and  grandparents  to  see  pictures  of  the  last 
vacation, or a group of friends that meets to plan a fishing trip for the next weekend.  

In many of these informal meetings and social encounters many people try to look 
at  a  computing  device  screen  because  they  have  no  projector  or  special  cables  to 
connect a mobile device to a LSTV. Although many meeting sites (including homes) 
have a LSTV (e.g. a LCD or LED TV device), people are not able to take advantage 
of it due to the burden involved in connecting the device. 

In this paper we present a software tool named Clairvoyance that allows a smooth 
integration  of  LSTV  and  mobile  devices.  Since  this  integration  is  based  on  a  WiFi 
communication channel, people do not need to use cables or directly manipulate the 
LSTV  device.  Thus,  this  application  enables  any  room  with  a  LSTV  to  become  a 
potential meeting room with projection capabilities.  

Fig. 

1 

shows 

the 
Clairvoyance  basic  working 
scenario. The application is also 
able  to  locate  available  and 
busy  LSTVs  in  a  certain  area, 
as  a  way  to  guide  interested 
people towards a free resource.  
Clairvoyance  has  a  client 
the 
application 
mobile  device  (e.g.  a  laptop  or 
smartphone) 
server 
application  running  in  a  microcomponent 
 (a  nettop)  that  is 
connected to the LSTV.  

running 

and 

a 

in 

Fig. 1. Clairvoyance interaction scenario 

 

The system  has been tested in a real scenario and the obtained results are highly 
positive.  The  next  section  presents  the  related  work.  Section  3  describes  the 
Clairvoyance  application  and 
the 
experimentation  scenarios  and  the  obtained  results.  Finally,  Section  5  presents  
the conclusions and future work.  

its  main  components.  Section  4  presents 

2 

Related Work 

LSTV’s  and  HD  projectors  are  becoming  ubiquitous.  They  are  usually  available  in 
meeting  rooms  and  increasingly  so  in  corridors,  near  elevators  and  other  office 
spaces.  Many  meetings  and  informal  encounters  are  currently  supported  by 
audiovisual equipment. The LSTVs (measuring 32” and up) are commonly used often 
in several rooms. 

LSTVs can also be installed outside the meeting room being used to show contents. 
If these devices have some intelligence, they also can support interactions with people 
[2].  Several  researchers  have  studied  the  role  played  by  these  devices  as  public 
screens.  In  particular,  they  can  be  used  to  provide  information  to  passers-by  [3,  4], 
and also as mechanisms to support casual meetings [5, 6]. 

 

280 

C. Berkhoff et al. 

LSTVs  may  become  ubiquitous  in  the  near  future  and  smartphones  may  be  the 
input  devices  to  interact  with  them.  In  a  certain  sense,  smartphones  could  be 
considered the future universal remote controls for several other devices. 

Various  techniques  have  been  proposed  to  allow  computing  devices  to  interact 
with LSTVs. However most of them require considerable effort to set up (e.g. cables 
or  adapters).  Jeon  et  al.  [7]  present,  e.g.,  several  techniques  that  could  be  used  to 
deploy  images  and  video/animations  on  a  LSTV,  but  they  do  not  address  the 
connection process between devices or the communication issues among them.  

Cornejo  et  al.  [8] provide  a  solution  that  allows  users  to  show  pictures  in  LSTV 
using  hand  gestures.  Such  gestures  are  captured  and  recognized  by  a  Kinect  sensor 
which sends particular orders to a computer controlling the LSTV. Although such a 
solution  is  interesting,  it  requires  additional  infrastructure  and  for  the  user  to  be 
familiar with the gestures understood by the device.  

Although  the  previous  works  are  interesting,  in  most  cases  the  contents  to  be 
shared  must  be  stored  in  the  server  controlling  the  LSTV,  which  jeopardizes  the 
ubiquity of this sharing process and the privacy of the shared resources.  

3 

Clairvoyance 

Clairvoyance allows mobile devices to connect to a LSTV on demand using a Mobile 
Ad hoc network (MANET). The application uses the HLMP API [1] to detect mobile 
devices and LSTVs in the vicinity, and also to automatically form a MANET among 
them. In order to make the LSTV visible for mobile devices a small nettop needs to be 
plugged to the smartTV. The nettop is a micro-computer with WiFi, processing and 
storage capabilities. The application has a client-server architecture.  

The server module runs in the nettop and the 
client runs in the mobile devices used to interact 
with  the  LSTV  (Fig.  2.).  The  client  and  the 
server  modules  have  four  components:  the 
HLMP  API,  the  net  component,  the  screencast 
and 
interface.  They  are  briefly 
described below. 

the  user 

 

Fig. 2. Basic Architecture 

3.1  User Interface 

When  the  user  of  a  mobile  computing  device  wants  to  connect  to  a  LSTV,  the 
Clairvoyance client application scans the environment and detects all LSTVs within 
one or more hops of distance. Fig.3.a shows the process result indicating that just one 
LSTV (named WindBox) is available. If the user selects such a screen and connects to 
it, then the mobile device displays the features of the connection. (Fig. 3.b). While the 
link is active, any application or resource deployed in the client device is shown also 

 

 

Implementing Shared Displays: A Tool for Smooth Integration 

281 

on the LSTV (Fig. 3.c). Depending on the resource size, the user could perceive that 
this deployment is done in real-time. 

          (a)                                     (b)                                           (c) 

Fig. 3. Clairvoyance user interface of the client module 

 

If  other  users  are  participating  in  the  meeting,  all  of  them  are  able  to  scan  the 
environment  and  detect  the  presence  of  the  WindBox  screen  (i.e.  the  LSTV).  Since 
they  know  that  the  WindBox  screen  is  busy  (i.e.  linked  to  another  device),  the 
connection button will appear as disabled until the current user frees the LSTV. 

3.2 

Screencast 

According to the architecture shown in Fig. 2, this component is divided in a client 
and a server module. The screencast client is in charge of compressing and packing 
the user interface of the client device connected to a LSTV, and the server module is 
the counterpart; i.e. it is in charge of unpacking and decompressing such information 
when it is received by the nettop connected to the LSTV (Fig. 4). The server module 
makes available this information to the upper layer components (i.e. those managing 
the LSTV user interface) to allow thus the image deployment on the screen. 

From the client side, the ICompressionStrategy class is in charge of selecting one 
of two currently available compressions strategies: simple or BDS compression. Fig. 
4 shows the classes (i.e. SimpleCompressor and BSDcompressor) that are responsible 
of performing such a compression. The information to be compressed is a screenshot 
of the client device, which is captured by the ScreenShooter class. 

From the server side we have almost the same classes than in the client side, except 

the ScreenShooter, which does not make sense in the server.  

 

282 

C. Berkhoff et al. 

Fig. 4. Structure of the screencast component 

 

3.3  Net 

The net component is responsible for managing the connection (i.e., it implements a 
session  link)  between  a  client  device  and  a  LSTV.  Like  the  screencast  component, 
this one is also implemented through a client and a server module (Fig.5). From the 
client  side,  the  CommunicationController  interface  allows  access  to  the  services 
provided by the class with the same name. That class is in charge of configuring and 
managing  the  communication  link  between  a  client  device  and  a  LSTV  using  the 
Protocol  class.  The  Constants  class  is  used  by  the  Protocol  class  to  identify  the 
devices participating in the meeting session.  

The  CommunicationController  uses  the  ScreenEmitter  class  which  allows  a 
Clairvoyance  client  to  build  the  messages  containing  the  graphical  information  (i.e. 
ScreenMessage). In order to perform this operation the ScreenEmitter uses interfaces 
to  the  ICompressionStrategy  and  CompresssionStrategies  classes  that  belong  to  the 
Screencast component.  

The  net  client  module  also  implements  the  interfaces  to  access  the  services  and 
message  types  provided  by  the  HLMP  (High-Level  MANET  Protocol)  [1].  HLMP 
implements the MANET that allows interactions among devices participating  in the 
meeting. Each of these devices shares control information with the rest of the nodes 
by  using  the  UserDataAdmin  class.  The  shared  information  includes  the  type  of 
device (e.g. smartphone, slate, laptop or LSTV) and its status (e.g. available or busy). 
Thus, it is possible to identify LSTVs available in the area. A HLMP service indicates 
the distance (in terms of hops) between a client device and the available LSTV.  

The Linker class encapsulates the task of linking a client device and a LSTV. In the 
client  side  this  class  implements  a  blocking  call  to  the  server  module  that  returns  a 
boolean value. True indicates the linking process was successful, and false means that 

 

 

Implementing Shared Displays: A Tool for Smooth Integration 

283 

it failed (typically by the server unavailability or timeout). To perform this  task the 
Linker uses the Protocol and LinkMessage classes. 

Fig. 5. Structure of the net component 

 

The  LinkMessage,  UnlinkMessage  and  ResponseMessage  message 

types 
implement  the  SafeUnicastMessage  interface,  since  they  require  a  more  reliable 
delivery than the one used for regular messages. From the server side the net structure 
is similar to the client. However the server by default is passive and just reacts to the 
requests sent by the client devices. 

Finally,  the  HLMP  API  is  the  component  that  automatically  creates  a  MANET 
among  computing  devices  that  are  physically  close,  and  manage  it  appropriately 
depending on the movements of the users [1]. This middleware manages the mobile 
nodes  connection  and  disconnections,  and  messages  passing  and  routing.  HLMP 
provides  the  developers  with  an  abstraction  layer  to  manage  the  messages  passing 
through the MANET without the need to address the low-level details involved in this 
type of networks.  

4 

Experimental Results 

Two  types  of  evaluation  processes  were  performed  to  assess  Clairvoyance 
performance and usability. The performance evaluation used 30 instances of the same 
test. Half of the tests were done using a smartphone as client device and the rest used 
a  laptop.  The  following  variables  were  measured  in  each  test:  scanning  time, 
connection time, number of timeouts, channel throughput between client and server, 
and time to detect a change of status. The scanning time indicates the time spent by a 
Clairvoyance  client  to  sense  the  environment  and  determine  which  devices  are 
present. Similarly, the connection time measures the time required by a client device 

 

284 

C. Berkhoff et al. 

to connect to a LSTV. That period goes from the time that the linking request is sent, 
until the instant at which the link between the client and server is available for use. 
The number of timeouts indicates the number of connection requests which reached a 
timeout  due  to  connection  problems  in  spite  of  the  LSTV  (i.e.  the  server)  being 
available. The channel throughput indicates the number of bytes per second received 
by the Clairvoyance server during a connection. Finally, the time to detect a change of 
status  indicates  the  delay  between  the  time  the  LSTV  changes  its  status  (e.g.  from 
busy to available) and the time the rest of the devices detect the new status. Table 1 
shows the obtained results. 

Table 1. Performance evaluation results 

Variable 

Smartphone 

Laptop 

 
Scanning time 
Connection time 
Number of timeouts 
Channel throughput  
Change of status detection delay 

Avrg. 
4 sec 
8 sec 

0 

Std.Dev. 

2 sec 
3 sec 

-

Avrg. 
3 sec 
6 sec 

0 

Std.Dev. 

1 sec 
1 sec 

- 

143Kbps 

35 Kbps 

228 Kbps 

42 Kbps 

8 sec 

3 sec 

5 sec 

2 sec 

 

The  obtained  results  are  quite  consistent  and  within  the  expectable  values.  We 
observe the interaction between the LSTV and powerful client devices (i.e. a laptop) 
achieves a better performance than the case of a smartphone being used as client. The 
throughput  of 
the  HLMP  API 
implementation. Although the throughput values could seem relatively low, they are 
comparable to those obtained by well-known MANET implementation infrastructures 
[1]; e.g. Optimized Link State Routing (OLSR).  

the  communication  channel 

is 

limited  by 

 We performed usability evaluation with twelve participants in order to determine 
whether this performance was acceptable for end-users. Three of them were between 
10 and 15 years old, four between 18 and 25, three between 42 and 45, and two over 
55 years old. People received a basic instruction (2 or 3 minutes), and then they used 
the  application  to  complete  a  sketch  of  actions  consisting  of  3  connections,  3 
disconnections, 2 scans and deployment of 5 images and one video on the LSTV.  

A random device (between smartphone and laptop) was assigned to each user. Five 
of them used a laptop and seven people used a smartphone. All participants were able 
to  complete  the  sketch.  The  main  difference  among  them  was  the  time  spent  to 
complete  the  sketch.  The  fastest  in  completing  the  sketch  were  the  youngest 
participant,  with  an  average  time  of  7  minutes  using  a  smartphone  and  8  using  a 
laptop. The slowest users were the oldest participants with a time of 16 minutes using 
a  laptop  and  22  minutes  using  a  smartphone.  These  numbers  are  not  enough  to  get 
definitive conclusions, but they provide some hint about the Clairvoyance usability.    
After using the system the users completed a survey using a 5-point scale to rate 
each  item:  good  (5),  acceptable  (4),  neutral  (3),  deficient  (2),  and  unacceptable  (1). 
Table 2 shows the obtained results. 

 

 

Implementing Shared Displays: A Tool for Smooth Integration 

285 

Table 2. Usability evaluation results 

Variable 

 
Response time 
Understandability 
Usefulness 
Reliability  

Smartphone 

Laptop 

Avrg. 
3,9 
4,3 
4,6 
4,7 

Std.Dev. 

0,69 
0,76 
0,53 
0,49 

Avrg. 
4,6 
4,4 
3,8 
4,6 

Std.Dev. 

0,55 
0,55 
0,45 
0,55 

 

Seven participants asked us for a copy of the software to try to use it in their own 
homes.  Although  the  results  are  preliminary,  they  offer  some  evidence  that 
Clairvoyance is usable and useful for most users. 

5 

Conclusions and Future Work 

This  article  presents  a  middleware  named  Clairvoyance,  which  allows  a  smooth 
integration  between  large-screen  TVs  and  mobile  devices.  The  main  goal  of  this 
application is to help people to share visual resources during formal meeting or social 
encounters. The solution uses a wireless link between a micro-computer connected to 
the  LSTV  and  the  mobile  device  used  to  deploy  the  visual  information.  No 
infrastructure-based communication networks are required in the environment where 
this  solution  is  used,  since  Clairvoyance  automatically  creates  and  manages  the 
communication links required to perform the operations. 

After evaluating the usability and performance with real users, the obtained results 
were quite good for most people. Particularly young people were highly enthusiastic 
of using the application. The system performance is appropriate to support this type of 
information sharing; however, it is still not good enough to reproduce real-time video 
or  large  images  (e.g.  weighting  more  than  20  MB). Provided  the  Clairvoyance  user 
interface is simple, an ample range of people were able to use it successfully. 

Acknowledgements.  This  work  has  been  partially  supported  by  Fondecyt  (Chile), 
grant Nº 1120207 and LACCIR, grant N° R1210LAC002.  

References 

1.  Rodríguez-Covili,  J.F.,  Ochoa,  S.F.,  Pino,  J.A.,  Messeguer,  R.,  Medina,  E.,  Royo,  D.:  A 
the  Development  of  Mobile  Collaborative 

Communication  Infrastructure 
Applications. J. of Network and Computer Applications 34(6), 1883–1893 (2011) 

to  Ease 

2.  Scanlon, J.: If walls could talk, streets might join in. New York Times (September 18, 2003) 
3.  Churchill, E., Nelson, L., Denoue, L.: Multimedia Fliers: Information Sharing With Digital 

Community Bulletin Boards, pp. 97–117. Kluwer Acad. Pub., Palo Alto (2003) 

4.  Greenberg, S., Boyle, M., LaBerge, J.: PDAs and Shared Public Displays: Making Personal 

Information Public, and Public Information Personal. Personal Techn. Springer (1999) 

 

286 

C. Berkhoff et al. 

5.  McCarthy,  J.:  Using  public  displays  to  create  conversation  opportunities.  In:  Proc.  of  the 
ACM 2002 Conf. on Computer Supported Cooperative Work (CSCW 2002), New Orleans 
(2002) 

6.  Russell,  D.M.,  Drews,  C.,  Sue,  A.:  Social  Aspects  of  Using  Large  Public  Interactive 
Displays for Collaboration. In: Borriello, G., Holmquist, L.E. (eds.) UbiComp 2002. LNCS, 
vol. 2498, pp. 229–236. Springer, Heidelberg (2002) 

7.  Jeon, S., Hwang, S., Kim, G.J., Billinghurst, M.: Interaction Techniques in Large Display 

Environments using Hand-held Devices. In: Proc. of the ACM VRST 2006, Cyprus (2006) 

8.  Cornejo, R., Hernández, D., Favela, J., Tentori, M., Ochoa, S.F.: Persuading older adults to 
socialize and exercise through ambient games. In: Proc. of the Workshop of Wellness and 
HCI, PervasiveHealth, San Diego California, May 21-24 (2012) 

9.  Mejia,  A.D.,  Favela,  J.,  Moran,  A.L.:  Understanding  and  Supporting  Lightweight 

Communication in Hospital Work. IEEE TIT in BioMedicine 14(1), 140–146 (2010) 

 

