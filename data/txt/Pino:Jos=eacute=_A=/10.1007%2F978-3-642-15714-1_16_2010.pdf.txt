 

Awareness Checklist: Reviewing the Quality of 
Awareness Support in Collaborative Applications 

Pedro Antunes1, Claudio Sapateiro1, Jose A. Pino2, Valeria Herskovic2,  

and Sergio F. Ochoa2 

1 Department of Informatics of the Faculty of Sciences, Campo Grande, Lisbon, Portugal 

paa@di.fc.ul.pt, claudio.sapateiro@estsetubal.ips.pt 

2 Computer Science Department, Universidad de Chile, Santiago, Chile 

{jpino,vherskov,sochoa}@dcc.uchile.cl 

Abstract.  A  proposal  of  a  method  to  assess  awareness  support  is  made.  This 
proposal is intended for the use of collaborative applications developers at any 
time during development. It consists of a checklist. It is made with the inclusion 
of design elements obtained by the analysis of Quality Assurance ideas applied 
to collaborative systems. The proposal is illustrated with its use in two cases. 

Keywords: Awareness Inspection, Collaborative Applications.  

1   Introduction 

Awareness  in  its  various  types  has  always  been  considered  a  distinctive  feature  of 
collaborative systems when compared with other kinds of information systems [17]. 
Moreover, numerous studies have found awareness to be a very important component 
of a collaborative system [61, 27, 34]. Users’ mobility increases the need for awareness 
since the collaboration environments typically change very often in this case. 

We are particularly interested in assessing the awareness support in collaborative 
systems. An approach to do this study is by asking users about it. Questionnaires can 
be used for that purpose [53]. Alternatively, observation of people using the system 
can  be  useful  to  do  this  inquiry.  Analysis  of  logging  interactions  [55]  or  video  recordings 
[41] can then provide some answers to the evaluation of awareness support. 
Nevertheless, all these approaches require the participation of users.  

Participation of users is not always possible or available at the time of evaluation 
[40]. For that case, we propose an awareness checklist which may be useful to system 
developers to assess their applications at various development stages. It can be argued 
a system’s users are the best evaluators of it, which is true, but an alternative way may 
be required as a substitute or complement for the users’ evaluation. The construction 
of the awareness checklist followed a process consisting of the following steps:  

•  Definition of awareness types.  
•  Definition of the design elements contributing to awareness that will be subject 

to the evaluation.  

•  Definition  of  correlations  between  design  elements  and  awareness  types,  with 

help from experts in collaborative systems development.  

G. Kolfschoten, T. Herrmann, and S. Lukosch (Eds.): CRIWG 2010, LNCS 6257, pp. 202–217, 2010. 
© Springer-Verlag Berlin Heidelberg 2010 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

203 

•  Construction of the awareness checklist and summary tables.  
•  Validation of the awareness checklist in case studies. 

The paper continues with a review of related work (Section 2); it starts with quality 
assurance, following with its relation to collaborative systems and then, with awareness.
 Section 3 deals with the awareness types. Then, Section 4 presents the proposed 
checklist. The use of this checklist in two cases is illustrated in Section 5. Section 6 
concludes the paper with a summary of the obtained results.  

2   Related Work 

2.1   Quality Assurance 

Quality Assurance (QA) establishes the extent to which quality is being controlled in 
an  organization  [43].  QA  typically  applies  control  measures  to  an  input-processoutput 
production system, uncovering nonconformities in the system, avoiding wasted 
resources, while doing so at the least possible cost [39].  

Hinckley [39] provides an insightful view over QA progress. Initial QA measures 
were  based  on  loose judge  inspections  made  by  skilled  craftsman  in  the  production 
line.  Later  on,  the  adoption  of  gage  instruments  and  standards  has  led  to  improved 
inspections  and  greater  consistency.  The  emergence  of  Statistical  Quality  Control 
(SQC)  brought  a  higher  concern  with  predictable  production  models,  adopting  production 
samples and statistical methods to guide process adjustments [42].  

Six-Sigma [4] has been developed to make drastic improvements in QA based on 
standards,  measurement and  analysis systems, and continuous quality improvement. 
Total Quality Management (TQM) also deals with a continuous optimization of business 
performance [5]. But its emphasis has shifted away from the technical towards 
broader organizational factors such as team development, learning and culture.  

Of course most concerns with QA extend beyond the traditional industrial organizations 
 and  apply  to  software  development.  For  instance,  the  Cleanroom  Software 
Engineering approach adopts SQC to maintain software development under statistical 
control  [54].  However,  one  main  limitation  of  this  approach  is  the  process  requires 
stable  software  specifications,  a  requirement  that  is  hard  to  ensure  in  the  software 
development field.  

The Software Quality Function Deployment (SQFD) [35] method adopts the Six-
Sigma’s  scorecard  with a particular  focus on customer  needs. The origins of  SQFD 
are rooted in the need to improve the quality of software design using precise control 
points throughout the development process and constant traceability of the customer 
requirements [9]. Thus the QA chart adopted by SQFD correlates customer-required 
quality functions with the product’s engineering characteristics.  

Formal Technical Reviews (FTR) [25] have been widely adopted in software engineering 
[2]. They involve several people in a formal meeting during which a software 
artifact  is  presented,  discussed  and  approved.  FTR  seek  to  identify  defects  and  discrepancies 
in the software against plans, specifications, standards and best practices. 
They cover the whole software development life-cycle [50].  

Johnson [46] analyzed the impact of software reviews on quality, showing that defects 
 can  be  one  or  two  orders  of  magnitude  less  costly  to  remove  when  found  in 

 

204 

P. Antunes et al. 

initial development stages than after distribution to the customers. Moreover, software 
reviews were considered effective for discovering certain soft, but nevertheless costly, 
defects such as logically correct but poorly structured code.  

2.2   Collaborative Systems and Quality Assurance 

Collaborative systems bring together two main organizational assets: technology and 
humans.  The  development  of  collaborative  systems  has  for  long  been  considered  a 
special  branch  of  software  development  concerned  with:  group  characteristics  and 
dynamics;  communication,  coordination  and  collaboration;  conflict  resolution  and 
decision making; social context of work; and positive and negative effects of technology 
on tasks, groups and organizations.  

QA  is  essential  to  ensure  the  quality  of  collaborative  systems  development.  The 
problem now is that QA must assess a very wide range of factors related with multiple 
stakeholders (customers, managers, individual workers, formal and informal work 
groups),  various  domains  of  concern  (business  processes,  goals,  tasks,  group  wellbeing,
  culture)  and  multiple  technology  components  (addressing  various  aspects  of 
collaboration such as awareness). All in all, what distinguishes collaborative systems 
QA is indeed the need to evaluate its impact with an eclectic perspective.  

Research shows that QA activities are difficult to accomplish when collaborative systems 
are involved. First, these systems are difficult to assess due to the complexity, cost 
and time involved [38]. Second, the assessments tend to be informal [1]. Finally, collaborative 
systems involve conflicting views that consider technology and its impact in 
organizations [38]. Nevertheless several assessment methods have been proposed; e.g. 
Herskovic et al. [38] identifies twelve methods and classifies them according to various 
criteria such as development status, scope, time span of the assessment and who participates 
in the assessment. Of these twelve methods, six require the participation of end 
users in several ways, like focus groups and observations. However, participation of end 
users in QA turns the process costly and quite difficult to manage.  

Of  the  remaining  six  methods,  three  require  modeling  and  analyzing  the  system 
functionality at a very low level of detail. And finally the remaining methods adapt 
the FTR approach to the specific characteristics of collaborative systems assessment. 
The  methods  are:  Groupware  Heuristic  Evaluation  (GHE)  [3],  Groupware  Walkthrough 
 (GW)  [56]  and  Knowledge  Management  Approach  (KMA)  [62].  GHE  
defines  a  procedure  for  inspecting  how  a  collaborative  system  conforms  with  eight 
heuristics  that  codify  best  practices  in  collaborative  systems  development  [3].  GW 
entails  stepping  through  task  sequences  to  conceptually  explore  task  goals,  actions 
necessary to perform tasks, knowledge needed to accomplish tasks, and possible performance 
failures [33, 56]. Finally, KMA involves using a checklist to assess how the 
system helps knowledge circulation [62].  

2.3   Quality Assurance and Awareness 

We will now delve into the three FTR methods mentioned above to unravel how they 
address  the  quality  of  awareness  support.  As  previously  mentioned,  GHE  systematizes 
QA activities around a set of heuristics [3]. These heuristics define a checklist 
with qualities that a collaborative system should have. Some of these heuristics point 

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

205 

towards the importance of awareness: (1) Provide the means for intentional and appropriate 
 gestural  communication,  (2)  Provide  consequential  communication  of  an 
individual’s  embodiment,  (3)  Provide  consequential  communication  of  shared  artifacts,
 (4) Management of tightly and loosely-coupled collaboration, (5) Allow people 
to coordinate their actions, and (6) Facilitate finding collaborators and establishing 
contact.  

GW involves stepping through task sequences to conceptually explore the actions 
users will perform. In order to formalize the analysis of the work context, Pinelle and 
Gutwin  [56]  defined  the  Mechanics  of  Collaboration,  a  set  of  seven  collaboration 
primitives that makes up group dynamics [33], that include monitoring as an explicit 
concern with awareness. 

KMA differs  from the other techniques. Instead of  focusing on  the essential features 
of collaboration support, KMA seeks to evaluate how organizations are able to 
manage their knowledge while using collaborative systems [62]. It focuses on analyzing 
situations where knowledge does not flow correctly. A checklist is provided with 
a set of questions that expose missing links, black holes and points of congestion in 
information flows. Awareness is indirectly considered in this approach.  

All in all, we observe concern with awareness is present in these FTR methods but 
diluted among many other issues. Thus we find here an opportunity to develop a FTR 
method specifically concerned with reviewing the quality of awareness support.  

2.4   Other Methods to Evaluate Quality of Awareness Support 

Convertino et al. [12] developed a laboratorial method to assess activity awareness in 
controlled  settings.  This  is  the  only  work  we  found  that  explicitly  develops  a  QA 
technique for awareness in collaboration systems. The method is based on collaboration 
 scenarios  drawn  from  field  studies  and  assessed  during  laboratory  experiments 
using  questionnaires,  interviews  and  observations.  Unfortunately  this  approach  requires 
significant time and effort to prepare and run the experiments. Furthermore, it 
requires  a  mature  definition  of  the  system  functionality,  which  makes  it  difficult  to 
apply at early design stages.  

QA  of  awareness  has  also  been  a  major  issue  in  a  quite  different  research  field: 
cognitive systems engineering. The main reference in this area is the work by Endsley 
et al. on situation awareness [22-24]. Situation awareness is the capability to understand 
a series of events at three different levels [24]: in level 1, training and experience 
 direct  attention  to  critical  elements  in  the  environment;  level  2  integrates  
elements that aid understanding the meaning of critical elements; and level 3 considers 
 understanding  the  possible  future  scenarios.  Endsley  developed  the  Situational 
Awareness Global Assessment Technique (SAGAT) [20] to assess the users’ situation 
awareness.  SAGAT  uses  questionnaires  to  inquire  users  about  perception,  comprehension 
 and  projection  issues  in  situations  where  working  activities  have  been  
interrupted [21]. The main application areas of SAGAT deal with complex activities 
like piloting. Other techniques, like thinking aloud, filling mini situation reports and 
probing questions have been used to assess situation awareness [65]. All these techniques 
involve end users in the assessment process.   

Still regarding the cognitive perspective, Zhang and Hill [66] developed a patternbased 
 approach  to  situation  assessment.  The  approach  uses  spatial  relationships  in 

 

206 

P. Antunes et al. 

synthetic workspaces to represent the situation. Situation assessment is based on two 
major  steps:  data  organization  for  perception  (e.g.  clustering)  and  matching  against 
situation templates, which have to be predefined.  

2.5   Summary 

Figure 1 summarizes our analysis of the related literature. The discussion on Quality 
Assurance  brings  forward  the  TQM  movement,  which  originated  new  assessment 
methods  based  on  participation  and  collaboration.  Of  those  methods,  FTR  take  a 
prominent  place  in  software  development.  Collaborative  systems  are  a  specialized 
sector within software development, which has lead to specialized FTR methods such 
as  GHE,  GW  and  KMA.  Our  analysis  of  these  methods  uncovered  there  was  little 
coverage of awareness. This opens up the opportunity to develop a FTR method specifically 
 focused  on  awareness  assessment.  Beyond  the  FTR  context,  we  have  only 
found one technique in the literature whose major concern is awareness assessment. 
However, the proposed approach requires significant effort and time  to accomplish; 
and it is difficult to apply at early design stages.  

Fig. 1. Summary view of awareness assessment 

 

3   Awareness Elements 

The time/place relationship is the most prevalent subject related to collaborative applications.
 The time/place map proposed by Johansen et al. [45] is founded upon the 
discussion by DeSanctis and Gallupe [15] on the support to remote and local groups. 
The distinctions between same-place, different-place and any-place do not only highlight 
 spatial  issues  but  also  the  actual  extent  members  have  to  access  the  group.  In 
particular,  the  members  located  at  different  places  are  conditioned  by  infrastructure 
factors like network connectivity, data distribution, throughput, bandwidth and message 
delays. Some variations of the time/place map have been elaborated to encapsulate 
these factors [57]. They expand the place dimension to three categories, considering 
co-located, virtual co-located and remote places. 

Social theorists have also regarded the degree of communication afforded by technology 
 as  a  fundamental  constraint  to  collaboration.  Studies  of  media  richness  [13] 
and  media naturalness [48] show that communication  mediated by technology loses 
several important features such as nonverbal cues, rapid feedback and arousal. In this 
line of reasoning, the notion of place is fundamental to adapt the medium to the group 
and task. The time/place differences define collaboration awareness as the perception 
of temporal and spatial structures in a group of peers [26, 59].  

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

207 

Several authors extend the notion of place, linked above to infrastructural issues, to 
the notion of space [18]. Spaces provide additional context to places such as physical 
location, topology and mobility. We may identify five types of space. The first one is 
the geographical space, which introduces geographical relationships such as location, 
distance and orientation. Dix et al. [16] further characterized location as either being 
Cartesian or topological.  

Then  we  have  the  physical  space,  which  mainly concerns  mobility. Mobility has 
been categorized in  wandering,  visiting and traveling [49]. Dix et al. [16] proposed 
another taxonomy: fixed, mobile, autonomous, free, embedded and pervasive. Hazas 
et  al.  [37]  discuss  location  awareness  as  the  means  to  determine  physical  location 
using various types of sensing technology such as GPS and RFID. Hazas et al. [37] 
also  make  the  distinction  between  physical  and  semantic  locations  such  as  rooms, 
floors and buildings.  

Cheverst et al. [10] studied the relationships between physical spaces, mobility, location 
 awareness  and  location  services  to  derive  important  requirements  such  as 
flexibility, visibility and context-sensitivity. Davis also [14] analyzed the challenges 
posed by mobility and information access, including the removal of time/space constraints 
to communication and knowledge work, improved access to decision makers 
and increased ability to receive and process information.  

The third type of space  we consider is the  virtual  space. Rodden [58] developed 
the notion of virtual space as a collection of computer-supported interactive spaces. 
Many collaborative applications offer  various types of  virtual  spaces, including  virtual 
meeting rooms, media spaces and Collaborative Virtual Environments [60].  

Virtual spaces have a conceptual topology, they are interactive, shared, malleable, 
populated and may be navigated. Interaction involves the dissemination of interaction 
and navigation information to the group members, thus constructing what Rodden has 
coined context awareness [58]. Rodden also proposed a conceptual model of context 
awareness in virtual spaces using focus and nimbus. Focus and nimbus are subspaces 
that map the attention and presence of elements in spaces. Also related with context 
awareness, we find the distinction between private and public spaces, the former pertaining 
to things and actions belonging to one single individual and the latter shared 
among a group [28, 11].  

Navigation in virtual spaces is not necessarily spatial but may also be logical. For 
instance,  the  rooms-metaphor  defines  navigation  in  virtual  spaces  like  discussion 
forums [29] that are not spatially organized but rather organized according to a set of 
interests. Virtual spaces may assume complex structures, such as clusters, stacks, lists, 
tables  and  rooms  [30].  Users  should  then  be  able  to  navigate  these  structures  and 
obtain context awareness. Collaborative visualization, as an enabler of collaboration, 
is naturally a major challenge to consider in virtual spaces [6, 11]. Collaborative visualization 
involves data exchange, shared control and dynamic interaction [52].  

Another type of space we identify is the social space. Dourish [18] and Brewer and 
Dourish [7] proposed social spaces as adequate to understand broader issues related to 
social practice and context. In this respect, social places combine geographical, physical 
and virtual affordances with social interaction, cultural meaning, experience and 
knowledge. Dourish [19] also proposed the notion of embodied interaction to account 
for the embedded relationships between social and the other spaces.  

 

208 

P. Antunes et al. 

The final type of space we consider is the workspace. According to Snowdon et al. 
[60], a workspace is a container of places with ongoing activities. We may distinguish 
two  different  aspects  of  workspaces.  On  the  one  hand,  workspaces  may  organize 
activities according to logical sets. A group editor is a good example of this type of 
workspace,  as  it  serves  to  organize  activities  like  writing  and  revising,  while  maintaining 
a coherent view of the whole [47]. On the other hand, workspaces also introduce 
geography as an important context for working activities [52].  

Liechti [51] studied the relationship between context and workspace and proposed 
peripheral awareness as the capability to understand the activities being carried out by 
others nearby one’s place. Gutwin and Greenberg [32] expanded this view to account 
for the  whole  space, defining  workspace awareness as the  understanding of another 
person’s interactions in a shared workspace using a basic set of questions: who, what, 
where, when, and how.  

Fig. 2. Overview of main awareness elements 

 

According to Gutwin et al. [31], workspace awareness is a specialization of a more 
broad  concept  designated  situation  awareness.  Endsley  [23,  24]  defined  situation 
awareness as the understanding of what is going on in the working environment with 
the purpose of performing tasks effectively. Endsley defined three levels of situation 
awareness: perception of elements in the current situation, comprehension of current 
situation and projection of future status.  

Jensen  [44]  combined  situation  awareness  with  sensemaking,  a  theory  developed 
by Weick [63, 64] to understand the relationships between environmental changes and 
organizational responses. Sensemaking is defined as the capability to create order and 

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

209 

make retrospective sense of what occurs through the articulation of several cognitive 
functions  like  perception,  interpretation  and  anticipation  of  events  [64].  CecezKecmanovic 
[8] highlighted that sensemaking emerges from individual, coordinated 
and collaborative efforts.  

Figure 2 presents an overview of the awareness elements that we have identified: 
time x place, space (geographical, physical, virtual and social), workspace and situation 
awareness, as well as their main aspects and the types of awareness they support. 

4   The Awareness Checklist  

In Section 3 we laid out a comprehensive overview of the main awareness elements 
we  find  in  collaborative  systems.  We  identified  seven  types  of  awareness:  time  x 
place, geographical space, physical space, virtual space, social space, workspace, and 
situation  awareness.  We  also  uncovered  several  design  elements  that  influence  or 
contribute to awareness support. The total number of design elements discussed in the 
previous section is 77. To make this a  manageable list,  we organize the design elements 
in the 14 categories shown in Table 1.  

Table 1. Main design elements influencing awareness 

Design elements 
  Design categ. 
1  Accessibility 
Same place, different place, any place, co-located, virtually co-located, remote 
2  Communication  Synchronous, asynchronous, network connectivity, message delivery, network 

management 
Cartesian locations, topological locations, distances, orientation, focus/nimbus 
Wandering, visiting, traveling, fixed, mobile, autonomous, independent, embedded,
 pervasive 
Physical constraints, physical places, physical topology, physical attributes 
Viewports, links, radar views, teleports 
Private, group, public, data access privileges, concurrency control, floor control, 
version control, virtual constraints, virtual places, virtual topology, virtual attributes 

Participants, roles, activities, privileges, group history 
Eye-gaze orientation, body orientation, voice filtering, portholes/peepholes 
Who, what, where, when, how, task history 
Feedback, feedthrough, backchannel feedback 

3  Spatiality 
4  Mobility 

5  Physicality 
6  Navigation 
7  Virtuality 

8  Membership 
9  Attention 
10  Task 
11 
12 

13 
14  Externalization 

Interaction 
Interdependence  Parallel activities, coordinated activities, mutually adjusted activities, loosely 

coupled, tightly coupled 

Internalization  Events, actions, resources, critical elements, meaning, future scenarios 

Individual cognition, distributed cognition, team cognition 

 

In  Table  2  we  define  the  relationship  between  design  and  awareness  elements. 
These  relationships  are  derived  from  the  analysis  presented  in  Section  3.  However, 
during this research, we observed that these relationships are more complex than what 
Table 2 implies. For instance, the different-place design element has main influence 
on “time x place” awareness. However, a different-place design also influences negatively 
workspace awareness, especially because communication channels tend to be a 
limiting  factor.  Therefore  we  may  say  that  accessibility  directly  influences  “time  x 
space” awareness and indirectly influences workspace awareness.  

 

210 

P. Antunes et al. 

Table 2. Main relationships between design and awareness elements 

  Type of awareness  
1  Time x place  
2  Geographical space  
3  Physical space  
4  Virtual space  
5  Social space  
6  Workspace  
7  Situation  

Design categories 
Accessibility, communication 
Spatiality 
Mobility, physicality 
Navigation, virtuality 
Membership, attention 
Task, interaction, interdependence 
Internalization, externalization 

 
To find out these indirect relationships, we requested five experts in collaborative 
technology to define the relationships between the 77 design elements and the seven 
types of awareness. These experts were supplied with a table having the strong relationships 
 shown  in  Table  2  and  were  requested  to  define  additional  moderate  and 
weak relationships. To calculate the correlations, the strong, moderate and weak relationships 
were empirically given the values 4, 2 and 1, respectively. The accumulated 
correlations obtaining a value equal or below 2 were zeroed.  

 

 

  

Fig. 3. Correlations matrix with moderate and weak relationships expressed by the experts 

The  correlations  were  then  normalized  in  two  ways:  (1)  normalize  the  impact  of 
each design category in the awareness  score, avoiding that design categories  with a 
higher number of design elements have more impact on the awareness scores; and (2) 
normalize  the  awareness  scale  so  the  sum  of  all  correlations  for  a  given  awareness 
category is 100%. The correlations matrix is shown in Figure 3. 

We constructed the awareness checklist based on the elements summarized in Tables 12 
and Figure 3. The checklist is also inspired on the House of Quality (HoQ), a basic QA 
map used by many organizations to correlate software implementations to quality items 
[36]. In our case, we correlate 77 design elements with seven awareness categories. The 
correlations adopt a qualitative classification that is also common in the HoQ: strong positive 
(+2); positive (+1); uncorrelated (0); negative (-1) and strong negative (-2).  

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

211 

The checklist is shown in Figure 4. After completion, it automatically reports the 
applications’ positive and negative scores (Figure 5). The scores are determined in the 
following way:  

1.  For each awareness category, every design element in the checklist that received 
a  positive  assessment  (+2  or +1)  is  multiplied  by  the  corresponding  correlation 
expressed in the correlations matrix for that awareness category.  

2.  The same operation is executed for the negative assessments (-2 or -1).  
3.  For  each  awareness  category,  the  positive  score  is  obtained  by  adding  the  adjusted 
results obtained in step 1, multiplied by a 0.5 factor. This allows normalizing 
the scores on a [0-100] scale.  

4.  For  each  awareness  category,  the  negative  score  is  obtained  by  adding  the  adjusted 
results obtained in step 2, multiplied by a -0.5 factor, which again normalizes 
the scores on a [0-100] scale.  

 

 

Fig. 4. COIN awareness checklist (Θ=2; O=1; X=-1; ⊗=0) 

The  awareness  checklist  is  used  during  FTR  in  the  following  way.  The  reviewers 
check the implementation against the 77 design elements. Positive relationships indicate 
the  implementation  contributes  to  realize  the  design  element,  while  negative  relationships 
indicate the implementation is detrimental to the respective design requirement.  

Then  the  reviewers  analyze  the  results  in  the  awareness  report. The  positive  and 
negative scores are discriminated according to the 14 design categories and 7 awareness 
categories. Overall scores for each awareness category are also shown. It should 
be noted the most positive outcome that may be achieved in one awareness category 
is  having  100  positive  and  0  negative  scores,  while  the  most  negative  outcome  is 
having 0 positive and 100 negative scores.  

 

 

212 

P. Antunes et al. 

 

 

Fig. 5. COIN awareness report 

5   Examples of Use 

This section briefly presents the inspection of two collaborative applications. The first 
application  is  MobileMap  (Figure  6),  which  supports  firefighters  attending  regular 
emergencies in urban areas. The second application is COIN (Figure 8), which supports 
construction inspectors reviewing physical infrastructures in construction sites.  
 

Fig. 6. MobileMap user interface 

Fig. 7. MobileMap scores 

 

 

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

213 

Fire truck drivers use MobileMap to guide themselves to their destination. The user 
interface presents two arrows pointing from the current location (Figure 6): the white 
arrow  indicates  the  direction  in  which  the  fire  truck  is  moving;  and  the  black  one 
shows  the  direction  in  which  the  truck  should  move  to  get  to  the  emergency  place. 
This simple interface helps arriving faster to emergency sites (ref. omitted).  

Two developers individually inspected MobileMaps using the awareness checklist. 
Figure 7 shows the obtained average scores. Analyzing these results, we may see that 
virtual space awareness (category 4) is the most problematic type of awareness. This 
should  raise  the  developers’  attention  to  understand  if  this  type  of  awareness  is  required 
to guide the fire truck and realize how the application could better support the 
firemen.  

Figure 8 shows the COIN user interface, which construction inspectors use to annotate 
digital maps related to construction projects. These annotations are done in the 
field  and  used  in  the  office  to  schedule  maintenance  tasks  to  sub-contractors.  Two 
developers also inspected COIN. Figure 9 shows the obtained results. COIN obtained 
low positive scores in physical and virtual space awareness (items 3 and 4). Situation 
awareness (item 7) also seems problematic because of the high negative scores.  

 

 

 

 

Fig. 8. COIN main interface 

Fig. 9. COIN evaluation results 

The situation with physical awareness in the two applications is particularly interesting 
to observe. In these applications, mobility and location awareness play an important 
role; however, it is not well supported. In the case of COIN, mobility support 
is quite appropriate but location support seems insufficient.  On the contrary, in the 
case of MobileMap, location support seems to be appropriate. However, there is insufficient 
 support  to  mobility.  That  is  the  main  reason  why  the  negative  scores  are 
high. Developers have here the chance to improve collaboration support by identifying 
 the  awareness  categories  and  specific  design  elements  requiring  additional  support.
 In that sense, the proposed checklist is an important instrument helping on the 
identification of deficiencies in collaborative applications. 

6   Conclusions 

Awareness is an important component of collaborative systems that helps users to conduct 
interaction processes. In this paper, we have studied the assessment of awareness 
support starting with the basic concepts of quality assurance of software systems. 

 

214 

P. Antunes et al. 

We  developed  an  awareness  checklist  helping  developers  inspect  the  quality  of 
awareness support in collaborative applications. The checklist is founded on quality 
assurance  principles  and  especially  on  the  formal  technical  review  technique.  The 
checklist  items  were  defined  based  on  a  comprehensive  overview  of  awareness  research 
that allowed us to identify 77 design elements contributing to seven different 
types of awareness. Of course, the developer is not forced to require all these design 
elements  to  be  present  in  a  certain  system;  the  developer  can  use  this  checklist  together 
 with  the  possible  mechanisms  intended  to  provide  awareness  pondering  the 
benefit of a certain awareness element with the estimated cost to the users in terms of 
information overload. 

The correlations between design and awareness elements  were defined according 
to  theory  and  practice,  incorporating  the  views  of  several  experts  in  collaborative 
systems development. The awareness checklist allows obtaining a fast assessment of 
the quality of awareness support supplied by an application by simply inquiring about 
how  effectively  some  key  design  elements  have  been  supported.  The  awareness 
checklist  serves  to  obtain  positive  and  negative  scores,  both  contributing  to  inform 
developers  about  which  design  areas  require  major  interventions.  The  awareness 
checklist also serves to define quality metrics, control the development processes and 
benchmark  various  applications.  The  awareness  checklist  has  already  been  used  to 
inspect  two  collaborative  applications.  The  obtained  results  indicate  the  checklist  is 
adequate to formally review awareness support.  

 

Acknowledgements.  This  paper  was  supported  by  the  Portuguese  Foundation  for 
Science and Technology (PTDC/EIA/102875/2008) and Fondecyt (Chile) Grants Nº 
11060467 and 1080352, and Proyecto Enlace VID 2010 (University of Chile), Grant 
ENL 10/10. 

References 

1.  Antunes, P., Pino, J.: A Review of CRIWG Research. In: 16th CRIWG (2010) (in press) 
2.  Aurm,  A.,  Petersson,  H.,  Wohlin,  C.:  State-of-the-Art:  Software  Inspections  after  25 

Years. Software Testing Verification and Reliability 12, 133–154 (2002) 

3.  Baker,  K.,  Greenberg,  S.,  Gutwin,  C.:  Empirical  Development  of  a  Heuristic  Evaluation 

Methodology for Shared Workspace Groupware. In: CSCW 2002, pp. 96–105 (2002) 
4.  Barney, M.: Motorola’s Second Generation. Six Sigma Forum Magazine (May 2002) 
5.  Boaden,  R.:  What  Is  Total  Quality  Management...  And  Does  It  Matter?  Total  Quality 

Management 8, 153–171 (1997) 

6.  Brewer, I., MacEachren, A., Abdo, H., Gundrum, J., Otto, G.: Collaborative Geographic 
Visualization:  Enabling  Shared  Understanding  of  Environmental  Processes.  In:  Proc.  of 
IEEE Symposium on Information Visualization, Washington, DC, p. 137 (2000) 

7.  Brewer, J., Dourish, P.: Storied Spaces: Cultural Accounts of Mobility, Technology, and 

Environmental Knowing. Int. Journal of Human-Computer Studies 66, 963–976 (2008) 

8.  Cecez-Kecmanovic,  D.:  A  Sensemaking  Theory  of  Knowledge  in  Organizations  and  Its 
Application. In: Davis, J., et al. (eds.) Knowledge Management. Organizational and Technological 
Dimensions. Springer, Heidelberg (2005) 

9.  Chan, L.: Quality Function Deployment: A Literature Review. European Journal of Operational 
Research 143, 463–497 (2002) 

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

215 

10.  Cheverst, K., Davies, N., Mitchell, K., Friday, A., Efstratiou, C.: Developing a ContextAware 
Electronic Tourist Guide: Some Issues and Experiences. In: Proc. SIGCHI Conf. on 
Human Factors in Comp. Systems, pp. 17–24. ACM Press, The Hague (2000) 

11.  Convertino, G., Ganoe, C., Schafer, W., Yost, B., Carroll, J.: A Multiple View Approach 
to Support Common Ground in Distributed and Synchronous Geo-Collaboration. In: 3rd 
Int. Conf. on Coordinated and Multiple Views in Exploratory Visualization, pp. 121–132 
(2005) 

12.  Convertino, G., Neale, D., Hobby,  L., Carroll, J., Rosson, M.: A Laboratory Method for 
Studying Activity Awareness. In: Proc. Third Nordic Conf. on Human-Computer interaction,
 pp. 313–322. ACM Press, Tampere (2004) 

13.  Daft, R., Lengel, R.: Organizational Information Requirements, Media Richness and Structural 
Design. Management Science 32 (1986) 

14.  Davis, G.: Anytime/Anyplace Computing and the Future of Knowledge Work. Communications 
of ACM 45, 67–73 (2002) 

15.  DeSanctis, G., Gallupe, R.: A Foundation for the Study of Group Decision Support Systems.
 Management Science 33, 589–609 (1987) 

16.  Dix, A., Rodden, T., Davies, N., Trevor, J., Friday, A., Palfreyman, K.: Exploiting Space 
and Location as a Design Framework for Interactive Mobile Systems. ACM Transactions 
on CHI 7 (2000) 

17.  Dourish,  P.,  Bellotti,  V.:  Awareness  and  Coordination  in  Shared  Workspaces.  In:  ACM 
Conf.  on  Computer-Supported  Cooperative  Work,  pp.  107–114.  ACM  Press,  New  York 
(1992) 

18.  Dourish, P.: Re-Space-Ing Place: "Place" And "Space" Ten Years On. In: 20th Conf. on 

Computer Supported Cooperative Work, pp. 299–308. ACM Press, Alberta (2006) 

19.  Dourish, P.: Where the Action Is. The MIT Press, Cambridge (2001) 
20.  Endsley, M., Aircraft, N., Hawthorne, C.: Situation Awareness Global Assessment Technique 
 (Sagat).  In:  Proc.  IEEE  National  Aerospace  and  Electronics  Conf.,  pp.  789–795 
(1988) 

21.  Endsley,  M.,  Garland,  D.:  Situation  Awareness  Analysis  and  Measurement.  CRC  Press, 

Boca Raton (2000) 

22.  Endsley, M., Jones, W.: A Model of Inter and Intra Team Situation Awareness: Implications 
for Design, Training and Measurement. New Trends in Cooperative Activities: Understanding 
System Dynamics in Complex Environments, pp. 46–67. Human Factors and 
Ergonomics Society, Santa Monica (2001) 

23.  Endsley, M.: Designing for Situation Awareness. Taylor & Francis, Abington (2003) 
24.  Endsley, M.: Toward a Theory of Situation Awareness in Dynamic Systems. Human Factors 
31, 32–64 (1995) 

25.  Fagan, M.: Design and Code Inspections to Reduce Errors in Program Development. IBM 

Systems Journal 15, 182–211 (1976) 

26.  Fisher,  D.,  Dourish,  P.:  Social  and  Temporal  Structures  in  Everyday  Collaboration.  In: 
Proc. SIGCHI Conf. on Human Factors in Comp. Syst., pp. 551–558. ACM Press, New 
York (2004) 

27.  Gaver,  W.:  Sound  support  for  collaboration.  In:  Proc.  of  ECSCW  1991,  pp.  293–308 

(1991) 

28.  Greenberg, S., Boyle, M., Laberge, J.: PDAs and Shared Public Displays: Making Personal 

Information Public, and Public Information Personal. Personal Technol. 3, 54–64 (1999) 

29.  Greenberg, S., Roseman, M.: Using a Room Metaphor to Ease Transitions in Groupware. 
In:  Ackerman,  M.,  et  al.  (eds.)  Sharing  Expertise.  Beyond  Knowledge  Management,  pp. 
203–256. MIT Press, Cambridge (2003) 

 

216 

P. Antunes et al. 

30.  Grønbæk,  K.,  Vestergaard,  P.,  Ørbæk,  P.:  Towards  Geo-Spatial  Hypermedia:  Concepts 
and  Prototype  Implementation.  In:  13th  ACM  Conf.  on  Hypertext  and  Hypermedia,  pp. 
117–126 (2002) 

31.  Gutwin, C., Greenberg, S.: A Descriptive Framework of Workspace Awareness for RealTime 
Groupware. Computer Supported Cooperative Work 11, 411–446 (2002) 

32.  Gutwin, C., Greenberg, S.: The Effects of Workspace Awareness Support on the Usability 

of Real-Time Distributed Groupware. ACM T. on Comp.-Human Int. 6, 243–281 (1999) 

33.  Gutwin, C., Greenberg, S.: The Mechanics of Collaboration: Developing Low Cost Usability 
 Eval.  Methods  for  Shared  Workspaces.  In:  WETICE  2000,  pp.  98–103.  IEEE  Press, 
Los Alamitos (2000) 

34.  Gutwin,  C.,  Roseman,  M.,  Greenberg,  S.:  A  usability  study  of  awareness  widgets  in  a 

shared workspace groupware system. In: Proc. of CSCW 1996, pp. 258–267 (1996) 

35.  Haag, S., Raja, M., Schkade, L.: Quality Function Deployment Usage in Software Development.
 Communications of the ACM 39, 41–49 (1996) 

36.  Hauser,  J.,  Clausing,  D.:  The  House  of  Quality.  Harvard  Business  Review 66,  63–73 

(1988) 

37.  Hazas, M., Scott, J., Krumm, J.: Location-Aware Computing Comes of Age. Computer 37, 

95–97 (2004) 

38.  Herskovic, V., Pino, J., Ochoa, S., Antunes, P.: Evaluation Methods for Groupware Systems.
 In: Haake, J.M., Ochoa, S.F., Cechich, A. (eds.) CRIWG 2007. LNCS, vol. 4715, pp. 
328–336. Springer, Heidelberg (2007) 

39.  Hinkley, C.: Defining the Best Quality-Control Systems by Design and Inspection. Clinical 
Chemistry 43, 873–879 (1997) 

40.  Holzinger, A.: Usability engineering methods for software developers. Communications of 

the ACM 48, 71–74 (2005) 

41.  Hornecker,  E.,  Marshall,  P.,  Dalton,  N.S.,  Rogers,  Y.:  Collaboration  and  interference: 

awareness with mice or touch input. In: Proc. of CSCW 2008, pp. 167–176 (2008) 
42.  Howell, J.: Statistical Quality Control. Mathematics Magazine 25, 155–157 (1952) 
43.  Hoyle, D.: ISO9000 Quality Systems Handbook. Elsevier, Oxford (2009) 
44.  Jensen,  E.:  Sensemaking  in  Military  Planning:  A  Methodological  Study  of  Command 

Teams. Cognition, Technology & Work 11, 103–118 (2009) 

45.  Johansen, R., Sibbet, D., Benson, S., Martin, A., Mittman, R., Saffo, P.: Leading Business 

Teams. Addison-Wesley, Reading (1991) 

46.  Johnson, P.: Reegineering Inspection. Communications of ACM 41, 49–52 (1998) 
47.  Koch, M., Koch, J.: Application of Frameworks in Groupware—the Iris Group Editor Environment.
 ACM Computing Surveys (CSUR) 32 (2000) 

48.  Kock, N.: Media Richness or Media Naturalness? The Evolution of Our Biological Communication 
Apparatus and Its Influence on Our Behavior toward E-Communication Tools. 
IEEE Transactions on Professional Communications 48, 117–130 (2005) 

49.  Kristoffersen,  S.,  Ljungberg,  F.:  Your  Mobile  Computer  Is  a  Stationary  Computer.  In: 

CSCW 1998 Handheld CSCW Ws., Seattle, USA (1998) 

50.  Laitenberger,  O.,  DeBaud,  J.:  An  Encompassing  Life-Cycle  Centric  Survey  of  Software 

Inspection. The Journal of Systems & Software 50, 5–31 (2000) 

51.  Liechti, O.: Supporting Social Awareness on the World Wide Web with the Handheld Cyberwindow.
 In: Ws. on Handheld CSCW at CSCW 1998, Seattle, USA (1998) 

52.  MacEachren,  A.,  Brewer,  I.:  Developing  a  Conceptual  Framework  for  Visually-Enabled 

Geocollaboration. Int. Journal of Geographical Information Science 18, 1–34 (2004) 

 

 

Awareness Checklist: Reviewing the Quality of Awareness Support 

217 

53.  MacMillan, J., Paley, M., Entin, E.: Questionnaires for Distributed Assessment of Team 
Mutual Awareness. In: Salas (ed.) Handbook of Human Factors and Ergonomic Methods, 
pp. 3–32. Taylor & Francis, Abington (2004) 

54.  Mills, H., Dyer, M., Linger, R.: Cleanroom Software Engineering. IEEE Software 4, 19–

25 (1987) 

55.  Nacenta, M., Pinelle, D., Stuckel, D., Gutwin, C.: The Effects of Interaction Technique on 
Coordination  in  Tabletop  Groupware.  In:  Graphics  Interface  2007,  pp.  191–198.  ACM 
Press, New York (2007) 

56.  Pinelle, D., Gutwin, C.: Groupware Walkthrough: Adding Context to Groupware Usability 
Evaluation. In: Proc. SIGCHI Conf. on Human factors in computing systems, pp. 455–462. 
ACM Press, Minneapolis (2002) 

57.  Rodden, T., Blair, G.: CSCW and Distributed Systems: The Problem of Control. In: Proc. 
2nd  Conf.  on  European  Conf.  on  Computer-Supported  Coop.  Work,  pp. 49–64.  Kluwer, 
Dordrecht (1991) 

58.  Rodden, T.: Populating the Application: A Model of Awareness for Cooperative Applications.
 In: ACM Conf. on Computer Supported Coop. Work, pp. 87–96. ACM Press, New 
York (1996) 

59.  Sacramento, V., Endler, M., Rubinsztejn, H., Lima, L.S., Goncalves, K., Nascimento, F., 
Bueno,  G.:  Moca:  A  Middleware  for  Developing  Collaborative  Applications  for  Mobile 
Users. IEEE Distributed Systems Online 5 (2004) 

60.  Snowdon,  D.,  Munro,  A.  (eds.):  Collaborative  Virtual  Environments:  Digital  Places  and 

Spaces for Interaction. Springer, New York (2000) 

61.  Tang, J.: Findings from observational studies of collaborative work. International Journal 

of Man-Machine Studies 34, 143–160 (1991) 

62.  Vizcaíno,  A.,  Martinez,  M.,  Aranda,  G.,  Piattini,  M.:  Evaluating  Collaborative  Applications 
 from  a  Knowledge  Management  Approach.  In:  14th  WETICE  2005,  pp.  221–225. 
IEEE Press, Los Alamitos (2005) 

63.  Weick, K.: Making Sense of the Organization. Blackwell, Oxford (2001) 
64.  Weick,  K.:  The  Collapse  of  Sensemaking  in  Organizations:  The  Mann  Gulch  Disaster. 

Administrative Science Quarterly 38, 628–652 (1993) 

65.  Yanco, H., Drury, J.: “Where Am I?” Acquiring Situation Awareness Using a Remote Robot 
Platform. IEEE Conf. on Systems, Man and Cybernetics 3, 2835–2840 (2004) 

66.  Zhang, W., Hill, R.: A Template-Based and Pattern-Driven Approach to Situation Awareness 
 and  Assessment  in  Virtual  Humans.  In:  4th  Int.  Conf.  on  Autonomous  Agents,  pp. 
116–123 (2000) 

 

