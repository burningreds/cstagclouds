6
1
0
2

 

y
a
M
3
1

 

 
 
]
S
D
.
s
c
[
 
 

1
v
1
3
0
4
0

.

5
0
6
1
:
v
i
X
r
a

Proceedings of the 27th International Conference on Probabilistic, Combinatorial
and Asymptotic Methods for the Analysis of Algorithms
Krak´ow, Poland, 4-8 July 2016

Robin Hood Hashing really has constant
average search cost and variance in full
tables

Patricio V. Poblete1†, Alfredo Viola2 ‡

1Dept. of Computer Science, University of Chile, Chile
2Universidad de la Rep´ublica, Uruguay

Thirty years ago, the Robin Hood collision resolution strategy was introduced for open addressing hash tables, and
a recurrence equation was found for the distribution of its search cost. Although this recurrence could not be solved
analytically, it allowed for numerical computations that, remarkably, suggested that the variance of the search cost
approached a value of 1.883 when the table was full. Furthermore, by using a non-standard mean-centered search
algorithm, this would imply that searches could be performed in expected constant time even in a full table.
In spite of the time elapsed since these observations were made, no progress has been made in proving them. In this
paper we introduce a technique to work around the intractability of the recurrence equation by solving instead an
associated differential equation. While this does not provide an exact solution, it is sufﬁciently powerful to prove a
bound for the variance, and thus obtain a proof that the variance of Robin Hood is bounded by a small constant for
load factors arbitrarily close to 1. As a corollary, this proves that the mean-centered search algorithm runs in expected
constant time.
We also use this technique to study the performance of Robin Hood hash tables under a long sequence of insertions
and deletions, where deletions are implemented by marking elements as deleted. We prove that, in this case, the
variance is bounded by 1/(1 − α) + O(1), where α is the load factor.
To model the behavior of these hash tables, we use a uniﬁed approach that can be applied also to study the First-
Come-First-Served and Last-Come-First-Served collision resolution disciplines, both with and without deletions.

Keywords: Robin Hood Hashing, full tables, constant variance, constant expected search time

1 Introduction
In 1986, Celis et al [3, 4] introduced the Robin Hood collision resolution strategy for open addressing
hash tables. Under this discipline, collisions are decided in favor of the element that is farthest from its
home location. While this does not change the expected search cost, it turns out to have a dramatic effect

†Supported in part by NIC Chile
‡This work has been partially supported by Project CSIC I+D ”Combinatoria Anal´ıtica y aplicaciones en criptograf´ıa, comunicaciones 
y recuperaci´on de la informaci´on”, fondos 2015-2016.

2

P.V Poblete and A. Viola

on its variance. In effect, unlike other disciplines where the variance tends to inﬁnity as the table becomes
full, the variance of Robin Hood seems to remain constant, and very small. This fact, conjectured from
numerical computations, has not been proved in the years since it was observed, and is the main focus
of our work. This problem has been hard to solve because the distribution of the search cost obeys a
nonlinear recurrence equation for which no successful line of attack has been found.

To show the kind of recurrence involved, we quote now Theorem 3.1 from [3] (our notation will be

slightly different):
Theorem 3.1 In the asymptotic model for an inﬁnite Robin Hood hash table with load factor α (α < 1),
the probability pi(α) that a record is placed in the i-th or further position in its probe sequence is equal
to

(1)

p1(α) = 1,

pi+1(α) = 1 −(cid:18) 1 − α

α (cid:19)(cid:16)eα(p1(α)+···+pi(α))(cid:17) .

They then go on to deﬁne another function ri(α) = α(pi(α) + · · · + p∞(α)), in terms of which the

variance can be expressed as

V (α) =

2
α

∞

Xi=1

ri(α) +

ln(1 − α)

α

−

ln2(1 − α)

α2

.

They show that ri(α)satisﬁes the following recurrence equation:

ri(α) − ri+1(α) = 1 − e−ri(α)

(2)

(3)

with r1(α) = − ln(1 − α). By leaving the “(α)” implicit and using the ∆ operator (deﬁned as ∆ri =
ri+1 − ri), this can be rewritten as ∆ri = f (ri) where f is the function f (x) = −1 + e−x.

This seemingly simpler equation has, nonetheless, so far remained unsolved.
In this paper, we will introduce a technique applicable to equations of this form, and we will use it ﬁrst
to prove a bound on the variance of Robin Hood hashing. Then we will use it to study another recurrence
equation of the same type arising from the problem of hashing with deletions.

2 Modeling hashing algorithms
In this paper we will study the search cost of a random element in a hash table, using the random probing
model. This is an open addressing hashing scheme in which collisions are resolved by additional probes
into the table. The sequence of these probes are considered to be random and depends only on the value of
the key. The difference with uniform probing is that positions may be repeated in this sequence. We use
the asymptotic model for a hash table with load factor α [9, 8, 4, 12], where we assume that the number
of keys n and the table size m both tend to inﬁnity, maintaining constant their ratio α = n/m.

Each element has associated with it an inﬁnite probe sequence consisting of i.i.d. integers uniformly
distributed over {0, . . . , m− 1}, representing the consecutive places of probes for that element. The probe
sequence for element x is denoted by h1(x), h2(x), h3(x), . . .. Elements are inserted sequentially into the
table. If element x is placed in position hj(x), then we say that element x has age j, as it requires j probes
to reach the element in case of a search. When an element x of age j and an element y of age k compete
for the same slot (hj(x) = hk(y)), a collision resolution strategy is needed.

In the standard method, a collision is resolved in favor of the incumbent key, so the incoming key
continues probing to its next location. We call this a First-Come-First-Served (FCFS) collision resolution

Robin Hood Hashing really has constant average search cost and variance in full tables

3

discipline. Several authors [2, 1, 7] observed that a collision could be resolved in favor of any of the keys
involved, and used this additional degree of freedom to decrease the expected search time in the table.

Celis et al [3, 4] were the ﬁrst to observe that collisions could be resolved having instead variance
reduction as a goal. They deﬁned the Robin Hood (RH) heuristic, in which each collision occurring
during an insertion is resolved in favor of the key that is farthest away from its home location (i.e., oldest
in terms of age). Later, Poblete and Munro [14] deﬁned the Last-Come-First-Served heuristic, where
collisions are resolved in favor of the incoming key.

In both cases, the variance is reduced, and this can be used to speed up searches by replacing the
standard search algorithm by a mean-centered one that ﬁrst searches in the vicinity of where we would
expect the element to have drifted to, rather than in its initial probe location. This mean-centered approach
was introduced in [3] (and called “organ-pipe search”) to speed up successful searches in the Robin
Hood heuristic, with expected cost bounded by the standard deviation of this random variable. Numerical
computations in [3] suggest that for full tables the variance of the search cost for RH is constant, but no
formal proof is given.

In this paper we formally settle this conjecture, by proving that this is in fact the case, and give an
explicit upper bound (although not as tight as the numerical results seem to suggest). As a consequence
we prove that the mean-centered searching algorithm in [3] has constant expected cost for full tables.

In section 4 we extend this approach to perform the analysis of hashing with deletions. Deletions in
open addressing hash tables are often handled by marking the cells as deleted instead of empty, because
otherwise the search algorithm might fail to ﬁnd some of the keys. The space used by deleted cells
may be reused by subsequent insertions. Intuitively, search times should deteriorate as tables become
contaminated with deleted cells and, as Knuth[11] points out, in the long run the average successful
search time should approach the average unsucessful search time.

In this paper we analize the effect of a long sequence of insertions and deletions in the asymptotic
regime (α-full tables with 0 ≤ α < 1) and prove a bound for the variance of RH with deletions that is
close to numerical results.

There is an alternative algorithm designed to keep variance low in the presence of deletions. This
method marks cells as deleted, but keeps the key values (these cells are called tombstones). In this paper
we do not study the algorithm with tombstones. We note that [12] derives equations for this algorithm,
but only obtains numerical solutions.

3 Analysis without deletions
To analyze the cost of searching for a random element, we begin by presenting a general framework,
based on the one used in [5]. This framework applies also to FCFS and LCFS, but in this paper we use
it to analyze RH, which has been a long standing open problem. As stated before, we use the asymptotic
model for a hash table with load factor α and random probing.

Under this model, if collisions are resolved without “looking ahead” in the table, the cost of inserting a
random element is 1 plus a random variable that follows a geometric distribution with parameter 1 − α,
and therefore its expected cost is 1/(1 − α), independently of the collision resolution discipline used.
Let pi(α) be the probability that a randomly chosen key has age i when the table has load factor α.
Suppose we insert a new element. Depending on the insertion discipline used, a number of keys will
change locations and therefore increase their ages as a consequence of the arrival of the new element. Let
us call ti(α) the expected number of probes made by keys of age i during the course of the insertion. It is

4

easy to see that

P.V Poblete and A. Viola

t1(α) = 1, Xi≥1

ti(α) =

1

1 − α

.

Before the insertion, the expected number of keys of age i is αmpi(α). After the insertion, it is

(αm + 1)pi(α +

1
m

) = αmpi(α) + ti(α) − ti+1(α)

If we write ∆α = 1/m and qi(α) = αpi(α), this equation becomes

and, as ∆α → 0 (i.e. m → ∞),

qi(α + ∆α) − qi(α)

∆α

= ti(α) − ti+1(α)

∂αqi(α) = ti(α) − ti+1(α),

(4)

(5)

(6)

(7)

where ∂α denotes a derivative with respect to α, and with the initial condition qi(0) = 0.

We introduce a notation that we will use throughout the paper. For any sequence ai we deﬁne its tail ai

as

Using this, equation (7) can be rewitten as

ai = Xj≥i

aj.

∂αqi(α) = ti(α).

(8)

(9)

We note that this equation is valid for all three collision resolution strategies, and it generalizes formula

(10) in [12], where it is proved only for RH.

The mean of the search cost can be obtained using the tail notation, as

µα = p1(α) =

1
α

q1(α)

and the variance as

α = 2p1(α) − µα − µ2
σ2

α =

2
α

q1(α) − µα − µ2

α

(10)

(11)

We note that we can already compute the expected search cost, without needing to know the exact form

of the function ti(α). Taking tails in both sides of (9), we have ∂αqi(α) = ti(α).

Now setting i = 1 and using (10), we obtain ∂α(αµα) = 1

1−α , and from this we obtain

µα =

1
α

ln

1

1 − α

(12)

independently of the collision resolution discipline used.

The fact that the mean search cost is independent of the collision resolution discipline used does not
necessarily carry over to higher moments or to the distribution of the search cost. To compute them, we
need to know the ti(α) for the speciﬁc discipline.

Robin Hood Hashing really has constant average search cost and variance in full tables

5

For RH, a key will be forced to try its (i + 1)st probe location or higher each time there is a collision
between an incoming key of age i or higher and another key in the table that is also of age i or higher.
Therefore, and leaving the “(α)” implicit, to simplify notation, we have:

ti+1 = tiqi

(13)
Together with equation (7) this implies ∂αqi = (1 − qi)∂αqi. Then, after integrating both sides of the
= qi from where we obtain qi = 1 − e−qi. Moreover, by expressing q as the

equation we have ln 1
difference of two q, we arrive at
Theorem 1 Under the asymptotic model for an inﬁnite hash table with random probing, and Robin Hood
collision resolution discipline, the double tail of the probability distribution of the search cost of a random
element satisﬁes the recurrence

1−qi

with the initial condition q1 = ln 1

1−α .

qi+1 = qi − 1 + e−qi

(14)

✷

This is exactly equation (3) that we quoted from [3], but we obtained it through a completely different
derivation. As we mentioned before, numerical computations performed in [4] indicate that as α → 1, the
variance converges to a small constant, approximately equal to 1.883.

3.1 Bounding the variance of RH
Since we are interested in the behavior of the method as α → 1, we will introduce a variable β deﬁned as
β = 1

β → 1 as β → ∞. Now we rewrite equation (14) as

1−α , so that α = 1 − 1

∆qi = −1 + e−qi,

with q1 = ln β. This equation is of the form

∆qi = f (qi),

(15)

(16)

where f is the function f (x) = −1 + e−x. This recurrence equation seems very hard to solve exactly, but
we will be able to obtain useful information about its solution by studying instead the differential equation

with the same initial condition Q(1) = ln β. The solution to this equation is

Q′(x) = f (Q(x))

Q(x) = ln (β − 1 + ex−1) − x + 1.

(17)

(18)

Figure 1 compares the solution qi (polygonal line) of recurrence equation (16) to the solution Q(x)
(smooth line) of differential equation (17). This plot suggests that Q(i) is an upper bound for qi. This is
true, and will follow from the following lemma.
Lemma 1 Let ai satisfy the recurrence equation ∆ai = f (ai), and A(x) satisfy the differential equation
A′(x) = f (A(x)), where f : [0, +∞) → (−∞, 0] is a decreasing function. Then

A(i) ≥ ai =⇒ A(i + 1) ≥ ai+1

(19)

for all i ≥ 1.

6

P.V Poblete and A. Viola

2

1

0

1

Q(x)

qi

2

3

4

5

6

7

8

9

10

Fig. 1: Comparison of qi and Q(x) for β = 10

A(i)

ai

ai+1

A(i + 1)

i

x

i + 1

Fig. 2: Proof of Lemma 1

Robin Hood Hashing really has constant average search cost and variance in full tables

7

Proof : We begin by noting that both a and A are decreasing functions, because f is negative. Reasoning
by contradiction, suppose that A(i) ≥ ai but A(i + 1) < ai+1. Therefore, there exists an x ∈ (i, i + 1)
such that A(x) intersects the straight line joining points (i, ai) and (i + 1, ai+1), as illustrated in Figure 2.
The slope of this line at x is f (ai) and the slope of A at point x is f (A(x)). At the intersection we must
have f (ai) > f (A(x)). But ai > A(x) implies f (ai) < f (A(x)), a contradiction.
✷
Corollary 1

Using this, we can rewrite equation (11) to obtain the following upper bound for the variance:

qi ≤ Q(i) ∀i ≥ 1.

σ2
α ≤

2

α Xi≥1

Q(i) − µα − µ2
α

(20)

(21)

To approximate the summation, we use Euler’s summation formula [10],

Q(i) = Z ∞

1

Xi≥1

Q(x)dx +

m

Xk=1

Bk
k!

(Q(k−1)(∞) − Q(k−1)(1)) + Rm,

(22)

where the Bk are the Bernoulli numbers (B0 = 1, B1 = − 1
[10] Exercise 1.2.11.2-3, we know that for even m, if Q(m)(x) ≥ 0 for x ≥ 1 then

2 , B2 = 1

6 , B3 = 0, B4 = − 1

30 , . . .). From

| Rm | ≤ |

Bm
m!

(Q(m−1)(∞) − Q(m−1)(1)) | .

(23)

We note that, as x → ∞, all derivatives of Q(x) tend to zero, because they all contain the factor f (Q(x)),
by repeated differentiation of equation (17), and since Q(∞) = 0, we have f (Q(∞)) = f (0) = 0.

In our case, we will apply this formula with m = 2. We note that Q(1) = q1 = αµα and Q′(1) =
f (Q(1)) = f (q1) = ∆q1 = −q1 = −α. Furthermore, Q(2)(x) ≥ 0 for x ≥ 1 because Q′(x) = f (Q(x))
is an increasing function. Therefore, we have

Q(i) = Z ∞

1

Xi≥1

Q(x)dx +

1
2

Q(1) −

1
12

Q′(1) + R2 ≤ Z ∞

1

Q(x)dx +

1
2

αµα +

1
6

α

and therefore the bound for the variance can be written as

σ2
α ≤

2

α Z ∞

1

Q(x)dx +

1
3

− µ2
α

(24)

(25)

Note that, until now, we have not made use of the speciﬁc form of the function Q(x). Using now

formulas (18) and (12), we obtain the following upper bound for the variance:
Theorem 2 Under the asymptotic model for an inﬁnite α-full hash table with random probing and RH
collision resolution discipline, the variance of the search cost of a random element satisﬁes (with β =
1/(1 − α))

σ2
α ≤

π2
3

+

1
3

+ O(cid:18) ln β

β (cid:19) .

(26)

8

P.V Poblete and A. Viola

✷
This gives us an upper bound of 3.6232 . . . for the variance of Robin Hood Hashing. Although a
numerically computed value of approximately 1.883 has been known for a long time, this is the ﬁrst proof
that this variance is bounded by a small constant as α → 1. As Celis et al. observed, the fact that the
variance is very small can be used to carry out a more efﬁcient mean-centered search. If we call X the
random variable “search cost of a random key” the expected cost of this modiﬁed search is Θ(E|X − µα|).
But Jensen’s inequality implies that

E|X − µα| = Ep(X − µα)2 ≤ pE(X − µα)2 = σα

(27)
so, the mean value of the search cost of a mean-centered search is proportional to the standard deviation of
the cost of a standard seach. Theorem 2 then implies that this search algorithm runs in expected constant
time in a full table.
3.2 Bounding the tail of RH
We focus now on the tail of the distribution of the search cost, i.e. we study

Pr{X ≥ i} = pi =

1
α

qi =

β

β − 1

qi.

(28)

We proved earlier that qi ≤ Q(i). By applying f to both sides and recalling that f is a decreasing function,
we have f (qi) ≥ f (Q(i)). Using equations (16) and (17), we have ∆qi = −qi ≥ Q′(i), and therefore

Pr{X ≥ i} ≤ −

β

β − 1

Q′(i) =

β

β − 1 + ei−1 .

(29)

If we take the upper bound as the tail
would be

β

β−1+ex−1 of a continuous probability function, its density function

p(x) =

βex−1

(β − 1 + ex−1)2 ,

(30)

which is symmetric around its mean (and mode) located at the point x such that ex−1 = β − 1, i.e.,
x = 1 + ln (β − 1).

As a consequence, by equation (29), the probability that the search cost will exceed this amount by a

given number of steps k:

Pr{X ≥ 1 + ln (β − 1) + k} ≤

β

1

β − 1

ek + 1

→

1

ek + 1

(31)

as β → ∞.

Therefore, as the table becomes full, the mean moves to the right without bound, but the distribution
remains tightly packed to the right of the mean, and the probability that the search cost exceeds the mean
by a given amount decreases exponentially with the distance.

Finally, it is interesting to note that if we shift to the left the density function (30) so it is centered

around zero, we obtain

p(1 + ln (β − 1) + x) =

which, as β → ∞, converges to
distribution.

ex

(1+ex)2 , or, equivalently,

β

ex

(32)

(1 + ex)2

β − 1
e−x
(1+e−x)2 , the density function of a Logistic(0,1)

Robin Hood Hashing really has constant average search cost and variance in full tables
4 Analysis with deletions
We assume a process where we ﬁrst insert keys until the table reaches load factor α, and then we enter an
inﬁnite cycle where we alternate one random insertion followed by one random deletion.

9

If the distribution of the retrieval cost is given by pi(α) and a random element is inserted, the effect is
described by equation (5). If we then perform a random deletion, the following classical lemma[6] shows
that the distribution remains unchanged:

Lemma 2 Suppose a set contains n balls of colors 1, 2, . . . , k, such that the probability that a ball chosen
at random is of color i is pi. Then, if one ball is chosen at random and discarded, the a posteriori
probability that a random ball is of color i is still pi.

Proof : Call p′
of balls of color i afterwards is (n − 1)p′
before, npi, minus the expected number of balls of color i lost, i.e.,

i the probability that a random ball is of color i after the deletion. The expected number
i, but that number can also be obtained as the expected number

(n − 1)p′

i = npi − 1 · pi.

(33)

The result follows.

✷
Therefore, equation (5) describes also the probability distribution after one insert-delete step. Now,
assume the process reaches a steady state. In that case, the distribution after the insert-delete must be
equal to the distribution before, i.e. pi(α + 1

m ) = pi(α), and replacing this in (5) we have

and equivalently,

pi(α) = ti(α) − ti+1(α).

pi(α) = ti(α).

(34)

(35)

These equations play the role that equation (7) did for the case without deletions. Taking tails in both
sides of this equation and setting i = 1, we can obtain the expected search cost µα as

µα = p1 = t1 =

1

1 − α

,

(36)

conﬁrming the prediction that the expected successful search cost should approach the expected unsuccessful 
search cost when deletions are allowed.

For RH, from (35) we get pi = ti, and combining this with (13) we obtain

p1 =

1

1 − α

,

pi+1 =

αp

2
i

1 + αpi

(37)

We can use this recurrence to compute numerically the distribution for RH.

Figure 3 shows the value of the variance of RH as a function of β = 1/(1 − α), and from the plot
we may see that the variance is very close to β. Moreover, Figure 4 shows the distribution of the search
cost for the three methods, for α = 0.99. As proven in [13] it can be seen that FCFS and LCFS are
now identical and have very large dispersion (σ2
(1−α)2 ), while RH retains a much more concentrated
shape. We prove that this is indeed the case.

α = α

10

P.V Poblete and A. Viola

100

σ2

0

0

β

100

Fig. 3: The variance of RH with deletions as a function of β

0.2

0.1

0

1

RH

150

FCFS, LCFS

Fig. 4: Distribution of search costs for FCFS, LCFS and RH for α = 0.99

Robin Hood Hashing really has constant average search cost and variance in full tables

11

4.1 Bounding the variance of RH with deletions
We begin by rewriting the recurrence equation (37) as

q1 = β − 1, ∆qi = −

qi

1 + qi

(38)

This equation is of the form ∆qi = f (qi) for f (x) = − x
1+x , and all the conditions required in section
3.1 are satisﬁed, so we can apply the exact same technique used there. Solving the associated differential
equation

we ﬁnd the solution

Q′(x) = f (Q(x)), Q(1) = β − 1

Q(x) = W ((β − 1)eβ−x),

(39)

(40)

where W is Lambert’s function satisfying x = W (x)eW (x). As a consequence, proceeding as in the proof
of Theorem 2, we obtain the following result:
Theorem 3 Under the asymptotic model for an inﬁnite α-full hash table with random probing and RH
collision resolution discipline, in the steady state of a sequence of insert-delete operations, the variance
of the search cost of a random element satisﬁes (with β = 1/(1 − α))

σ2
α ≤ β +

1
3

=

1

1 − α

+

1
3

.

(41)

✷

This proves our earlier conjecture that the variance was very close to 1

1−α .

5 Acknowledgements
We are grateful to the anonymous reviewers, for their valuable comments and suggestions, that helped us
improve the paper.

References
[1] O. Amble and D. E. Knuth. Ordered-hash-tables. Computer Journal, 17(2):135–142, 1974.

[2] R. P. Brent. Reducing-the-retrieval-time-of-scatter-storage-techniques. CACM, 16(2):105–109,

1973.

[3] P. Celis. Robin Hood Hashing. PhD thesis, University of Waterloo, 1986. Technical Report CS-8614.


[4] P. Celis, P.- ˚A. Larson, and J.I. Munro. Robin Hood Hashing.

In 26th IEEE Symposium on the

Foundations of Computer Science, pages 281–288, 1985.

[5] Walter Cunto and Patricio V Poblete. Two hybrid methods for collision resolution in open addressing

hashing. In SWAT 88, pages 113–119. Springer, 1988.

12

P.V Poblete and A. Viola

[6] William Feller. An Introduction to Probability Theory and Its Applications, volume 1. Wiley, January

1968.

[7] G. H. Gonnet and J. I. Munro. Efﬁcient-ordering-of-hash-tables. SIAM Journal on Computing,

8(3):463–478, 1979.

[8] Leo J. Guibas. The analysis of hashing techniques that exhibit k-ary clustering. J. ACM, 25(4):544–

555, October 1978.

[9] L.J. Guibas. The analysis of hashing algorithms. STAN-CS. Stanford University, 1976.

[10] D.E. Knuth. Art of Computer Programming Volume 1: Fundamental Algorithms. Addison-Wesley

Publishing Company, 1972.

[11] D.E. Knuth. The Art of Computer Programming vol. 3 Sorting and Searching. Addison-Wesley

Publishing Company, 1998.

[12] M. Mitzenmacher. A new approach to analyzing robin hood hashing. Preliminary version in

http://arxiv.org/abs/1401.7616, 2014.

[13] P. Poblete and A. Viola. The effect of deletions on different insertion disciplines for hash tables. In

Brazilian Symposium on Graphs, Algorithms and Combinatorics (GRACO), 2001.

[14] P.V. Poblete and J.I. Munro. Last-Come-First-Served Hashing. Journal of Algorithms, 10:228–248,

1989.

