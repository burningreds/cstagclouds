Eﬃcient Compressed Indexing

for Approximate Top-k String Retrieval(cid:2)

H´ector Ferrada and Gonzalo Navarro

Department of Computer Science, University of Chile, Chile

{hferrada,gnavarro}@dcc.uchile.cl

Abstract. Given a collection of strings (called documents), the top-k
document retrieval problem is that of, given a string pattern p, ﬁnding
the k documents where p appears most often. This is a basic task in
most information retrieval scenarios. The best current implementations
require 20–30 bits per character (bpc) and k to 4k microseconds per
query, or 12–24 bpc and 1–10 milliseconds per query. We introduce a
Lempel-Ziv compressed data structure that occupies 5–10 bpc to answer
queries in around k microseconds. The drawback is that the answer is
approximate, but we show that its quality improves asymptotically with
the size of the collection, reaching over 85% of the accumulated term
frequency of the real answer already for patterns of length 4–6 on rather
small collections, and improving for larger ones.

1

Introduction

Finding the k documents most relevant to a search query is the most basic
information retrieval problem. Originally deﬁned on natural language text collections,
 its generalization to collections of arbitrary strings turns out to be a
problem arising naturally in areas like bioinformatics, multimedia databases,
software repositories, and so on [11]. For example, one might want to ﬁnd the
genes where a certain motif appears most often (as they may deserve further
biological analysis), modules where a function is called most often (to spot cohesion 
issues in software design), songs containing most occurrences of a certain
sequence (to hint plagiarism), and so on. On East Asian languages like Chinese
and Korean, classical solutions for Western natural languages are not applicable,
and they are usually handled as generic string collections as well.

Our collection will contain D documents, which are strings d1, . . . , dD, over
(cid:2) |di|. We preprocess them to build
an alphabet [1, σ], of total length n =
an index. Later, given a pattern string p[1, m] and a threshold k, we must list
the k documents where p appears most often. In natural language searching
the measure of relevance can be more sophisticated than just the number of
occurrences of p, but frequency is still a key component. Usually even more
complex measures are used in a second step, where the top-k documents are
further ﬁltered to obtain the ﬁnal result [14].

(cid:2) Partially funded by Fondecyt grant 1-140796, Chile.

E. Moura and M. Crochemore (Eds.): SPIRE 2014, LNCS 8799, pp. 18–30, 2014.
c(cid:2) Springer International Publishing Switzerland 2014

Eﬃcient Compressed Indexing for Approximate Top-k String Retrieval

19

Hon et al. [4] proposed a ﬁrst index for this problem, but its space usage is
superlinear, O(n log n) words; their implementation also uses too much space.
Later, Hon et al. [6] presented a structure using linear space, that is, O(n) words
or O(n log n) bits. They solved queries in O(m + k log k) time. Navarro and
Nekrich [12] reduced the time to the optimal O(m + k). Konow and Navarro [7]
implemented this index, obtaining an index that uses 20–30 bits per character
(bpc)1 and answers top-k queries in k to 4k microseconds (μsec). Their time
complexity is O(m + (k + log log n) log log n) with high probability, on statistically 
typical texts [15]. Shah et al. [5] proposed another index that is not yet
implemented, but it is likely to perform similarly, and has a time complexity
of O(m + (log log n)6 + k(log σ log log n)1+) for any constant  > 0. Navarro
and Valenzuela [13] aimed at using less space, reaching 12–24 bpc depending
on the compressibility of the collections, but retrieval times are an order of
magnitude higher, 1 to 10 milliseconds (the time complexity is upper-bounded
by O(m + k log4+ n)). There are several other theoretical proposals [11] that
promise to use much less space than current implementations, but that are most
likely to be even slower in practice (as already hinted in current studies [13]).

(cid:3)

(cid:3)

In this paper we introduce an index that uses much less space and time
than current alternatives. It is based on Lempel-Ziv compression, precisely LZ78
[16], which compresses texts by building a dictionary of frequent strings (called
(cid:3) ≤
phrases) and then parsing the text as a sequence of n
n/ lgσ n for any text, and moreover n
lg n = nHk+O(n(k log σ+log log n)/ logσ n)
for any k, where Hk is the k-th order empirical entropy of the text [8]. This is
(cid:3)
n
lg n = nHk + o(n log σ) for any k = o(logσ n). Our structure builds on previous 
LZ78-compressed indexes called LZ-indexes, developed for ﬁnding all the
occurrences of p [10,2] and for listing all the documents where p occurs [3].
log σ) =
Like these indexes, our structure uses, in practice, (2 + )n
(2 + )nHk + o(n log σ) bits, and it solves top-k queries in time O(m + k log D).
In practice, the space is around 5–10 bpc to achieve a query time around k μsec.
This time/space tradeoﬀ is well below that of previous implementations.

phrases. It holds n

(cid:3)

lg n + O(n

(cid:3)

(cid:3) ≤ n/ lgσ n, only (n/d)m(n

In exchange, our top-k answer is approximate, as we consider only the occurrences 
of p within phrases. If the text is generated by a stationary source,
the occurrences of any pattern p appear regularly, every d positions on average 
(e.g., d = σm if the symbols are generated uniformly and independently).
/n) ≤ (n/d)m/ lgσ n of
On the other hand, since n
those occurrences hit a phrase boundary on average. This means that a fraction
of 1 − m/ lgσ n of the occurrences are within phrases (the fraction improves to
1 − mHk/ lg n on compressible texts). Thus, we are considering asymptotically
all of the occurrences of p when building the approximate top-k answers for short
enough patterns, m = o(logσ n). Note that, if m ≥ lgσ n, then it occurs O(1)
times on average in the collection, and then a plain listing of all the documents
where it appears [3] is an appropriate tool to ﬁnd its top-k documents.

(cid:3)

We show that, already on moderate collections of n = 25–130 MB, the quality
of the answer (measured as the number of occurrences of p on the k retrieved

1 The space results they report [7] are somewhat underestimated, as we show here.

20

H. Ferrada and G. Navarro

documents as a percentage of the number of occurrences on the actual top-k
documents) is always over 85% for short patterns (m = 4–6), improving as the
collection size grows and as the collection becomes more compressible with LZ78.

2 The LZ-Index
Assume we concatenate the documents d1 ··· dD (each terminated with a special

(cid:3)

(cid:3)

(cid:3)

symbol $, which always marks the end of a phrase) into a text T [1, n] over
alphabet [1, σ]. The LZ78 compression algorithm cuts the text into n
distinct
phrases, each of which is equal to the longest possible previous phrase plus the
following new symbol. Each phrase is then replaced by the id of the previous
corresponding phrase and the extra symbol. The number of bits output by the
compressor is |LZ78| = n
(cid:3)
+ lg σ), which converges to the statistical entropy
(lg n
(cid:3) ≤ n/ lgσ n. The LZ-index [10] is a text index built
of T [8], and it always holds n
on the LZ78 parsing of the text, and it supports locating the occurrences of a
pattern p[1, m] in T . The index is formed by the following components (among
others not relevant for this paper).
1. LZTrie: a trie composed of all the phrases produced by the LZ78 parsing.
Note that the set of phrases is preﬁx-closed (every preﬁx of a phrase is also a
phrase), so LZTrie has n
nodes. It stores the phrase identiﬁer of each node.
2. RevTrie: a trie storing the reversed phrases. It is not preﬁx-closed, so there
are empty nodes not associated with phrases. It contains originally trev nodes.
We contract unary paths of empty nodes to a single edge, after which the
trie has nrev = n
nodes, where ne empty nodes remain after
contracting. The phrase numbers of the n

nonempty nodes are stored.

+ ne ≤ 2n

3. Node: an array mapping from phrase numbers to their preorder in LZTrie.
The modern version [2] of the LZ-index uses (2+)|LZ78|(1+o(1)) bits, for any
>0. The occurrences of pattern p are divided into type 1 (those completely inside
a phrase), and types 2 and 3 (those spanning two or more phrases, respectively).
Those are found separately at search time. In this paper we are only interested in
ﬁnding occurrences of type 1. For those, we search for pr (the reversed pattern)
in RevTrie, arriving at node vr. Each node ur descending from vr (including vr)
corresponds to an occurrence of type 1 where p appears at the end of the phrase.
that descend from u in LZTrie,
The other occurrences of type 1 are the nodes u
where u corresponds to ur. Thus, for each node ur that is nonempty, we read
the phrase id fu of ur, compute u = Node(fu), and report all the phrase ids in
the subtree of u. It takes O(m + occ) time to report the occ type-1 occurrences.

(cid:3)

(cid:3)

(cid:3)

(cid:3)

3 An LZ-Index for Approximate Top-k Retrieval

Our top-k retrieval LZ-Index is a modiﬁcation of the original LZ-Index. The
parsing into phrases is changed so as to force phrases to ﬁnish when the document
terminator $ is seen, so that no phrase crosses a document border. The LZ-Index
is then represented with the following structures, inspired in previous work [3]:

Eﬃcient Compressed Indexing for Approximate Top-k String Retrieval

21

LZTrie: We store only the topology and the documents where the phrases lie,

(cid:3)

(cid:3)

using in total n
Plz: The LZTrie topology represented with parentheses in a preorder traverlg 
D + O(n

) bits.

Dlz: An array storing, for each node v of LZTrie in preorder, the document

sal, and made navigable in O(1) time using 2n
identiﬁer (using (cid:4)lg D(cid:5) bits) where its corresponding phrase lies.

) bits (FF [1]).

+ o(n

(cid:3)

(cid:3)

Revtrie: We store the structures needed to carry out searches directly on it,
without the help of the LZTrie, using in total trev lg σ+O(trev) bits. In theory
trev can be as large as n but in practice it is much closer to nrev ≤ 2n
Prev: The tree topology using parentheses and made constant-time naviga-

(cid:3)

.

ble, using 2trev + o(trev) bits (FF [1]).

Erev: A bitmap marking empty nodes, in preorder, using trev bits.
Urev: A bitmap marking empty unary nodes (i.e., contracted), from those

that are marked empty in Erev, using trev − n

(cid:3)

bits.

Lrev: A sequence of the nrev letters that label the non-contracted edges leading 
to the nodes, in preorder. Used to ﬁnd the child nodes at searching.
Mrev: A sequence of the trev − nrev letters that label the contracted edges
leading to the nodes, in preorder. Used to check that the characters in
the contracted edge match the search pattern.

All the bitmaps are stored with sublinear extra data structures that solve
rank/select operations in constant time [9]. This allows, for example, ﬁnding
the jth 0 or 1 in the bitmap in constant time, or count the number of 0s or
1s in any bitmap interval.

(cid:3)

(cid:3)

(cid:3)

∗

∗

lg n

) bits.

+ O(n

LZTrie preorder numbers, using n

Node: This is recast as a mapping from nonempty RevTrie nodes to their
Top: To solve top-k document retrieval for any k ≤ k
is a parameter
deﬁned at construction time, we will store the top-k
answers, in decreasing
frequency order, for some RevTrie nodes. We use a parameter g to deﬁne the
RevTrie nodes that will store their top-k
answer: These will be the (empty
or nonempty) nodes representing a string with at least gk
occurrences of
type 1 in T . Empty unary nodes will not store their answer set, as this is the
values in [1..D] that
same of its child. The marking will be node for all the k
are a power of 2. Nodes v will store their top-k
answers for the maximum
∗
k
value for which they are marked. This is implemented with the following
additional structures:

, where k
∗

∗

∗

∗

∗

Btop: A bitmap of size nrev marking which RevTrie nodes have top-k

∗

answers 
precomputed, in preorder.

∗

Ktop: The sequences of k

most frequent documents where each node marked
in Btop appears, concatenated in the same order of Btop. The identiﬁers
are stored using (cid:4)lg D(cid:5) bits, in decreasing frequency order.

LKtop: A bitmap marking the starting positions of the sequences in Ktop.
Atop: Since there may be less than k

distinct documents where the marked
node appears, this bitmap indicates whether a node marked in Btop
already lists all of the possible documents.

∗

22

H. Ferrada and G. Navarro

The larger g, the fewer RevTrie nodes store their top-k
theory we might store up to nrev k
to (nrev/(gk
∗
k

documents: While in
lg D bits, in practice this is much closer
lg D = (nrev lg D)/g, which added over the lg D values for

gives (nrev lg2 D)/g bits. The other bitmaps use O(nrev) bits.

)) k

∗

∗

∗

∗

Figure 1 illustrates the main components of our index. The overall space is, in
+lg D +2 lg σ +2(lg2 D)/g +O(1)) bits. Thus
practice, upper bounded by n
a value like g = Θ(lg D) obtains space similar to the original pattern-matching
LZ-index, (2 + )n

log σ) bits [2].

lg n + O(n

(lg n

(cid:3)

(cid:3)

(cid:3)

(cid:3)

Since phrases are cut at the end of documents, there may appear a few repeated 
phrases across the collection. Therefore, at construction time, we have to
consider the special case when two or more documents end with the same phrase.
This is handled by storing a short linked list, both in RevTrie and LZTrie, attached 
to the nodes representing phrases that appear more than once.

Querying. At query time, we ﬁnd the RevTrie node corresponding to pr, move
to its highest descendant not marked in Urev, vr, and check if it is marked in
Btop. If marked and either (1) Atop indicates it stores all the possible documents,
(cid:3) ≥ k top documents, then we return the
or (2) LKtop indicates that it stores k
ﬁrst k documents stored for vr in Ktop and ﬁnish. Otherwise, we need to solve the
answer by brute force, by traversing all its type-1 occurrences. By construction,
this takes place only if vr has k
= 0).
If k
answers,
thus by construction it has less than gk
occurrences of type 1. Therefore the
brute-force process must traverse O(gk) occurrences.

is the power of 2 next to k, then vr does not store its top-k

< k answers stored (including the case k

In order to solve vr by brute force, we use Prev to compute its preorder iv
and its subtree size sv. Thus all the subtree of vr has the preorder interval
[iv, iv + sv − 1]. Then we use rank on Erev to map it to the interval [i1, i2] of

∗

∗

∗

(cid:3)

(cid:3)

nonempty preorder values. For each i in this interval, we compute iu = N ode(i),
which is the preorder of the corresponding node in LZTrie, and then use Plz to
obtain the corresponding node u in LZTrie. Then we compute the size su of u
and obtain the interval [iu, iu + su − 1] of all the descendants of u in LZTrie. We
process all the document identiﬁers in Dlz[iu, iu + su − 1], for all the nodes u in
LZTrie that correspond to all the RevTrie descendants ur of vr, accumulating
their frequencies and then choosing the k highest ones. The whole process takes
O(m + gk + k log k) = O(m + k log D) time.

4 Experimental Results

We use various document collections, following previous work [13,7] and exploring 
diﬀerent aspects of statistical compressibility, size, number of documents, and
repetitiveness: ClueWiki (English, few large documents), DNA (synthetic, mildly
repetitive with 5% mutations among documents), KGS (Go game records), Wiki
(more and shorter documents), Proteins (many more documents, almost incom-
pressible), and TodoCL (a snapshot of the Chilean Web, with real queries, used to

Eﬃcient Compressed Indexing for Approximate Top-k String Retrieval

23

Fig. 1. The main data structures of our index. The search for the pattern qr reaches
node W r in the RevTrie, which is marked in Btop, therefore the answer is retrieved
from the vector Ktop using the marks in the bit array LKtop. The search for pr, instead,
reaches node V r in the RevTrie. Since this is an unmarked node, the answer is computed
online by accumulating frequencies from the document array of phases, Dlz.

measure quality). Table 1 shows their main characteristics (column “compress”
shows how the LZ78-based Unix Compress program compresses them).

Our machine is an Intel Xeon with 8 processors of 2.4GHz and 12MB cache,
with 96GB RAM. It runs Linux 2.6.32-46-server, and we use gcc with full optimization 
and no multithreading. We chose 40,000 patterns of lengths m = 3 and
m = 8 extracted randomly from the collection.

4.1 Time and Space

Table 1 shows the size of our structure with g = 512, where it uses almost its
minimum possible space, and with g = 128, where it achieves around k μsec to
solve queries, as we will see. The minimum space ranges from 1.2 to 2.8 times
the space of Unix Compress. For this value of g our analysis predicts a factor
around 2. On the other hand, our index uses around 5–10 bpc with g = 128.

Fig. 2 gives the breakdown of the space obtained by our index on those collections,
 for increasing values of g. The components are LZTrie (the tree topology
and the document identiﬁers, which dominate), RevTrie (the tree topology and
the letters), array Node, and Top (the storage of the best documents for some
precomputed nodes). We show the breakdown as cumulative space curves. As g
increases, the Top component is reduced and the structure becomes slower.

Now we compare our structure with previous work. We consider search patterns 
of lengths m = 3 in Fig. 3 and m = 8 in Fig. 4, and measure the cost to
compute the top-10 and top-100 documents, for g = 512, 256, 128, . . .. We denote
DCC’13 the existing fast and large structure [7] and denote SEA’12 a choice of
relevant space/time tradeoﬀs of the existing small and slow structure [13]. In
most texts, our structure uses 5–7 bpc to solve top-k queries in around k μsec.

24

H. Ferrada and G. Navarro

Table 1. Main measures related to the space usage of our index. We refer here to the
ﬁrst 200MB of TodoCL.

Collection

ClueWiki
DNA
KGS
Wiki
Proteins
TodoCL.200

n

(MB)
131
95
25
80
56
200

D

3,334
10,000
18,838
40,000
143,244
48,186

(cid:2)
n/n

17.24
11.50
14.97
9.58
6.43
9.86

compress

(bpc)

g = 512
(bpc)

g = 128
(bpc)

3.63
2.68
1.85
3.34
4.61
3.91

4.50
4.86
5.13
6.73
9.58
7.32

6.31
5.30
6.23
7.43
10.10
6.65

The exception is Proteins, where it uses around 10 bpc due to its incompressibility.
 Except on Proteins, where it uses over 20 bpc, structure SEA’12 can use
similar or less space than ours, but at the cost of being 4–5 orders of magnitude
slower. Even if using much more space, SEA’12 is at least 10 times slower than
ours. Structure DCC’13, on the other hand, is 4–50 times slower than ours, and
uses 2.5–7 times our space.

4.2 Quality

(cid:3)

The drawback is that our structure delivers approximate top-k answers. We
present in Fig. 5 two measures of the quality of the answer. On the left we show
(cid:3) ∈ [1, k], we
traditional recall, measured in the following way: for each value k
measure how many of the (correct) top-k
documents are reported within the
(approximate) top-k results. For example, the point at k
= 1 indicates how
many times the most relevant document is contained in our top-k answer. The
= k indicates how many of the correct top-k documents are actually
point at k
returned. This measure is interesting in applications where the top-k answer is
postprocessed with a more sophisticated relevance function in order to deliver
(cid:3) (cid:7) k results. The ﬁgure shows that, in this scenario, the k
(cid:3)
a ﬁnal answer of k
most relevant candidates are frequently in the approximate top-k answer set, for
becomes closer to k, the recall degrades, more or less
small k
depending on the collection, and faster for m = 8 than for m = 3. On the other
hand, there are no signiﬁcant diﬀerences between the results for k = 10 and for
k = 100. Results are particularly bad for DNA, KGS, and Proteins.

. However, when k

(cid:3)

(cid:3)

(cid:3)

(cid:3)

If our index fails to return a top-k document but returns another one with
the same frequency, we take it as a hit, as both are equally good. In this sense,
recall is a too strict measure of relevance: if the system returns a document with
only slightly fewer occurrences than the correct one, it counts as zero. As the
frequency is only a rough measure of relevance, a much more precise measure of
quality is the sum of the frequencies of the documents in the approximate top-k
answer as a fraction of the sum in the correct top-k answer.

Fig. 5 (right) shows the results under this measure of quality. All collections
= k.
perform very well for k = 3, reaching 90%–100% of quality even for k
For k = 8, collections ClueWiki and KGS still achieve a reasonable quality over

(cid:3)

Eﬃcient Compressed Indexing for Approximate Top-k String Retrieval

25

ClueWiki

DNA

)
c
p
b
(
 
e
c
a
p
s

)
c
p
b
(
 
e
c
a
p
s

)
c
p
b
(
 
e
c
a
p
s

 14

 12

 10

 8

 6

 4

 2

 0

 12

 10

 8

 6

 4

 2

 0

 20
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0

LZTrie
RevTrie
Node
Top

 0

 100

 200

 300

 400

 500

KGS

LZTrie
RevTrie
Node
Top

 0

 100

 200

 300

 400

 500

Proteins

LZTrie
RevTrie
Node
Top

 0

 100

 200

 300

 400

 500

)
c
p
b
(
 
e
c
a
p
s

)
c
p
b
(
 
e
c
a
p
s

)
c
p
b
(
 
e
c
a
p
s

 12

 10

 8

 6

 4

 2

 0

 14

 12

 10

 8

 6

 4

 2

 0

 20
 18
 16
 14
 12
 10
 8
 6
 4
 2
 0

LZTrie
RevTrie
Node
Top

 0

 100

 200

 300

 400

 500

Wiki

LZTrie
RevTrie
Node
Top

 0

 100

 200

 300

 400

 500

TodoCL.200

LZTrie
RevTrie
Node
Top

 0

 100

 200

 300

 400

 500

Fig. 2. Space breakdown of our structures for diﬀerent g values (g is the x-axis)

(cid:3)

80%, DNA over 60%, Wiki over 50%, and Proteins only 10%. These diﬀerences
in quality can be predicted with Table 1: the less compressible the collection,
, and the worse quality obtained for a given pattern length m.
the smaller n/n
On the other hand, the fact that better quality is obtained for shorter patterns
coincides with our probabilistic analysis. Fig. 6 illustrates this eﬀect more closely,
for increasing pattern lengths. It can be seen that, for the moderate collection
sizes of 25–130 MB we considered, we obtain quality well above 85% for m =
4–6, depending on the text type and its n/n
value. Fig. 7 shows the case of real
query words (of length > 3 to exclude most stopwords, average length 7.2) and 2word 
phrases (average length 8.0), on increasing preﬁxes of TodoCL converted to
lowercase (as case is generally ignored in natural language queries). As predicted,
= 10.1) up to
the quality improves with n, from 33%–46% on 200 MB (n/n
59%–72% on 1.6 GB (n/n

= 12.5).

(cid:3)

(cid:3)

(cid:3)

26

H. Ferrada and G. Navarro

ClueWiki, k = 10, m = 3

ClueWiki, k = 100, m = 3

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 

e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

DNA, k = 10, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

KGS, k = 10, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

Wiki, k = 10, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

Proteins, k = 10, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 

e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

DNA, k = 100, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

KGS, k = 100, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

Wiki, k = 100, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

Proteins, k = 100, m = 3

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

Fig. 3. Space/time comparison for pattern length m = 3. Space (bpc) is the x-axis.

Eﬃcient Compressed Indexing for Approximate Top-k String Retrieval

27

ClueWiki, k = 10, m = 8

ClueWiki, k = 100, m = 8

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 

e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

DNA, k = 10, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

KGS, k = 10, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

Wiki, k = 10, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

Proteins, k = 10, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 

e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
e
m

i
t

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

 1e+06

 100000

 10000

 1000

 100

 10

 1

 0

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

DNA, k = 100, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

KGS, k = 100, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

Wiki, k = 100, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

 35

Proteins, k = 100, m = 8

LZ-Index
DCC’13
SEA’12

 5

 10

 15

 20

 25

 30

Fig. 4. Space/time comparison for pattern length m = 8. Space (bpc) is the x-axis.

28

H. Ferrada and G. Navarro

ClueWiki

ClueWiki

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

l
l

a
c
e
r

l
l

a
c
e
r

l
l

a
c
e
r

l
l

a
c
e
r

l
l

a
c
e
r

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

DNA

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

KGS

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Wiki

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Prot

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

DNA

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

KGS

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Wiki

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Prot

m = 3, k = 10
m = 3, k = 100
m = 8, k = 10
m = 8, k = 100

 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1

Fig. 5. Recall (left) and quality (right) of our approximate top-k solution, as a function
of the fraction of the answer (x-axis)

Eﬃcient Compressed Indexing for Approximate Top-k String Retrieval

29

k = 10

k = 100

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

 1

 0.95

 0.9

 0.85

 0.8

 0.75

 0.7

 0.65

 0.6

ClueWiki
DNA
KGS
Wiki
Proteins

 2

 4

 6

 8

 10

 12

 14

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

 1

 0.95

 0.9

 0.85

 0.8

 0.75

 0.7

 0.65

 0.6

ClueWiki
DNA
KGS
Wiki
Proteins

 2

 4

 6

 8

 10

 12

 14

Fig. 6. Quality of our approximate top-k solution, as a function of the pattern length,
for top-10 (left) and top-100 (right)

TodoCL - 1-word queries

TodoCL - 2-word queries

k=10
k=100

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

k=10
k=100

 0.75
 0.7
 0.65
 0.6
 0.55
 0.5
 0.45
 0.4
 0.35
 0.3

y
c
n
e
u
q
e
r
f
 
f

o

 

n
o

i
t
c
a
r
f

 0.75
 0.7
 0.65
 0.6
 0.55
 0.5
 0.45
 0.4
 0.35
 0.3

 200

 400

 600

 800  1000  1200  1400  1600

MB

 200

 400

 600

 800  1000  1200  1400  1600

MB

Fig. 7. Quality of our approximate top-k solution, as a function of the preﬁx size of
TodoCL in MB, for words (left) and phrases of 2 words (right)

5 Conclusions

We have introduced a top-k retrieval index for general string collections, based
on Lempel-Ziv compression. The index is orders of magnitude faster, and uses
much less space, than previous work. In exchange, it delivers approximate top-k
answers, which is acceptable in most applications. We analytically show that,
under reasonable assumptions on the text distribution, the answers tend to exactness 
asymptotically, when the collection is large enough compared to the
pattern length. Our experiments also show that the quality of the answer is
good enough for short patterns already on our moderate-size text collections.
The larger the text collection, or the more compressible it is with LZ78, the
longer the patterns that can be searched with high quality. In this sense, the
index is a very promising alternative to handle the large text collections one
aims at in real life.

We obtain good-quality results for real word queries on a moderately large text
collection. Our next step is to use our index to ﬁnd top-k candidate documents
for the individual words of multiword queries and then postprocessing the result
into weighted conjunctive or disjunctive queries [14].

30

H. Ferrada and G. Navarro

In natural language, retrieving approximate top-k answers to improve eﬃciency 
is a common practice. This avenue has not been explored much for general
string collections. Our work shows that this idea is promising, as large space and
time reductions are possible while still returning answers of good quality.

References

1. Arroyuelo, D., C´anovas, R., Navarro, G., Sadakane, K.: Succinct trees in practice.

In: Proc. ALENEX, pp. 84–97 (2010)

2. Arroyuelo, D., Navarro, G., Sadakane, K.: Stronger Lempel-Ziv based compressed

text indexing. Algorithmica 62(1), 54–101 (2012)

3. Ferrada, H., Navarro, G.: A Lempel-Ziv compressed structure for document listing.
In: Kurland, O., Lewenstein, M., Porat, E. (eds.) SPIRE 2013. LNCS, vol. 8214,
pp. 116–128. Springer, Heidelberg (2013)

4. Hon, W.-K., Patil, M., Shah, R., Wu, S.-B.: Eﬃcient index for retrieving top-k

most frequent documents. J. Discr. Alg. 8(4), 402–417 (2010)

5. Hon, W.-K., Shah, R., Thankachan, S.V.: Towards an optimal space-and-querytime 
index for top-k document retrieval. In: K¨arkk¨ainen, J., Stoye, J. (eds.) CPM
2012. LNCS, vol. 7354, pp. 173–184. Springer, Heidelberg (2012)

6. Hon, W.-K., Shah, R., Vitter, J.: Space-eﬃcient framework for top-k string retrieval

problems. In: Proc. FOCS, pp. 713–722 (2009)

7. Konow, R., Navarro, G.: Faster compact top-k document retrieval. In: Proc. DCC,

pp. 351–360 (2013)

8. Kosaraju, R., Manzini, G.: Compression of low entropy strings with Lempel-Ziv

algorithms. SIAM J. Comp. 29(3), 893–911 (1999)

9. Munro, I.: Tables. In: Proc. FSTTCS, pp. 37–42 (1996)

10. Navarro, G.: Indexing text using the Ziv-Lempel trie. J. Discr. Alg. 2(1), 87–114

(2004)

11. Navarro, G.: Spaces, trees and colors: The algorithmic landscape of document retrieval 
on sequences. ACM Comp. Surv. 46(4), article 52 (2014)

12. Navarro, G., Nekrich, Y.: Top-k document retrieval in optimal time and linear

space. In: Proc. SODA, pp. 1066–1077 (2012)

13. Navarro, G., Valenzuela, D.: Space-eﬃcient top-k document retrieval. In: Klasing,

R. (ed.) SEA 2012. LNCS, vol. 7276, pp. 307–319. Springer, Heidelberg (2012)

14. Clarke, C., B¨uttcher, S., Cormack, G.: Information Retrieval: Implementing and

Evaluating Search Engines. MIT Press (2010)

15. Szpankowski, W.: A generalized suﬃx tree and its (un)expected asymptotic behaviors.
 SIAM J. Comp. 22(6), 1176–1198 (1993)

16. Ziv, J., Lempel, A.: Compression of individual sequences via variable-rate coding.

IEEE Trans. Inf. Theor. 24(5), 530–536 (1978)

