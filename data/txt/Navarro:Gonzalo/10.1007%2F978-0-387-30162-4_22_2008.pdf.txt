46 A

Approximate Dictionary Matching

Approximate Dictionary Matching
(cid:2) Dictionary Matching and Indexing (Exact and with

Errors)

Approximate Maximum
Flow Construction
(cid:2) Randomized Parallel Approximations to Max Flow

Approximate Membership
(cid:2) Approximate Dictionaries

Approximate Nash Equilibrium
(cid:2) Non-approximability of Bimatrix Nash Equilibria

Approximate Periodicities
(cid:2) Approximate Tandem Repeats

Approximate Regular
Expression Matching
1995; Wu, Manber, Myers

GONZALO NAVARRO
Department of Computer Science, University of Chile,
Santiago, Chile

Keywords and Synonyms
Regular expression matching allowing errors or diﬀerences


Problem Definition
Given a text string T = t1t2 : : : tn and a regular expression 
R of length m denoting language L(R), over an alphabet 
˙ of size (cid:3), and given a distance function among
strings d and a threshold k, the approximate regular expression 
matching (AREM) problem is to ﬁnd all the text
positions that ﬁnish a so-called approximate occurrence of
R in T, that is, compute the set fj;9i; 1  i  j;9P 2
L(R); d(P; ti : : : t j)  kg. T, R, and k are given together,
whereas the algorithm can be tailored for a speciﬁc d.

This entry focuses on the so-called weighted edit distance,
 which is the minimum sum of weights of a sequence 
of operations converting one string into the other.
The operations are insertions, deletions, and substitutions
of characters. The weights are positive real values associated 
to each operation and characters involved. The
weight of deleting a character c is written w(c ! (cid:2)), that
of inserting c is written w((cid:2) ! c), and that of substituting 
c by c0 6= c is written w(c ! c0). It is assumed
w(c ! c) = 0 for all c 2 ˙ [ (cid:2) and the triangle inequality,
 that is, w(x ! y) + w(y ! z) (cid:6) w(x ! z) for any
x; y; z 2 ˙ [ f(cid:2)g. As the distance may be asymmetric, it is
also ﬁxed that that d(A; B) is the cost of converting A into
B. For simplicity and practicality m = o(n) is assumed in
this entry.

Key Results
The most versatile solution to the problem [3] is based on
a graph model of the distance computation process. Assume 
the regular expression R is converted into a nondeterministic 
ﬁnite automaton (NFA) with O(m) states and
transitions using Thompson’s method [8]. Take this automaton 
as a directed graph G(V ; E) where edges are labeled 
by elements in ˙ [ f(cid:2)g. A directed and weighted
graph G is built to solve the AREM problem. G is formed
by putting n + 1 copies of G; G0; G1; : : : ; Gn, and connecting 
them with weights so that the distance computation
reduces to ﬁnding shortest paths in G.
More formally, the nodes of G are fvi ; v 2 V ; 0  i 
ng, so that vi is the copy of node v 2 V in graph Gi. For
each edge u c! v in E, c 2 ˙ [ f(cid:2)g, the following edges are
added to graph G:

with weight w(c ! (cid:2)) ;

ui ! vi ;
ui ! ui+1 ; with weight w((cid:2) ! ti+1) ;
ui ! vi+1 ; with weight w(c ! ti+1) ;

0  i  n ;
0  i < n ;
0  i < n :

Assume for simplicity that G has initial state s and a unique
ﬁnal state f (this can always be arranged). As deﬁned, the
shortest path in G from s0 to f n gives the smallest distance
between T and a string in L(R). In order to adapt the graph
to the AREM problem, the weights of the edges between si
and si+1 are modiﬁed to be zero.
Then, the AREM problem is reduced to computing
shortest paths. It is not hard to see that G can be topologically 
sorted so that all the paths to nodes in Gi are computed 
before all those to Gi+1. This way, it is not hard to
solve this shortest path problem in O(mn log m) time and
O(m) space. Actually, if one restricts the problem to the
particular case of network expressions, which are regular

Approximate Regular Expression Matching

A 47

expressions without Kleene closure, then G has no loops
and the shortest path computation can be done in O(mn)
time, and even better on average [2].

The most delicate part in achieving O(mn) time for
general regular expressions [3] is to prove that, given the
types of loops that arise in the NFAs of regular expressions,
it is possible to compute the distances correctly within
each Gi by (a) computing them in a topological order of Gi
without considering the back edges introduced by Kleene
closures; (b) updating path costs by using the back edges
once; (c) updating path costs once more in topological order 
ignoring back edges again.
Theorem 1 (Myers and Miller 1989 [3]) There exists an
O(mn) worst-case time solution to the AREM problem under 
weighted edit distance.
It is possible to do better when the weights are integervalued,
 by exploiting the unit-cost RAM model through
a four-Russian technique [10]. The idea is as follows. Take
a small subexpression of R, which produces an NFA that
will translate into a small subgraph of each Gi. At the time
of propagating path costs within this automaton, there will
be a counter associated to each node (telling the current
shortest path from s0). This counter can be reduced to
a number in [0; k + 1], where k + 1 means “more than k”.
If the small NFA has r states, rdlog2(k + 2)e bits are needed
to fully describe the counters of the corresponding subgraph 
of Gi. Moreover, given an initial set of values for the
counters, it is possible to precompute all the propagation
that will occur within the same subgraph of Gi, in a table
having 2rdlog2(k+2)e entries, one per possible conﬁguration
of counters. It is suﬃcient that r < ˛ logk+2 n for some
˛ < 1 to make the construction and storage cost of those
tables o(n). With the help of those tables, all the propagation 
within the subgraph can be carried out in constant
time. Similarly, the propagation of costs to the same subgraph 
at Gi+1 can also be precomputed in tables, as it depends 
only on the current counters in Gi and on text character 
ti+1, for which there are only (cid:3) alternatives.

Now, take all the subtrees of R of maximum size
not exceeding r and preprocess them with the technique
above. Convert each such subtree into a leaf in R labeled
by a special character aA, associated to the corresponding
small NFA A. Unless there are consecutive Kleene closures
in R, which can be simpliﬁed as R(cid:4)(cid:4) = R(cid:4), the size of R after 
this transformation is O(m/r). Call R0 the transformed
regular expression. One essentially applies the technique
of Theorem 1 to R0, taking care of how to deal with the
special leaves that correspond to small NFAs. Those leaves
are converted by Thompson’s construction into two nodes
linked by an edge labeled aA. When the path cost propagation 
process reaches the source node of an edge labeled
aA with cost c, one must update the counter of the initial
state of NFA A to c (or k + 1 if c > k). One then uses the
four-Russians table to do all the cost propagation within
A in constant time, and ﬁnally obtain, at the counter of
the ﬁnal state of A, the new value for the target node of
the edge labeled aA in the top-level NFA. Therefore, all the
edges (normal and special) of the top-level NFA can be traversed 
in constant time, so the costs at Gi can be obtained
in O(mn/r) time using Theorem 1. Now one propagates
the costs to Gi+1, using the four-Russians tables to obtain
the current counter values of each subgraph A in Gi+1.
Theorem 2 (Wu et al. 1995 [10]) There exists an
O(n + mn/ logk+2 n) worst-case time solution to the AREM
problem under weighted edit distance if the weights are integer 
numbers.

Applications
The problem has applications in computational biology,
to ﬁnd certain types of motifs in DNA and protein sequences.
 See [1] for a more detailed discussion. In particular,
 PROSITE patterns are limited regular expressions
rather popular to search protein sequences. PROSITE patterns 
can be searched for with faster algorithms in practice 
[7]. The same occurs with other classes of complex
patterns [6] and network expressions [2].

Open Problems
The worst-case complexity of the AREM problem is not
fully understood. It is of course ˝(n), which has been
achieved for m log(k + 2) = O(log n), but it is not known
how much can this be improved.

Experimental Results
Some recent experiments are reported in [5]. For small
m and k, and assuming all the weights are 1 (except
w(c ! c) = 0), bit-parallel algorithms of worst-case complexity 
O(kn(m/ log n)2) [4,9] are the fastest (the second
is able to skip some text characters, depending on R). For
arbitrary integer weights, the best choice is a more complex 
bit-parallel algorithm [5]; or the four-Russians based
one [10] for larger m and k. The original algorithm [3] is
slower but it is the only one supporting arbitrary weights.

URL to Code
Well-known packages oﬀering eﬃcient AREM (for simpliﬁed 
weight choices) are agrep [9] (http://webglimpse.
net/download.html, top-level subdirectory agrep/) and

48 A

Approximate Repetitions

nrgrep [4] (http://www.dcc.uchile.cl/~gnavarro/software).
For biological applications, anrep [2] (http://www.cs.
arizona.edu/people/gene/CODE/anrep.tar.Z) matches sequences 
of approximate network expressions with arbitrary 
weights and a speciﬁed gap length between each network 
expression and the next.

Cross References
(cid:2) Regular Expression Matching is the simpliﬁed case
where exact matching with strings in L(R) is sought.

(cid:2) Sequential Approximate String Matching is

a simpliﬁcation of this problem, and the relation
between graph G here and matrix C there should be
apparent.

Recommended Reading
1. Gusfield, D.: Algorithms on strings, trees and sequences. Cambridge 
University Press, Cambridge (1997)

2. Myers, E.W.: Approximate matching of network expressions

with spacers. J. Comput. Biol. 3(1), 33–51 (1996)

3. Myers, E.W., Miller, W.: Approximate matching of regular expressions.
 Bullet. Math. Biol. 51, 7–37 (1989)

4. Navarro, G.: Nr-grep: a fast and flexible pattern matching tool.

Softw. Pr. Exp. 31, 1265–1312 (2001)

5. Navarro, G.: Approximate regular expression searching with arbitrary 
integer weights. Nord. J. Comput. 11(4), 356–373 (2004)
6. Navarro, G., Raffinot, M.: Flexible Pattern Matching in Strings
– Practical on-line search algorithms for texts and biological
sequences. Cambridge University Press, Cambridge (2002)

7. Navarro, G., Raffinot, M.: Fast and simple character classes and
bounded gaps pattern matching, with applications to protein
searching. J. Comput. Biol. 10(6), 903–923 (2003)

8. Thompson, K.: Regular expression search algorithm. Commun.

ACM 11(6), 419–422 (1968)

9. Wu, S., Manber, U.: Fast text searching allowing errors. Commun.
 ACM 35(10), 83–91 (1992)

10. Wu, S., Manber, U., Myers, E.W.: A subquadratic algorithm for
approximate regular expression matching. J. Algorithms 19(3),
346–360 (1995)

Approximate Repetitions
(cid:2) Approximate Tandem Repeats

Approximate Tandem Repeats
2001; Landau, Schmidt, Sokol
2003; Kolpakov, Kucherov
GREGORY KUCHEROV1, DINA SOKOL2
1 LIFL and INRIA, Villeneuve d’Ascq, France
2 Department of Computer and Information Science,

Brooklyn College of CUNY, Brooklyn, NY, USA

Keywords and Synonyms
Approximate repetitions; Approximate periodicities

Problem Definition
Identiﬁcation of periodic structures in words (variants
of which are known as tandem repeats, repetitions, powers 
or runs) is a fundamental algorithmic task (see entry
(cid:2) Squares and Repetitions). In many practical applications,
 such as DNA sequence analysis, considered repetitions 
admit a certain variation between copies of the repeated 
pattern. In other words, repetitions under interest
are approximate tandem repeats and not necessarily exact
repeats only.

The simplest instance of an approximate tandem repeat 
is an approximate square. An approximate square
in a word w is a subword uv, where u and v are within
a given distance k according to some distance measure
between words, such as Hamming distance or edit (also
called Levenstein) distance. There are several ways to deﬁne 
approximate tandem repeats as successions of approximate 
squares, i. e. to generalize to the approximate case
the notion of arbitrary periodicity (see entry (cid:2) Squares
and Repetitions). In this entry, we discuss three diﬀerent
deﬁnitions of approximate tandem repeats. The ﬁrst two
are built upon the Hamming distance measure, and the
third one is built upon the edit distance.
Let h((cid:3);(cid:3)) denote the Hamming distance between two

words of equal length.

Deﬁnition 1 A word r[1::n] is called a K-repetition of period 
p, p  n/2, iﬀ h(r[1::n (cid:2) p]; r[p + 1::n])  K.
Equivalently, a word r[1::n] is a K-repetition of period 
p, if the number of mismatches, i. e. the number
of i such that r[i] ¤ r[i + p],
is at most K. For example,
 ataa atta ctta ct is a 2-repetition of period 4.
atc atc atc atg atg atg atg atg is a 1-repetition of period
3 but atc atc atc att atc atc atc att is not.

Deﬁnition 2 A word r[1::n] is called a K-run, of period 
p, p  n/2, iﬀ for every i 2 [1::n (cid:2) 2p + 1], we have
h(r[i::i + p (cid:2) 1]; r[i + p; i + 2p (cid:2) 1])  K.
A K-run can be seen as a sequence of approximate squares
uv such that juj = jvj = p and u and v diﬀer by at most K
mismatches. The total number of mismatches in a K-run
is not bounded.
Let ed((cid:3);(cid:3)) denote the edit distance between two

strings.

Deﬁnition 3 A word r is a K-edit repeat if it can be partitioned 
into consecutive subwords, r = v0w1w2 : : : w`v00,

