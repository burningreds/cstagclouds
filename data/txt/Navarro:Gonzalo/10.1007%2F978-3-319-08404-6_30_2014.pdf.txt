Ranked Document Selection(cid:2)

J. Ian Munro1, Gonzalo Navarro2, Rahul Shah3, and Sharma V. Thankachan1

1 Cheriton School of CS, Univ. Waterloo, Canada

{imunro,thanks}@uwaterloo.ca
2 Dept. of CS, Univ. Chile, Chile

gnavarro@dcc.uchile.cl

3 School of EECS, Louisiana State Univ., USA

rahul@csc.lsu.edu

Abstract. Let D be a collection of string documents of n characters in
total. The top-k document retrieval problem is to preprocess D into a
data structure that, given a query (P, k), can return the k documents
of D most relevant to pattern P . The relevance of a document d for a
pattern P is given by a predeﬁned ranking function w(P, d). Linear space
and optimal query time solutions already exist for this problem.

In this paper we consider a novel problem, document selection queries,
which aim to report the kth document most relevant to P (instead
of reporting all top-k documents). We present a data structure using
O(n log n) space, for any constant  > 0, answering selection queries
in time O(log k/ log log n), and a linear-space data structure answering
queries in time O(log k), given the locus node of P in a (generalized)
suﬃx tree of D. We also prove that it is unlikely that a succinct-space
solution for this problem exists with poly-logarithmic query time.

1

Introduction and Related Work

i=1

(cid:2)D

Document retrieval is a special branch of pattern matching related to information
retrieval and web searching. In this problem, the data consists of a collection of
text documents, and the queries refer to documents rather than text positions
[12]. In this paper we focus on arguably the most important of those problems,
called top-k document retrieval : Given D = {d1, d2, d3, ..., dD}, of total length
|di|, preprocess it into a data structure that, given a pattern P and a
n =
threshold k, retrieves the k documents from D that are more most relevant to P ,
in decreasing order of relevance. The relevance of a document d with respect to P
is captured using any function w(P, d) of the starting positions of the occurrences
of P in d. A popular example of relevance is the term frequency metric, that is,
the number of occurrences of P in d. This a well studied problem, and the best
known linear space data structure can answer queries in optimal time O(k) [17],
once the locus node of P in a generalized suﬃx tree of D is found.
(cid:3) Funded in part by NSERC of Canada and the Canada Research Chairs program,

Fondecyt Grant 1-140796, Chile, and NSF Grants CCF–1017623, CCF–1218904.

R Ravi and I.L. Gørtz (Eds.): SWAT 2014, LNCS 8503, pp. 344–356, 2014.
c(cid:2) Springer International Publishing Switzerland 2014

Ranked Document Selection

345

In this paper we study a new related problem called document selection, where
we must return the kth document of D most relevant to P , that is, the kth
element returned by a top-k query (breaking ties arbitrarily).

We present three results, depending on the amount of space used: (1) We give
 n) space, for any constant  > 0, and answers
a data structure that uses O(n log
queries in time O(log k/ log log n). (2) We give a linear-space data structure that
answers queries in O(log k) time. (3) We prove that it is highly unlikely that the
problem can be solved in less than linear space within poly-logarithmic time, via
a reduction from the position restricted substring searching problem [9,5].

Document selection is useful for various advanced queries. When a user browses
ranked results of a query and asks for the next set of results, we need to report
the top-k2 documents that are not top-k1. Instead of computing a top-k2 query
in time O(k2), which is nonoptimal if k2 − k1 = o(k2), our results allow solving
this query in O((k2 − k1) log k2) time and linear space. Another possible query
is to count the number K of documents d with w(P, d) ≥ τ , given P and τ .
This can be answered via doubling search using document selection queries, in
time O(log2 K), assuming w(P, d) can be computed in constant time given the
locus of P . Similarly, we can count or list the documents d with w(P, d) ∈ [τ1, τ2].

Such queries are important in bioinformatics, for example for motif mining or for
avoiding sequences where P is “over-expressed”, and for data mining in general,
for example to estimate the distribution of relevance scores of certain patterns.

Related Work. The notion of relevance-based string retrieval was introduced by
Muthukrishnan [11], who proposed and solved various problem but not top-k
document retrieval. The ﬁrst data structure for this problem, under the term
frequency measure and using O(n log n) words of space, was given by Hon et
al. [4]. Later, Hon et al. [7] introduced a linear space structure (O(n) words),
that works for general weight functions as described earlier, with query time
O(p + k log k). This was improved to O(p + k) [13], and ﬁnally to the optimal
O(k) [17], all using linear space. Those times are in addition to the time for
ﬁnding the locus node of P , locus(P ), in the generalized suﬃx tree of D, GST.
The problem has also been studied in scenarios where less than linear space
(i.e., o(n log n) bits) can be used. For example, it is possible to solve the problem
eﬃciently using n log σ + o(n log σ) bits [14,18], where σ is the alphabet size of
the text (thus n log σ bits are used to represent the text itself). The results are
mostly tailored to the term frequency measure of relevance, and achieve times
of the form O(k polylog n). See [12,3,6] for more details.

2 The Top-k Framework

This section brieﬂy describes the linear-space framework of Hon et al. [7] for
top-k queries. The generalized suﬃx tree (GST) of a document collection D =
{d1, d2, d3, . . . , dD} is the combined compact trie of all the non-empty suﬃxes of
all the documents [19]. The total number of leaves in GST is same as the total
length n of all the documents. For each node j in GST, pref ix(j) is the string

346

J.I. Munro et al.

obtained by concatenating the edge labels on the path from the root to node j.
The highest node v satisfying that P is a preﬁx of pref ix(v) is called the locus
of P and denoted locus(P ) = v.

Let (cid:5)i represent the ith leftmost leaf node in GST. We say that a node is
marked with a document d if it is either a leaf node whose corresponding suﬃx
belongs to d, or it is the lowest common ancestor (LCA) of two such leaves. This
implies that the number of nodes marked with document d is exactly equal to the
number of nodes in the suﬃx tree of d (at most 2|d|). A node can be marked with
multiple documents. For each node j and each of its marking documents d, deﬁne
a link to be a quadruple (origin = j, target, doc = d, weight = w(pref ix(j), d)),
where target is the lowest proper ancestor of node j marked with d (a dummy
parent of the root node is added, marked with all the documents). Since the
number of links with document doc = d is at most 2|d|, the total number of links
is ≤ (cid:2)D
i=1 2|di| ≤ 2n. The following is a crucial observation by Hon et al. [7].

Lemma 1. For each document d that contains a pattern P , there is a unique
link with origin in the subtree of locus(P ), a proper ancestor of locus(P ) as its
target, and weight w(P, d).

We say that a link is stabbed by a node j if its origin is in the subtree of j (j
itself included) and its target is a proper ancestor of j. Therefore, the problem
of ﬁnding the kth most relevant document for P can be reduced to ﬁnding the
kth highest weighted link stabbed by locus(P ).

3 Super-Linear Space Structure

In this section we start by introducing a basic data structure that uses O(n log n)
words and answers queries in O(log n) time. Then we enhance it to a structure
that uses O(n log1+ n) words, for any constant  > 0, and O(log n/ log log n)
time. The basic structure will be used in Section 4 to achieve linear space within
 n) words. In
the same time, whereas the enhanced one will be reduced to O(n log
Section 5 we show how how the linear-space structure can be improved to answer
queries in time O(log k) and the enhanced structure in time O(log k/ log log n),
thus reaching our ﬁnal results.

3.1 The Basic Structure

We prove the following result.

Lemma 2. Given the GST of a text collection of total length n, we can build
an O(n log n)-word structure that, given locus(P ) and k, answers the document
selection query in time O(log n).

Let N represent the set of nodes in GST and S represent the set of links
(origin, target, doc, weight) in GST, as described in Section 2. Next we construct
a balanced binary tree T of |S| leaves, so that the ith highest weighted link (ties

Ranked Document Selection

347

broken arbitrarily) is associated with the ith leftmost leaf of T . Notice that
n ≤ |S| ≤ 2n. We use S(x) to denote the set of links associated with the leaves
in the subtree of node x ∈ T . Further, let N (x) denote the set of nodes in GST
that are (i) either the origin or the target of a link in S(x), or (ii) the LCA of
two such nodes. Clearly |N (x)| = Θ(|S(x)|) = Θ(n/2depth(x)), where depth(x) is
the number of ancestors of x (depth of root is 0).
With every node x ∈ T , we associate a tree structure GST(x). GST(x) is the
subtree of GST obtained by retaining only the nodes in N (x), so that node v
is the parent of node w in GST(x) iﬀ v is the lowest proper ancestor of w in
GST that also belongs to N (x). The number of nodes and edges in GST(x) is
Θ(n/2depth(x)).
Notice that the same node w ∈ GST may appear in several GST(·)’s. With
each node w ∈ GST(x) we associate the following information:

– stab.countx(w): The number of links in S(x) that are stabbed by w.
– left.ptrx(w): Let xL be the left child of x (in T ). Let wL be the highest node
in the subtree of w (in GST(x)) that appears also in GST(xL) (wL can be w
itself). Then left.ptrx(w) is a pointer from w ∈ GST(x) to wL ∈ GST(xL). If
there exists no such node wL, then left.ptrx(w) is null.
– right.ptrx(w): Analogous to left.ptrx(w), now considering xR, the right child
of x ∈ T , and wR being the highest node in the subtree of w ∈ GST(x) that
appears also in GST(xR).

Note that the space needed for maintaining GST(x) and the associated information 
is O(n/2depth(x)) words. Added over all the nodes x ∈ T , the total
space occupancy of all GST(·)’s is O(n log n) words. Finally, the following result
is crucial for our data structure (the case of wR and xR is analogous).

Lemma 3. Both w and wL stab the same subset of links of S(xL).

Proof. Otherwise, the target of a link in S(xL) stabbing wL but not w would be
higher than wL, below w, and belong to GST(xL), contradicting the deﬁnition
of wL. The same happens with the source of a link stabbing w but not wL. (cid:5)(cid:6)

3.2 Query Algorithm for Document Selection

Assume locus(P ) is given. Notice that the tree GST(root) associated with the
root of T is the same GST of the collection. Therefore, stab.count root(locus(P ))
gives the number of documents containing P . If the count is less than k, there
be the kth highest weighted link
is no kth document to select. Otherwise, let L
stabbed by locus(P ). Our query algorithm traverses T top-down, starting from
root and ending at the leaf node associated with link L
. Then it reports the
∗
document d
In our query algorithm, we use x to denote a node in T , w to denote a node
in GST(x) and K to denote an integer ≤ k. First we initialize x to the root
of T , w to locus(P ) and K to k. This establishes the invariant that we have
to return the Kth highest weighted link in S(x) stabbed by w. Let xL and xR

corresponding to L

∗

∗

∗

.

348

J.I. Munro et al.

be the left and right children of x. Then we obtain the nodes wL ∈ GST(xL)
and wR ∈ GST(xR) pointed by left.ptrx(w) and right.ptrx(w), respectively. The
following values are then computed in constant time.

– c = stab.countx(w), the number of links in S(x) stabbed by w.
– cL = stab.countxL(wL), the number of links in S(xL) stabbed by w (or wL).
– cR = stab.countxR(wR), the number of links in S(xR) stabbed by w (or wR).
Notice that c = cL + cR. If cL ≥ K then, by Lemma 3, the Kth link below
S(x) (or S(xL)) stabbed by w ∈ GST(x) is the same as the Kth link below S(xL)
stabbed by wL ∈ GST(xL). Therefore, we maintain the invariant if we continue
the traversal in the subtree of x ← xL with GST(xL) node w ← wL. On the
other hand, if cL < K, then by Lemma 3 the Kth link stabbed by w below S(x)
is same as the (K − cL)th link below S(xR) stabbed by wR ∈ GST(xR). In this
case, we maintain the invariant if we continue the traversal in the subtree of
x ← xR with GST(xR) node w ← wR and with K ← K − cL. We terminate the
. As the height of T
algorithm when x is a leaf, thus K = 1 and x represents L
is O(log n) and the time spent at each node is constant, the total query time is
O(log n) and Lemma 2 is proved.

∗

3.3 An Enhanced Structure

We now prove the following result, which will hold in the RAM model of computation,
 with a computer word of w = Ω(log n) bits.

Lemma 4. Given the GST of a text collection of total length n and any constant
0 <  ≤ 1, we can build an O(n log1+ n)-word structure that, given locus(P )
and k, answers the document selection query in time O(log n/ log log n).

) = depth(x) + s, instead of just to xL or xR.

(cid:4) ∈ T as above (x
(cid:4)

(cid:4)
at depth depth(x
Given x, x

In order to speed up the structure of Lemma 2, we will choose a step s =
 log log n and build the GST(x) structures only for nodes x ∈ T whose depth is a
multiple of s. Each node w ∈ GST(x) for the selected nodes x will store suﬃcient
information for the query algorithm to jump directly to the corresponding node
(cid:4)
x
in the subtree of x) and w ∈ GST(x), we deﬁne
(cid:4)
wx(cid:2) as the highest node in the subtree of w that appears also in GST(x
). Let us
call x1, x2, . . . , x2s the nodes at depth depth(x) + s that descend from x (or the
leaves below x, if they have depth less than depth(x) + s), ordered left to right
in T (i.e., from highest to lowest weights in S(xi)).
Associated to each node w ∈ GST(x), we store 2s pointers ptr x(w)[i] = wxi .
We also store the 2s cumulative values accx(w)[i] =
j=1 stab.count xj (wxj );
note that accx(w)[2s] = stab.count x(w). We will store those accx(w) values
 n) words of space and solves
in a fusion tree [1], which takes O(2s) = O(log
predecessor queries in accx(w) in constant time. The space is the same used by
array ptr x(w), which added over all the GST(·)’s is O(n log1+ n) words (even if
only one level out of s in T stores GST(·) structures).

(cid:2)i

Ranked Document Selection

349

Queries now proceed as in Section 3.2, but now we use the fusion tree to
determine, given w ∈ GST(x), which is the node xi ∈ T that contains the Kth
link below S(x) stabbed by w. Therefore we can move directly from x to xi
and from w ∈ GST(x) to wi ∈ GST(xi), where wi = ptr x(w)[i]. We also update
K ← K−accx(w)[i−1] (assume accx(w)[0] = 0). Thus we complete the query in
O((log n)/s) = O(log n/( log log n)) constant-time steps and Lemma 4 is proved.

4 Linear Space Structure

In this section we build on the basic structure of Lemma 2 in order to achieve
linear space and logarithmic query time. At the end, we reduce the space of the
enhanced structure to O(n log

 n). The results hold under the RAM model.

Lemma 5. Given the GST of a text collection of total length n, we can build an
O(n)-word structure that, given locus(P ) and k, answers the document selection
query in time O(log n).

To achieve linear space, we replace some of our data structures by succinct
ones. We will measure the space in bits, aiming at using O(n log n) bits overall.
The binary tree T can be maintained in O(n log n) bits, where each internal node
x stores an O(log n)-bit pointer to the corresponding tree GST(x) and each leaf
stores the document identiﬁer corresponding to the associated link. The global
GST can also be maintained in O(n log n) bits. Therefore, the space-consuming
component are the GST(·)’s and their associated information.

Using well-known succinct data structures [16], the GST(x) tree topologies can
be represented in O(1) bits per node (i.e., O(n log n) bits overall) with constanttime 
support of all the basic navigational operations required in our algorithm.
We refer to any node w ∈ GST(x) by its pre-order rank, that is, node j means
the node with pre-order rank j. The pre-order rank of the root node of any
GST(x) is 1. Next we show how to encode the remaining information associated
with each node in GST(x) using O(1) bits per node.

4.1 Encoding stab.countx(j)

We note that stab.countx(j) is exactly equal to the number of links of S(x) associated 
with GST(x) that originate in the subtree of j minus the number of
links in S(x) that target any node in the subtree of j (j belongs to its sub-
tree). We encode this information in two bit vectors: Bx = 10α110α210α3 . . .
(cid:4)
x = 10β110β210β3 . . ., where αj (resp., βj) is the number of links of S(x)
and B
(cid:4)
originating from (resp., targeting at) node j in GST(x). We augment Bx and B
x
with structures supporting constant-time rank/select queries [10]. Notice that
(cid:2)
(cid:4)
x can be

βj = O(|S(x)|) = O(|GST(x)|). Therefore, both Bx and B

(cid:2)

αj =

represented in O(1) bits per node.

Now we can compute stab.countx(j) for any j in O(1) time as follows: ﬁnd the
rightmost leaf node j
in the subtree of j in O(1) time using the succinct tree
representation of GST(x) [16]. Then the number no of links originating from the

(cid:4)

350

J.I. Munro et al.

(cid:4)

subtree of j is equal to the number of 0-bits between the jth and (j
+ 1)th 1-bit
in Bx (because j and j
are preorder numbers). Similarly, the number nt of links
targeted at any node in the subtree of j is equal to the number of 0-bits between
(cid:4)
(cid:4)
x. Using rank/select operations on Bx and B
the jth and (j
x,
no and nt are computed in O(1) time and stab.countx(j) is given by no − nt.

+ 1)th 1-bits in B

(cid:4)

(cid:4)

4.2 Encoding left.ptrx(j) and right.ptrx(j)
We show how to encode left.ptr x(·) for all nodes in GST(x); right.ptrx(j) is symmetric.
 The idea is to maintain a bit vector LP such that LP [j] = 1 iﬀ there
exists a node jL ∈ GST(xL) such that both j ∈ GST(x) and jL ∈ GST(xL)
represent the same node in GST. We add constant-time rank/select data structures 
[10] on LP . Since the length of LP is equal to the number of nodes in
GST(x), its space occupancy is O(1) bits per node.
Now, for any given node j ∈ GST(x), the node jL ∈ GST(xL) to which
left.ptrx(j) points is the (unique) highest descendant of j that is marked in LP ,
thus it can be identiﬁed by (1) ﬁnding the position j
of the leftmost 1-bit in
is in the subtree of node j in GST(x); (3) if
LP [j . . .]; (2) checking if node j
so, then jL ∈ GST(xL) is equal to the number of 1’s in LP [1...j
], otherwise, jL
is null. All these operations require constant time, either using the succinct tree
operations or the rank/select data structures. This works because all the nodes
in GST(xL) appear in GST(x), in the same order (pre-order).

∗

∗

∗

In summary, the space requirement of our encoding scheme is O(1) bits per
node in any GST(x), thus adding to O(n log n) bits. The query algorithm, as well
as its time complexity, remain the same. This completes the proof of Lemma 5.

4.3 Reducing Space of the Enhanced Structure

The space of the enhanced structure of Section 3.3 can be similarly reduced to
O(n log

 n) words, obtaining the following result.

Lemma 6. Given the GST of a text collection of total length n and a constant
n)-word structure that, given locus(P ) and k,
 > 0, we can build an O(n log
answers the document selection query in time O(log n/ log log n).



For this sake, recalling the deﬁnition of x1, . . . , x2s of Section 3.3, we will
maintain bit vectors LPi for i = 1 to 2s, so that LPi[j] = 1 iﬀ there exists a
node ji ∈ GST(xi) such that both j ∈ GST(x) and ji ∈ GST(xi) represent the
same node in GST. Then each array entry ptr x(j)[i] is computed using LPi as in
 n)
Section 4.2. The total space used by all the LPi bit vectors is O(2s) = O(log
bits per node, adding up to O(n log1+ n) bits in total.
(cid:4)
x,2s,
analogous to B and B
3 . . ., so
that αi
r=1 s(r), where s(r) is the number of links of S(xr) originating from
node ptr x(j)[i] ∈ GST(xr), and B
r=1 t(r),
where t(r) is the number of links of S(xr) targeting at node ptr x(j)[i] ∈ GST(xr).

To compute accx(j)[i], we store bitmaps Bx,1, . . . , Bx,2s and B

of Section 4.1. In this case, Bx,i = 10αi

(cid:4)
x,1, . . . , B
110αi
210αi

3 . . ., so that βi

(cid:4)
x,i = 10βi

110βi

210βi

(cid:2)i

j =

(cid:4)

(cid:2)i

j =

Ranked Document Selection

351

Then, it holds accx(j)[i] = αi
rank/select operations. Since it holds αi
total space of these 2s = log

j − βi

j, which is computed in constant time using
j ≤ βj for all i values, the

j ≤ αj and βi

 n bitmaps adds up to O(n log1+ n) bits.

To carry out predecessor searches on the virtual vector accx(j), we use succinct 
SB-trees [2, Lemma 3.3]. Given constant-time access to any accx(j)[i], this
structure provides predecessor searches in O(1 + log(2s)/ log log n) = O(1) time
and use O(2s log log n) = O(log
n) bits per node (by adjusting ). Thus the total
space is O(n log1+ n) bits as well. This concludes the proof of Lemma 6.



5 Achieving O(log k) Query Time and Better

In this section we ﬁrst build on the linear-space data structure of Lemma 5 in
order to improve its query time to O(log k). At the end, we show that the result
extends to our superlinear-space data structure of Lemma 6, improving its query
time to O(log k/ log log n). Thus we start by proving the following theorem.
Theorem 1. A collection D of documents can be preprocessed into a linearspace 
data structure that can answer any document selection query (P, k) in
time O(log k), given the locus of pattern P in the generalized suﬃx tree of D.

n. Therefore, we turn our attention to the case where k ≤ √
√
Notice that the query time O(log n) in Lemma 5 can be written as O(log k) for
n. First, we
k >
derive a space-eﬃcient structure DS(δ), which can answer document selection
n.

queries faster, but only for values of k below a predeﬁned parameter δ ≤ √

More precisely, structure DS(δ) will satisfy the following properties:

Lemma 7. The structure DS(δ) uses O(n(log δ + log log n)) bits of space and
can answer document selection queries in time O(log δ + log log n), for k ≤ δ ≤
√
n.

(cid:9)n1/2i(cid:10) for i = 1, 2, 3, . . . , r, where δr+1 ≤ √

To obtain the result in Theorem 1, we maintain structures DS(δi) with δi =
log n < δr (therefore r < log log n).
The total space needed is O(n
i=1(log δi + log log n)) = O(n log n) bits (O(n)
words). When k comes as a query, if k > δr+1, we ﬁrst ﬁnd h, where δh+1 <
k ≤ δh and obtain the answer using DS(δh). The resulting time is O(log δh +
log log n) = O(log k). The case where k < δr+1 is handled separately using other
structures in O(1) time (Section 5.2). We now describe the details of DS(δ).

(cid:2)r

5.1 Structure DS(δ)

The ﬁrst step is to identify certain nodes in GST as marked nodes and prime
nodes, based on a parameter g = (cid:9)δ log n(cid:10) called the grouping factor. Every gth
leftmost leaf is marked, and the LCA of every two consecutive marked leaves
is also marked. Therefore, the number of marked nodes is Θ(n/g). Nodes with
their parent marked are prime. A prime node with at least one marked node in
its subtree is a type-1 prime node, otherwise it is a type-2 prime node. Notice

352

J.I. Munro et al.

(cid:4)

(cid:4)

(cid:4)

∗

∗

that the highest marked node in the subtree of any node is unique, if it exists.
Therefore, except the root node, every marked node j
can be associated with
a unique type-1 prime node j
, which is the ﬁrst prime node on the path from
∗
j

to the root. Notice that a node can be both prime and marked.
Let j

be the highest marked node in its subtree (j

be a prime node and j

(cid:4)\j
). We use G(j
∗
(j
after removing the subtree of j
(cid:4)\j

) to
∗
is
) to represent the
) as well. A crucial result [17] is that, for any prime

is of type-1, and it can be that j

exists only if j
represent the subtree of GST rooted at j
not removed). With a slight abuse of notation, we use G(j
set of nodes within G(j
node j
) is O(g).
on the path from j to the root. Note that j ∈ G(j
(cid:4)
(strict) descendant of j
and its corresponding j

, the number of nodes in G(j

We deﬁne prime.parent(j) of any node j in GST as the ﬁrst prime node j
), otherwise j would be a

∗

(cid:4)\j
would be below j

(cid:4)\j

(cid:4)\j

= j

∗

∗

∗

∗

∗

∗

∗

∗

(cid:4)

(cid:4)

(cid:4)

(cid:4)

It is not hard to determine j

= prime.parent (j) in constant time and O(n)
bits, by sampling the prime nodes in a succinct tree representation and looking
for the lowest sampled ancestor of j [15, Lemma 4.4].

(cid:4)
The structure DS(δ) is a collection of substructures ST R(j
in GST. If the input node locus(P ) ∈ G(j
(cid:4)

every prime node j
we obtain the answer using ST R(j
Based on the type of j

) associated with
(cid:4)\j
) and k ≤ δ,
) in O(log g) = O(log δ + log log n) time.

, we have two cases; we describe the simpler one ﬁrst.

∗

(cid:4)

(cid:4)

(cid:4)

.

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

), the subtree rooted at node j

) Associated with a Type-2 Prime Node j(cid:2)

)|]. Notice that the number of links chosen is O(|G(j

ST R(j(cid:2)
: The structure can be
constructed as follows: take G(j
, and replace the
pre-order rank of each node j by (j−j
+1). Also associate a dummy parent node
to the root. Then, among the links deﬁned over GST (Section 2), choose those
(cid:4)
that originate from the subtree of j
and: (1) Assign a new value to its origin and
target, which is its original value minus j
plus 1. The target of some links can
be negative; replace those by 0. (2) Replace the weight by a rank-space reduced
)|). (3)
value in [1, O|G(j
Let d be its document identiﬁer. Instead of writing d explicitly in (cid:9)log D(cid:10) bits,
)|(cid:10) bits, where the suﬃx
use a pointer to one leaf node in G(j
corresponding to that leaf belongs to document d.
)|) links asIn 
summary, we have a tree of (|G(j
sociated with it. The information (origin, target, document, weight) associated
with each link is encoded in O(log |G(j
) is the structure 
described in Lemma 5 over these nodes and links. The space required is
)| log g) bits. We maintain structures ST R(j
O(|G(j
(cid:4)
)
for all type-2 prime nodes j
in total O(n log g) bits, since a node can be in the
subtree of at most one type-2 prime node.

)| + 1) nodes and O(|G(j
)|) bits. Then ST R(j
(cid:4)
(cid:4)

), using (cid:9)log |G(j

)|) = O(|G(j

)| log |G(j

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

) Associated with a Type-1 Prime Node j(cid:2)

ST R(j(cid:2)
candidate set C(j
by any node j ∈ G(j
do not originate from the subtree of j
the following types [17]: near-links are stabbed by j

: We ﬁrst identify the
) of O(g) links, such that for any k ≤ δ, the kth link stabbed
). Clearly we can ignore the links that
. The links that do can be categorized into
; far-links

) belongs to C(j

, but not by j

(cid:4)\j

∗

∗

(cid:4)

(cid:4)

(cid:4)

Ranked Document Selection

353

∗

(cid:4)

; small-links are targeted at a node in the subtree

are stabbed by both j
of j

∗
; and fringe-links are the others.
We include all near-links and fringe-links into C(j

and j

(cid:4)

∗

(cid:4)\j

), which are O(g) in number 
[17, Lemma 8]. All small-links can be ignored as none of them is stabbed
by any node in G(j
) stabs a far-link, it
indeed stabs all far-links. Therefore, it is suﬃcient to insert the top-δ far-links
into C(j
(cid:4)\j
as well as of the information associated with the links in C(j

Now we perform a rank-space reduction of pre-order rank of nodes in G(j
), as follows:

). Thus, we have O(g) links in C(j

). Notice that if any node in G(j

) overall.

(cid:4)\j

∗

∗

)

(cid:4)

(cid:4)

(cid:4)

.

(cid:4)

(cid:4)

(cid:4)

∗

∗

∗

∗

∗

(cid:4)\j

(cid:4)\j

(cid:4)\j

– The target of those links targeting at any proper ancestor of j

is changed to
. Similarly, the origin of all those links originating

)| log |G(j

is changed to node j

– The pre-order rank of all those nodes in G(j

a dummy parent node of j
in the subtree of j
), and the corresponding
origin and target values of links in C(j
), are changed to a rank-space reduced
value in [0,|G(j
is 1 and
that of its dummy parent node is 0. We remark that this mapping (and
remapping) can be stored separately in O(|G(j

)|]. Notice that the new pre-order rank of j
(cid:4)\j
∗

)|) bits.
– The weights of the links are also replaced by rank-space reduced values.
– Let L be a nearor 
fringe-link in C(j

) with d its corresponding document.
Then there must be at least one leaf (cid:5) in G(j
) where the suﬃx corresponding 
to (cid:5) belongs to d. Therefore, instead of representing d, we maintain
a pointer to (cid:5), which takes only O(log g) bits. This trick will not work for
far-links, as the existence of such a leaf node is not guaranteed. Therefore,
we spend log D bits for each far-link, which is still aﬀordable because there
are only O(δ) = O(g/ log n) far-links.
In summary, we have a tree of (|G(j
(cid:4)\j

)| + 1) = O(g) nodes with O(g) links
associated with it. Then ST R(j
) is the structure described in Lemma 5 over
these nodes and links. The space required is O(g log g) bits. As the number of
type-1 prime nodes is O(n/g), the total space to maintain ST R(j
) for all type-2
primes nodes j

is O(n log g) bits.

(cid:4)\j

∗

∗

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

Query Answering: Given node j = locus(P ), we ﬁnd j
= prime.parent(j).
(cid:4)
Then we map node j to the corresponding node in ST R(j
) and obtain the
answer by querying ST R(j
), in O(log g) = O(log δ + log log n) time. The answer
), which is mapped back to GST in
may come in the form of a node in ST R(j
order to obtain the associated document. This completes the proof of Lemma 7.

(cid:4)

(cid:4)

(cid:4)

5.2

Structure for k ≤ δr+1

(cid:4)

, we explicitly maintain the candidate set C(j

First, identify the marked and prime nodes in GST with g = δr+1 log n. At every 
prime node j
). This takes
O(n)-word space. Then for any k ≤ δr+1, the kth link stabbed by node j can
be encoded as a pointer to the corresponding entry in C(prime.parent(j
)) using 
(cid:9)log |C(prime.parent(j
))|(cid:10) = O(log g) = O(log log n) bits. Therefore, the

(cid:4)

(cid:4)

(cid:4)

354

J.I. Munro et al.

answers for all k ∈ [1, δr+1] for all nodes in GST can be maintained in additional 
O(n · δr+1 log log n) = o(n log n) bits of space. Now the kth link (and
its document) stabbed by any query node locus(P ) can be obtained from
C(prime.parent(locus(P ))) in O(1) time.

5.3 Speeding Up the Enhanced Structure

(cid:4)

(cid:2)r

 n

(cid:4)

). The space of the form O(n log

The same construction used above can be used to speed up our superlinearspace 
structure of Lemma 6, simply by using it instead of the linear-space one of
 n)
Lemma 5 to implement the structures ST R(j
words, or O(n log1+ n) bits, will become O(g log g log
 n) inside the structures
), because we will maintain the sampling step s =  log log n dependST 
R(j
ing on n, not on g, and use the succinct SB-trees with parameter n, not g.
 n) bits, and
As a result, the total space per value of δ will be O(n log g log
i=1(log δi + log log n)) =
added over all the values of δ we will have O(n log
O(n log1+ n) bits, or O(n log
 n) words. The time, on the other hand, will be
O(1 + log δ/( log log n)) on DS(δ), which becomes O(1 + log k/( log log n)) in
terms of k. We have proved our ﬁnal result for the superlinear structure.
Theorem 2. A collection D of documents of total length n can be preprocessed
 n) words of space, for any constant  > 0,
into a data structure using O(n log
which can answer document selection queries (P, k) in time O(1+log k/ log log n),
given the locus of pattern P in the generalized suﬃx tree of D.

6 Hardness of an Eﬃcient Succinct Solution

One could expect to obtain an index using O(n log σ) bits of space, proportional
to the n log σ bits needed to store D, as achieved for the top-k document retrieval
problem. We show, however, that this is very unlikely unless a signiﬁcant breakthrough 
in the current state of the art of computational geometry is obtained.

Theorem 3. If there exists a data structure using O(n log σ + D polylog n) bits
with query time O(|P| polylog n) for document selection (σ being the alphabet 
size), then there exists a linear-space data structure that can answer threedimensional 
range reporting queries in poly-logarithmic time per reported point.

Proof. We reduce from the position restricted substring searching (PRSS) problem,
 which is deﬁned as follows: Index a given a text T [1, n] over an alphabet set
[1, σ], such that whenever a pattern P (of length p) and a range [x, y] comes as
a query, all those occx,y occurrences of P in T [x . . . y] can be reported eﬃciently.
Many indexes oﬀering diﬀerent space and query time trade-oﬀs exist [9,8].

Hon et al. [5] proved that answering PRSS queries in polylog time and succinct
space is at least as hard as performing 3-dimensional orthogonal range reporting
in polylog time and linear space. They also showed that if the query pattern
is longer than α = (cid:9)log2+ n(cid:10) for some predeﬁned constant  > 0, an eﬃcient
succinct space index can be designed. Therefore, the harder case arises when

Ranked Document Selection

355

p < α. We now show how to answer PRSS queries with p < α via document

selection queries on the following set: D = {d1, d2, d3, ..., d(cid:5)n/α(cid:6)}, where di =
T [1 + (i − 1)α...(i + 1)α] and |di| = 2α, except possibly for d(cid:5)n/α(cid:6)−1 and d(cid:5)n/α(cid:6).

The score function w(P, di) is i if P appears at least once in di and 0 otherwise.
Notice that an occurrence of any pattern of length at most α overlaps with at
least one and at most two documents in D. Therefore, the previously deﬁned
PRSS query on T can be answered via multiple document selection queries on D
as follows: ﬁrst report all those documents di with w(P, di) ∈ [(cid:9)x/α(cid:10),(cid:11)y/α + 2(cid:12)].
Then, within all those reported documents, look for other occurrences of P via
an exhaustive scanning. If the time for document selection queries is polylog in
the total length of all documents in D (which is at most 2n), then the time for
PRSS query is also bounded by O((p + occx,y)polylog n). Therefore, answering
document selection queries in polylog time and succinct space is at least as hard
(cid:5)(cid:6)
as answering PRSS queries in polylog time and succinct space.

References

1. Fredman, M., Willard, D.: Surpassing the information theoretic barrier with fusion

trees. J. Comp. Sys. Sci. 47, 424–436 (1993)

2. Grossi, R., Orlandi, A., Raman, R., Rao, S.S.: More haste, less waste: Lowering

the redundancy in fully indexable dictionaries. In: STACS, pp. 517–528 (2009)

3. Hon, W.-K., Patil, M., Shah, R., Thankachan, S.V., Vitter, J.S.: Indexes for document
retrieval with relevance. In: Brodnik, A., L´opez-Ortiz, A., Raman, V., Viola, A. (eds.)
Ianfest-66. LNCS, vol. 8066, pp. 351–362. Springer, Heidelberg (2013)

4. Hon, W.-K., Patil, M., Shah, R., Wu, S.-B.: Eﬃcient index for retrieving top-k

most frequent documents. J. Discr. Alg. 8(4), 402–417 (2010)

5. Hon, W.-K., Shah, R., Thankachan, S.V., Vitter, J.S.: On position restricted substring 
searching in succinct space. J. Discr. Alg. 17, 109–114 (2012)

6. Hon, W.-K., Shah, R., Thankachan, S.V., Vitter, J.S.: Space-eﬃcient framework

for top-k string retrieval. J. of the ACM (to appear, 2014)

7. Hon, W.-K., Shah, R., Vitter, J.S.: Space-eﬃcient framework for top-k string retrieval 
problems. In: FOCS, pp. 713–722 (2009)

8. Lewenstein, M.: Orthogonal range searching for text indexing. In: Brodnik, A.,
L´opez-Ortiz, A., Raman, V., Viola, A. (eds.) Ianfest-66. LNCS, vol. 8066,
pp. 267–302. Springer, Heidelberg (2013)

9. M¨akinen, V., Navarro, G.: Position-restricted substring searching. In: Correa, J.R.,
Hevia, A., Kiwi, M. (eds.) LATIN 2006. LNCS, vol. 3887, pp. 703–714. Springer,
Heidelberg (2006)

10. Munro, I.: Tables. In: FSTTCS, pp. 37–42 (1996)
11. Muthukrishnan, S.: Eﬃcient algorithms for document retrieval problems. In:

SODA, pp. 657–666 (2002)

12. Navarro, G.: Spaces, trees and colors: The algorithmic landscape of document retrieval 
on sequences. ACM Computing Surveys 46(4), article 52 (2014)

13. Navarro, G., Nekrich, Y.: Top-k document retrieval in optimal time and linear

space. In: SODA, pp. 1066–1077 (2012)

14. Navarro, G., Thankachan, S.V.: Faster top-k document retrieval in optimal space.
In: Kurland, O., Lewenstein, M., Porat, E. (eds.) SPIRE 2013. LNCS, vol. 8214,
pp. 255–262. Springer, Heidelberg (2013)

356

J.I. Munro et al.

15. Russo, L., Navarro, G., Oliveira, A.: Fully-compressed suﬃx trees. ACM Trans.

Alg. 7(4), art. 53 (2011)

16. Sadakane, K., Navarro, G.: Fully-functional succinct trees. In: SODA, pp. 134–149

(2010)

17. Shah, R., Sheng, C., Thankachan, S.V., Vitter, J.S.: Top-k document retrieval in
external memory. In: Bodlaender, H.L., Italiano, G.F. (eds.) ESA 2013. LNCS,
vol. 8125, pp. 803–814. Springer, Heidelberg (2013)

18. Tsur, D.: Top-k document retrieval in optimal space. Inf. Process. Lett. 113(12),

440–443 (2013)

19. Weiner, P.: Linear pattern matching algorithms. In: SWAT (FOCS), pp. 1–11

(1973)

