Encodings for Range Selection and Top-k Queries

Roberto Grossi1, John Iacono2, Gonzalo Navarro3,(cid:2), Rajeev Raman4,

and Satti Srinivasa Rao5,(cid:2)(cid:2)

2 Dept. of Comp. Sci. and Eng., Polytechnic Institute of New York Univ., USA

1 Dip. di Informatica, Univ. of Pisa, Italy

3 Dept. of Comp. Sci., Univ. of Chile, Chile
4 Dept. of Comp. Sci., Univ. of Leicester, UK

5 School of Comp. Sci. and Eng., Seoul National Univ.

Abstract. We study the problem of encoding the positions the top-k
elements of an array A[1..n] for a given parameter 1 ‚â§ k ‚â§ n. SpeciÔ¨Åcally,
for any i and j, we wish create a data structure that reports the positions
of the largest k elements in A[i..j] in decreasing order, without accessing
A at query time. This is a natural extension of the well-known encoding
range-maxima query problem, where only the position of the maximum
in A[i..j] is sought, and Ô¨Ånds applications in document retrieval and
ranking. We give (sometimes tight) upper and lower bounds for this
problem and some variants thereof.

1

Introduction

We consider the problem of encoding range top-k queries over an array of distinct
values A[1..n]. Given an integer 1 ‚â§ k ‚â§ n, we wish to preprocess A and create
a data structure that can answer top-k-pos queries: given two indices i and j,
return the positions where the largest k values in A[i..j] occur.

The encoding version of the problem requires this query to be answered without 
accessing A: this is useful when the values in A are intrinsically uninteresting
and only the indices where the top-k values occur are of interest. An example is
auto-completion search in databases and search engines [13, 15]. Here, as the user
types in a query, the system presents the user with the k most popular completions,
 chosen from a lexicon of phrases, based on the text entered so far. Viewing
the lexicon as a sorted sequence of strings with popularity scores stored in A,
the indices i and j can specify the range of phrases preÔ¨Åxed by the text typed in
so far. Similarly, in document search engines, A could contain the (virtual) sequence 
of PageRank values of the pages in an inverted list sorted by URL. Then
we could eÔ¨Éciently retrieve the k most highly ranked documents that contain a
query term, restricted to a range of page identiÔ¨Åers (which can model a domain

(cid:2) Partially funded by Millennium Nucleus Information and Coordination in Networks

ICM/FIC P10-024F, Mideplan, Chile.

(cid:2)(cid:2) Research partly supported by Basic Science Research Program through the National
Research Foundation of Korea (NRF) funded by the Ministry of Education, Science
and Technology (Grant number 2012-0008241).

H.L. Bodlaender and G.F. Italiano (Eds.): ESA 2013, LNCS 8125, pp. 553‚Äì564, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

554

R. Grossi et al.

of any granularity). An encoding data structure for top-k queries will allow us to
reduce the amount of space needed to perform these searches in main memory.
One can always use a non-encoding data structure (i.e., one that accesses A
during the execution of queries) for top-k-pos, such as that of Brodal et al. [4], on
an array A(cid:3)
that contains the sorted permutation of the elements in A, and thus
trivially avoid access to A at query time. This yields an encoding that uses O(n)
words, or O(n lg n) bits, of memory and answers top-k-pos queries in optimal
O(k) time. We aim to Ô¨Ånd non-trivial encodings of size o(n lg n) bits (from which,
of course, it is not possible to recover the sorted permutation, but one can still
answer any top-k-pos query). As we prove a lower bound of Œ©(n lg k) bits on the
space of any top-k encoding, non-trivial encodings can exist only if lg k = o(lg n).
This is a reasonable assumption for the aforementioned applications.

Related Work. The encoding top-k problem is closely related to the problem
of encoding range maximum query (RMQ), which is the particular case with
k = 1: RMQA(i, j) = argmaxi‚â§p‚â§jA[p]. The RMQ problem has a long history
and many applications [2, 3, 12], and the problem of encoding RMQs has been
studied in [8, 19]. In particular, Fischer and Heun [8] gave an encoding of A
that uses 2n + o(n) bits and answers RMQ in O(1) time; their space bound is
asymptotically optimal to within lower-order terms. We are not aware of any
work on top-k encoding for k > 1.

Our work is also related to range selection, which is to preprocess A to Ô¨Ånd the
kth largest element in a range A[i..j], with i, j, k given at query time. This problem 
has recently been studied intensively in its non-encoding version [5, 6, 9, 10,
14]. J√∏rgensen and Larsen [14] obtained a query time of O(lg k/ lg lg n + lg lg n),
very recently improved to O(lg k/ lg lg n) by Chan and Wilkinson [6], both using 
Œò(n) words, i.e., Œ©(n lg n) bits. J√∏rgensen and Larsen [14] introduced the
Œ∫-capped range selection problem, where a parameter Œ∫ is given at preprocessing 
time, and the data structure only supports selection for ranks k ‚â§ Œ∫. They
showed that even the one-sided Œ∫-capped range selection problem requires query
time Œ©(lg k/ lg lg n) for structures using O(n polylog n) words, and the result of
Chan and Wilkinson is therefore the best possible. Although the problems we
consider are diÔ¨Äerent in essential ways, we borrow some techniques, most notably
that of shallow cuttings [6, 14], in some of our results.

Contributions. We present new lower and upper bounds shown in Table 1, where
we assume that the word RAM model has word size of w = Œ©(lg n) bits, for the
following operations on encoding data structures for oneand 
two-sided range
selection and range top-k queries and for any 1 ‚â§ i ‚â§ j ‚â§ n.
1. kth-pos(i) returns the position of the k-th largest value in range A[1..i] for

any array A, and

2. top-k-pos(i) returns the top-k largest positions in A[1..i] (one-sided variant)
or top-k-pos(i, j) for the top-k largest positions in A[i..j] (two-sided variant).

We make heavy use of rank and select operations on bitmaps. Given a bitmap
B[1..n], operation rankb(B, i) is the number of occurrences of bit b in the preÔ¨Åx

Encodings for Range Selection and Top-k Queries

555

Table 1. Our lower and upper bounds for encodings for oneand 
two-sided range
selection and range top-k queries, simpliÔ¨Åed for the interesting case lg k = o(lg n), and
valid for any function lg lg k/ lg k (cid:3) (k) (cid:3) 1

Problem

kth-pos(i)
top-k-pos(i)
top-k-pos(i, j)

Lower bound
space (bits)
n lg k ‚àí O(n)
n lg k ‚àí O(n)
n lg k ‚àí O(n)

Upper bound
space (bits)

Upper bound

time

n lg k + O((k)n lg k)

O(1/(k))

n lg k + O(n)

O(n lg k)

O(k)
O(k)

B[1..i], whereas selectb(B, j) is the position in B of the j-th occurrence of bit b.
These operations generalize in the obvious way to sequences over an alphabet
[œÉ]. We also make use of the Cartesian tree [21] of an array A[1..n], which is
fundamental for RMQ solutions. The root of the Cartesian tree represents the
position m of a maximum of A[1..n], thus m = rmqA(1, n). Its left and right
subtrees are the Cartesian trees of A[1..m ‚àí 1] and A[m + 1..n], respectively.

2 One-Sided Queries

We start by considering one-sided queries. We are given an array A of n integers
and a Ô¨Åxed value k. We can assume w.l.o.g. that A is a permutation in [n],
otherwise we can replace each A[i] by its rank in {A[1], . . . , A[n]}, breaking ties
as desired, and obtain the same results from queries. We want to preprocess and
encode A to support the one-sided operations of Table 1 eÔ¨Éciently.

2.1 Lower Bounds
For queries kth-pos(i) and top-k-pos(i), we give a lower bound of Œ©(n lg k) bits
on the size of the encoding. Assume for simplicity that n = (cid:6)k, for some integer
(cid:6). Consider an array A of length n, with A[i] initialized to i, for 1 ‚â§ i ‚â§ n, and
re-order its elements as follows: take (cid:6) ‚àí 1 permutations œÄj of size k, 0 ‚â§ j <
(cid:6)‚àí 1, and permute the elements in the subarray A[jk + 1..(j + 1)k] according to
permutation œÄj, A[jk + i] = jk + œÄj (i) for 0 ‚â§ j < (cid:6) ‚àí 1 and 1 ‚â§ i ‚â§ k. Observe
that, for each 1 ‚â§ j < (cid:6), A[x] < A[y] for any x ‚â§ jk and y > jk. We now show
how to reconstruct the (cid:6)‚àí 1 permutations by performing several kth-pos queries
on the array A. By the above property of A, the position of the k-th value in
the preÔ¨Åx A[1..jk + i ‚àí 1] is the position of value (j ‚àí 1)k + i, for any 1 ‚â§ j < (cid:6)
and 1 ‚â§ i ‚â§ k. This position is (j ‚àí 1)k + œÄ‚àí1
j‚àí1(i). Then, any œÄj‚àí1 can be easily
computed with the k queries, kth-pos(jk + i ‚àí 1) for 1 ‚â§ i ‚â§ k. Since the (cid:6) ‚àí 1
permutations require ((cid:6) ‚àí 1) lg k! = (n ‚àí k) lg k ‚àí O(n) bits, the claim follows.
Similar arguments apply to top-k-pos(i) as well, even if it gives the results
not in order: using the array A above, kth-pos(i) is precisely the element that
disappears from the answer when we move from top-k-pos(i) and top-k-pos(i+1).
Theorem 1. Any encoding of an array A[1..n] answering kth-pos or top-k-pos
queries requires at least (n ‚àí k) lg k ‚àí O(n) bits of space.

556

R. Grossi et al.

	  
         
       





Fig. 1. Encoding of an array A of length n to support kth-pos and top-k-pos queries,
for k = 3. The encoding consists of a bitmap P of length n = 18 with n(cid:2)
= 13 ones,
and a string X of length n(cid:2)

over the alphabet [1..k].

2.2 Upper Bounds and Encodings

We Ô¨Årst consider query kth-pos(i). We scan the array from left to right, and keep
track of the top-k values in the preÔ¨Åx seen so far. At any position i > k, if we
insert A[i] into the top-k values, then we have to remove the k-th largest value
of the preÔ¨Åx A[1..i ‚àí 1]. The idea to solve these queries is to record the position
of that leaving k-th largest value, so that to solve kth-pos(i) we Ô¨Ånd the next
i(cid:3) > i where the top-k list changes, and then Ô¨Ånd the value leaving the list when
A[i(cid:3)
] enters it. This one was the k-th largest value in A[1..i]. We wish to store
this data using O(n lg k) bits.

lg lg k) by Jensen‚Äôs inequality.

Further, we store string X of length n(cid:3)

We store a bit vector P of length n, where P [i] = 1 iÔ¨Ä a new element is
inserted into the top-k values at position i (or equivalently, the k-th largest
value of A[1..i ‚àí 1] is deleted at position i). Let n(cid:3) ‚â§ n be the number of ones
in P . The Ô¨Årst k bits of P are set to 1. We encode P using n + o(n) bits, while
supporting constant-time rank and select operations on it [7, 16].
, such that X[j] = j for 1 ‚â§ j ‚â§ k, and
X[j] = X[rank1(P, kth-pos(select1(P, j) ‚àí 1))], for k < j ‚â§ n(cid:3)
. String X encodes
the positions of the top-k values in A[1..i] as follows. Let j = rank1(P, i) > k.
Then the last occurrence of X[j] = Œ± in X[1..j ‚àí 1] marks the position of the
element that was the k-th in the segment A[1..i ‚àí 1]. This is because the last
occurrence of each distinct symbol Œ± in X[1..j] is the position of a top-k value
in A[1..i]. This is obviously true for i = j = k, and by induction it stays true
when, at a position P [i] = 1, we set X[j + k] = Œ±, where Œ± marked the position
of the k-th maximum in A[1..i ‚àí 1]. Figure 1 shows an example.
over the alphabet [k]. Hence, X can be
encoded using (1 + (k))n(cid:3)
lg k bits, so that select is supported in O(1) time and
access in O(1/(k)) time [11], for any (k) = O(1) (including functions in o(1)).
On top of this we add O(n(cid:3)
lg lg k) bits. to support in constant time partial rank
queries, of the form rankX[i](X, i). This is obtained by storing one monotone
minimum perfect hash function (mmphf) [1] per distinct symbol c appearing
nc > 0 times in X. The space for each c is O(nc lg lg(n(cid:3)/nc)) bits, which adds
up to O(n(cid:3)
By the discussion above, for i < n we compute j = rank1(P, i) + 1, and
Œ± = X[j]. Then it holds kth-pos(i) = select1(P, selectŒ±(X, rankŒ±(X, j)‚àí 1)). This
is correct because the top-k list changes when A[i] enters the list, and we Ô¨Ånd
the next time X[j] = Œ± is mentioned, which is where A[i] is Ô¨Ånally displaced

Note that X is a string of length n(cid:3)

Encodings for Range Selection and Top-k Queries

557

from the top-k list. Thus, this operation can be supported in O(1/(k)) time,
where the time to access X dominates. Theorem 2 follows.

Theorem 2. Given an array A[1..n] and a value k, there is an encoding of A
and k on a RAM machine of w = Œ©(lg n) bits that uses n lg k + O((k)n lg k) bits
and support kth-pos(i) queries in O(1/(k)) time, for any function (k) ‚àà O(1)
and (k) ‚àà Œ©(lg lg k/ lg k).

For supporting top-k-pos(i) queries we need a diÔ¨Äerent query on X: Given a
position j, Ô¨Ånd the rightmost occurrence preceding j of every symbol in [k]. This
can be done in O(k) time using our representation of X [11]: The string is cut
into chunks of size k. We can traverse the chunk of j in time O(k) to Ô¨Ånd all the
last occurrences, preceding j, of distinct symbols1. For each symbol not found in
the chunk, we use constant-time rank and select on bitmaps already present in
the representation to Ô¨Ånd the previous chunk where it appears, and Ô¨Ånally Ô¨Ånd
in constant time its last occurrence in that previous chunk (as we have already
chosen, for our purposes, constant-time select inside the chunks).

By the discussion above on the meaning of X, it is clear that the rightmost
occurrences, up to position j = rank1(P, i) + 1, of the distinct symbols in [k],
form precisely the answer to top-k-pos(i). Thus we Ô¨Ånd all those positions p in
time O(k) and remap them to the original array using select1(P, p). Since we
need only select queries on X, we need only n lg k + O(n) bits for it [11].

Note the top-k positions do not come sorted by largest value. By the same
properties of X, if the Ô¨Årst occurrence of Œ± after X[j] precedes the Ô¨Årst occurrence
of Œ≤ after X[j], then the value associated to Œ± in our answer is smaller than that
associated to Œ≤, as it is replaced earlier. Thus we Ô¨Ånd the Ô¨Årst occurrence, after
j, of all the symbols in [k], analogously as before, and sort the results according
to the positions found to the right, in O(k lg k) time. Thus Theorem 3 follows.

Theorem 3. Given an array A[1..n] and a value k, there is an encoding of A
and k that uses n lg k + O(n) bits and supports top-k-pos(i) queries in O(k) time
on a RAM machine of w = Œ©(lg n) bits. The result can be sorted from largest to
lowest value in O(k lg k) time. The encoding is a subset of that of Theorem 2.

3 Two-Sided Range Top-k Queries

We now consider the problem of encoding the array A[1..n] so as to answer the
query top-k-pos(i, j). We will also consider solving top-k queries for any k ‚â§ Œ∫,
where Œ∫ is set at construction time. Clearly, a lower bound on the encoding size
of Œ©(n lg Œ∫) bits follows from Section 2.1.
Corollary 1. Any encoding of an array A[1..n] answering top-k-pos(i, j) queries
requires at least (n ‚àí k) lg k ‚àí O(n) bits of space.

We give now two upper bounds for query top-k-pos(i, j). The Ô¨Årst is weaker,

but it is used to obtain the second.
1 Although we do not have constant-time access to the symbols, we can select all the

(overall) k positions of all the k distinct symbols in the chunk, in time O(k).

558

R. Grossi et al.

3.1 Using O(kn) Bits and O(k2) Time

Let A[1..n] = a1 . . . an. We deÔ¨Åne, for each element aj, Œ∫ pointers j > P1[j] >
. . . > PŒ∫[j], to the last Œ∫ elements to the left of j that are larger than aj.

DeÔ¨Ånition 1. Given a sequence a1, . . . , an, we deÔ¨Åne arrays of pointers P0[1..n]
to PŒ∫[1..n] as P0[j] = j, and Pk+1[j] = max ({i, i < Pk[j] ‚àß ai > aj} ‚à™ {0}).

These pointers allow us to answer top-k queries without accessing A. We now

prove a result that is essential for their space-eÔ¨Écient representation.

Lemma 1. Let 1 ‚â§ j1, j2 ‚â§ n and 0 < k ‚â§ Œ∫, and let us call i1 = Pk‚àí1[j1] and
i2 = Pk‚àí1[j2]. Then, if i1 < i2 and Pk[j2] < i1, it holds Pk[j1] ‚â• Pk[j2].
Proof. It must hold ai1 < ai2 , since otherwise Pk[j2] ‚â• i1 by DeÔ¨Ånition 1 (as it
would hold aj2 < ai2 ‚â§ ai1 and 0 < i1 < i2), contradicting the hypothesis.
Now let us call r1 = Pk[j1] and r2 = Pk[j2] < i1. If it were r1 < r2 (and
thus r2 > 0), then we would have the following contradiction: (1) aj1 ‚â• ar2
(because otherwise it would be r1 = Pk[j1] ‚â• r2, as implied by DeÔ¨Ånition 1 since
r2 = Pk[j2] < i1 = Pk‚àí1[j1] and ar2 > aj1 ); (2) ar2 > aj2 (because r2 = Pk[j2]);
(3) aj2 ‚â• ai1 (because otherwise it would be r2 = Pk[j2] ‚â• i1, as implied by
DeÔ¨Ånition 1 since i1 < i2 = Pk‚àí1[j2] and ai1 > aj2 , and r2 ‚â• i1 contradicts the
(cid:7)(cid:8)
hypothesis); (4) ai1 > aj1 (because i1 = Pk‚àí1[j1]).

This lemma shows that if we draw, for a given k, all the arcs starting at Pk‚àí1[j]
and ending at Pk[j] for all j, then no arc ‚Äúcrosses‚Äù another. This property enables
a space-eÔ¨Écient implementation of the pointers.

Pointer Representation. We represent each ‚Äúlevel‚Äù k > 0 of pointers separately,
 as a set of arcs leading from Pk‚àí1[j] to Pk[j]. For a level k > 0 and for
any 0 ‚â§ i ‚â§ n, let pk[i] = |{j, Pk[j] = i}| be the number of pointers of level k
that point to position i. We store a bitmap

Tk[1..2n + 1] = 10pk[0] 10pk[1] 10pk[2] . . . 10pk[n],

where we mark the number of times each position is the target of pointers from
level k. Each 1 corresponds to a new position and each 0 to the target of an arc.
Note that the sources of those arcs correspond to the 0s in bitmap Tk‚àí1, that
is, to arcs that go from Pk‚àí2[j] to Pk‚àí1[j]. Arcs that enter the same position i
are sorted according to their source position, so that we associate the leftmost
0s of 0pk[i] to the arcs with the rightmost sources. Conversely, we associate the
rightmost 0s of 0pk‚àí1[i] to the arcs with the leftmost targets. This rule ensures
that those arcs entering, or leaving from, a same position do not cross in Tk.
Then we deÔ¨Åne a balanced sequence of parentheses

Bk[1..2n] = (

pk‚àí1[0])

pk‚àí1[0](

pk[0]‚àípk‚àí1[0])

pk‚àí1[1](

pk[1])

pk‚àí1[2](

pk[2] . . . )

pk‚àí1[n].

Encodings for Range Selection and Top-k Queries

559

This sequence matches arc targets (opening parentheses) and sources (their
corresponding closing parentheses). The arcs that leave from and enter at the
special position 0 receive special treatment to make the sequence balanced.

Calling Ô¨Åndopen(Bk, i) the position of the opening parenthesis matching the
closing parenthesis at Bk[i], the following algorithm computes the position zk
of the 0 of Tk corresponding to Pk[j], given the position zk‚àí1 of the 0 of Tk‚àí1
corresponding to Pk‚àí1[j].

1. p ‚Üê rank 0(Tk‚àí1, zk‚àí1)
2. z ‚Üê select 1(Tk‚àí1, zk‚àí1 ‚àí p)
3. z(cid:3) ‚Üê select 1(Tk‚àí1, zk‚àí1 ‚àí p + 1)
4. p ‚Üê z(cid:3) ‚àí (zk‚àí1 ‚àí z)

5. c ‚Üê select )(Bk, p)
6. o ‚Üê Ô¨Åndopen(Bk, c)
7. r ‚Üê rank ((Bk, o)
8. zk ‚Üê select 0(Tk, r)

The code works as follows. Given the position Tk‚àí1[zk‚àí1] = 0 corresponding
to the target of pointer Pk‚àí1[j], we Ô¨Årst compute in p the number of 0s up to
zk‚àí1 in Tk‚àí1. This position is corrected so as to (virtually) reverse the 0s that
form the run where zk‚àí1 lies (between the 1s at positions z and z(cid:3)
), in order to
convert entering into leaving arcs. Then we Ô¨Ånd c, the p-th closing parenthesis
in Bk, which is the target of this arc, and Ô¨Ånd its source o, the matching opening
parenthesis. Finally we compute the rank r of o among the opening parentheses
to the left, and match it with the corresponding 0 in Tk, zk.

We use the code as follows. Starting with P0[j] = j and z0 = 2j + 1, we use
the code up to Œ∫ times in order to Ô¨Ånd, consecutively, z1, z2, . . . , zŒ∫. At any point
we have that Pk[j] = rank 1(Tk, zk) ‚àí 1. Finally, since we know T0 = 1(10)n, we
can avoid storing it, and replace lines 1‚Äì4 by p ‚Üê j + 1, when computing z1.

By using a representation of Tk that supports constant-time rank and select
operations in 2n + O(n/ lg2 n) bits [17], and a representation of Bk that in
addition supports operation Ô¨Åndopen in constant time and the same space [20],
we have that the overall space is 4Œ∫n+o(n) bits for any Œ∫ = O(lg n). With such a
representation, we can compute any Pk[j], for any j and any 1 ‚â§ k ‚â§ Œ∫, in time
O(k) and, more precisely, in time O(1) after having computed Pk‚àí1[j] using the
same procedure.

Top-k Algorithm. To Ô¨Ånd the k largest elements of A[i..j] we use the structure
of Fischer and Heun [8] that takes 2n + o(n) bits and answers RMQs in constant
time. Our algorithm reconstructs the top part of the Cartesian tree [21] of A[i..j]
that contains the top-k elements, and also their children. The invariant of the
algorithm is that, at any time, the internal nodes of the reconstructed tree are
top-k elements already reported, whereas the next largest element is one of the
current leaves. The tree that is reconstructed is of size at most 3k.

The nodes p of the tree will be associated with an interval [ip..jp] of [1..n], and
with a position mp where the maximum of A[ip..jp] occurs. In internal nodes it
will hold ip = jp = mp. Those intervals will form a cover of [i..j] (i.e., will be
disjoint and their union will be [i, j]), and values ip (and jp) will increase as we
traverse the tree in inorder form.

560

R. Grossi et al.

We start taking rmq(i, j), which gives the position m of the maximum (top-
1); this would be enough for k = 1. In general, we initialize a tree of just one leaf
and no internal nodes. The leaf is associated to position m and interval [i..j].
This establishes the invariants.

To report the next largest element, we take the position ml of the maximum
of the rightmost leaf l, and traverse the interval [i..ml] backwards using P1[ml],
P2[ml], and so on. Each position (larger than 0) we arrive at contains an element
larger than A[ml]. However, if those are elements we have already reported, our
candidate ml is still good to be the next one to report. To determine this in
constant time, we traverse the tree in reverse inorder at the same time we do the
backward interval traversal. When we are at an internal node, we know that the
backward traversal will stop there, as the element is larger than A[ml]. Leaves,
instead, are not yet reported and their interval may be skipped by the traversal.
If, however, the backward traversal stops at a position Pr[ml] that falls within
the interval of another leaf p, then ml is not the next largest element, since Pr[ml]
is not yet reported. Instead of continuing with the new candidate at position
Pr[ml], we take the leaf position mp, which is indeed the largest of the interval.
We restart the backward traversal from l ‚Üê p, using again P1[ml], P2[ml], and so
on. When the backward traversal surpasses the left limit i, the current candidate
is the next largest element to report. We split its area into two, compute rmqs
to deÔ¨Åne the two new leaves of l, and restart the process.

For example, the Ô¨Årst thing that happens when we start this algorithm for
k > 1 is that P1[m] < i, thus we report m and create a left child with interval
[i..m ‚àí 1] and position rmq(i, m ‚àí 1) and a right child with interval [m + 1..j]
and position rmq(m + 1, j). Then we go on to report the second element.

Since each step can be carried out in constant time, and our backward traversal
performs k to 3k steps to determine the k-th answer, it follows that the time
complexity of the algorithm is O(k2). We are able to run this algorithm for any
k ‚â§ Œ∫ + 1. By renaming Œ∫ we have our Ô¨Ånal result, that with Œ∫ = 1 matches the
RMQ lower bounds.

Theorem 4. Given an array A[1..n] and a value Œ∫, there is an encoding of A
and Œ∫ that uses (4Œ∫‚àí 2)n + o(n) bits and supports top-k-pos(i, j) queries for any
k ‚â§ Œ∫, in O(k2) time on a RAM machine of w = Œ©(lg n) bits. The positions are
given sorted by value.

3.2 Using O(n lg k) Bits and O(k) Time

Our Ô¨Ånal solution achieves asymptotically optimal time and space, building on
the results of Section 3.1. It uses J√∏rgensen and Larsen‚Äôs ‚Äúshallow cuttings‚Äù idea
[14], which we now outline. Imagine the values of A[1..n], already mapped to
the interval [n], as a grid of points (i, A[i]). Now sweep a horizontal line from
y = n to y = 1. Include all the points found along the sweep in a cell, that is, a
rectangle [1, n] √ó [y, n]. Once we reach a point y0 such that the cell reaches the
threshold of containing 2Œ∫+1 points, create two new cells by splitting the current
cell. Let (x, y) be the point whose x-coordinate is the median in the current cell.

Encodings for Range Selection and Top-k Queries

561

This will be called a split point; note it is not necessarily the point (x0, y0) that
caused the split. Then the two new cells are initialized as [1, x] √ó [y0, n] and
[x, n] √ó [y0, n] (note the vertical limit is y0, that of the point causing the split,
which now belongs to one of the two cells). Both cells now contain Œ∫ points, and
the sweep continues, further splitting the new cells as we include more points.
We create a binary tree of cells TC , where the new cells are the left and right
children, respectively, of the current cell.

In general, at any point in time, we will have a sequence of split points already
determined, x1, x2, . . ., and the cells that are leaves in the current TC cover an
x-coordinate interval of the form [xi, xi+1] (we implicitly add split points 1 and
n at the extremes). When the next split occurs at a point (x0, y0) within the
cell covering the interval [xi, xi+1], we will split it into two new cells covering
[xi, x] √ó [y0, n] and [x, xi+1] √ó [y0, n], for some x. We will associate to those
cells the keys [xi, x] and [x, xi+1], respectively, and the extents [xi‚àí1, xi+1] and
[xi, xi+2], respectively. Finally, once we have Ô¨Ånished the sweep on the plane, we
are left with a Ô¨Ånal set of split points x1, x2, . . . , xt (from now on xi will refer
to this Ô¨Ånal sequence of split points). We add t further keyless cells with extents
[xi‚àí1, xi+1] for all 1 ‚â§ i ‚â§ t.
J√∏rgensen and Larsen prove various interesting properties of this process: (i)
it creates O(t) = O(n/Œ∫) cells, each containing Œ∫ to 2Œ∫ points (if n ‚â• Œ∫); (ii) if
c = [xi, xj]√ó [y0, n] is the cell with maximum y0 value whose key is contained in
a query range [l, r], then [l, r] is contained in the extent of c and (iii) the top-Œ∫
values in [l, r] belong to the union of the 3 cells that comprise the extent of c.

We give now an encoding of this data structure that contains two parts. The
Ô¨Årst part uses O((n/Œ∫) lg Œ∫) + o(n) = o(n) bits2 and identiÔ¨Åes in constant time
the desired cell whose extent contains [l, r]. The second part uses O(n lg Œ∫) bits
and gives us the Ô¨Årst Œ∫ elements in the extent, in O(Œ∫) time.

Finding the Cell. We mark the Ô¨Ånal split points xi in a bitmap S[1..n] with
constant-time rank and select support. As there are t bits set, S can be implemented 
in O((n/Œ∫) lg Œ∫) + o(n) bits [18]. It allows us Ô¨Ånding in constant time the
range [m, M ] of split points l ‚â§ xm < . . . < xM ‚â§ r contained in [l, r]. If this
range contains zero or one split point (i.e., m ‚â• M ), then [l, r] is contained in
the extent of the keyless cell number m and we are done for the Ô¨Årst part.

Otherwise, the following procedure Ô¨Ånds the desired key [14]. Find the split
point xi with maximum associated y0-coordinate (this is the y0 coordinate given
to the two cells created by split point xi). Find the split point xj with second
maximum. If j < i (i.e., xj is to the left of xi), then the desired key is [xj , xi],
else it is [xi, xj].

We map, using rank1 on S, the range [l, r] to the range [m, M ]. Consider the
array Y [1..t] of y0 values associated to the t split points. We store a range top-2
encoding T on the array Y , using the result of Section 3.1. This requires O(n/Œ∫)
bits and returns the positions of the Ô¨Årst and second maxima in Y [m, M ], xi and

2 It is not o(n) if Œ∫ = O(1), yet in this case the results of Section 3.1 are asymptotically

equivalent.

562

R. Grossi et al.

xj, in O(1) time. Assume w.l.o.g. that i < j and thus the desired key is [xi, xj ];
the case [xj, xi] is symmetric.

Now the Ô¨Ånal problem is to Ô¨Ånd the extent associated to the key [xi, xj ]. For
this we need to Ô¨Ånd the split points that, at the moment when the key [xi, xj ]
was created, preceded xi and followed xj. Since, at the time we created split
point xj , the split points that existed were precisely those with y0 larger than
that associated to xj, it follows that the split point that preceded xi is xi(cid:2) ,
where i(cid:3)
= P2[j], as deÔ¨Åned in Section 3.1 (Def. 1). Similarly, the split point that
followed xj was xj(cid:2) , where j(cid:3)
= N1[j] (Nk is deÔ¨Åned symmetrically to Pk but
pointing to the right, and it can be represented analogously). Those structures
still require O(n/Œ∫) bits and answer in O(1) time.

Thus, using O((n/Œ∫) lg Œ∫) + o(n) bits and O(1) time, we Ô¨Ånd the extent that
contains query [l, r]. The actual x-coordinates of the extent, [xi(cid:2) , xj(cid:2) ], are found
using select1 on S.

Traversing the Maxima. For the second structure, we represent the tree of
cells TC using O(n/Œ∫) bits, so that a number of operations are supported in
constant time [20]. Since the key [xi, xj] was created with the split point xj, the
corresponding node of TC is the left child of the j-th node of TC in inorder. This
node with inorder j is computed in constant time, and then we can compute
the preorder of its left child also in constant time (note that leaves do not have
inorder number, but all nodes have a preorder position) [20].

Associated to the preorder index of each node of TC we store an array
M [1..O(Œ∫)] over [O(Œ∫)], using O(Œ∫ lg Œ∫) bits (and O(n lg Œ∫) overall). This array 
stores the information necessary to Ô¨Ånd the successive maxima of the extent 
of the node. We use RMQ queries on A[xi(cid:2) , xj(cid:2) ]. Clearly the maximum
in the extent is m1 = rmqA(xi(cid:2) , xj(cid:2) ). The second maximum is either m2 =
rmqA(xi(cid:2) , m1 ‚àí 1) or m2 = rmqA(m1 + 1, xj(cid:2) ). Which of the two is greater
is stored (in some way to be speciÔ¨Åed soon) in M [1]. Assume M [1] indicates
that m2 = rmqA(xi(cid:2) , m1 ‚àí 1) (the other case is symmetric). Then the third
maximum is either m3 = rmqA(xi(cid:2) , m2 ‚àí 1), m3 = rmqA(m2 + 1, m1 ‚àí 1), or
m3 = rmqA(m1 + 1, xj(cid:2) ). Which of the three is the third maximum is indicated
by M [2], and so on. Note that we cannot store directly the maxima positions in
M because we would need O(Œ∫ lg n) bits. Rather, we use M to guide the search
across the Cartesian tree slice that covers the extent.

To achieve O(Œ∫) time we will encode the values in M in the following way.
At query time, will initialize an array I[1..k] and start with the interval I[1] =
[xi(cid:2) , xj(cid:2) ]. Now M [1] = 1 will tell us that we must now split the interval at I[1]
using an RMQ query, m1 = rmqA(I[M [1]]) = rmqA(I[1]) = rmqA(xi(cid:2) , xj(cid:2) ). We
write the two resulting subintervals in I[2] = [xi(cid:2) , m1‚àí1] and I[3] = [m1 +1, xj(cid:2) ].
Now M [2] ‚àà {2, 3} will tell us in which of those intervals is the second maximum.
 Assume again it is in M [2] = 2. Then we compute m2 = rmqA(I[2]) =
rmq(xi(cid:2) , m1 ‚àí 1), and write the two resulting subintervals in I[4] = [xi(cid:2) , m2 ‚àí 1]
and I[5] = [m2 + 1, m1 ‚àí 1]. Now M [3] ‚àà {3, 4, 5} tells which interval contains

the third maximum, and so on. Note the process is deterministic, so we can
precompute the M values.

Encodings for Range Selection and Top-k Queries

563

Therefore, we obtain in O(Œ∫) time the O(Œ∫) elements that belong to the extent,
that is, the union of the three cells. By the properties of the shallow cutting,
those contain the Œ∫ maxima of the query interval [l, r]. Therefore, in O(Œ∫) time
we obtain the successive maxima of the extent, and Ô¨Ålter out those not belonging
to [l, r]. We are guaranteed to have seen the Œ∫ maxima of [l, r], in order, after
examining O(Œ∫) maxima of the extent. Note that if we want only the top-k, for
k ‚â§ Œ∫, we also need O(Œ∫) time.

Theorem 5. Given an array A[1..n] and a value Œ∫, there is an encoding of A
and Œ∫ that uses O(n lg Œ∫) bits and supports top-k-pos(i, j) queries for any k ‚â§ Œ∫,
in O(Œ∫) time on a RAM machine of w = Œ©(lg n) bits. The positions are given
sorted by value.

By building this structure for (cid:10)lg Œ∫(cid:11) successive powers of 2, we can use one

where the search cost is O(k), for any k ‚â§ Œ∫.

Corollary 2. Given an array A[1..n] and a value Œ∫, there is an encoding of A
and Œ∫ that uses O(n lg2 Œ∫) bits and supports top-k-pos(i, j) queries for any k ‚â§ Œ∫,
in O(k) time on a RAM machine of w = Œ©(lg n) bits. The positions are given
sorted by value.

4 Conclusions

We have given lower and upper bounds to several extensions of the RMQ problem,
 considering the encoding scenario. Some variants of range selection and
range top-k queries were considered in the simpler one-sided version, where the
interval starts at the beginning of the array. For those, we have obtained optimal
or nearly-optimal time, and matched the space lower bound up to lower-order
terms. For the general two-sided version of the problem we have largely focused
on the range top-k query, where we have obtained optimal time and asymptotically 
optimal space (up to constant factors). Several problems remain open,
especially handling range selection queries in the two-sided case, which we have
not addressed. Tightening the constant space factors is also possible. Finally,
most of our results Ô¨Åx k at construction time (although for two-sided queries we
can Ô¨Åx a maximum k at construction time, at the price of an O(lg k) extra space
factor). Removing these restrictions is also of interest.

References

1. Belazzougui, D., Boldi, P., Pagh, R., Vigna, S.: Monotone minimal perfect hashing:

searching a sorted table with o(1) accesses. In: Proc. SODA, pp. 785‚Äì794 (2009)

2. Bender, M., Farach-Colton, M.: The level ancestor problem simpliÔ¨Åed. Theor.

Comp. Sci. 321(1), 5‚Äì12 (2004)

3. Berkman, O., Vishkin, U.: Recursive star-tree parallel data structure. SIAM J.

Comp. 22(2), 221‚Äì242 (1993)

564

R. Grossi et al.

4. Brodal, G.S., Fagerberg, R., Greve, M., L¬¥opez-Ortiz, A.: Online sorted range reporting.
 In: Dong, Y., Du, D.-Z., Ibarra, O. (eds.) ISAAC 2009. LNCS, vol. 5878,
pp. 173‚Äì182. Springer, Heidelberg (2009)

5. Brodal, G., Gfeller, B., J√∏rgensen, A., Sanders, P.: Towards optimal range medians.

Theor. Comp. Sci. 412(24), 2588‚Äì2601 (2011)

6. Chan, T., Wilkinson, B.: Adaptive and approximate orthogonal range counting.

In: Proc. SODA, pp. 241‚Äì251 (2013)

7. Clark, D.: Compact Pat Trees. Ph.D. thesis, Univ. of Waterloo, Canada (1996)
8. Fischer, J., Heun, V.: Space-eÔ¨Écient preprocessing schemes for range minimum

queries on static arrays. SIAM J. Comp. 40(2), 465‚Äì492 (2011)

9. Gagie, T., Navarro, G., Puglisi, S.: New algorithms on wavelet trees and applications 
to information retrieval. Theor. Comp. Sci., 426‚Äì427, 25‚Äì41 (2012)

10. Gagie, T., Puglisi, S., Turpin, A.: Range quantile queries: another virtue of wavelet
trees. In: Karlgren, J., Tarhio, J., Hyyr¬®o, H. (eds.) SPIRE 2009. LNCS, vol. 5721,
pp. 1‚Äì6. Springer, Heidelberg (2009)

11. Golynski, A., Munro, I., Rao, S.: Rank/select operations on large alphabets: a tool

for text indexing. In: Proc. SODA, pp. 368‚Äì373 (2006)

12. Harel, D., Tarjan, R.: Fast algorithms for Ô¨Ånding nearest common ancestors. SIAM

J. Comp. 13(2), 338‚Äì355 (1984)

13. Hsu, P., Ottaviano, G.: Space-eÔ¨Écient data structures for top-k completion. In:

Proc. WWW, pp. 583‚Äì594 (2013)

14. J√∏rgensen, A., Larsen, K.: Range selection and median: Tight cell probe lower

bounds and adaptive data structures. In: Proc. SODA, pp. 805‚Äì813 (2011)

15. Li, G., Ji, S., Li, C., Feng, J.: EÔ¨Écient type-ahead search on relational data: a

tastier approach. In: Proc. SIGMOD, pp. 695‚Äì706. ACM (2009)

16. Munro, I.: Tables. In: Chandru, V., Vinay, V. (eds.) FSTTCS 1996. LNCS,

vol. 1180, pp. 37‚Äì42. Springer, Heidelberg (1996)

17. PÀáatra¬∏scu, M.: Succincter. In: Proc. FOCS, pp. 305‚Äì313 (2008)
18. Raman, R., Raman, V., Rao, S.S.: Succinct indexable dictionaries with applications 
to encoding k-ary trees, preÔ¨Åx sums and multisets. ACM Trans. Alg. 2(4),
43:1‚Äì43:25 (2007)

19. Sadakane, K.: Succinct representations of lcp information and improvements in the

compressed suÔ¨Éx arrays. In: Proc. SODA, pp. 225‚Äì232 (2002)

20. Sadakane, K., Navarro, G.: Fully-functional succinct trees. In: Proc. SODA,

pp. 134‚Äì149 (2010)

21. Vuillemin, J.: A unifying look at data structures. Comm. ACM 23(4), 229‚Äì239

(1980)

