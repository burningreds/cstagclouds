Top-k Document Retrieval

in Compact Space and Near-Optimal Time

Gonzalo Navarro1,(cid:2) and Sharma V. Thankachan2,(cid:2)(cid:2)

1 Dept. of Computer Science, University of Chile, Chile

2 Dept. of Computer Science, Louisiana State University, USA

gnavarro@dcc.uchile.cl

thanks@csc.lsu.edu

Abstract. Let D={d1, d2, ...dD} be a given set of D string documents
of total length n. Our task is to index D such that the k most relevant
documents for an online query pattern P of length p can be retrieved
eﬃciently. There exist linear space data structures of O(n) words for answering 
such queries in optimal O(p + k) time. In this paper, we describe
a compact index of size |CSA| + n lg D + o(n lg D) bits with near optimal
∗ n), for the basic relevance metric term-frequency, where
time, O(p + k lg
|CSA| is the size (in bits) of a compressed full-text index of D, and lg
∗ n
is the iterated logarithm of n.

1

Introduction and Related Work

Top-k document retrieval is the problem of preprocessing a text collection so that,
given a search pattern P [1..p] and a threshold k, we retrieve the k documents
most “relevant” to P , for some deﬁnition of relevance. This is the basic problem
of search engines and forms the core of the Information Retrieval (IR) ﬁeld [5].
In this paper we focus on the popular term frequency as the relevance measure,
that is, the number of times P appears in a document.

The inverted index successfully solves top-k queries in various IR scenarios.
However, it applies to text collections that can be segmented into “words”, so
that only whole words can be queried. This excludes East Asian languages such
as Chinese and Korean, where automatic segmenting is an open problem, and is
troublesome even in languages such as German and Finnish. A simple solution
for those cases is to treat the text as a plain sequence of symbols and look for any
substring in those sequences. This string model is also appealing in applications
like bioinformatics and software repositories. Supporting document retrieval on
those general string collections has proved much more challenging.

Suﬁx trees [29] and arrays [15] are useful tools to search string collections.
These structures solve the pattern matching problem, that is, count or list all
the occ individual occurrences of P in the collection. Obtaining the k most
relevant documents from that set requires time Ω(occ), usually much higher
than k. Only recently [13,9,12,18,26] was the top-k problem solved satisfactorily,

(cid:2) Funded in part by Fondecyt Grant 1-110066.
(cid:2)(cid:2) Supported by National Science Foundation (NSF) Grants CCF–1017623 (R. Shah

and J. S. Vitter) and CCF–1218904 (R. Shah).

L. Cai, S.-W. Cheng, and T.-W. Lam (Eds.): ISAAC2013, LNCS 8283, pp. 394–404, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

Top-k Document Retrieval in Compact Space and Near-Optimal Time

395

ﬁnally reaching the optimal time O(p + k). Those solutions, like suﬃx trees,
have the drawback of requiring O(n lg n) bits of space on a collection of length
n, whereas the collection itself would require no more than n lg σ bits, where σ is
the alphabet size. This renders these indexes impractical on large text collections.
Compressed Suﬃx Arrays (CSAs) satisfactorily solve the pattern matching
problem within the size of the compressed text collection, under some entropy
model [17]. They can in addition retrieve any substring of any document, and
hence replace the collection with a compressed version that in addition supports
queries. We call their space |CSA| ≤ n lg σ(1 + o(1)), which can be thought of as
the minimum space in which the text collection can be represented.
A similar result for top-k queries has been sought. Various solutions use
2|CSA| + o(n) bits [24,12,7,3], culminating with the fastest solution so far in this
family, O(p+k lg k lg1+ n) time by Hon et al. [11]. Recently, asymptotically optimal 
space |CSA| + o(n) bits was obtained as well [27], being O(p + k lg2 k lg1+ n)
the best time achieved so far [20].

In all those solutions there is a signiﬁcant time factor per element returned,
of at least lg k lg1+ n. It seems unlikely that this factor can disappear in this
type of solutions. Experimental comparisons [6,19] show that these schemes are
impractically slow compared to those that use n lg D + o(n lg D) bits to store a
so-called document array [16,28]. We call compact the solutions that use |CSA| +
n lg D + o(n lg D) bits. The best practical results to date [6,21,3,14] are nearly
compact. Their space requirement, 1–3 times the collection size (and including
it), while not optimal, is aﬀordable in many practical situations.

It is therefore relevant to ask which is the best time performance that can be
achieved within compact space. The time-optimal result of Navarro and Nekrich
[18], O(p + k) time, requires O(n(lg D + lg σ)) bits. While of the same order
of compact solutions, the constants are still way too large in practice. There
have been some attempts to achieve truly compact solutions. Hon et al. [10]
obtained O(p + (lg lg n)6 + k(lg σ lg lg n)1+) time, for any constant  > 0, using
compact space. Alternatively, they obtain time O(p + (lg lg n)4 + k lg lg n) using
|CSA| + 2n lg D + o(n lg D) bits. Konow and Navarro [14] achieved time O(p +
(lg lg n)2 + k lg lg n) using |CSA| + n(lg D + 4 lg lg n)(1 + o(1)) bits, but the result
holds only on typical texts, not in the worst case.

In this paper we show that it is possible to get very close to optimal time
within compact space. We prove the following result, where we remark that the
top-k results are not returned in sorted order of relevance.
Theorem 1. There exists a compact index of |CSA| + n lg D + o(n lg D) bits and
n) query time time, for the (unsorted) top-k frequent
near-optimal O(p + k lg
∗
document retrieval problem, where lg
∗

n is the iterated logarithm of n.

∗

In Section 5 we achieve O(p + k lg

k) time, using o(n lg σ) further bits.

2 The Data Structure

Three main components of our structure are a generalized suﬃx tree (GST), the
document array, and some precomputed answer lists. These are described next.

396

G. Navarro and S.V. Thankachan

Generalized Suﬃx Tree (GST): Let T = d1d2d3...dD be the text (of length
n) obtained by concatenating all the documents in D. The last character of
each document is $, a special symbol that does not appear anywhere else in T .
Each substring T [i..n], with i ∈ [1..n], is called a suﬃx of T . The suﬃx tree
for T (or, equivalently, the generalized suﬃx tree (GST) of D) is a lexicographic
arrangement of all these n suﬃxes in a compact trie structure, where the ith
leftmost leaf represents the ith lexicographically smallest suﬃx. Each edge in
the suﬃx tree is labeled by a string, and path(x) of a node x (node x refers to
the node with preorder rank x) is the concatenation of edge labels along the

path from the root of GST to node x. Let (cid:5)i for i ∈ [1..n] represent the (preorder 
rank of) the ith leftmost leaf in GST . Then path((cid:5)i) represents the ith
lexicographically smallest suﬃx of T . A node x is called the locus of a pattern
P , if it is the node closest to the root with path(x) preﬁxed by P .

The suﬃx array SA[1..n] is an array of length n, where SA[i] is the starting
position (in T ) of the ith lexicographically smallest suﬃx of T . An important
property of SA is that the starting positions of all the suﬃxes with the same
preﬁx are always stored in a contiguous region of SA. Based on this property,
we deﬁne the suﬃx range of P in SA to be the maximal range [sp, ep] such that
for all i ∈ [sp, ep], SA[i] is the starting point of a suﬃx of T preﬁxed by P .

A compressed representation of suﬃx array is called a Compressed Suﬃx Array 
(CSA). We will use a recent CSA [1], which obtains high-order entropy compression 
and can compute the suﬃx range [sp, ep] of any given pattern P [1..p] in
O(p) time. We also maintain the tree topology of GST in (at most) 4n+o(n) bits
[25], with constant-time support of the operations parent(x) (the parent of node
x), lca(x, y) (the lowest common ancestor of nodes x and y), left-leaf(x)/right-
leaf(x) (the leftmost/rightmost leaf in the subtree rooted at node x), and leaf(i)
(the ith leftmost leaf), and mapping from nodes to their preorder ranks and
back. The total space of this component is |CSA| + O(n) bits.

Document Array (DA): Deﬁne a bit-vector B[1..n], such that B[i] = 1 iﬀ
T [i] = $. Then suﬃx T [i, n] belongs to document dr if r = 1 + rank B(i), where
rank B(i) is the number of 1s in B[1, i]. The document array DA[1..n] is deﬁned
as DA[j] = r if the suﬃx SA[j] belongs to document dr. Moreover, we say that
the corresponding leaf node (cid:5)j is marked with document dr. Now,

– rank DA(r, i) returns the number of occurrences of r in DA[1, i];
– select DA(r, j) returns i where DA[i] = r and rank DA(r, i) = j; and
– access DA(i) returns DA[i];

Then we have use the following representation for DA [2].

Lemma 1. The document array DA can be stored in n lg D + o(n lg D) bits and
support queries rank DA, selectDA and accessDA in times O(lg lg n), O(f (n, D))
and O(1) respectively, where f (n, D) = ω(1) is any non-constant function.

The so-called partial rank query can be added to this repertoire [3].

Lemma 2. Operation rank DA(DA[i], i) can be supported in constant time by
storing O(n lg lg D) = o(n lg D) additional bits on top of the DA.

Top-k Document Retrieval in Compact Space and Near-Optimal Time

397

Thus the total space of this component is n lg D + o(n lg D) bits.

Precomputed Answer Lists: We start with the following deﬁnitions:

– L(x) is the set of leaves in the subtree of node x in GST .
– L(x\y) = L(x) \ L(y), the leaves in the subtree of x, but not in that of y.
– score(r, x) is the number of leaves in L(x) marked with document dr (i.e.,

|{(cid:5)i ∈ L(x), DA[i] = r}|).
We use the following scheme to identify a subset Sg of marked nodes in GST
[12,21]: Let g be a parameter called grouping factor, then mark every gth leftmost 
leaf in GST , and then mark the lowest common ancestor (LCA) of every
consecutive pair of marked leaves. Then, we have the following lemma [12,21].

Lemma 3. The above marking scheme ensures the following properties:

1. The number of marked nodes is |Sg| = Θ(n/g).

unique, and |L(x\y)| < 2g.

2. If it exists, the closest marked descendant node y of any unmarked node x is
3. If there exists no marked node in the subtree of x, then |L(x)| < 2g.

Let F (x, k) represent the list (or set) of top-k documents dr, along with
score(r, x), corresponding to a pattern with locus node x in GST . Clearly we
cannot aﬀord to maintain F (x, k) for all possible x’s and k’s. Rather, we will
maintain the lists F (x, z) only for marked nodes x’s (for various g values) and
for k’s that are powers of 2. Then F (x, k) for any x and k will be eﬃciently
computed using that sampled data. The next section describes how we store and
retrieve the sampled lists.

3 Storing and Retrieving the Lists F (x, z)

The following is a key result in our scheme.

∗

∗

Lemma 4. Let gh = z(lg(h) n)2 for any 1 ≤ h < lg
n, where lg(1) n = lg n,
n) n ≤ 1. Then F (x, z) for all x ∈ Sgh can be
lg(h) n = lg(lg(h−1) n), and lg(lg
encoded in sh = sh−1 + O(n/ lg(h) n) bits, and F (x, z) for any given x ∈ Sgh can
be decoded in time th = th−1 + O(z), where s1 = O(n/ lg n) and t1 = O(z).
Proof. We use induction. Consider the base case h = 1. For every x ∈ Sg1 , we
a pointer to the location where it is stored, in s1 = O(|Sg1|z lg n) = O(n/ lg n)
bits. Thus the list F (x, z), for any x ∈ Sg1, can be decoded in time t1 = O(z).
Now consider the grouping factor is gh for h ≥ 2. As we cannot aﬀord to

maintain the list F (x, z) explicitly (using O(lg n) bits per element), along with

use Θ(lg n) bits per element, we introduce encoding schemes that reduce it to
O(lg(h) n) bits. Thus the overall space for maintaining F (x, z) (in encoded form)
for all x ∈ Sgh can be bounded by O(|Sgh
|z lg(h) n) = O(n/ lg(h) n) bits. Instead
of using pointers as in the base case, we mark in a bitmap Bh[1..2n] the node

398

G. Navarro and S.V. Thankachan

preorders of GST that belong to Sgh . Therefore the list F (x, z) of a node x ∈ Sgh
is stored in an array at oﬀset rank Bh[x]. Since we will only compute rank on
positions x where Bh[x] = 1, an “indexed dictionary” is suﬃcient [23], which
requires O((n/gh) lg gh + lg lg n) = o(n/ lg(h) n) bits and computes rank in time
O(1). We now show how to encode the list F (x, z), for x ∈ Sgh , in O(lg(h) n)
bits per element, and how to decode it in th−1 + O(z) time.
We will maintain a structure STRh, using sh bits, for each grouping factor gh,
and will decode F (x, z) for x ∈ Sgh recursively, using O(z) time in addition to
the time needed to decode F (y, z) for some y ∈ Sgh−1 , as suggested in Lemma 4.

As we cannot aﬀord to sort the documents within the targeted query time, it
is important to assume a ﬁxed arrangement of documents within any particular
decoded list F (·,·). That is, each time we decode a speciﬁc list, the decoding
algorithm must return the elements in the same order.

Let x be a node in Sgh and y (if it exists) be its highest descendant node in
Sgh−1 . We show how to encode and decode F (x, z). To decode F (x, z), we ﬁrst
decode the list F (y, z) using STRh−1 in time th−1. From now onwards we have
constant-time access to any element the list F (y, z). The the list F (x, z) will be
partitioned into the following two disjoint lists:

(i) Dold, the documents that are common to F (x, z) and F (y, z).
(ii) Dnew, the documents that are present in F (x, z), but not in F (y, z).

(cid:4)

(cid:4)

[1..z], where B

Encoding and decoding document identifers in Dold. We maintain a bit vector
B
[i] = 1 iﬀ the ith document in F (y, z) is present in F (x, z).
Therefore Dold can be decoded by listing those elements in F (y, z) (in the same
[i] = 1. Thus space for maintaining
order as they appear) at positions i where B
the encoded information is z bits and the time for decoding is O(z).

(cid:4)

(cid:4)(cid:4)

(cid:4)(cid:4)

|Dnew| 1’s: for every document dr ∈ Dnew, we set one bit, say B
the ith leaf in L(x\y) is marked with dr. Since |B

Encoding and decoding document identifers in Dnew. For each document dr ∈
Dnew, there exists at least one leaf in L(x\y) that is marked with dr (otherwise
score(r, x) = score(r, y) and dr could not be in F (x, z) and not in F (y, z)).
Therefore, instead of explicitly storing r, it is suﬃcient to refer to such a leaf.
[1..|L(x\y)|] with all its bits in 0, except for
For this we shall store a bit vector B
[i] = 1, where
(cid:4)(cid:4)| = |L(x\y)| < 2gh−1 and the
can be encoded in O(z lg(gh−1/z)) = O(z lg(h) n)
number of 1’s is at most z, B
bits with constant time select support [22] (selectB(cid:3)(cid:3)(j) is the position of the j-th
, the documents in Dnew can be identiﬁed in O(z) time
1 in B
as follows: Find all those (at most z) increasing positions i where B
[i] = 1 using
select queries. Then, for each such i, ﬁnd the ith leaf (cid:5)i(cid:3) ∈ L(x\y) in constant
time using the tree operations1. Finally, report dDA[i(cid:3)] as a document in Dnew
for each such i
using a constant-time access operation on the document array.
As mentioned before, it is important for our (recursive) encoding/decoding
algorithm to assume a ﬁxed permutation of elements within any list F (·,·). We
1 Compute the leftmost leaves (cid:2)ix and (cid:2)iy , respectively, of x and y, then (cid:2)i(cid:3) is (cid:2)ix+i−1,
if ix + i − 1 < iy, and (cid:2)jy +i−(iy−ix ) otherwise, where (cid:2)jy is the rightmost leaf of y.

). Now, given B

(cid:4)(cid:4)

(cid:4)(cid:4)

(cid:4)(cid:4)

(cid:4)(cid:4)

(cid:4)

Top-k Document Retrieval in Compact Space and Near-Optimal Time

399

(cid:4)
i

(cid:2)

(cid:4)
i =

use the convention that, in F (x, z), the documents in Dold come before the
documents in Dnew. Moreover the documents within Dold and Dnew are in the
same order as the decoding algorithm identiﬁed them. In conclusion, the list
of identiﬁers of documents in F (x, z) can be encoded in O(z lg(h) n) bits and
decoded in O(z) time, assuming constant-time access to any element in F (y, z).
If node y does not exist, we proceed as if F (y, z) = ∅ and F (x, z) = Dnew. We
(i.e., score(r, x) for all dr ∈ F (x, z)).
Encoding and decoding of scores. Let dri, for i ∈ [1..z], be the ith document in
F (x, z), and fi = score(ri, x). Then, deﬁne δi = fi − f

now consider how to encode the score’s associated with the elements in F (x, z)

≥ 0, where

if i ≤ |Dold| (i.e., if ri ∈ Dold),
if i > |Dold| (i.e., if ri ∈ Dnew).

score(ri, y)
τ = min{score(r, y), r ∈ F (y, z)}

marked with a unique document, we have the inequality

f
The following is an important observation: The number of leaves in L(x\y)
marked with document dri is score(ri, x) − score(ri, y), which is same as δi for
i ≤ |Dold|. For i > |Dold|, score(ri, x)−score(ri, y) ≥ δi, otherwise score(ri, y) >
τ and dri would have qualiﬁed as a top-z document in F (y, z) (which is a contradiction 
as dri ∈ Dnew). By combining with the fact that each leaf node is
i=1 δi ≤ |L(x\y)| <
2gh−1. Therefore, δi for all i ∈ [1..z] can be encoded using a bit vector B
=
10δ110δ210δ3 . . . 10δz of length at most 2gh−1 + z with z 1’s, in O(z lg(gh−1/z)) =
O(z lg(h) n) bits with constant-time select support [22].
(cid:4)
i ’s for i =
1 . . . z in the ascending order of i. For i ≤ |Dold|, f
(cid:4)
i is given by score associated
with the (selectB(cid:3)[i])th document (which is same as dri ) in F (y, z). This takes
only O(z) time as the number of constant-time select operations is O(z), and
we have constant-time access to any element and score in F (y, z). Next, τ =
min{score(r, y), r ∈ F (y, z)} can be obtained by scanning the list F (y, z) once.
(cid:4)
i ’s are computed in O(z) time. Next we decode each δi and add
Thus all the f
i to obtain fi, for i = 1 . . . z in O(z) time, where δi = selectB(cid:3)(cid:3)(cid:3)(i) −
(cid:4)
it to f
selectB(cid:3)(cid:3)(cid:3)(i − 1) − 1 is computed in O(1) time. Thus the space for maintaining
the scores is O(z lg(h) n) bits and the time for decoding them is O(z).

The decoding algorithm is described as follows: compute the f

(cid:3)

(cid:4)(cid:4)(cid:4)

z

Adding over the h levels, the total space is sh = sh−1 + O(n/ lg(h) n) =
O(n/ lg(h) n) bits and the total decoding time is th = th−1 + O(z) = O(zh) (note
(cid:6)(cid:7)
that s1 = O(n/ lg n) and t1 = O(z)). This completes the proof.

∗

n) be an integer such that lg(π−1) n ≥
∗
n = Θ(lg

4 Completing the Picture
Let π ∈ [1.. lg
n > lg(π) n, then
lg(π) n = ω(1) (note that π = lg
n)). Then, by choosing
gπ as the grouping factor, the space sπ is O(n/ lg(π) n) = o(n) bits. We maintain
, in o(n lg D) bits
lg D such structures corresponding to z = 1, 2, 4, 8, ..., 2
total space. By combining the space bounds of all the components, we obtain
the following lemma.

n − lg

∗(cid:4)

(cid:5)lg D(cid:6)

lg

lg

∗

∗

∗

(cid:4)

400

G. Navarro and S.V. Thankachan

Lemma 5. The total space requirement of our data structure is |CSA|+ n lg D +
o(n lg D) bits.

The next lemma gives the total time to extract the sampled results and hints

how we will use them.

Lemma 6. Given any node q in GST and an integer k, our data structure can
report the list F (q
is a node in the subtree of q
with |L(q\q

(cid:4)
)| = O(k

n) time, where q

, k) in O(k lg

(cid:4)

n).

lg

∗

∗

(cid:4)

(cid:4)

(cid:7)lg k(cid:8)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

if i

Since gπ = z lg(π) n < z

= gπ·(cid:8)i/gπ(cid:9) and j

). This takes constant time on our representation of the

= lca((cid:5)i(cid:3), (cid:5)j(cid:3) ) where i
(cid:4)

Proof. As the ﬁrst step, round k to z = 2
, which is the next highest power
, in the subtree of q, that is marked with
of 2. Then identify the highest node q
respect to the grouping factor gπ: Let (cid:5)i and (cid:5)j be the leftmost and rightmost
= gπ·(cid:10)j/gπ(cid:11)
leaves of q in GST , then q
(there is no q
GST topology.

(cid:4) ≥ j
(cid:4)
O(z lg(π) n) = O(k
, z) can be decoded in time
lg
∗
n) from the precomputed lists (from Lemma 4). The ﬁnal
tπ = O(zπ) = O(z lg
F (q
, z) with score at
least θ by a single scan of the list, where θ is the kth highest score in F (q
, z)
(which can be computed in O(z) = O(k) time using the linear-time selection
, k) = ∅, and even in such
algorithm [4]). In case q
a case the inequality condition |L(q)| < 2gπ is guaranteed (from Lemma 3). (cid:6)(cid:7)

n, from Lemma 3 it holds |L(q\q
(cid:4) ∈ Sgπ , the list F (q

, k) can be obtained by ﬁltering those documents in F (q

does not exist, we report F (q

)| = O(gπ) =

n). As q

lg

∗

∗

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

4.1 Query Answering

The query answering algorithm consists of the following steps:

(cid:4)

1. Find the locus node q of the input pattern P in GST by ﬁrst obtaining the
suﬃx range [sp, ep] of P using CSA in O(p) time, and then computing the
lowest common ancestor of (cid:5)sp and (cid:5)ep in O(1) time.
)| =
(cid:4)

in the subtree of q, where |L(q\q
(cid:4)
, k) in O(k lg

2. Using Lemma 6, ﬁnd the node q

3. Every document dr in the ﬁnal output F (q, k) must either belong to F (q

, k),
). Let us call Scand the
union of both sets of candidate documents. Then we compute score(r, q) of

or it must be that r = DA[i] for some leaf (cid:5)i ∈ L(q\q
each document dr ∈ Scand.

n) and retrieve the list F (q

n) time.
(cid:4)

O(k

lg

∗

∗

(cid:4)

(cid:4)

4. Report k documents in Scand with the highest score(r, q) value. In this step,
we ﬁrst compute the kth highest score θ using the selection algorithm, and
then use θ as a threshold for a document to be an output (more precisely,
we report the k
pass, and then report the ﬁrst k − k
score(r, q) = θ in a second pass). The time is O(|Scand|) = O(k

< k documents dr ∈ Scand with score(r, q) < θ in a ﬁrst
documents dr ∈ Scand we ﬁnd with

(cid:4)

n).

lg

∗

(cid:4)

(cid:4)

The overall time for Steps 1, 2, and 4 is O(p + k lg

n). In the remaining part
of this section we show how to handle Step 3 eﬃciently as well, for the documents

∗

Top-k Document Retrieval in Compact Space and Near-Optimal Time

401

(cid:4)

r = DA[i] we ﬁnd in L(q\q
). Note that score(r, q) can be computed as rankDA
(r, ep)− rank DA(r, sp− 1) using two rank queries on the document array, but those
rank queries are expensive. Instead, we use a more sophisticated scheme where only
the faster select , access, and partial rank queries are used. This is described next.

4.2 Computing Scores Online

∗

∗

Firstly, we construct a supporting structure, SUP, in O(k lg
n) time and occupying 
o(n lg D) + O(z lg n) bits, capable of answering the following query in
O(lg lg
, k), otherwise
return −1. Let Δ = Θ(lg
n), then structure SUP is a forest of D/Δ balanced
binary search trees T1,T2, . . . ,TD/Δ. Initially each Ti is empty, hence the initial

n) time: for any given r, return score(r, q

) if r ∈ F (q

∗

(cid:4)

(cid:4)

space is O(lg n) bits per tree (for maintaining a pointer to the location where
it is stored), adding up to O((D/Δ) lg n) = o(n lg D) bits, which we consider
, k), along with

a part of index. Next we shall insert each document dr ∈ F (q
its associated score, into tree T(cid:7)r/Δ(cid:8) of SUP. The size of each search tree can

(cid:4)

size of the output. Now we can search for any dr in Tr/Δ and, if dr ∈ F (q

grow up to Δ, hence the total insertion time is O(k lg Δ). These insertions will
increase the space of SUP by O(k lg n) bits, which can be justiﬁed as it is the
, k),
we will retrieve score(r, q
) in O(lg Δ) time. Once we ﬁnish Step 3, these binary
search trees can be set back to their initial empty state by visiting each docu-
, k) and deleting it from the corresponding tree in total O(k lg Δ)

ment dr ∈ F (q

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

time. This does not impact the total asymptotic query processing time.

An outline of Step 3 follows: We scan each leaf (cid:5)i ∈ L(q\q

), and compute
score(·, q) of the corresponding document dDA[i]. Note that there can be many
leaves in L(q\q
) marked with the same document, but we compute score(·, q) of
a document only once (i.e., when we encounter it for the ﬁrst time). After this,
we also scan the documents dr ∈ F (q
, k) and compute score(r, q) if we have
not considered this document in the previous step. However, the scanning of
leaves is performed in a carefully chosen order. Let (cid:5)sp(cid:3) and (cid:5)ep(cid:3) be the leftmost
and rightmost leaves in the subtree of q
, and B[1..D] be a bit vector initialized
to all 0’s (its size is D bits and can be considered a part of index). A detailed
description of Step 3 follows:

(cid:4)

(cid:4)

3.1 Start scanning the leaves (cid:5)i for i = sp, sp + 1, . . . , sp

(cid:4)

(cid:4) − 1, in the ascending 
order of i, then for i = ep, ep − 1, . . . , ep
+ 1, in the descending order 
of i, and do the following: if B[DA[i]] = 0, then set it to 1, compute
score(DA[i], q), and store the result (DA[i], score(DA[i], q)) for Step 4. Note
that each time we compute score(DA[i], q), i is either the ﬁrst or the last
occurrence of DA[i] in DA[sp, ep]. Assume it is the ﬁrst (the other case is sym-
metric). We use a constant-time partial rank query, x = rank DA(DA[i], i).
Then, by performing successive selectDA(DA[i], j) queries for j = x + 1, x +
2, . . . , y, where selectDA(DA[i], y) > ep ≥ selectDA(DA[i], y−1), we compute
score(DA[i], q) = y − x. The number of select queries required is precisely
y − x = score(DA[i], q), which can be further reduced as follows:
– If dDA[i] ∈ F (q

, k), retrieve score(DA[i], q

n).
) ≤ score(DA[i], q), we start select queries

) from SUP in time O(lg lg

As we know that score(DA[i], q

∗

(cid:4)

(cid:4)

(cid:4)

402

G. Navarro and S.V. Thankachan

(cid:4)

(cid:4)

(cid:4)

(cid:4)

– If dDA[i] (cid:12)∈ F (q

) marked with dDA[i].

) = score(DA[i], L(q\q

), so the number of select queries used to ﬁnd
from j = x + score(DA[i], q
y is reduced to score(DA[i], q)− score(DA[i], q
)),
that is, the number of leaves in L(q\q
= selectDA(DA[i], x + τ − 1), where we
(cid:4)
, k), compute x
remind that τ = min{score(r, q
), r ∈ F (q
(cid:4)
> ep, we conclude
that score(DA[i], q) < τ , and hence dDA[i] can be discarded from being
(cid:4) ≤ ep, the
a candidate for the ﬁnal output. On the other hand, if x
select queries can be started from j = x + τ , which reduces the number
of select queries to score(DA[i], q) − τ ≤ score(DA[i], L(q\q
)) (since
dDA[i] /∈ F (q

, k), it holds score(DA[i], q

, k)}. If x
(cid:4)

) ≤ τ ).

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

)) = |L(q\q

)|. By choosing the cost f (n, D) =

3.2 Now scan the documents dr ∈ F (q

The query time for executing this step can be analyzed as follows: for each i,
we perform a query on SUP. The computation of score(DA[i], q) requires at
most score(DA[i], L(q\q
)) select queries. As we do this computation only
(cid:3)
once per distinct document, the total number of select queries is at most
r score(r, L(q\q
n for
select queries, the total time is O(|L(q\q
∗
n).
, k). If B[r] = 0, then there exists no
leaf in L(q\q
) marked with dr. Thus score(r, q) = score(r, q
) and the pair
(cid:4)
)) is stored for Step 4. If B[r] = 1 then dr has already been
(r, score(r, q
dealt with in the previous pass. The time for accessing score(r, q
) using
SUP is O(lg lg
3.3 Reset B to its initial state (all bits set to 0) for supporting queries in future.
By revisiting the leaves in L(q\q
, k), we can exactly ﬁnd
out those locations in B where the corresponding bit is 1. The time for this
step can be bounded by O(|L(q\q
∗

) and the list F (q
)| + k) = O(k

n), hence this step takes O(k lg lg

)|(f (n, D) + lg lg

n)) = O(k lg

n) time.

(cid:4)

n).

lg

lg

∗

∗

∗

∗

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

(cid:4)

Thus the time for Step 3 is O(k lg

∗

n), and the result follows.

5 Reducing the Time to O(p + k lg

∗ k)

∗

n) = O(p +
k). Therefore, we now concentrate on the case when max(p, k) < lg lg n. We

Note that, when p or k is at least lg lg n, it already holds O(p + k lg
k lg
use the following result [8].

∗

Lemma 7. Given a ﬁxed κ, an array A[1..n] of n indices can be indexed in O(n lg2 κ)
bits for answering the following query in O(k) time, without accessing A and for any
1 ≤ k ≤ κ: given i, j, and k, output the positions of the k highest elements in A[i, j].

Let Sδ be the set of nodes in GST with node depth equal to δ. We start with
the description of an O(n lg2 κ)-bit structure for a ﬁxed κ = lg lg n and a ﬁxed
δ < lg lg n, for answering top-k queries for any 1 ≤ k ≤ κ and those patterns with
their locus node belonging to Sδ. First, we construct an array A[1..n] (with all
its elements initialized to zero) as follows: For i = 1 . . . n, if the ﬁrst occurrence
of document DA[i] in DA[a, b] is at position i, where [a, b] is the suﬃx range

corresponding to a unique node u ∈ Sδ, then set A[i] = score(DA[i], u). We

do not store this array explicitly, instead we maintain the structure of Lemma 7

Top-k Document Retrieval in Compact Space and Near-Optimal Time

403

query on the structure of Lemma 7 with the suﬃx range [sp, ep]. The output will

over it, requiring O(n lg2 κ) bits space. Now the list of documents F (u, k) for any
locus node u ∈ Sδ can be reported in O(k) time as follows: First perform a top-k
be a set of k locations j1, j2, . . . , jk ∈ [sp, ep], and then the identiﬁers of the top-k
documents are DA[j1], DA[j2], . . . , DA[jk]. By maintaining similar structures for
all the δ ∈ [1, lg lg n), any such top-k query with p < lg lg n can be answered
be bounded by o(n lg σ) bits if, say, lg σ ≥ √
in O(p + k) time. The additional space required is o(n(lg lg n)3) bits, which can
lg n. Otherwise, we shall explicitly
maintain the top-κ documents corresponding to all patterns of length at most
lg lg n, in decreasing frequency order, using a table of O(σlg lg n lg lg n lg D) =
o(n) bits. The query time in this case is just O(k).

∗

Thus, by combining the cases, we achieve O(p + k lg

k) query time.

Theorem 2. There exists a compact index of |CSA| + n lg D + o(n(lg σ + lg D))
k) query time time, for the (unsorted) top-k
bits and near-optimal O(p + k lg
frequent document retrieval problem.

∗

6 Conclusions

∗

We have shown that it is possible to obtain almost optimal time for top-k docu-
n), using compact space, |CSA|+n lg D+o(n lg D) bits.
ment retrieval, O(p+k lg
By adding o(n lg σ) bits, the time decreases to O(p+k lg
k). This is an important
step towards answering the question of which is the minimum space that is necessary 
to obtain the optimal time, O(p + k). The other important open question
is which is the minimum time that can be obtained by using the asymptotically
optimal space, |CSA| + o(n) bits. Right now this time is O(p + k lg2 k lg1+ n)
[20], and it is not clear which is the lower bound.

∗

References

1. Belazzougui, D., Navarro, G.: Alphabet-independent compressed text indexing. In:
Demetrescu, C., Halld´orsson, M.M. (eds.) ESA 2011. LNCS, vol. 6942, pp. 748–759.
Springer, Heidelberg (2011)

2. Belazzougui, D., Navarro, G.: New lower and upper bounds for representing sequences.
 In: Epstein, L., Ferragina, P. (eds.) ESA 2012. LNCS, vol. 7501, pp. 181–
192. Springer, Heidelberg (2012)

3. Belazzougui, D., Navarro, G., Valenzuela, D.: Improved compressed indexes for

full-text document retrieval. J. Discr. Alg. 18, 3–13 (2013)

4. Blum, M., Floyd, R.W., Pratt, V.R., Rivest, R.L., Tarjan, R.E.: Time bounds for

selection. J. Comp. Sys. Sci. 7(4), 448–461 (1973)

5. B¨uttcher, S., Clarke, C., Cormack, G.: Information Retrieval: Implementing and

Evaluating Search Engines. MIT Press (2010)

6. Culpepper, J.S., Navarro, G., Puglisi, S.J., Turpin, A.: Top-k ranked document
search in general text databases. In: de Berg, M., Meyer, U. (eds.) ESA 2010, Part
II. LNCS, vol. 6347, pp. 194–205. Springer, Heidelberg (2010)

7. Gagie, T., K¨arkk¨ainen, J., Navarro, G., Puglisi, S.J.: Colored range queries and

document retrieval. Theoretical Computer Science 483, 36–50 (2013)

404

G. Navarro and S.V. Thankachan

8. Grossi, R., Iacono, J., Navarro, G., Raman, R., Rao, S.S.: Encodings for range selection 
and top-k queries. In: Bodlaender, H.L., Italiano, G.F. (eds.) ESA 2013.
LNCS, vol. 8125, pp. 553–564. Springer, Heidelberg (2013)

9. Hon, W.-K., Patil, M., Shah, R., Wu, S.-B.: Eﬃcient index for retrieving top-k

most frequent documents. J. Discr. Alg. 8(4), 402–417 (2010)

10. Hon, W.-K., Shah, R., Thankachan, S.V., Vitter, J.S.: Document listing for queries
with excluded pattern. In: K¨arkk¨ainen, J., Stoye, J. (eds.) CPM 2012. LNCS,
vol. 7354, pp. 185–195. Springer, Heidelberg (2012)

11. Hon, W.-K., Shah, R., Thankachan, S., Vitter, J.: Faster compressed top-k document 
retrieval. In: Proc. 23rd DCC, pp. 341–350 (2013)

12. Hon, W.-K., Shah, R., Vitter, J.: Space-eﬃcient framework for top-k string retrieval

problems. In: Proc. 50th FOCS, pp. 713–722 (2009)

13. Hon, W.-K., Shah, R., Wu, S.-B.: Eﬃcient index for retrieving top-k most frequent 
documents. In: Karlgren, J., Tarhio, J., Hyyr¨o, H. (eds.) SPIRE 2009. LNCS,
vol. 5721, pp. 182–193. Springer, Heidelberg (2009)

14. Konow, R., Navarro, G.: Faster compact top-k document retrieval. In: Proc. 23rd

DCC, pp. 351–360 (2013)

15. Manber, U., Myers, G.: Suﬃx arrays: a new method for on-line string searches.

SIAM J. Comp. 22(5), 935–948 (1993)

16. Muthukrishnan, S.: Eﬃcient algorithms for document retrieval problems. In: Proc

13th SODA, pp. 657–666 (2002)

17. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Comp. Surv. 39(1),

art. 2 (2007)

18. Navarro, G., Nekrich, Y.: Top-k document retrieval in optimal time and linear

space. In: Proc. 23rd SODA, pp. 1066–1078 (2012)

19. Navarro, G., Puglisi, S.J., Valenzuela, D.: Practical compressed document retrieval.
In: Pardalos, P.M., Rebennack, S. (eds.) SEA 2011. LNCS, vol. 6630, pp. 193–205.
Springer, Heidelberg (2011)

20. Navarro, G., Thankachan, S.V.: Faster top-k document retrieval in optimal space.
In: Kurland, O., Lewenstein, M., Porat, E. (eds.) SPIRE 2013. LNCS, vol. 8214,
pp. 255–262. Springer, Heidelberg (2013)

21. Navarro, G., Valenzuela, D.: Space-eﬃcient top-k document retrieval. In: Klasing,

R. (ed.) SEA 2012. LNCS, vol. 7276, pp. 307–319. Springer, Heidelberg (2012)

22. Okanohara, D., Sadakane, K.: Practical entropy-compressed rank/select dictionary.

In: Proc. 9th ALENEX (2007)

23. Raman, R., Raman, V., Rao, S.S.: Succinct indexable dictionaries with applications
to encoding k-ary trees, preﬁx sums and multisets. ACM Trans. Alg. 3(4), art. 43
(2007)

24. Sadakane, K.: Succinct data structures for ﬂexible text retrieval systems. J. Discr.

Alg. 5, 12–22 (2007)

25. Sadakane, K., Navarro, G.: Fully-functional succinct trees. In: Proc. 21st SODA,

pp. 134–149 (2010)

26. Shah, R., Sheng, C., Thankachan, S.V., Vitter, J.S.: Top-k document retrieval in
external memory. In: Bodlaender, H.L., Italiano, G.F. (eds.) ESA 2013. LNCS,
vol. 8125, pp. 803–814. Springer, Heidelberg (2013)

27. Tsur, D.: Top-k document retrieval in optimal space. Inf. Proc. Lett. 113(12), 440–

443 (2013)

28. V¨alim¨aki, N., M¨akinen, V.: Space-eﬃcient algorithms for document retrieval. In:
Ma, B., Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 205–215. Springer,
Heidelberg (2007)

29. Weiner, P.: Linear pattern matching algorithm. In: Proc. 14th Annual IEEE Symposium 
on Switching and Automata Theory, pp. 1–11 (1973)

