7
1
0
2
 
c
e
D
5
1

 

 
 
]
S
D
.
s
c
[
 
 

3
v
0
5
5
2
0

.

8
0
5
1
:
v
i
X
r
a

Relative Suﬃx Trees

Andrea Farruggia1, Travis Gagie2,3, Gonzalo Navarro2,4,

Simon J. Puglisi5 and Jouni Sir´en6

1Department of Computer Science, University of Pisa.

2CeBiB – Center for Biotechnology and Bioengineering, Chile.

3EIT, Diego Portales University, Chile.

4Department of Computer Science, University of Chile, Chile.

5Department of Computer Science, University of Helsinki, Finland.

6Wellcome Trust Sanger Institute, United Kingdom.

Email: jouni.siren@iki.ﬁ

Suﬃx trees are one of the most versatile data structures in stringology, with
many applications in bioinformatics. Their main drawback is their size, which
can be tens of times larger than the input sequence. Much eﬀort has been
put into reducing the space usage, leading ultimately to compressed suﬃx trees.
These compressed data structures can eﬃciently simulate the suﬃx tree, while
using space proportional to a compressed representation of the sequence. In this
work, we take a new approach to compressed suﬃx trees for repetitive sequence
collections, such as collections of individual genomes. We compress the suﬃx
trees of individual sequences relative to the suﬃx tree of a reference sequence.
These relative data structures provide competitive time/space trade-oﬀs, being
almost as small as the smallest compressed suﬃx trees for repetitive collections,

and competitive in time with the largest and fastest compressed suﬃx trees.

1.

INTRODUCTION

is one of

The suﬃx tree [1]
the most powerful
bioinformatic tools to answer complex queries on DNA
and protein sequences [2, 3, 4]. A serious problem that
hampers its wider use on large genome sequences is
its size, which may be 10–20 bytes per character.
In
addition, the non-local access patterns required by most
interesting problems solved with suﬃx trees complicate
secondary-memory deployments. This problem has led
to numerous eﬀorts to reduce the size of suﬃx trees
by representing them using compressed data structures
[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], leading to
compressed suﬃx trees (CST). Currently, the smallest
CST is the so-called fully-compressed suﬃx tree (FCST)
[10, 14], which uses 5 bits per character (bpc) for
DNA sequences, but takes milliseconds to simulate
suﬃx tree navigation operations. In the other extreme,
Sadakane’s CST [5, 11] uses about 12 bpc and operates
in microseconds, and even nanoseconds for the simplest
operations.

A space usage of 12 bpc may seem reasonable to
handle, for example, one human genome, which has
about 3.1 billion bases:
it can be operated within
a RAM of 4.5 GB (the representation contains the
sequence as well). However, as the price of sequencing
has fallen, sequencing the genomes of a large number
of individuals has become a routine activity. The 1000

Genomes Project [18] sequenced the genomes of several
thousand humans, while newer projects can be orders
of magnitude larger. This has made the development of
techniques for storing and analyzing huge amounts of
sequence data ﬂourish.

Just storing 1000 human genomes using a 12 bpc
CST requires almost 4.5 TB, which is much more
than the amount of memory available in a commodity
server. Assuming that a single server has 256 GB
of memory, we would need a cluster of 18 servers to
handle such a collection of CSTs (compared to over 100
with classical suﬃx tree implementations!). With the
smaller (and much slower) FCST, this would drop to
7–8 servers. It is clear that further space reductions in
the representation of compressed suﬃx trees would lead
to reductions in hardware, communication, and energy
costs when implementing complex searches over large
genomic databases.

An important characteristic of those large genome
databases is that they usually consist of the genomes of
individuals of the same or closely related species. This
implies that the collections are highly repetitive, that
is, each genome can be obtained by concatenating a
relatively small number of substrings of other genomes
and adding a few new characters. When repetitiveness
is considered, much higher compression rates can be
obtained in compressed suﬃx trees. For example, it
is possible to reduce the space to 1–2 bpc (albeit with

2

A. Farruggia et al.

operation times in the milliseconds) [13], or to 2–3 bpc
with operation times in the microseconds [15]. Using
2 bpc, our 1000 genomes could be handled with just 3
servers with 256 GB of memory.

Compression algorithms best capture repetitiveness
by using grammar-based compression or Lempel-Ziv
compression.7
In the ﬁrst case [19, 20] one ﬁnds a
context-free grammar that generates (only) the text
collection. Rather than compressing the text directly,
the current CSTs for repetitive collections [13, 15] apply
grammar-based compression on the data structures that
simulate the suﬃx tree. Grammar-based compression
yields relatively easy direct access to the compressed
sequence [21], which makes it attractive compared
to Lempel-Ziv compression [22], despite the latter
generally using less space.

Lempel-Ziv compression cuts the collection into
phrases, each of which has already appeared earlier
in the collection. To extract the content of a phrase,
one may have to recursively extract the content at
that earlier position, following a possibly long chain
of indirections. So far, the indexes built on LempelZiv 
compression [23] or on combinations of Lempel-Ziv
and grammar-based compression [24, 25, 26] support
only pattern matching, which is just one of the wide
range of functionalities oﬀered by suﬃx trees. The high
cost to access the data at random positions lies at the
heart of the research on indexes built on Lempel-Ziv
compression.

A simple way out of this limitation is the socalled 
relative Lempel-Ziv (RLZ) compression [27],
where one of the sequences is represented in plain
form and the others can only take phrases from that
reference sequence. This enables immediate access
for the symbols inside any copied phrase (as no
transitive referencing exists) and, at least if a good
reference sequence has been found, oﬀers compression
competitive with the classical Lempel-Ziv. In our case,
taking any random genome per species as the reference
is good enough; more sophisticated techniques have
been studied [28, 29, 30]. Structures for direct access
[31, 32] and even for pattern matching [33] have been
developed on top of RLZ.

Another approach to compressing a repetitive
collection while supporting interesting queries is to
build an automaton that accepts the sequences in the
collection, and then index the state diagram as an
directed acyclic graph (DAG); see, for example, [34,
35, 36] for recent discussions. The ﬁrst data structure
to take this approach was the Generalized Compressed
Suﬃx Array (GCSA) [37, 36], which was designed for
pangenomics so queries can return information about
sequences not in the collection but that can be obtained
from those in the collection by recombination.

The FM-index of an alignment (FMA) [38, 39] is

7We refer to “long-range” repetitiveness, where similar texts

may be found far away in the text collection.

similar to the GCSA but indexes only the sequences in
the collection: whereas the GCSA conceptually embeds
the automaton in a de Bruijn graph, the FMA embeds
it in a coloured de Bruijn graph [40], preserving its
speciﬁcity. Both the GCSA and FMA are practical
but neither support the full functionality of a suﬃx
tree. The precursor to the FMA, the suﬃx tree of an
alignment (STA) [41, 42], allows certain disjunctions
in the suﬃx tree’s edge labels in order to reduce the
size of the tree while maintaining its functionality.
Unlike the FMA, however, the STA has not been
implemented. Both the STA and FMA divide the
sequences in the collection into regions of variation and
conserved regions, and depend on the conserved regions
being long enough that they can be distinguished from
each other and the variations. This dependency makes
these structures vulnerable to even a small change in
even one sequence to an otherwise-conserved region,
which could hamper their scalability.

1.1. One general CST or many individual CSTs

It is important to note that the existing techniques to
reduce the space of a collection of suﬃx trees on similar
texts build a structure that indexes the collection as a
whole, which is similar to concatenating all the texts
of the collection and building a single suﬃx tree on the
concatenation. As such, these structures do not provide
the same functionality of having an individual CST of
each sequence.

Exploiting the repetitiveness of a collection while
retaining separate index structures for each text has
only been achieved for a simpler pattern-matching
index, the suﬃx array [43], by means of the socalled 
relative FM-indexes [44]. The suﬃx array is a
component of the suﬃx tree.

Depending on the application, we may actually need
a single CST for the whole collection, or one for
In bioinformatics, a single CST is
each sequence.
more appropriate for search and discovery of motifs
across a whole population,
for example by looking
for approximate occurrences of a certain sequence
in the genomes of the population or by discovering
signiﬁcant sequences that appear in many individuals.
Other bioinformatic problems,
for example related
to the study of diseases,
inheritance patterns, or
forensics, boil down to searching or discovering patterns
in the genomes of
individuals, by ﬁnding common
approximate subsequences between two genomes, or
looking for
speciﬁc motifs or discovering certain
patterns in a single genome.

An example of recent research making use of the
relative storage of individual genomic datasets is how
Muggli et al. [45] (see also [46, 47]) adapted relative FMindexes 
to an FM-index variant that Bowe et al. [48] had
described for de Bruijn graphs, thus obtaining a spaceeﬃcient 
implementation of Iqbal et al.’s [49] coloured
de Bruijn graphs. These overlay de Bruijn graphs for

Relative Suffix Trees

3

many individuals to represent genetic variation in a
population.

1.2. Our contribution

In this paper, we develop a CST for
repetitive
collections by augmenting the relative FM-index with
structures based on RLZ. This turns out to be the
ﬁrst CST representation that takes advantage of the
repetitiveness of the texts in a collection while at the
same time oﬀering an individual CST for each such
text. Besides retaining the original functionality, such
an approach greatly simpliﬁes inserting and deleting
texts in the collection and implementing the index in
distributed form.

Our compressed suﬃx tree, called Relative Suﬃx Tree
(RST), follows a trend of CSTs [6, 7, 9, 8, 11, 13] that
use only a suﬃx array and an array with the length
of the longest common preﬁx between each suﬃx and
the previous one in lexicographic order (called LCP).
We use the relative FM-index as our suﬃx array, and
compress LCP using RLZ. On top of the RLZ phrases
we build a tree of range minima that enables fast range
minimum queries, as well as nextand 
previous-smallervalue 
queries, on LCP [13]. All the CST functionality
is built on those queries [6]. Our main algorithmic
contribution is this RLZ-based representation of the
LCP array with the required extra functionality.

On a collection of human genomes, our RST achieves
less than 3 bpc and operates within microseconds. This
performance is comparable to that of a previous CST
[15] (as explained, however, the RST provides a diﬀerent
functionality because it retains the individual CSTs).

2. BACKGROUND

A string S[1, n] = s1 . . . sn is a sequence of characters
over an alphabet Σ = {1, . . . , σ}.
For indexing
purposes, we often consider text strings T [1, n] that
are terminated by an endmarker T [n] = $ = 0 not
occurring elsewhere in the text. Binary sequences are
sequences over the alphabet {0, 1}. If B[1, n] is a binary
its complement is binary sequence B[1, n],
sequence,
with B[i] = 1 − B[i].

For any binary sequence B[1, n], we deﬁne the
subsequence S[B] of string S[1, n] as the concatenation
of the characters si with B[i] = 1. The complement
S[B] of subsequence S[B]
is the subsequence S[B].
Contiguous subsequences S[i, j] are called substrings.
Substrings of the form S[1, j] and S[i, n], i, j ∈ [1, n],
are called preﬁxes and suﬃxes, respectively. We deﬁne
the lexicographic order among strings in the usual way.

2.1. Full-text indexes

The suﬃx tree (ST) [1] of text T is a trie containing the
suﬃxes of T , with unary paths compacted into single
edges. Because the degree of every internal node is at
least two, there can be at most 2n − 1 nodes, and the

suﬃx tree can be stored in O(n log n) bits. In practice,
this is at least 10n bytes for small texts [50], and more
for large texts as the pointers grow larger.
If v is
a node of a suﬃx tree, we write π(v) to denote the
concatenation of the labels of the path from the root to
v.

Suﬃx arrays (SA) [43] were introduced as a spaceeﬃcient 
alternative to suﬃx trees. The suﬃx array
SAT [1, n] of text T is an array of pointers to the suﬃxes
of the text in lexicographic order.8 In its basic form,
the suﬃx array requires n log n bits in addition to the
text, but its functionality is more limited than that of
the suﬃx tree.
In addition to the suﬃx array, many
algorithms also use the inverse suﬃx array ISA[1, n],
with SA[ISA[i]] = i for all i.

(LCP) of

strings S1 and S2.

Let lcp(S1, S2) be the length of the longest common
The LCP
preﬁx
array [43] LCP[1, n] of text T stores the LCP lengths
for lexicographically adjacent suﬃxes of T as LCP[i] =
lcp(T [SA[i − 1], n], T [SA[i], n]) (with LCP[1] = 0). Let
v be an internal node of the suﬃx tree, (cid:96) = |π(v)| the
string depth of node v, and SA[sp, ep] the corresponding
suﬃx array interval. The following properties hold
for the lcp-interval LCP[sp, ep]:
i) LCP[sp] < (cid:96);
ii)
LCP[i] ≥ (cid:96) for all sp < i ≤ ep; iii) LCP[i] = (cid:96) for at
least one sp < i ≤ ep; and iv) LCP[ep + 1] < (cid:96) [51].

Abouelhoda et al. [51] showed how traversals on the
suﬃx tree could be simulated using the suﬃx array,
the LCP array, and a representation of the suﬃx tree
topology based on lcp-intervals, paving the way for more
space-eﬃcient suﬃx tree representations.

2.2. Compressed text indexes

Data structures supporting rank and select queries over
sequences are the main building blocks of compressed
text indexes. If S is a sequence, we deﬁne rankc(S, i)
as the number of occurrences of character c in the
preﬁx S[1, i], while selectc(S, j) is the position of the
occurrence of rank j in sequence S. A bitvector is
a representation of a binary sequence supporting fast
rank and select queries. Wavelet trees (WT) [52]
use bitvectors to support rank and select on general
sequences.

The Burrows-Wheeler transform (BWT) [53]

is a
reversible permutation BWT[1, n] of text T . It is deﬁned
as BWT[i] = T [SA[i] − 1] (with BWT[i] = T [n]
if
SA[i] = 1). Originally intended for data compression,
the Burrows-Wheeler transform has been widely used
in space-eﬃcient text indexes, because it shares the
combinatorial structure of the suﬃx tree and the suﬃx
array.
Let LF be a function such that SA[LF(i)] = SA[i] −
1 (with SA[LF(i)] = n if SA[i] = 1). We can
compute it as LF(i) = C[BWT[i]] + rankBWT[i](BWT, i),
where C[c] is the number of occurrences of characters
with lexicographical values smaller than c in BWT.

8We drop the subscript if the text is evident from the context.

4

A. Farruggia et al.

The inverse function of LF is Ψ, with Ψ(i) =
selectc(BWT, i − C[c]), where c is the largest character
value with C[c] < i. With functions Ψ and LF, we
can move forward and backward in the text, while
maintaining the lexicographic rank of the current suﬃx.
If the sequence S is not evident from the context, we
write LFS and ΨS.

Compressed suﬃx arrays (CSA) [54, 55, 56] are
text indexes supporting a functionality similar to the
suﬃx array. This includes the following queries:
i)
ﬁnd(P ) = [sp, ep] determines the lexicographic range of
suﬃxes starting with pattern P [1, (cid:96)]; ii) locate(sp, ep) =
SA[sp, ep] returns the starting positions of these suﬃxes;
and iii) extract(i, j) = T [i, j] extracts substrings of the
text. In practice, the ﬁnd performance of CSAs can be
competitive with suﬃx arrays, while locate queries are
orders of magnitude slower [57]. Typical index sizes are
less than the size of the uncompressed text.

The FM-index (FMI) [55]

is a common type of
compressed suﬃx array. A typical implementation [58]
stores the BWT in a wavelet tree [52]. The index
implements ﬁnd queries via backward searching. Let
[sp, ep] be the lexicographic range of the suﬃxes of
the text starting with suﬃx P [i + 1, (cid:96)] of the pattern.
We can ﬁnd the range matching suﬃx P [i, (cid:96)] with a
generalization of function LF as
LF([sp, ep], P [i]) = [C[P [i]] + rankP [i](BWT, sp−1)+1,

C[P [i]] + rankP [i](BWT, ep)].

We support locate queries by sampling some suﬃx
array pointers.
If we want to determine a value
SA[i] that has not been sampled, we can compute
it as SA[i] = SA[j] + k, where SA[j]
is a sampled
pointer found by iterating LF k times, starting from
position i. Given sample interval d, the samples can
be chosen in suﬃx order, sampling SA[i] at positions
divisible by d, or in text order, sampling T [i] at
positions divisible by d and marking the sampled SA
positions in a bitvector. Suﬃx-order sampling requires
less space, often resulting in better time/space tradeoﬀs 
in practice, while text-order sampling guarantees
better worst-case performance. We also sample the ISA
pointers for extract queries. To extract T [i, j], we ﬁnd
the nearest sampled pointer after T [j], and traverse
backwards to T [i] with function LF.

Compressed suﬃx trees (CST) [5] are compressed
functionality of a
text indexes supporting the full
suﬃx tree (see Table 1). They combine a compressed
suﬃx array, a compressed representation of the LCP
array, and a compressed representation of suﬃx tree
topology. For the LCP array, there are several common
representations:
•

LCP-byte [51] stores the LCP array as a byte array.
If LCP[i] < 255, the LCP value is stored in the
byte array. Larger values are marked with a 255
in the byte array and stored separately. As many

texts produce small LCP values, LCP-byte usually
requires n to 1.5n bytes of space.
• We can store the LCP array by using variablelength 
codes. LCP-dac uses directly addressable
codes [59] for the purpose, resulting in a structure
that is typically somewhat smaller and somewhat
slower than LCP-byte.
• The permuted LCP (PLCP) array [5] PLCP[1, n] is
the LCP array stored in text order and used as
LCP[i] = PLCP[SA[i]]. Because PLCP[i + 1] ≥
PLCP[i]−1, the array can be stored as a bitvector of
length 2n in 2n+o(n) bits. If the text is repetitive,
run-length encoding can be used to compress the
bitvector to take even less space [6]. Because
accessing PLCP uses locate, it is much slower than
the above two encodings.

followed by the encodings of

Suﬃx tree topology representations are the main
diﬀerence between the various CST proposals. While
the compressed suﬃx arrays and the LCP arrays are
interchangeable, the tree representation determines how
various suﬃx tree operations are implemented. There
are three main families of compressed suﬃx trees:
•

Sadakane’s compressed suﬃx tree (CST-Sada) [5]
uses a balanced parentheses
representation for
the tree. Each node is encoded as an opening
parenthesis,
its
children and a closing parenthesis. This can be
encoded as a bitvector of length 2n(cid:48), where n(cid:48) is
the number of nodes, requiring up to 4n + o(n)
bits. CST-Sada tends to be larger and faster than
the other compressed suﬃx trees [11, 13].
• The fully compressed suﬃx tree (FCST) of Russo
et al. [10, 14] aims to use as little space as possible.
It does not require an LCP array at all, and
stores a balanced parentheses representation for a
sampled subset of suﬃx tree nodes in o(n) bits.
Unsampled nodes are retrieved by following suﬃx
links. FCST is smaller and much slower than the
other compressed suﬃx trees [10, 13].

• Fischer

et al.

[6] proposed an intermediate
representation, CST-NPR, based on lcp-intervals.
Tree navigation is handled by searching for the
values deﬁning the lcp-intervals. Range minimum
queries rmq(sp, ep) ﬁnd the leftmost minimal value
in LCP[sp, ep], while next/previous smaller value
queries nsv(i)/psv(i) ﬁnd the next/previous LCP
value smaller than LCP[i]. After the improvements
by various authors [7, 9, 8, 11, 13], the CST-NPR is
perhaps the most practical compressed suﬃx tree.

For typical texts and component choices, the size of
compressed suﬃx trees ranges from the 1.5n to 3n bytes
of CST-Sada to the 0.5n to n bytes of FCST [11, 13].
There are also some CST variants for repetitive texts,
such as versioned document collections and collections
of individual genomes. Abeliuk et al. [13] developed
a variant of CST-NPR that can sometimes be smaller

Relative Suffix Trees

5

TABLE 1. Typical compressed suﬃx tree operations.

Operation

Description

Root()
Leaf(v)
Ancestor(v, w)

The root of the tree.
Is node v a leaf?
Is node v an ancestor of node w?

Count(v)
Locate(v)

Parent(v)
FChild(v)
NSibling(v)
LCA(v, w)

SDepth(v)
TDepth(v)
LAQS(v, d)
LAQT (v, d)
SLink(v)
SLinkk(v)
Child(v, c)
Letter(v, i)

Number of leaves in the subtree with v as the root.
Pointer to the suﬃx corresponding to leaf v.

The parent of node v.
The ﬁrst child of node v in alphabetic order.
The next sibling of node v in alphabetic order.
The lowest common ancestor of nodes v and w.
String depth: Length (cid:96) = |π(v)| of the label from the root to node v.
Tree depth: The depth of node v in the suﬃx tree.
The highest ancestor of node v with string depth at least d.
The ancestor of node v with tree depth d.
Suﬃx link : Node w such that π(v) = cπ(w) for a character c ∈ Σ.
Suﬃx link iterated k times.

The child of node v with edge label starting with character c.
The character π(v)[i].

than n bits, while achieving performance similar to the
FCST. Navarro and Ord´o˜nez [15] used grammar-based
compression for the tree representation of CST-Sada.
The resulting compressed suﬃx tree (GCT) requires
slightly more space than the CST-NPR of Abeliuk et
al., while being closer to the non-repetitive CST-Sada
and CST-NPR in performance.

2.3. Relative Lempel-Ziv

Relative Lempel-Ziv (RLZ) parsing [27] compresses
target sequence S relative to reference sequence R. The
target sequence is represented as a concatenation of z
phrases wi = (pi, (cid:96)i, ci), where pi is the starting position
of the phrase in the reference, (cid:96)i is the length of the
copied substring, and ci is the mismatch character. If
phrase wi starts from position p(cid:48) in the target, then
S[p(cid:48), p(cid:48) + (cid:96)i − 1] = R[pi, pi + (cid:96)i − 1] and S[p(cid:48) + (cid:96)i] = ci.
The shortest RLZ parsing of the target sequence can
be found in (essentially) linear time. The algorithm
builds a CSA for the reverse of the reference sequence,
and then parses the target sequence greedily by using
backward searching.
If the edit distance between the
reference and the target is s, we need at most s phrases
to represent the target sequence. On the other hand,
because the relative order of the phrases can be diﬀerent
in sequences R and S, the edit distance can be much
larger than the number of phrases in the shortest RLZ
parsing.

In a straightforward implementation,

the phrase
pointers pi and the mismatch characters ci can be stored
in arrays Wp and Wc. These arrays take z log|R| and
z log σ bits, respectively. To support random access to
the target sequence, we can encode phrase lengths as a
bitvector W(cid:96) of length |S| [27]: we set W(cid:96)[j] = 1 if S[j]
is the ﬁrst character of a phrase. The bitvector requires

z log n
z + O(z) bits if we use the sdarray representation
[60]. To extract S[j], we ﬁrst determine the phrase wi,
with i = rank1(W(cid:96), j).
If W(cid:96)[j + 1] = 1, we return
the mismatch character Wc[i]. Otherwise we determine
the phrase oﬀset with a select query, and return the
character R[Wp[i] + j − select1(W(cid:96), i)].

Ferrada et al.

[32] showed how, by using relative
pointers instead of absolute pointers, we can avoid
the use of select queries. They also achieved better
compression of DNA collections,
in which most of
the diﬀerences between the target sequences and the
reference sequence are single-character substitutions.
By setting Wr[i] = pi − select1(W(cid:96), i), the general
case simpliﬁes to S[j] = R[Wr[i] + j].
If most of the
diﬀerences are single-character substitutions, pi+1 will
often be pi+(cid:96)i+1. This corresponds to Wr[i+1] = Wr[i]
with relative pointers, making run-length encoding of
the pointer array worthwhile.

When we sort the suﬃxes in lexicographic order,
substitutions in the text move suﬃxes around, creating
insertions and deletions in the suﬃx array and related
structures. In the LCP array, an insertion or deletion
aﬀecting LCP[i] can also change the value of LCP[i + 1].
Hence RLZ with relative pointers is not enough to
compress the LCP array.

Cox et al. [61] modiﬁed Ferrada et al.’s version of RLZ
to handle other small variations in addition to singlecharacter 
substitutions. After adding a phrase to the
parse, we look ahead a bounded number of positions to
ﬁnd potential phrases with a relative pointer Wr[i] close
to the previous explicit relative pointer Wr[j].
If we
can ﬁnd a suﬃciently long phrase this way, we encode
the pointer diﬀerentially as Wr[i] − Wr[j]. Otherwise
we store Wr[i] explicitly. We can then save space by
storing the diﬀerential pointers separately using less bits

6

A. Farruggia et al.

per pointer. Because there can be multiple mismatch
characters between phrases i and i + 1, we also need
a preﬁx-sum data structure L for ﬁnding the range
Wc[a, b] containing the mismatches. Cox et al. showed
that their approach compresses both DNA sequences
and LCP arrays better than Ferrada et al.’s version,
albeit with slightly slower random access. We refer
the reader to their paper for more details of their
implementation.

3. RELATIVE FM-INDEX

The relative FM-index (RFM) [44]
is a compressed
suﬃx array of a sequence relative to the CSA of
another sequence. The index is based on approximating
the longest common subsequence (LCS) of BWTR and
BWTS, where R is the reference sequence and S is the
target sequence, and storing several structures based
on the common subsequence. Given a representation
of BWTR supporting rank and select, we can use the
relative index RFMS|R to simulate rank and select on
BWTS.

In this section, we describe the relative FM-index
using the notation and the terminology of this paper.
We also give an explicit description of the locate and
extract functionality, which was not included in the
original paper. Finally, we describe a more spaceeﬃcient 
variant of the algorithm for building a relative
FM-index with full functionality.

3.1. Basic index

lcs-positions,

Assume that we have found a long common subsequence
of sequences X and Y . We call positions X[i]
and Y [j]
if they are in the common
subsequence. If BX and BY are the binary sequences
marking the common subsequence (X[select1(BX , i)] =
Y [select1(BY , i)]), we can move between lcs-positions
in the two sequences with rank and select operations.
If X[i] is an lcs-position, the corresponding position in
sequence Y is Y [select1(BY , rank1(BX , i))]. We denote
this pair of lcs-bitvectors Align(X, Y ) = (cid:104)BX , BY (cid:105).

In its most basic form, the relative FM-index RFMS|R
only supports ﬁnd queries by simulating rank queries on
BWTS.
It does this by storing Align(BWTR, BWTS)
and the complements (subsequences of non-aligned
characters) Align(BWTR) and Align(BWTS).
The
lcs-bitvectors are
compressed using entropy-based
compression [62], while the complements are stored in
structures similar to the reference BWTR.

To compute rankc(BWTS, i), we ﬁrst determine the
number of lcs-positions in BWTS up to position S[i]
with k = rank1(BBWTS , i). Then we ﬁnd the lcs-position
k in BWTR with j = select1(BBWTR , k). With these
positions, we can compute

rankc(BWTS, i) = rankc(BWTR, j)

−rankc(Align(BWTR), j − k)
+rankc(Align(BWTS), i − k).

3.2. Relative select

We can implement
the entire functionality of a
compressed suﬃx array with rank queries on the BWT.
However, if we use the CSA in a compressed suﬃx tree,
we also need select queries to support forward searching
with Ψ and Child queries. We can always implement
select queries by binary searching with rank queries, but
the result will be much slower than the rank queries.

A faster alternative to support select queries in the
relative FM-index is to build a relative select structure
rselect [63]. Let FX be a sequence consisting of the
characters of sequence X in sorted order. Alternatively,
FX is a sequence such that FX [i] = BWTX [ΨX (i)].
The relative select structure consists of bitvectors
Align(FR, FS), where BFR [i] = BBWTR [ΨR(i)] and
BFS [i] = BBWTS [ΨS(i)], as well as the C array CLCS
for the common subsequence.

To compute selectc(BWTS, i), we ﬁrst determine how
many of the ﬁrst i occurrences of character c are lcspositions 
with k = rank1(BFS , CBWTS [c] + i) − CLCS[c].
Then we check from bit BFS [CBWTS [c] + i] whether
the occurrence we are looking for is an lcs-position
If it is, we ﬁnd the position in BWTR as
or not.
j = selectc(BWTR, select1(BFR , CLCS[c] + k) − CR[c]),
selectc(BWTS, i) by usand 
then map j
ing
we
with
ﬁnd
j = selectc(Align(BWTS), i − k),
and return
selectc(BWTS, i) = select0(BBWTS , j).

Align(BWTR, BWTS).
the

Align(BWTS)

Otherwise

to

occurrence

in

3.3. Full functionality

If we want the relative FM-index to support locate and
extract queries, we cannot build it from any common
subsequence of BWTR and BWTS. We need a bwtinvariant 
subsequence [44], where the alignment of the
BWTs is also an alignment of the original sequences.

Definition 3.1. Let X be a common subsequence of
BWTR and BWTS, and let BWTR[iR] and BWTS[iS] be
the lcs-positions corresponding to X[i]. Subsequence X
is bwt-invariant if

SAR[iR] < SAR[jR] ⇐⇒ SAS[iS] < SAS[jS]

for all positions i, j ∈ {1, . . . ,|X|}.

In addition to the structures already mentioned, the
full relative FM-index has another pair of lcs-bitvectors,
Align(R, S), which marks the bwt-invariant subsequence
in the original sequences. If BWTR[iR] and BWTS[iS]
are lcs-positions, we set BR[SAR[iR] − 1] = 1 and
BS[SAS[iS] − 1] = 1.9

To compute the answer to a locate(i) query, we
start by iterating BWTS backwards with LF queries,
until we ﬁnd an lcs-position BWTS[i(cid:48)] after k steps.
9For simplicity, we assume that the endmarker is not a part
of the bwt-invariant subsequence. Hence SA[i] > 1 for all lcspositions 
BWT[i].

Relative Suffix Trees

7

Then we map position i(cid:48) to the corresponding position
j(cid:48)
in BWTR by using Align(BWTR, BWTS). Finally
we determine SAR[j(cid:48)] with a locate query in the
reference index, and map the result to SAS[i(cid:48)] by using
Align(R, S).10 The result of the locate(i) query is
SAS[i(cid:48)] + k.

The ISAS[i] access required for extract queries is
supported in a similar way. We ﬁnd the lcs-position
for the smallest k ≥ 0, and map it to
S[i + k]
the corresponding position R[j] by using Align(R, S).
Then we determine ISAR[j + 1] by using the reference
index, and map it back to ISAS[i + k + 1] with
Align(BWTR, BWTS). Finally we iterate BWTS k + 1
steps backward with LF queries to ﬁnd ISAS[i].

If the target sequence contains long insertions not
present in the reference, we may also want to include
some SA and ISA samples for querying those regions.

3.4. Finding a bwt-invariant subsequence

With the basic relative FM-index, we approximate the
longest common subsequence of BWTR and BWTS
by partitioning the BWTs according to lexicographic
contexts, ﬁnding the longest common subsequence
for each pair of substrings in the partitioning, and
concatenating the results. The algorithm is fast, easy
to parallelize, and quite space-eﬃcient. As such,
RFM construction is practical, having been tested with
datasets of hundreds of gigabytes in size.

In the following, we describe a more space-eﬃcient
variant of the original algorithm [44] for ﬁnding a bwtinvariant 
subsequence. We
•
save space by simulating the mutual suﬃx array
SARS with CSAR and CSAS;
• match suﬃxes of R and S only if they are adjacent
•

in SARS; and
run-length encode the match arrays to save space.

Definition 3.2. Let R and S be two sequences, and
let SA = SARS and ISA = ISARS. The left match of
suﬃx R[i,|R|] is the suﬃx S[SA[ISA[i] − 1] − |R|,|S|],
if ISA[i] > 1 and SA[ISA[i] − 1] points to a suﬃx of S
(SA[ISA[i]−1] > |R|). The right match of suﬃx R[i,|R|]
is the suﬃx S[SA[ISA[i] + 1] − |R|,|S|], if ISA[i] < |RS|
and SA[ISA[i] + 1] points to a suﬃx of S.

We simulate the mutual suﬃx array SARS with
CSAR, CSAS, and the merging bitvector BR,S of length
|RS|. We set BR,S[i] = 1,
if SARS[i] points to a
suﬃx of S. The merging bitvector can be built in
O(|S| · tLF) time, where tLF is the time required for an
LF query, by extracting S from CSAS and backward
searching for it in CSAR [64]. Suﬃx R[i,|R|] has a left
(right) match, if BR,S[select0(BR,S, ISAR[i]) − 1] = 1
(BR,S[select0(BR,S, ISAR[i]) + 1] = 1)).

10If BWTS [i(cid:48)] and BWTR[j(cid:48)] are lcs-positions, the corresponding 
lcs-positions in the original sequences are S[SAS [i(cid:48)] − 1] and
R[SAR[j(cid:48)] − 1].

Our next step is building the match arrays left and
right, which correspond to the arrays A[·][2] and A[·][1]
in the original algorithm. This is done by traversing
CSAR backwards from ISAR[|R|] = 1 with LF queries
and following the left and the right matches of the
current suﬃx. During the traversal, we maintain the
invariant j = SAR[i] with (i, j) ← (LFR(i), j − 1).
If suﬃx R[j,|R|] has a left (right) match, we use
the shorthand l(j) = rank1(BR,S, select0(BR,S, i) − 1)
(r(j) = rank1(BR,S, select0(BR,S, i) + 1)) to refer to its
position in CSAS.
We say that suﬃxes R[j,|R|] and R[j + 1,|R|] have
the same left match if l(j) = LFS(l(j + 1)). Let
R[j,|R|] to R[j + (cid:96),|R|] be a maximal run of suﬃxes
having the same left match, with suﬃxes R[j,|R|] to
R[j + (cid:96) − 1,|R|] starting with the same characters as
their left matches.11 We ﬁnd the left match of suﬃx
R[j,|R|] as j(cid:48) = SAS[l(j)] by using CSAS, and set
left[j, j + (cid:96) − 1] = [j(cid:48), j(cid:48) + (cid:96) − 1]. The right match array
right is built in a similar way.
The match arrays require 2|R| log|S| bits of space. If
sequences R and S are similar, the runs in the arrays
tend to be long. Hence we can run-length encode
the match arrays to save space. The traversal takes
O(|R| · (tLF + trank + tselect) + rd · tLF) time, where trank
and tselect denote the time required by rank and select
operations, r is the number of runs in the two arrays,
and d is the suﬃx array sample interval in CSAS.12
The ﬁnal step is determining the bwt-invariant
subsequence. We ﬁnd a binary sequence BR[1,|R|],
which marks the common subsequence in R, and a
strictly increasing integer sequence Y , which contains
the positions of the common subsequence in S. This can
be done by ﬁnding the longest increasing subsequence
over R, where we consider both left[i] and right[i] as
candidates for the value at position i, and using the
If Y [j] comes from left[i]
found subsequence as Y .
(right[i]), we set BR[i] = 1, and align suﬃx R[i,|R|]
with its left (right) match S[Y [j],|S|]
in the bwtinvariant 
subsequence. We can ﬁnd BR and Y in
O(|R| log|R|) time with O(|R| log|R|) bits of additional
working space with a straightforward modiﬁcation
of the dynamic programming algorithm for ﬁnding
the longest increasing subsequence.
The dynamic
programming tables can be run-length encoded, but we
found that this did not yield good time/space trade-oﬀs.
As sequence Y is strictly increasing, we can convert it
into binary sequence BS[1,|S|], marking BS[Y [j]] = 1
for all j. Afterwards, we consider the binary sequences
BR and BS as the lcs-bitvectors Align(R, S). Because
every suﬃx of R starts with the same character as its
matches stored in the left and right arrays, subsequences
R[BR] and S[BS] are identical.

For any i,

let iR = select1(BR, i) and iS =
select1(BS, i) be the lcs-positions of rank i. As suﬃxes

11The ﬁrst character of a suﬃx can be determined by using the

C array.

12The time bound assumes text-order sampling.

A. Farruggia et al.

8
R[iR,|R|] and S[iS,|S|] are aligned in the bwt-invariant
subsequence, they are also adjacent in the mutual suﬃx
array SARS. Hence

ISAR[iR] < ISAR[jR] ⇐⇒ ISAS[iS] < ISAS[jS]

for 1 ≤ i, j ≤ |Y |, which is equivalent to the condition
in Deﬁnition 3.1. We can convert Align(R, S) to
Align(BWTR, BWTS) in O((|R| + |S|) · tLF) time by
traversing CSAR and CSAS backwards. The resulting
subsequence of BWTR and BWTS is bwt-invariant.

Note that the full relative FM-index is more limited
than the basic index, because it does not handle
substring moves very well. Let R = xy and S = yx,
for two random sequences x and y of length n/2 each.
Because BWTR and BWTS are very similar, we can
expect to ﬁnd a common subsequence of length almost
n. On the other hand, the length of the longest bwtinvariant 
subsequence is around n/2, because we can
either match the suﬃxes of x or the suﬃxes of y in R
and S, but not both.

4. RELATIVE SUFFIX TREE

The relative suﬃx tree (RST) is a CST-NPR of the target
sequence relative to a CST of the reference sequence.
It consists of two major components:
the relative
FM-index with full functionality and the relative LCP
(RLCP) array. The optional relative select structure can
be generated or loaded from disk to speed up algorithms
based on forward searching. The RLCP array is based on
RLZ parsing, while the support for nsv/psv/rmq queries
is based on a minima tree over the phrases.

4.1. Relative LCP array

Given LCP array LCP[1, n], we deﬁne the diﬀerential
LCP array DLCP[1, n] as DLCP[1] = LCP[1] and
DLCP[i] = LCP[i] − LCP[i − 1] for i > 1. If BWT[i, j] =
cj+1−i for some c ∈ Σ, then LCP[LF(i) + 1, LF(j)] is the
same as LCP[i + 1, j], with each value incremented by 1
[6]. This means DLCP[LF(i)+2, LF(j)] = DLCP[i+2, j],
making the DLCP array of a repetitive text compressible
with grammar-based compression [13].

We make a similar observation in the relative setting.
If target sequence S is similar to the reference sequence
R, then their LCP arrays should also be similar. If there
are long identical ranges LCPR[i, i + k] = LCPS[j, j + k],
the corresponding DLCP ranges DLCPR[i + 1, i + k] and
DLCPS[j + 1, j + k] are also identical. Hence we can use
RLZ parsing to compress either the original LCP array
or the DLCP array.

While the identical ranges are a bit longer in the LCP
array, we opt to compress the DLCP array, because it
behaves better when there are long repetitions in the
sequences. In particular, assembled genomes often have
long runs of character N , which correspond to regions
of very large LCP values.
If the runs are longer in
the target sequence than in the reference sequence, the

RLZ parsing of the LCP array will have many mismatch
characters. The corresponding ranges in the DLCP
array typically consist of values {−1, 0, 1}, making them
much easier to compress.

We consider DLCP arrays as strings over an integer
alphabet and create an RLZ parsing of DLCPS relative
to DLCPR. After parsing, we switch to using LCPR as
the reference. The reference is stored in a structure we
call slarray, which is a variant of LCP-byte. [51]. Small
values LCPR[i] < 255 are stored in a byte array, while
large values LCPR[i] ≥ 255 are marked with a 255 in the
byte array and stored separately. To quickly ﬁnd the
large values, we also build a rank255 structure over the
byte array. The slarray provides reasonably fast random
access and fast sequential access to the underlying array.
The RLZ parsing produces a sequence of phrases
wi = (pi, (cid:96)i, ci) (see Section 2.3; since we are using
Cox et al.’s version, ci is now a string). Because some
queries involve decompressing an entire phrase, we limit
the maximum phrase length to 1024. We also require
that |ci| > 0 for all i, using the last character of the
copied substring as a mismatch if necessary.

Phrase lengths are encoded in the W(cid:96) bitvector in the
usual way. We convert the strings of mismatching DLCP
values ci into strings of absolute LCP values, append
them into the mismatch array Wc, and store the array
as an slarray. The mismatch values are used as absolute
samples for the diﬀerential encoding.

To access LCPS[j], we determine the phrase wi as
usual, and check whether we should return a mismatch
character. If so, we compute which one using a preﬁx
If not, we determine
sum query on L, and return it.
the starting positions pi and si of the phrase wi
in
the reference and the target, respectively. We can then
compute the solution as

LCPS[j] = LCPS[si − 1] +

DLCPS[k]

j(cid:88)
j(cid:48)(cid:88)

k=si

k=pi

DLCPR[k]

= LCPS[si − 1] +
= LCPS[si − 1] + LCPR[j(cid:48)] − LCPR[pi − 1],
where j(cid:48) = pi + j − si. Each RLZ phrase ends with at
least one mismatch character, so LCPS[si − 1] is readily
available. After ﬁnding LCPS[j], accessing LCPS[j − 1]
and LCPS[j +1] is fast, as long as we do not cross phrase
boundaries.

reference
Example. Figure 1 shows an example
sequence S, with their
sequence R and target
corresponding arrays SA, LCP, and DLCP. The single
edit at S[4] with respect to R[4] may aﬀect the positions
of suﬃxes 4 and previous ones in SA, although in general
only a limited number of preceding suﬃxes are aﬀected.
In our example, suﬃx 4 moves from position 7 in SAR to
position 4 in SAS, and suﬃx 3 moves from position 11

Relative Suffix Trees

9

We encode the minima tree as two arrays. The
smallest LCP values are stored in MLCP, which we
encode as an slarray.
Plain array ML stores the
starting oﬀset of each level in MLCP, with the leaves
stored starting from oﬀset ML[1] = 1.
If i is a
minima tree node located at level j, the corresponding
minimum value is MLCP[i], the parent of the node is
ML[j + 1] + (cid:98)(i − ML[j])/64(cid:99), and its ﬁrst child is
ML[j − 1] + 64 · (i − ML[j]).

A range minimum query rmq(sp, ep) starts by ﬁnding
the minimal range of phrases wl, . . . , wr covering the
query and the maximal range of phrases wl(cid:48), . . . , wr(cid:48)
contained in the query (note that l ≤ l(cid:48) ≤ l + 1 and
r − 1 ≤ r(cid:48) ≤ r). We then use the minima tree to ﬁnd
the leftmost minimum value j = MLCP[k] in MLCP[l(cid:48), r(cid:48)],
and ﬁnd the leftmost occurrence LCP[i] = j in phrase
wk. If l < l(cid:48) and MLCP[l] ≤ j, we decompress phrase
wl and ﬁnd the leftmost minimum value LCP[i(cid:48)] = j(cid:48)
(with i(cid:48) ≥ sp) in the phrase.
If j(cid:48) ≤ j, we update
(i, j) ← (i(cid:48), j(cid:48)). Finally we check phrase wr in a similar
way, if r > r(cid:48) and MLCP[r] < j. The answer to the range
minimum query is LCP[i] = j, so we return (i, j).13
Finally, the particular case where no phrase is contained
in [sp, ep] is handled by sequentially scanning one or two
phrases in LCP.

The remaining queries are all similar to each other.
In order to answer query nsv(i), we start by ﬁnding the
phrase wk containing position i, and then determining
LCP[i]. Next we scan the rest of the phrase to see
whether there is a smaller value LCP[j] < LCP[i] later
in the phrase. If so, we return (j, LCP[j]). Otherwise
we traverse the minima tree to ﬁnd the smallest k(cid:48) > k
with MLCP[k(cid:48)] < LCP[i]. We decompress phrase wk(cid:48),
ﬁnd the leftmost position j with LCP[j] < LCP[i], and
return (j, LCP[j]).

5. EXPERIMENTS

We have implemented the relative suﬃx tree in C++,
extending the old relative FM-index implementation.14
The implementation is based on the Succinct Data
Structure Library (SDSL) 2.0 [65]. Some parts of the
implementation have been parallelized using OpenMP
and the libstdc++ parallel mode.

As our

reference CSA, we used the

succinct
suﬃx array (SSA) [58, 66] implemented using SDSL
components. Our implementation is very similar to
csa wt in SDSL, but we needed better access to the
internals than what the SDSL interface provides. SSA
encodes the Burrows-Wheeler transform as a Huﬀmanshaped 
wavelet tree, combining fast queries with size
close to the order-0 empirical entropy. This makes it
the index of choice for DNA sequences [57]. In addition

13The deﬁnition of the query only calls for the leftmost
minimum position i. We also return LCP[i] = j, because suﬃx
tree operations often need it.

14The current implementation is available at https://github.

com/jltsiren/relative-fm.

FIGURE 1. An example of our RLZ compression of DLCP.

in SAR to position 10 in SAS. Each suﬃx that is moved
from SAR[i] to SAS[j] may alter the values at positions
i or i + 1 (depending on whether j > i or j < i), as
well as j and j + 1, of LCPS. We have surrounded
in rectangles the conserved regions in LCPS (some are
conserved by chance). Even some suﬃxes that are not
moved may change their LCP values.
In turn, each
change in LCPS[k] may change values DLCPS[k] and
DLCPS[k + 1].

(with the copied symbols

After the change, we can parse DLCPS into three
phrases
surrounded by
(1, 4, 0), (5, 3,−2), (6, 2,−2), where the
rectangles):
latter is formed by chance. We represent this parsing
as Wc = (cid:104)1, 0, 0(cid:105) (since we store the absolute LCPS
values for the mismatches), W(cid:96) = 100001000100, and
Wp = (cid:104)1, 5, 6(cid:105) (or rather Wr = (cid:104)0,−1,−4(cid:105)).

Let us compute LCPS[j] for j = 8. This corresponds
to phrase number i = rank(W(cid:96), j) = 2, which starts
at position si = select(W(cid:96), i) = 6 in LCPS. The
corresponding position in LCPR is pi = Wp[i] = 5 (or
rather pi = si+Wr[i] = 5), and the mapped position j is
j(cid:48) = pi+j−si = 7. Finally, LCPS[si−1] = Wc[i−1] = 1.
According to our formula, then, we have LCPS[8] =
LCPS[si − 1] + LCPR[j(cid:48)]− LCPR[pi − 1] = 1 + 2− 1 = 2.

4.2. Supporting nsv/psv/rmq queries

Suﬃx tree topology can be inferred from the LCP array
with range minimum queries (rmq) and next/previous
smaller value (nsv/psv) queries [6].
Some suﬃx
tree operations are more eﬃcient if we also support
next/previous smaller or equal value (nsev/psev) queries
[13]. Query nsev(i) (psev(i)) ﬁnds the next (previous)
value smaller than or equal to LCP[i].

In order to support the queries, we build a 64ary 
minima tree over the phrases of the RLZ parsing.
Each leaf node stores the smallest LCP value in the
corresponding phrase, while each internal node stores
the smallest value in the subtree.
Internal nodes are
created and stored in a levelwise fashion, so that each
internal node, except perhaps the rightmost one of each
level, has 64 children.

ACGCGATCACG$R = ACGGATCACG$S = A12346789012151234678901215SA =LCP =DLCP =12912117031010031−21−246103510120−11−221SA =LCP =DLCP =0311−2−11−20−10310120110201291684211537108000010

A. Farruggia et al.

to the plain SSA with uncompressed bitvectors, we also
used SSA-RRR with entropy-compressed bitvectors [62]
to highlight the the time-space trade-oﬀs achieved with
better compression

We sampled SA in suﬃx order and ISA in text order.
In SSA, the sample intervals were 17 for SA and 64
for ISA. In RFM, we used sample interval 257 for SA
and 512 for ISA to handle the regions that do not exist
in the reference. The sample intervals for suﬃx order
sampling were primes due to the long runs of character
N in the assembled genomes.
If the number of long
runs of character N in the indexed sequence is even,
the lexicographic ranks of almost all suﬃxes in half of
the runs are odd, and those runs are almost completely
unsampled. This can be avoided by making the sample
interval and the number of runs relatively prime.

The experiments were done on a system with two
16-core AMD Opteron 6378 processors and 256 GB of
memory. The system was running Ubuntu 12.04 with
Linux kernel 3.2.0. We compiled all code with g++
version 4.9.2. We allowed index construction to use
multiple threads, while conﬁning the query benchmarks
to a single thread. As AMD Opteron uses a nonuniform 
memory access architecture, accessing local
memory controlled by the same physical CPU is faster
than accessing remote memory controlled by another
CPU. In order to ensure that all data structures are
in local memory, we set the CPU aﬃnity of the query
benchmarks with the taskset utility.

As our target sequence, we used the maternal
haplotypes of the 1000 Genomes Project individual
NA12878 [67]. As the reference sequence, we used the
1000 Genomes Project version of the GRCh37 assembly
of the human reference genome.15 Because NA12878
is female, we also created a reference sequence without
chromosome Y.

In the following, a basic FM-index is an index
supporting only ﬁnd queries, while a full index also
supports locate and extract queries.

and 4.6––5.3 times smaller than the full SSA. The
RLCP array is 2.7 times larger than the RFM index
with the full human reference and 1.5 times larger
with the female reference. Hence having a separate
female reference is worthwhile, if there are more than a
few female genomes among the target sequences. The
optional rselect structure is almost as large as the basic
RFM index.

Table 4 lists the sizes of the individual components
of the relative FM-index. Including the chromosome Y
in the reference increases the sizes of almost all relative
components, with the exception of Align(BWTS) and
Align(R, S). In the ﬁrst case, the common subsequence
still covers approximately the same positions in BWTS
as before. In the second case, chromosome Y appears in
bitvector BR as a long run of 0-bits, which compresses
well. The components of a full RFM index are larger
than the corresponding components of a basic RFM
index, because the bwt-invariant subsequence is shorter
than the approximate longest common subsequence (see
Table 2).

The size breakdown of the RLCP array can be seen in
Table 5. Phrase pointers and phrase lengths take space
proportional to the number of phrases. As there are
more mismatches between the copied substrings with
the full human reference than with the female reference,
the absolute LCP values take a larger proportion of
the total space with the full reference. Shorter phrase
length increases the likelihood that the minimal LCP
value in a phrase is a large value, increasing the size of
the minima tree.

In order to use relative data structures, we also need
to have the reference data structures in memory. The
basic SSA used by the basic RFM takes 1283 MB with
chromosome Y and 1248 MB without, while the full
SSA used by the full RFM takes 2162 MB and 2110 MB,
respectively. The reference LCP array used by the RLCP
array requires 3862 MB and 3690 MB with and without
chromosome Y.

5.1.

Indexes and their sizes

5.2. Query times

Table 2 lists the resource requirements for building
the relative indexes, assuming that we have already
built the corresponding non-relative structures for the
sequences. As a comparison, building an FM-index for
a human genome typically takes 16–17 minutes and 25–
26 GB of memory. While the construction of the basic
RFM index is highly optimized, the other construction
algorithms are just the ﬁrst implementations. Building
the optional rselect structures takes 4 minutes using two
threads and around 730 megabytes (|R| + |S| bits) of
working space in addition to RFM and rselect.

The sizes of the ﬁnal indexes are listed in Table 3.
The full RFM is over twice the size of the basic index,
but still 3.3––3.7 times smaller than the full SSA-RRR

15ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/

reference/

Average query times for the basic operations can be seen
in Tables 6 and 7. The results for LF and Ψ queries in
the full FM-indexes are similar to the earlier ones with
basic indexes [63]. Random access to the RLCP array
is about 30 times slower than to the LCP array, while
sequential access is 10 times slower. The nsv, psv, and
rmq queries are comparable to 1–2 random accesses to
the RLCP array.

We also tested the locate performance of the full RFM
index, and compared it to SSA and SSA-RRR. We built
the indexes with SA sample intervals 7, 17, 31, 61,
and 127, using the reference without chromosome Y for
RFM.16 The ISA sample interval was the maximum of
64 and the SA sample interval. We extracted 2 million
random patterns of length 32, consisting of characters

16With RFM, the sample intervals apply to the reference SSA.

Relative Suffix Trees

11

TABLE 2. Sequence lengths and resources used by index construction for NA12878 relative to the human reference genome
with and without chromosome Y. Approx and Inv denote the approximate LCS and the bwt-invariant subsequence. Sequence
lengths are in millions of base pairs, while construction resources are in minutes of wall clock time and gigabytes of memory.

Sequence length

RFM (basic)

RFM (full)

RST

ChrY Reference Target Approx

Inv

3036M 2992M 2980M 1.42 min 4.41 GB 175 min 84.0 GB 629 min
3036M 2991M 2980M 1.33 min 4.38 GB 173 min 82.6 GB 593 min

Time Memory Time Memory Time Memory
141 GB
142 GB

yes
no

3096M
3036M

TABLE 3. Various indexes for NA12878 relative to the human reference genome with and without chromosome Y. The total
for RST includes the full RFM. Index sizes are in megabytes and in bits per character.

SSA

SSA-RRR

RFM

RST
Total

ChrY Basic

Full

Full

Full

Basic

rselect
1248 MB 2110 MB 636 MB 1498 MB 225 MB 456 MB 1233 MB 1689 MB 190 MB
3.45 bpc 5.83 bpc 1.76 bpc 4.14 bpc 0.62 bpc 1.26 bpc 3.41 bpc 4.67 bpc 0.52 bpc
1248 MB 2110 MB 636 MB 1498 MB 186 MB 400 MB 597 MB 997 MB 163 MB
3.45 bpc 5.83 bpc 1.76 bpc 4.14 bpc 0.51 bpc 1.11 bpc 1.65 bpc 2.75 bpc 0.45 bpc

RLCP

Basic

yes

no

ACGT , from the target sequence, and measured the
total time taken by ﬁnd and locate queries. The results
can be seen in Figure 2. While SSA and SSA-RRR
query times were proportional to the sample interval,
RFM used 5.4–7.6 microseconds per occurrence more
than SSA, resulting in slower growth in query times.
In particular, RFM with sample interval 31 was faster
than SSA with sample interval 61. As the locate
performance of the RFM index is based on the sample
interval in the reference, it is generally best to use dense
sampling (e.g. 7 or 17), unless there are only a few target
sequences.

5.3. Synthetic collections

In order to determine how the diﬀerences between the
reference sequence and the target sequence aﬀect the
size of relative structures, we built RST for various
synthetic datasets. We took a 20 MB preﬁx of the
human reference genome as the reference sequence,
and generated 25 target sequences with every mutation
rate p ∈ {0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1}. A
total of 90% of the mutations were single-character
substitutions, while 5% were insertions and another 5%
deletions. The length of an insertion or deletion was
k ≥ 1 with probability 0.2 · 0.8k−1.

The results can be seen in Figure 3 (left). The
size of the RLCP array grew quickly with increasing
mutation rates, peaking at p = 0.01. At that point,
the average length of an RLZ phrase was comparable to
what could be found in the DLCP arrays of unrelated
DNA sequences. With even higher mutation rates,
the phrases became slightly longer due to the smaller
average LCP values. The RFM index, on the other
hand, remained small until p = 0.003. Afterwards, the
index started growing quickly, eventually overtaking the

RLCP array.

We also compared the size of the relative suﬃx
tree to GCT [15], which is essentially a CST-Sada
for repetitive collections. While the structures are
intended for diﬀerent purposes, the comparison shows
how much additional space is used for providing access
to the suﬃx trees of individual datasets. We chose to
skip the CST-NPR for repetitive collections [13], as its
implementation was not stable enough.

Figure 3 (right) shows the sizes of the compressed
suﬃx trees. The numbers for RST include individual
indexes for each of the 25 target sequences as well
as the reference data, while the numbers for GCT are
for a single index containing the 25 sequences. With
low mutation rates, RST was not much larger than
GCT. The size of RST starts growing quickly at around
p = 0.001, while the size of GCT stabilizes at 3–4 bpc.

5.4. Suﬃx tree operations

In the ﬁnal set of experiments, we compared the
performance of RST to the SDSL implementations of
various compressed suﬃx trees. We used the maternal
haplotypes of NA12878 as the target sequence and
the human reference genome without chromosome Y
as the reference sequence. We built RST, CST-Sada,
CST-NPR, and FCST for the target sequence. CST-Sada
uses Sadakane’s compressed suﬃx array (CSA-Sada)
[54] as its CSA, while the other SDSL implementations
use SSA. We used PLCP as the LCP encoding with both
CST-Sada and CST-NPR, and also built CST-NPR with
LCP-dac.

We used three algorithms

comparison.
traversal of
(cst dfs const forward iterator).

the performance
preorder
the suﬃx tree using SDSL iterators
The iterators

algorithm is

The ﬁrst

for

12

A. Farruggia et al.

TABLE 4. Breakdown of component sizes in the RFM index for NA12878 relative to the human reference genome with and
without chromosome Y in bits per character.

Basic RFM
no

yes

Full RFM

yes

no

ChrY
RFM

Align(BWTR)
Align(BWTS)

0.62 bpc 0.51 bpc 1.26 bpc 1.11 bpc
0.06 bpc
0.12 bpc
0.06 bpc
0.05 bpc
Align(BWTR, BWTS) 0.45 bpc
0.45 bpc
0.35 bpc
0.12 bpc
0.06 bpc

0.14 bpc
0.06 bpc
0.52 bpc
0.35 bpc
0.12 bpc
0.06 bpc

Align(R, S)
SA samples
ISA samples

–
–
–

0.05 bpc
0.05 bpc
0.42 bpc

–
–
–

TABLE 5. Breakdown of component sizes in the RLCP array for NA12878 relative to the human reference genome with
and without chromosome Y. The number of phrases, average phrase length, and the component sizes in bits per character.
“Parse” contains Wr and W(cid:96), “Literals” contains Wc and L, and “Tree” contains MLCP and ML.

ChrY Phrases Length Parse Literals Tree

Total

yes
no

128 million
94 million

23.6
32.3

1.35 bpc 1.54 bpc 0.52 bpc 3.41 bpc
0.97 bpc 0.41 bpc 0.27 bpc 1.65 bpc

use operations Root, Leaf, Parent, FChild, and NSibling,
though Parent queries are rare, as the iterators cache
the most recent parent nodes.

The other two algorithms ﬁnd the maximal substrings
of the query string occurring in the indexed text, and
report the lexicographic range for each such substring.
This is a key task in common problems such as
computing matching statistics [68] or ﬁnding maximal
exact matches. The forward algorithm uses Root,
SDepth, SLink, Child, and Letter, while the backward
algorithm [69] uses LF, Parent, and SDepth.

We used the paternal haplotypes of chromosome 1 of
NA12878 as the query string in the maximal substrings
algorithms. Because some tree operations in the SDSL
compressed suﬃx trees take time proportional to the
depth of the current node, we truncated the runs of
character N in the query string into a single character.
Otherwise searching in the deep subtrees would have
made some SDSL suﬃx trees much slower than RST.

The results can be seen in Table 8. RST was 1.8 times
smaller than FCST and several times smaller than the
other compressed suﬃx trees. In depth-ﬁrst traversal,
RST was 4 times slower than CST-NPR and about
15 times slower than CST-Sada. FCST was orders of
magnitude slower, managing to traverse only 5.3% of
the tree before the run was terminated after 24 hours.
It should be noted that the memory access patterns
of traversing CST-Sada, CST-NPR, and RST are highly
local. Traversal times are mostly based on the amount
of computation done, while memory latency is less
important than in the individual query benchmarks.
In RST, the algorithm is essentially the following:
1) compute rmq in the current range; 2) proceed

recursively to the left subinterval; and 3) proceed to
the right subinterval. This involves plenty of redundant
work, as can be seen by comparing the traversal time
(0.90 s per node) to sequential RLCP access (0.017 s
per position). A faster algorithm would decompress
large parts of the LCP array at once, build the
corresponding subtrees in postorder [51], and traverse
the resulting trees.

RST with rselect is as fast as CST-Sada in the forward
algorithm, 1.8–2.7 times slower than CST-NPR, and
4.1 times faster than FCST. Without the additional
structure, RST becomes 2.6 times slower. As expected
[69], the backward algorithm is much faster than the
forward algorithm. CST-Sada and RST, which combine
slow backward searching with a fast tree, have similar
performance to FCST, which combines fast searching
CST-NPR is about an order of
with a slow tree.
magnitude faster than the others in the backward
algorithm.

6. DISCUSSION

We have introduced relative suﬃx trees (RST), a new
kind of compressed suﬃx tree for repetitive sequence
collections. Our RST compresses the suﬃx tree of
an individual sequence relative to the suﬃx tree of
a reference sequence.
It combines an already known
relative suﬃx array with a novel relative-compressed
longest common preﬁx representation (RLCP). When
the sequences are similar enough (e.g., two human
genomes), the RST requires about 3 bits per symbol on
each target sequence. This is close to the space used by
the most space-eﬃcient compressed suﬃx trees designed
to store repetitive collections in a single tree, but the

Relative Suffix Trees

13

TABLE 6. Average query times in microseconds for 10 million random queries in the full SSA, the full SSA-RRR, and the
full RFM for NA12878 relative to the human reference genome with and without chromosome Y.

SSA

ChrY

LF

Ψ

SSA-RRR
Ψ

LF

RFM

LF

Ψ

rselect

Ψ

yes
no

0.328 s 1.048 s 1.989 s 2.709 s 3.054 s 43.095 s 5.196 s
0.327 s 1.047 s 1.988 s 2.707 s 2.894 s 40.478 s 5.001 s

TABLE 7. Query times in microseconds in the LCP array (slarray) and the RLCP array for NA12878 relative to the human
reference genome with and without chromosome Y. For the random queries, the query times are averages over 100 million
queries. The range lengths for the rmq queries were 16k (for k ≥ 1) with probability 0.5k. For sequential access, we list the
average time per position for scanning the entire array.

LCP array

RLCP array

ChrY Random Sequential Random Sequential

nsv

psv

rmq

yes
no

0.054 s
0.054 s

0.002 s
0.002 s

1.580 s
1.480 s

0.024 s
0.017 s

1.909 s 1.899 s 2.985 s
1.834 s 1.788 s 3.078 s

RST provides a diﬀerent functionality as it indexes each
sequence individually. The RST supports query and
navigation operations within a few microseconds, which
is competitive with the largest and fastest compressed
suﬃx trees.

The size of RST is proportional to the amount of
sequence that is present either in the reference or in
the target, but not both. This is unusual for relative
compression, where any additional material
in the
reference is generally harmless. Sorting the suﬃxes in
lexicographic tends to distribute the additional suﬃxes
all over the suﬃx array, creating many mismatches
between the suﬃx-based structures of the reference
and the target. For example, the 60 million suﬃxes
from chromosome Y created 34 million new phrases
in the RLZ parse of the DLCP array of a female
genome, doubling the size of the RLCP array. Having
multiple references (e.g. male and female) can hence be
worthwhile when building relative data structures for
many target sequences.

Most

some of

While our RST implementation provides competitive
time/space trade-oﬀs, there is still much room for
improvement.
the
construction algorithms require signiﬁcant amounts of
time and memory.
In many places, we have chosen
simple and fast implementation options, even though
there could be alternatives that require signiﬁcantly less
space without being too much slower.

importantly,

Our RST is a relative version of the CST-NPR.
Another alternative for future work is a relative
CST-Sada, using RLZ compressed bitvectors for suﬃx
tree topology and PLCP.

FUNDING

This work was supported by Basal Funds FB0001,
Conicyt, Chile; Fondecyt Grant [1-170048], Chile;

Academy of Finland grants [258308] and [250345]
(CoECGR); the Jenny and Antti Wihuri Foundation,
Finland; and the Wellcome Trust grant [098051].

REFERENCES

[1] Weiner, P. (1973) Linear pattern matching algorithms.
Proceedings SWAT (FOCS) 1973, Iowa City, IA, 15–17
October, pp. 1–11. IEEE.

[2] Gusﬁeld, D. (1997) Algorithms on Strings, Trees
and Sequences: Computer Science and Computational
Biology. Cambridge University Press, Cambridge, UK.
[3] Ohlebusch, E. (2013) Bioinformatics Algorithms: Sequence 
Analysis, Genome Rearrangements, and Phylogenetic 
Reconstruction. Oldenbusch Verlag, Germany.
[4] M¨akinen, V., Belazzougui, D., Cunial, F., and
Tomescu, A. I. (2015) Genome-Scale Algorithm Design.
Cambridge University Press, Cambridge, UK.

[5] Sadakane, K. (2007) Compressed suﬃx trees with full
functionality. Theory of Computing Systems, 41, 589–
607.

[6] Fischer, J., M¨akinen, V., and Navarro, G. (2009) Faster
entropy-bounded compressed suﬃx trees. Theoretical
Computer Science, 410, 5354–5364.

[7] Ohlebusch, E. and Gog, S. (2009) A compressed
enhanced suﬃx array supporting fast string matching.
Proceedings of SPIRE 2009, Saariselk¨a, Finland, 25–27
August, pp. 51–62. Springer, Berlin, Germany.

[8] Ohlebusch, E., Fischer, J., and Gog, S. (2010) CST++.
Proceedings of SPIRE 2010, Los Cabos, Mexico, 11–13
October, pp. 322–333. Springer, Berlin, Germany.

[9] Fischer, J. (2010) Wee LCP.

Information Processing

Letters, 110, 317–320.

[10] Russo, L. M. S., Navarro, G., and Oliveira, A. L. (2011)
Fully compressed suﬃx trees. ACM Transactions on
Algorithms, 7, article 4.

[11] Gog, S. (2011) Compressed Suﬃx Trees: Design,
PhD thesis Ulm

Construction, and Applications.
University, Germany.

14

A. Farruggia et al.

FIGURE 2. Average ﬁnd and locate times in microseconds per occurrence for 2 million patterns of length 32 with a total
of 255 million occurrences on NA12878 relative to the human reference genome without chromosome Y. Left: Query time vs.
suﬃx array sample interval. Right: Query time vs. index size in bits per character.

FIGURE 3. Index size in bits per character vs. mutation rate for 25 synthetic sequences relative to a 20 MB reference.

[12] Gog, S. and Ohlebusch, E. (2013) Compressed suﬃx
trees: Eﬃcient computation and storage of lcp-values.
ACM Journal of Experimental Algorithmics, 18, article
2.1.

[13] Abeliuk, A., C´anovas, R., and Navarro, G. (2013)
Practical compressed suﬃx trees. Algorithms, 6, 319–
351.

[14] Navarro, G. and Russo, L. M. S. (2014) Fast fullycompressed 
suﬃx trees. Proceedings of DCC 2014,
Snowbird, UT, 26–28 March, pp. 283–291. IEEE, Los
Alamitos, CA.

[15] Navarro, G. and Ord´o˜nez, A. (2016) Faster compressed
suﬃx trees for repetitive text collections. ACM Journal

of Experimental Algorithmics, 21, article 1.8.

[16] Ocker, C. (2015) Engineering Fully-Compressed Suﬃx
Trees. M.Sc. thesis, Karlsruhe Institute of Technology,
Germany.

[17] Belazzougui, D., Cunial, F., Gagie, T., Prezza, N., and
Raﬃnot, M. (2015) Composite repetition-aware data
structures. Proceedings of CPM 2015, Ischia Island,
Italy, 29 June – 1 July, pp. 26–39. Springer, Berlin,
Germany.

[18] The 1000 Genomes Project Consortium (2015) A global
reference for human genetic variation. Nature, 526, 68–
64.

[19] Kieﬀer, J. C. and Yang, E.-H. (2000) Grammar-based

7173161127Sample intervalTime (µs / occurrence)110100SSASSA−RRRRFMSize (bpc)0246810llllllSSASSA−RRRRFMMutation rateSize (bpc)0.00010.0010.010.103691215llllllllRFMRLCPReferenceRSTMutation rate0.00010.0010.010.1RSTGCTRelative Suffix Trees

15

TABLE 8. Compressed suﬃx trees for the maternal haplotypes of NA12878 relative to the human reference genome without
chromosome Y. Component choices; index size in bits per character; average time in microseconds per node for preorder
traversal; and average time in microseconds per character for ﬁnding maximal substrings shared with the paternal haplotypes
of chromosome 1 of NA12878 using forward and backward algorithms. The ﬁgures in parentheses are estimates based on the
progress made in the ﬁrst 24 hours.

CST

CSA

LCP

Size

Maximal substrings
Traversal Forward Backward

CST-Sada
CST-NPR
CST-NPR

FCST
RST

RST + rselect

CSA-Sada PLCP 12.33 bpc
PLCP 10.79 bpc
LCP-dac 18.08 bpc
4.98 bpc
2.75 bpc
3.21 bpc

SSA
SSA
SSA
RFM
RFM

RLCP
RLCP

–

0.06 s
0.23 s
0.23 s

79.97 s
44.55 s
29.70 s
(317.30 s) 332.80 s
208.62 s
80.20 s

0.90 s
0.90 s

5.14 s
0.46 s
0.40 s
3.13 s
3.72 s
3.71 s

codes: A new class of universal lossless source codes.
IEEE Transactions on Information Theory, 46, 737–
754.

[20] Charikar, M., Lehman, E., Liu, D., Panigrahy, R.,
Prabhakaran, M., Sahai, A., and Shelat, A. (2005)
The smallest grammar problem.
IEEE Transactions
on Information Theory, 51, 2554–2576.

[21] Bille, P., Landau, G. M., Raman, R., Sadakane, K.,
Rao, S. S., and Weimann, O. (2015) Random access to
grammar-compressed strings and trees. SIAM Journal
on Computing, 44, 513–539.

[22] Ziv, J. and Lempel, A. (1977) A universal algorithm
IEEE Transactions

for sequential data compression.
on Information Theory, 23, 337–343.

[23] Kreft, S. and Navarro, G. (2013) On compressing and
indexing repetitive sequences. Theoretical Computer
Science, 483, 115–133.

[24] Gagie, T., Gawrychowski, P., K¨arkk¨ainen, J., Nekrich,
Y., and Puglisi, S. J. (2012) A faster grammar-based
self-index.
Proceedings of LATA 2012, Tarragona,
Spain, 5–9 March, pp. 240–251. Springer, Berlin,
Germany.

[25] Gagie, T., Gawrychowski, P., K¨arkk¨ainen, J., Nekrich,
Y., and Puglisi, S. J. (2014) LZ77-based self-indexing
with faster pattern matching. Proceedings of LATIN
2014, Montevideo, Uruguay, 31 March – 4 April, pp.
731–742. Springer, Berlin, Germany.

[26] Gagie, T. and Puglisi, S. J.

(2015) Searching
and indexing genomic databases via kernelization.
Frontiers in Bioengineering and Biotechnology, 3.

[27] Kuruppu, S., Puglisi, S. J., and Zobel, J. (2010)
Relative Lempel-Ziv compression of genomes for largescale 
storage and retrieval.
Proceedings of SPIRE
2010, Los Cabos, Mexico, 11–13 October, pp. 201–206.
Springer, Berlin, Germany.

[28] Kuruppu, S., Puglisi, S. J., and Zobel, J. (2011) Reference 
sequence construction for relative compression of
genomes. Proceedings of SPIRE 2011, Pisa, Italy, 17–
21 October, pp. 420–425. Springer, Berlin, Germany.

[29] Kuruppu, S., Beresford-Smith, B., Conway, T. C., and
Zobel, J. (2012) Iterative dictionary construction for
compression of large DNA data sets.
IEEE/ACM
Transactions on Computational Biology and Bioinformatics,
 9, 137–149.

[30] Liao, K., Petri, M., Moﬀat, A., and Wirth, A.
(2016) Eﬀective construction of relative Lempel-Ziv
dictionaries. Proceedings of WWW 2016, Montreal,
Canada, 11–15 April, pp. 807–816. IW3C2, Geneva,
Switzerland.

[31] Deorowicz, S. and Grabowski, S.

(2011) Robust
relative compression of genomes with random access.
Bioinformatics, 27, 2979–2986.

[32] Ferrada, H., Gagie, T., Gog, S., and Puglisi, S. J. (2014)
Relative Lempel-Ziv with constant-time random access.
Proceedings of SPIRE 2014, Ouro Preto, Brazil, 20–22
October, pp. 13–17. Springer, Berlin, Germany.

[33] Do, H. H., Jansson, J., Sadakane, K., and Sung, W.-K.
(2014) Fast relative Lempel-Ziv self-index for similar
sequences. Theoretical Computer Science, 532, 14–30.
[34] Maciuca, S., del Ojo Elias, C., McVean, G., and Iqbal,
Z. (2016) A natural encoding of genetic variation in
a Burrows-Wheeler Transform to enable mapping and
genome inference. Proceedings of WABI 2016, Aarhus,
Denmark, 22–24 August, pp. 222–233. Springer, Berlin,
Germany.

[35] Paten, B., Novak, A. M., Eizenga, J. M., and Garrison,
E. (2017) Genome graphs and the evolution of genome
inference. Accepted to Genome Research.

[36] Sir´en, J. (2017) Indexing variation graphs. Proceedings
of ALENEX 2017, Barcelona, Spain, 17–18 January,
pp. 13–27. SIAM.

[37] Sir´en, J., V¨alim¨aki, N., and M¨akinen, V. (2014)
Indexing graphs for path queries with applications
in genome research.
ACM/IEEE Transactions on
Computational Biology and Bioinformatics, 11, 375–
388.

[38] Na, J. C., Kim, H., Park, H., Lecroq, T., L´eonard,
M., Mouchard, L., and Park, K. (2016) FM-index of
alignment: A compressed index for similar strings.
Theoretical Computer Science, 638, 159–170.

[39] Na, J.-C., Kim, H., Min, S., Park, H., Lecroq, T.,
L´eonard, M., Mouchard, L., and Park, K. (2017) FMindex 
of alignment with gaps. Accepted to Theoretical
Computer Science.

[40] Iqbal, Z., Caccamo, M., Turner, I., Flicek, P., and
McVean, G. (2012) De novo assembly and genotyping
of variants using colored de Bruijn graphs. Nature
Genetics, 44, 226–232.

16

A. Farruggia et al.

[58] Ferragina, P., Manzini, G., M¨akinen, V., and Navarro,
G. (2007) Compressed representations of sequences and
full-text indexes. ACM Transactions on Algorithms, 3,
article 20.

[59] Brisaboa, N. R., Ladra, S., and Navarro, G. (2013)
DACs: Bringing direct access to variable-length codes.
Information Processing and Management, 49, 392–404.
[60] Okanohara, D. and Sadakane, K. (2007) Practical
entropy-compressed rank/select dictionary. Proceedings 
of ALENEX 2007, New Orleans, LA, 6 January,
pp. 60–70. SIAM.

[61] Cox, A. J., Farruggia, A., Gagie, T., Puglisi, S. J.,
and Sir´en, J. (2016) RLZAP: Relative Lempel-Ziv with
adaptive pointers. Proceedings of SPIRE 2016, Beppu,
Japan, 18–20 October, pp. 1–14. Springer, Berlin,
Germany.

[62] Raman, R., Raman, V., and Satti, S. R. (2007)
Succinct indexable dictionaries with applications to
encoding k-ary trees, preﬁx sums and multisets. ACM
Transactions on Algorithms, 3, article 43.

[63] Boucher, C., Bowe, A., Gagie, T., Manzini, G.,
and Sir´en, J. (2015) Relative select. Proceedings of
SPIRE 2015, London, UK, 1–4 September, pp. 149–
155. Springer, Berlin, Germany.

[64] Sir´en, J. (2009) Compressed suﬃx arrays for massive
data. Proceedings SPIRE 2009, Saariselk¨a, Finland,
25–27 August, pp. 63–74. Springer, Berlin, Germany.

[65] Gog, S., Beller, T., Moﬀat, A., and Petri, M.
(2014) From theory to practice: Plug and play with
succinct data structures. Proceedings of SEA 2014,
Copenhagen, Denmark, 29 June – 1 July, pp. 326–337.
Springer, Berlin, Germany.

[66] M¨akinen, V. and Navarro, G. (2005) Succinct suﬃx
arrays based on run-length encoding. Nordic Journal
of Computing, 12, 40–66.

[67] Rozowsky, J. et al. (2011) AlleleSeq: analysis of allelespeciﬁc 
expression and binding in a network framework.
Molecular Systems Biology, 7, article 522.

[68] Chang, W. I. and Lawler, E. L. (1994) Sublinear approximate 
string matching and biological applications.
Algorithmica, 12, 327–344.

[69] Ohlebusch, E., Gog, S., and K¨ugel, A.

(2010)
Computing matching statistics and maximal exact
matches on compressed full-text indexes. Proceedings
of SPIRE 2010, Los Cabos, Mexico, 11–13 October, pp.
347–358. Springer, Berlin, Germany.

[41] Na, J. C., Park, H., Crochemore, M., Holub, J.,
Iliopoulos, C. S., Mouchard, L., and Park, K. (2013)
Suﬃx tree of alignment: An eﬃcient index for similar
data. Proceedings of IWOCA 2013, Rouen, France, 10–
12 July, pp. 337–348. Springer, Berlin, Germany.

[42] Na, J. C., Park, H., Lee, S., Hong, M., Lecroq,
T., Mouchard, L., and Park, K. (2013) Suﬃx array
of alignment: A practical
index for similar data.
Proceedings of SPIRE 2013, Jerusalem, Israel, 7–9
October, pp. 243–254. Springer, Berlin, Germany.

[43] Manber, U. and Myers, G. (1993) Suﬃx arrays: A new
method for on-line string searches. SIAM Journal on
Computing, 22, 935–948.

[44] Belazzougui, D., Gagie, T., Gog, S., Manzini, G., and
Sir´en, J. (2014) Relative FM-indexes. Proceedings of
SPIRE 2014, Ouro Preto, Brazil, 20–22 October, pp.
52–64. Springer, Berlin, Germany.

[45] Muggli, M. D., Bowe, A., Noyes, N. R., Morley, P.,
Belk, K., Raymond, R., Gagie, T., Puglisi, S. J.,
and Boucher, C. Succinct colored de Bruijn graphs.
Bioinformatics , ? to appear.

[46] Alipanahi, B., Muggli, M. D., Jundi, M., Noyes, N.,
and Boucher, C. (2017) Resistome SNP calling via read
colored de Bruijn graphs. Technical report. bioRxiv.

[47] Almodaresi, F., Pandey, P., and Patro, R. (2017)
Rainbowﬁsh: A succinct colored de Bruijn graph
representation. Proceedings WABI 2017, pp. 18:1–
18:15.

[48] Bowe, A., Onodera, T., Sadakane, K., and Shibuya, T.
(2012) Succinct de Bruijn graphs. Proceedings WABI
2012, pp. 225–235.

[49] Iqbal, Z., Caccamo, M., Turner, I., Flicek, P., and
McVean, G. (2012) De novo assembly and genotyping
of variants using colored de Bruijn graphs. Nature
genetics, 44, 226–232.

[50] Kurtz, S. (1999) Reducing the space requirement of
suﬃx trees. Software: Practice and Experience, 29,
1149–1171.

[51] Abouelhoda, M. I., Kurtz, S., and Ohlebusch, E. (2004)
Replacing suﬃx trees with enhanced suﬃx arrays.
Journal of Discrete Algorithms, 2, 53–86.

[52] Grossi, R., Gupta, A., and Vitter, J. S. (2003) Highorder 
entropy-compressed text indexes. Proceedings of
SODA 2003, Baltimore, MD, 12–14 January, pp. 841–
850. SIAM.

[53] Burrows, M. and Wheeler, D. J. (1994) A block sorting
lossless data compression algorithm. Technical Report
124. Digital Equipment Corporation, Palo Alto, CA.

[54] Sadakane, K. (2003) New text indexing functionalities
of the compressed suﬃx arrays. Journal of Algorithms,
48, 294–313.

[55] Ferragina, P. and Manzini, G.

(2005)

Indexing

compressed text. Journal of the ACM, 52, 552–581.

[56] Grossi, R. and Vitter, J. S. (2005) Compressed suﬃx
arrays and suﬃx trees with applications to text
indexing and string matching.
SIAM Journal on
Computing, 35, 378–407.

[57] Ferragina, P., Gonz´alez, R., Navarro, G., and Venturini,
R. (2009) Compressed text indexes: From theory to
practice. ACM Journal of Experimental Algorithmics,
13, article 1.12.

