The Wavelet Matrix

Francisco Claude1,(cid:2) and Gonzalo Navarro2,(cid:2)(cid:2)

1 David R. Cheriton School of Computer Science, University of Waterloo

2 Department of Computer Science, University of Chile

Abstract. The wavelet tree (Grossi et al., SODA 2003) is nowadays a
popular succinct data structure for text indexes, discrete grids, and many
other applications. When it has many nodes, a levelwise representation
proposed by M¨akinen and Navarro (LATIN 2006) is preferable. We propose 
a diﬀerent arrangement of the levelwise data, so that the bitmaps
are shuﬄed in a diﬀerent way. The result can no more be called a wavelet
tree, and we dub it wavelet matrix. We demonstrate that the wavelet matrix 
is simpler to build, simpler to query, and faster in practice than the
levelwise wavelet tree. This has a direct impact on many applications
that use the levelwise wavelet tree for diﬀerent purposes.

1

Introduction

The wavelet tree [20] is a data structure designed to represent a sequence S[1, n]
over alphabet [0, σ) and answer some queries on it. The following queries are
suﬃcient to provide eﬃcient data structures for many applications:

– access(S, i) returns S[i].
– ranka(S, i) returns the number of occurrences of symbol a in S[1, i].
– selecta(S, j) returns the position in S of the j-th occurrence of symbol a.
A wavelet tree is a balanced binary tree with σ leaves and σ − 1 internal
nodes, each of which holds a bitmap. In its most basic form, the bitmaps
add up to n(cid:2)lg σ(cid:3) bits. Those bitmaps are equipped with sublinear-size structures 
to carry out binary rank and select operations. Considering carefully
implemented pointers of lg n bits for the tree, the basic wavelet tree requires
n lg σ + o(n lg σ) + O(σ lg n) bits. This is asymptotically equivalent to a plain
representation of S, yet the wavelet tree is able to solve the three operations in
time O(lg σ). However, in applications where the alphabet is large, the O(σ lg n)
term may become dominant (both in theory and in practice). M¨akinen and
Navarro [24,26] showed that it is possible to concatenate all the bitmaps of each
level and still simulate the tree navigation using rank and select operations on
the concatenated bitmaps. The size was reduced to n lg σ + o(n lg σ) bits. While
in theory the complexities stayed the same, in practice one needs three times the

(cid:2) Funded by Google U.S./Canada PhD Fellowship.
(cid:2)(cid:2) Funded in part by Millennium Nucleus Information and Coordination in Networks

ICM/FIC P10-024F, Chile.

L. Calder´on-Benavides et al. (Eds.): SPIRE 2012, LNCS 7608, pp. 167–179, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012

168

F. Claude and G. Navarro

4
1

7
1

6
1

5
1

3
0

2
0

1
0

0
0

1
0

4
1

1
0

7
1

3
1

2
1

1
0

0
0

1
0

1
0

4
0

7
1

6
1

5
0

4
0

7
1

1
1

0
0

1
1

1
1

3
1

2
0

4
0

5
1

4
0

7
1

6
0

7
1

0

1

1

1

2

3

4

4

5

6

7

7

4
1

3
1

1
1

0

7
1

2
1

0
0

1

6
1

1
0

1
1

1

5
1

0
0

1
1

1

3
0

1
0

3
1

2

2
0

1
0

2
0

3

1
0

4
0

4
0

4

0
0

7
1

5
1

4

1
0

6
1

4
0

5

4
1

5
0

7
1

6

1
0

4
0

6
0

7

7
1

7
1

7
1

7

Fig. 1. On the left, the standard wavelet tree over a sequence. The subsequences Sv
are not stored. The bitmaps Bv, in bold, are stored, as well as the tree topology. On
the right, its levelwise version. The divisions into nodes are not stored but computed
on the ﬂy.

number of operations carried out over a standard wavelet tree. This slowdown
has been accepted since then as an unavoidable price to pay for having the tree
structure in implicit form.

In this paper we show that insisting in simulating the original wavelet tree
was not the best idea. We introduce a diﬀerent levelwise arrangement of the bits
that turns out to simplify all the operations. The result recovers much of the
performance of the original wavelet tree, and oﬀers the same functionality. The
structure cannot properly be called a “tree”; rather, we call it a wavelet matrix.
Our result, which is of practical nature, will have a large impact in a number
of applications where the levelwise wavelet tree was used: compressed full-text
indexes [22,29,14,24,7,4,11,23], inverted indexes [9,1,31,17], document retrieval
[36,18,16,13,17,32], graph representations [9,10], discrete grids [4,5,33,30], binary
relations [2,3], and general problems on numeric sequences [18,17,23]. All of those
will become up to twice as fast by using wavelet matrices.

2 The Wavelet Tree

A wavelet tree [20] for sequence S[1, n] over alphabet [0..σ) is a complete balanced
binary tree, where each node handles a range of symbols. The root handles [0..σ)
and each leaf handles one symbol. Each node v handling the range [αv, ωv)
represents the subsequence Sv[1, nv] of S formed by the symbols in [αv, ωv),
but it does not explicitly store Sv. Rather, it stores a bitmap Bv[1, nv], so that
(cid:3)lg(ωv−αv)(cid:4)−1 and Bv[i] = 1 otherwise. That is, we
Bv[i] = 0 if Sv[i] < αv + 2
partition the alphabet interval [αv, ωv) into two roughly equal parts: a “left”
(cid:3)lg(ωv−αv )(cid:4)−1, ωv). These
one, [αv, αv + 2
are handled by the left and right children of v. Figure 1 (left) gives an example.
The tree has height (cid:2)lg σ(cid:3), and it has exactly σ leaves and σ − 1 internal
nodes. If we regard it level by level, we can see that it holds, in the Bv bitmaps,
exactly n bits per level (the lowest one may hold fewer bits). Thus it stores at

(cid:3)lg(ωv−αv)(cid:4)−1) and a “right” one, [αv + 2

The Wavelet Matrix

169

most n(cid:2)lg σ(cid:3) bits. Storing the tree pointers, and pointers to the bitmaps, requires
O(σ lg n) further bits, if we use the minimum lg n bits for the pointers.

To extract S[i], we start from the root node ν. If Bν [i] = 0, this means that
(cid:3)lg σ(cid:4)−1 and that the symbol is represented in the subsequence Svl
S[i] = Sν[i] < 2
of the left child vl of the root. Otherwise, Sν[i] ≥ 2
(cid:3)lg σ(cid:4)−1 and it is represented
in the subsequence Svr of the right child vr of the root. In the ﬁrst case, the
position of Sν[i] in Svl is il = rank0(Bν, i), whereas in the second, the position
in Svr is ir = rank1(Bν , i). We continue recursively, extracting either Svl [il]
from node vl or Svr [ir] from node vr, until we arrive at a leaf representing the
alphabet interval [a, a], where we can ﬁnally report S[i] = a.
Therefore, the cost of operation access is that of (cid:2)lg σ(cid:3) binary rank operations 
on bitmaps Bv. Binary rank and select operations can be carried out in
constant time using only o(nv) bits on top of Bv [21,28,8].

The process to compute ranka(S, i) is similar. The diﬀerence is that we do not
descend according to whether Bv[i] equals 0 or 1, but rather according to the
bits of a: the highest bit of a tells us whether to go left or right, and the lower
bits are used in the next levels. When moving from one level to the other, we
update i to be the number of times the current bit of a appears up to position i
in the node. When we arrive at the leaf handling the range [a, a], the answer to
rank is the value of i at that leaf.

Finally, to compute selecta(S, j) we must proceed upwards. We start at the
leaf u that handles the alphabet range [a, a]. So we want to track the position
of Su[ju], ju = j, towards the root. If u is the left child of its parent v, then
the corresponding position at the parent is Sv[jv], where jv = select0(Bv, ju).
Else, the corresponding position is jv = select1(Bv, ju). When we ﬁnally arrive
at the root ν, the answer to the query is jν .
Thus the cost of query ranka(S, i) is (cid:2)lg σ(cid:3) binary rank operations (just like
access(S, i)), and the cost of query selecta(S, i) is (cid:2)lg σ(cid:3) binary select operations.
 Algorithm 1 gives the pseudocode (the recursive form is cleaner, but
recursion can be easily removed).

3 The Levelwise Wavelet Tree

Since the wavelet tree is a complete balanced binary tree, it is possible to concatenate 
all the bitmaps at each level and still retain the same functionality
[24,26]. Instead of a bitmap per node v, there will be a single bitmap per level (cid:6),
˜B(cid:7)[1, n]. Figure 1 (right) illustrates this arrangement. The main complication is
how to keep track of the range ˜B(cid:7)[sv, ev] corresponding to a node v of depth (cid:6).

3.1 The Strict Variant
The strict variant [24,26] stores no data apart from the (cid:2)lg σ(cid:3) pointers to the
level bitmaps. Keeping track of the node ranges is not hard if we start at the
root (as in access and rank). Initially, we know that [sν, eν] = [1, n], that is,
the whole bitmap ˜B0 is equal to the bitmap of the root, Bν. Now, imagine

170

F. Claude and G. Navarro

Algorithm 1. Standard wavelet tree algorithms: On the wavelet tree of sequence 
S rooted at ν, acc(ν, i) returns S[i]; rnk(ν, a, i) returns ranka(S, i); and
sel(ν, a, j) returns selecta(S, j). The left/right children of v are called vl/vr.
acc(v, i)

rnk(v, a, i)

if ωv − αv = 1 then

if ωv − αv = 1 then

sel(v, a, j)

if ωv − αv = 1 then

return i

return j

return αv

end if
if Bv[i] = 0

then

i ← rank0(Bv, i)
return acc(vl, i)
i ← rank1(Bv, i)
return acc(vr, i)

else

end if

(cid:2)lg(ωv−αv )(cid:3)−1

(cid:2)lg(ωv−αv )(cid:3)−1

end if
if a < 2
then

i ← rank0(Bv, i)
return rnk(vl, a, i)
i ← rank1(Bv, i)
return rnk(vr, a, i)

else

end if
if a < 2
then

j ← sel(vl, a, j)
return select0(Bv, j)
j ← sel(vr, a, j)
return select1(Bv, j)

else

end if

end if

that we have navigated towards a node v at depth (cid:6), and know [sv, ev]. The
two children of v share the same interval [sv, ev] at ˜B(cid:7)+1. The split point is
m = rank0( ˜B(cid:7), ev) − rank0( ˜B(cid:7), sv − 1), the number of 0s in ˜B(cid:7)[sv, ev]. Then, if
, evl] = [sv, sv + m − 1]. If we
we descend to the left child vl, we will have [svl
descend to the right child vr, we will have [svr , evr ] = [sv + m, ev].

Things are a little bit harder for select, because we must proceed upwards.
In the strict variant, the way to carry out selecta(S, j) is to ﬁrst descend to
the leaf corresponding to symbol a, and then track the leaf position j up to the
root as we return from the recursion.
Algorithm 2 gives the pseudocode (we use p = s − 1 instead of s = sv). Note
that, compared to the standard version, the strict variant requires two extra
binary rank operations per original binary rank, on the top-down traversals
(i.e., for queries access and rank). Thus the times are expected to triple for
these queries. For query select, the strict variant requires two extra binary
rank operations per original binary select. Since in practice the binary select
is more expensive than rank, the impact on query select is lower.

3.2 The Extended Variant
The extended variant [9], instead, stores an array C[0, σ − 1] of pointers to the
σ starting positions of the symbols in the (virtual) array of the leaves, or said
another way, C[a] is the number of occurrences of symbols smaller than a in
S. Note this array requires O(σ lg n) bits (or at best O(σ lg(n/σ)) + o(n) if
represented as a compressed bitmap [34]), but the constant is much lower than
on a pointer-based tree (which stores a left child, right child, a parent pointer,
the value nv, the pointer to bitmap Bv, an equivalent to array C, etc.).

With the help of array C, the number of operations equals that of the standard
version, since array C lets us compute the ranges: The range of any node v is
simply [C[αv] + 1, C[ωv]]. In the algorithms for queries access and rank, where
we descend from the root, the values αv and ωv are easily maintained.

The Wavelet Matrix

171

Algorithm 2. Levelwise wavelet tree algorithms (strict variant): On the
wavelet tree of sequence S, acc(0, i, 0, n) returns S[i]; rnk(0, a, i, 0, n) returns
ranka(S, i); and sel(0, a, j, 0, n) returns selecta(S, j). For simplicity we have
omitted the computation of [αv, ωv).
acc((cid:4), i, p, e)

if ωv − αv = 1 then

return αv

end if
l ← rank0( ˜B(cid:5), p)
r ← rank0( ˜B(cid:5), e)
if ˜B(cid:5)[i] = 0 then

z ← rank0( ˜B(cid:5), p + i)

return acc((cid:4)+1,
z−l, p, p+r−l)
z ← rank1( ˜B(cid:5), p + i)

else

return acc((cid:4)+1,
z−(p−l), p+r−l, e)

end if

rnk((cid:4), a, i, p, e)

if ωv − αv = 1 then

return i

sel((cid:4), a, j, p, e)

if ωv − αv = 1 then

return j

end if
l ← rank0( ˜B(cid:5), p)
r ← rank0( ˜B(cid:5), e)
if a < 2

(cid:2)lg(ωv−αv )(cid:3)−1 then

z ← rank0( ˜B(cid:5), p + i)
return rnk((cid:4)+1, a,
z−l, p, p+r−l)
z ← rank1( ˜B(cid:5), p + i)
return rnk((cid:4)+1, a,
z−(p−l), p+r−l, e)

else

end if
l ← rank0( ˜B(cid:5), p)
r ← rank0( ˜B(cid:5), e)
if a < 2

(cid:2)lg(ωv−αv )(cid:3)−1 then
j←sel((cid:4)+1, a, j, p, p+r−l)
return
select0( ˜B(cid:5), l + j)−p
j←sel((cid:4)+1, a, j, p+r−l, e)
return
select1( ˜B(cid:5), (p−l)+j)−p

else

end if

end if

This is slightly more complicated when solving query selecta(S, j). We start
at oﬀset C[a] + j and track this position upwards: If the leaf is a left child of
its parent (i.e., if a is even), then the parent’s range (in the deepest bitmap ˜B(cid:7))
is [C[a] + 1, C[a + 2]]. Instead, if the leaf is a right child of its parent, then the
parent’s range is [C[a − 1] + 1, C[a + 1]]. We use binary select on this range
to map the position j to the parent’s range. Now we proceed similarly at the
= a or a − 1 is even). If
parent, from range [C[a(cid:5)
a(cid:5)
= 0 mod 4, then this node is a left child, otherwise it is a right child. In the
ﬁrst case, it corresponds to range [C[a(cid:5)
+ 4]] in bitmap ˜B(cid:7)−1, otherwise
it is [C[a(cid:5) − 2] + 1, C[a(cid:5)
+ 2]]. We continue until the root, where j is the answer.

+ 2]] (where a(cid:5)

] + 1, C[a(cid:5)

] + 1, C[a(cid:5)

4 The Wavelet Matrix

The idea of the wavelet matrix is to break the assumption that the children of
a node v, at interval ˜B(cid:7)[sv, ev], must be aligned to it and occupy the interval
˜B(cid:7)+1[sv, ev]. Freeing the structure from this unnecessary assumption allows us
to design a much simpler mapping mechanism from one level to the next: all
the zeros of the level go left, and all the ones go right. For each level, we will
store a single integer z(cid:7) that tells the number of 0s in level (cid:6). This requires just
O(lg n lg σ) bits, which is insigniﬁcant, and allows us to implement the strict
levelwise mechanisms in a simpler and faster way.

More precisely, if ˜B(cid:7)[i] = 0, then the corresponding position at level (cid:6) + 1 will
be rank0( ˜B(cid:7), i). If ˜B(cid:7)[i] = 1, the position at level (cid:6) + 1 will be z(cid:7) + rank1( ˜B(cid:7), i).

172

F. Claude and G. Navarro

4
1

3
1

1
1

0

7
1

2
1

0
0

1

6
1

1
0

1
1

1

5
1

0
0

1
1

1

3
0

1
0

3
1

2

2
0

1
0

2
0

3

1
0

4
0

4
0

4

0
0

7
1

5
1

4

1
0

6
1

4
0

5

4
1

5
0

7
1

6

1
0

4
0

6
0

7

7
1

7
1

7
1

7

4
1

3
1

1
1

0

7
1

2
1

0
0

4

6
1

1
0

1
1

4

5
1

0
0

1
1

2

3
0

1
0

4
0

6

2
0

1
0

5
1

1

1
0

4
0

4
0

1

0
0

7
1

3
1

1

1
0

6
1

2
0

5

4
1

5
0

7
1

3

1
0

4
0

6
0

7

7
1

7
1

7
1

7

Fig. 2. On the left, the levelwise wavelet tree of the previous example (Figure 1).
On the right, the wavelet matrix over the same sequence. One vertical line per level
represents the position stored in the z(cid:5) values.

Note that we can map the position without knowledge of the boundaries of the
node the position belongs. Still, every node v at level (cid:6) occupies a contiguous
range in ˜B(cid:7). This is obviously true for the root ν. Now, assuming it is true for
v, with interval ˜B(cid:7)[sv, ev], all the positions with ˜B(cid:7)[i] = 0 for sv ≤ i ≤ ev will be
mapped to consecutive positions ˜B(cid:7)+1[rank0( ˜B(cid:7), i)], and similarly with positions
˜B(cid:7)[i] = 1. Figure 2 (left) illustrates the wavelet matrix, where it can be seen that
the blocks of the wavelet tree are maintained, albeit in diﬀerent order.

We describe now how to carry out access(S, i). If ˜B0[i] = 0, we set i to
rank0( ˜B0, i). Else we set i to z0 + rank1( ˜B0, i). Now we descend to level 1, and
continue until reaching a leaf. The sequence of bits ˜B(cid:7)[i] read along the way form
the value S[i] (or, said another way, we maintain the interval [αv, ωv) and upon
reaching the leaf it holds S[i] = αv). Note that we have carried out only one
binary rank operation per level, just as the standard wavelet tree.

Consider now the computation of ranka(S, i). This time we need to keep track
of the position i, and also of the position preceding the range, initially p = 0. At
(cid:3)lg(ωv−αv )(cid:4)−1, then we go “left” by mapping p
each node v of depth (cid:6), if a < 2
to rank0( ˜B(cid:7), p) and i to rank0( ˜B(cid:7), i). Otherwise, we go “right” by mapping p to
z(cid:7) + rank1( ˜B(cid:7), p) and i to z(cid:7) + rank1( ˜B(cid:7), i). When we arrive at the leaf level, the
answer is i − p. Note that we have needed one extra binary rank operation per
original rank operation of the standard wavelet tree, instead of the two extra
operations required by the (strict) levelwise variant.

Finally, consider operation selecta(S, j). We ﬁrst descend towards the leaf
of a just as done for ranka(S, i), keeping track only of p. When we arrive at
the last level, p precedes the range corresponding to the leaf of a, and thus we
wish to track upwards position p + j. The upward tracking of a position ˜B(cid:7)+1[i]
is simple: If we went left from level (cid:6), then this position was mapped from a
0 in ˜B(cid:7), and therefore it came from ˜B(cid:7)[select0( ˜B(cid:7), i)]. Otherwise, position i
was mapped from a 1, and thus it came from ˜B(cid:7)[select1( ˜B(cid:7), i − z(cid:7))]. When we
arrive at the root bitmap, i is the answer. Note that we have needed one extra
binary rank per original binary select required by the standard wavelet tree.
We remind that in practice rank is much less demanding, so the overhead is low.

Algorithm 3 gives the pseudocode.

Construction. Construction of the wavelet matrix is even simpler than that of
the levelwise wavelet tree, because we do not need to care for node boundaries.

The Wavelet Matrix

173

Algorithm 3. Wavelet matrix algorithms: On the wavelet matrix of sequence S,
acc(0, i) returns S[i]; rnk(0, a, i, 0) returns ranka(S, i); and sel(0, a, j, 0) returns
selecta(S, j). For simplicity we have omitted the computation of [αv, ωv).
acc((cid:4), i)

rnk((cid:4), a, i, p)

sel((cid:4), a, j, p)

if ωv − αv = 1 then

return αv

end if
if ˜B(cid:5)[i] = 0 then
i ← rank0( ˜B(cid:5), i)
i ← rank1( ˜B(cid:5), i)

else

end if
return acc((cid:4)+1, i)

if ωv − αv = 1 then

return i − p

if ωv − αv = 1 then

return p + j

end if
if a < 2

(cid:2)lg(ωv−αv )(cid:3)−1 then

p ← rank0( ˜B(cid:5), p)
i ← rank0( ˜B(cid:5), i)
p ← z(cid:5) + rank1( ˜B(cid:5), p)
i ← z(cid:5) + rank1( ˜B(cid:5), i)

else

end if
return rnk((cid:4)+1, a, i, p)

end if
if a < 2

(cid:2)lg(ωv−αv )(cid:3)−1 then

p ← rank0( ˜B(cid:5), p)
j ← sel((cid:4)+1, a, j, p)
return select0( ˜B(cid:5), j)
p ← z(cid:5) + rank1( ˜B(cid:5), p)
j ← sel((cid:4)+1, a, j, p)
return select1( ˜B(cid:5), j−z(cid:5))

else

end if

At the ﬁrst level we keep in bitmap ˜B0 the highest bits of the symbols in S, and
then stably sort S by those highest bits. Now we keep in bitmap ˜B1 the next-tohighest 
bits, and stably sort S by those next-to-highest bits. We continue until
considering the lowest bit. This takes O(n lg σ) time.

Indeed, we can build the wavelet matrix almost in place, by removing the
highest bits after using them and packing the symbols of S. This frees n bits,
where we can store the bitmap ˜B0 we have just generated, and keep doing the
same for the next levels. We generate the o(n lg σ)-space indexes at the end.
Thus the construction space is n(cid:2)lg σ(cid:3) + max(n, o(n lg σ)) bits.
Compression. As in previous work, we can replace the plain representations of
bitmaps ˜B(cid:7) by compressed ones [34], so that the total space is nH0(S)+ o(n lg σ)
bits[20]. The concatenation of the bitmaps adds an extra space (positive or
negative) that can be upper bounded by O(σ lg n), but is negligible in practice.

Practical Considerations. A problem that arises when combining the wavelet
matrix with the C[] array of the extended version is that the leaves are not in
order. While this is easily ﬁxed by reversing the bits of the symbols, this creates
holes in C if σ is not a power of 2, even if the alphabet was originally contiguous
(e.g., consider alphabet 0, 1, 2, 3, 4 = 000..100; after reversing the bits we obtain
positions 0, 1, 2, 3, 6, so we need to allocate 7 cells instead of 5). This can make
the size of C to double in the worst case.

5 Experimental Results

Our practical implementation is included in Libcds, a library implementing
several space-eﬃcient data structures, http://libcds.recoded.cl, version 1.0.12.
For each wavelet tree/matrix variant we present two versions, RG and RRR. The

174

F. Claude and G. Navarro

ﬁrst one corresponds to the implementation [19] of the proposals by Jacobson 
[21], and Clark [8] and Munro [28]. The second version, RRR, corresponds to
the implementation [9] of the proposal of Raman, Raman and Rao [34].

The variants measured are WT: standard pointer-based wavelet tree; WTNP:
the extended levelwise wavelet tree (i.e., No Pointers); and WM: the (extended)
wavelet matrix (array C is used to perform select in a single upward traversal).
These names are composed with the bitmap implementations by appending 
the bitmap representation name. For example, we call WTRRR the standard
pointer-based wavelet tree with all bitmaps represented with Raman, Raman
and Rao’s compressed bitmaps. For readability, we show only the extended versions.
 In general, they achieve space very close to the strict versions and yield
better time performance.

Datasets. We use four diﬀerent datasets, left at http://indexing.recoded.cl:

– ESWiki: Sequence of word identiﬁers generated by stemming the Spanish
Wikipedia (http://es.wikipedia.org dated 03/02/2010) with the Snowball
algorithm. The sequence has length n = 511,173,618 and alphabet size σ =
3,210,671. This allows, say, simulating a positional inverted index [9,1].

– BWT: The Burrows-Wheeler transform (BWT) [6] of ESWiki. The length and
size of the alphabet match those of ESWiki. This is useful to implement many
full-text compressed self-indexes [14,15],

– Indochina: The concatenation of all adjacency lists of Web graph Indochina2004,
 available at http://law.dsi.unimi.it. The length of the sequence is
n = 194,109,311 and the alphabet size is σ = 7,414,866. This supports forward 
and backward traversals on the graph [9,10].

– INV: Concatenation of inverted lists for a random sample of 2,961,510 documents 
from the English Wikipedia (http://en.wikipedia.org). This sequence
has length n = 338,027,430 and its alphabet size is σ = 2,961,510. This is
useful to simulate document inverted indexes [31,17].

Measurements. To measure performance we generated 100,000 inputs for each
query and averaged their execution time. The access queries were generated
by picking positions in the text uniformly at random. The rank queries were
generated the same way as for access, associating to each position one symbol
uniformly at random. Each select query was generated by ﬁrst picking a symbol
s uniformly at random, and then picking the positional argument for select
uniformly at random from the range [1, ranks(S, n − 1)].

The machine used is an Intel(R) Xeon(R) E5620 running at 2.40GHz with
96GB of RAM memory. The operating system is GNU/Linux, Ubuntu 10.04,
with kernel 2.6.32-33-server.x86 64. All our implementations use a single thread
and are coded in C++. The compiler is gcc version 4.4.3, with -O9 optimization.

Results. Figure 3 shows some of the results obtained for our four datasets
(the rest are similar). As expected, the wavelet matrix improves upon the levelwise 
wavelet tree considerably, doubling (or more) the speed for access and
improving (albeit less) on rank and select.

The Wavelet Matrix

175

Access Indochina

Access BWT

4
1

2
1

0
1

8

6

4

4
1

2
1

0
1

8

6

4

)
s
c
e
s
o
r
c
m

i

(
 

e
m
T

i

)
s
c
e
s
o
r
c
m

i

(
 

e
m
T

i

)
s
c
e
s
o
r
c
m

i

(
 

e
m
T

i

5
2

0
2

5
1

0
1

10

20

30

40

50

60

Space (bits/cell)

Rank BWT

● WTNPRRR

WTNPRG
WMRRR
WMRG
WTRG
WTRRR

15

20

25

30

Space (bits/cell)

Rank INV

)
s
c
e
s
o
r
c
m

i

(
 

e
m
T

i

)
s
c
e
s
o
r
c
m

i

(
 

e
m
T

i

4
1

2
1

0
1

8

6

4

4
1

2
1

0
1

8

6

4

15

20

25

30

15

20

25

30

Space (bits/cell)

Select ESWiki

Space (bits/cell)

Select BWT

)
s
c
e
s
o
r
c
m

i

(
 

e
m
T

i

0
3

5
2

0
2

5
1

0
1

15

20

25

30

15

20

25

30

Space (bits/cell)

Space (bits/cell)

Fig. 3. Running time per query for rank, select and access over four datasets

●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
176

F. Claude and G. Navarro

We also note that this new implementation of wavelet trees is competitive
with the pointer-based wavelet trees for access and rank operations, which use
much more space. For select, the pointer-based wavelet tree is faster. This is
because the pointer-based wavelet tree performs select queries over smaller
bitmaps, which in practice take time logarithmic on the bitmap length. This can
be overcome by implementing a position-restricted version of binary select.

As for space, it can be seen that the wavelet matrix achieves virtually the
same space as the levelwise wavelet tree, as expected. Pointer-based versions,
instead, pose a noticeable overhead related to the alphabet size.

It is tempting to consider an alternative wavelet matrix, which emulates a
radix sort of the sequence (i.e., it stably sorts ﬁrst by the least signiﬁcant bit and
ends with the most signiﬁcant bit). While this seems to be an innocent change
with the advantage of leaving the leaves in sorted order, it does not preserve the
wavelet tree blocks (even in scrambled form). Our experiments with this variant
showed a behavior very similar to the original in ESWiki, despite not preserving
blocks. Even in the case of BWT, which has long runs of the same symbol, those
runs are preserved even if the blocks are destroyed. Hence RRR compression is
not aﬀected. The case of Indochina and INV, however, was diﬀerent. These
are formed by long substrings of increasing values with small diﬀerences, which
induce long runs in the bitmaps in a decomposition by highest-bit-ﬁrst. However,
such runs do not appear in a lowest-bit-ﬁrst decomposition. As a result, the space
with RRR compression was much worse than on our original variant.

6 Conclusions

The (strict) levelwise wavelet tree [24,26], designed to avoid the O(σ lg n) space
overhead of standard wavelet trees [20], was unnecessarily slow in practice. We
have redesigned this data structure so that its time overhead over standard
wavelet trees is signiﬁcantly lower. The result, dubbed wavelet matrix, enjoys all
the good properties of strict levelwise wavelet trees. It requires n lg σ + o(n lg σ)
bits of space, it can be built in O(n lg σ) time and almost in-place.

There are many more sophisticated aspects of wavelet trees, which we have

ignored in this paper for simplicity. We brieﬂy sketch them here:

Range Searches: Levelwise wavelet trees are particularly useful for representing 
discrete n × n grids, where σ = n. They use algorithms that are slightly
more complex than our access/rank/select, for example they track ranges
downwards, usually to the left and to the right of the current node. All those
algorithms can perfectly be executed over the wavelet matrix. The fact that
the nodes at each level are scrambled is immaterial to the algorithms.

Dynamization: Inserting and deleting symbols of S can be carried out without
any complication, by tracking the position to insert (just like rank) and to
delete (just like access), and therefore all the results on dynamic wavelet
trees [27] translate directly to wavelet matrices.

Construction: We have built the wavelet matrix within n bits of extra space.
There are even more space-eﬃcient constructions for wavelet trees [12,35].
It would be interesting to ﬁnd out whether they apply to wavelet matrices.

The Wavelet Matrix

177

Multiary: Multiary wavelet trees [15] can also be adapted to wavelet matrices.
The only diﬀerence is that, instead of a single accumulator z(cid:7) per level, we
have an array of ρ− 1 accumulators in a ρ-ary wavelet matrix. As the useful
values for ρ are O(lg n), the overall space is still negligible, O(lg2 n lg σ).

Implicit Compression Boosting: M¨akinen and Navarro [25,27] proved that
the wavelet tree of the BWT [6] of a text T , if its bitmaps are compressed
to zero-order entropy (e.g., using Raman et al. [34]), would achieve highorder 
entropy compression of T . This was essential to simplify compressed
text indexing and to enable dynamic variants. Their results apply to wavelet
matrices as well, because all that is required is that the nodes are contiguous
in the levelwise bitmaps B(cid:7), being irrelevant which is the relative order of
the nodes. This eﬀect can already be noticed in our experiments; compare
the spaces on EsWiki with its BWT version BWT.

Acknowledgement. Thanks to Daisuke Okanohara for useful comments.

References

1. Arroyuelo, D., Gonz´alez, S., Oyarz´un, M.: Compressed Self-indices Supporting
Conjunctive Queries on Document Collections. In: Chavez, E., Lonardi, S. (eds.)
SPIRE 2010. LNCS, vol. 6393, pp. 43–54. Springer, Heidelberg (2010)

2. Barbay, J., Claude, F., Navarro, G.: Compact Rich-Functional Binary Relation
Representations. In: L´opez-Ortiz, A. (ed.) LATIN 2010. LNCS, vol. 6034, pp. 170–
183. Springer, Heidelberg (2010)

3. Barbay, J., Claude, F., Navarro, G.: Compact binary relation representations with

rich functionality. CoRR abs/1201.3602 (2012)

4. Bose, P., He, M., Maheshwari, A., Morin, P.: Succinct Orthogonal Range Search
Structures on a Grid with Applications to Text Indexing. In: Dehne, F., Gavrilova,
M., Sack, J.-R., T´oth, C.D. (eds.) WADS 2009. LNCS, vol. 5664, pp. 98–109.
Springer, Heidelberg (2009)

5. Brisaboa, N.R., Luaces, M.R., Navarro, G., Seco, D.: A Fun Application of Compact
Data Structures to Indexing Geographic Data. In: Boldi, P. (ed.) FUN 2010. LNCS,
vol. 6099, pp. 77–88. Springer, Heidelberg (2010)

6. Burrows, M., Wheeler, D.: A block sorting lossless data compression algorithm.

Tech. Rep. 124, Digital Equipment Corporation (1994)

7. Chien, Y.F., Hon, W.K., Shah, R., Vitter, J.: Geometric Burrows-Wheeler trans-
form: Linking range searching and text indexing. In: Proc. 18th DCC, pp. 252–261
(2008)

8. Clark, D.: Compact Pat Trees. Ph.D. thesis, Univ. of Waterloo, Canada (1996)
9. Claude, F., Navarro, G.: Practical Rank/Select Queries over Arbitrary Sequences.
In: Amir, A., Turpin, A., Moﬀat, A. (eds.) SPIRE 2008. LNCS, vol. 5280, pp.
176–187. Springer, Heidelberg (2008)

10. Claude, F., Navarro, G.: Extended Compact Web Graph Representations. In:
Elomaa, T., Mannila, H., Orponen, P. (eds.) Ukkonen Festschrift 2010. LNCS,
vol. 6060, pp. 77–91. Springer, Heidelberg (2010)

11. Claude, F., Navarro, G.: Self-indexed grammar-based compression. Fund.

Inf. 111(3), 313–337 (2010)

178

F. Claude and G. Navarro

12. Claude, F., Nicholson, P.K., Seco, D.: Space Eﬃcient Wavelet Tree Construction.
In: Grossi, R., Sebastiani, F., Silvestri, F. (eds.) SPIRE 2011. LNCS, vol. 7024, pp.
185–196. Springer, Heidelberg (2011)

13. Culpepper, J.S., Navarro, G., Puglisi, S.J., Turpin, A.: Top-k Ranked Document
Search in General Text Databases. In: de Berg, M., Meyer, U. (eds.) ESA 2010,
Part II. LNCS, vol. 6347, pp. 194–205. Springer, Heidelberg (2010)

14. Ferragina, P., Manzini, G.: Indexing compressed texts. J. ACM 52(4), 552–581

(2005)

15. Ferragina, P., Manzini, G., M¨akinen, V., Navarro, G.: Compressed representations

of sequences and full-text indexes. ACM Trans. Alg. 3(2), article 20 (2007)

16. Gagie, T., Navarro, G., Puglisi, S.J.: Colored Range Queries and Document Retrieval.
 In: Chavez, E., Lonardi, S. (eds.) SPIRE 2010. LNCS, vol. 6393, pp. 67–81.
Springer, Heidelberg (2010)

17. Gagie, T., Navarro, G., Puglisi, S.J.: New algorithms on wavelet trees and applications 
to information retrieval. Theor. Comp. Sci. 426-427, 25–41 (2012)

18. Gagie, T., Puglisi, S.J., Turpin, A.: Range Quantile Queries: Another Virtue of
Wavelet Trees. In: Karlgren, J., Tarhio, J., Hyyr¨o, H. (eds.) SPIRE 2009. LNCS,
vol. 5721, pp. 1–6. Springer, Heidelberg (2009)

19. Gonz´alez, R., Grabowski, S., M¨akinen, V., Navarro, G.: Practical implementation
of rank and select queries. In: Proc. 4th Workshop on Eﬃcient and Experimental
Algorithms (WEA), pp. 27–38 (2005) (posters)

20. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed text indexes. In:

Proc. 14th SODA, pp. 841–850 (2003)

21. Jacobson, G.: Space-eﬃcient static trees and graphs. In: Proc. 30th FOCS, pp.

549–554 (1989)

22. K¨arkk¨ainen, J.: Repetition-Based Text Indexing. Ph.D. thesis, Univ. of Helsinki,

Finland (1999)

23. Kreft, S., Navarro, G.: Self-indexing Based on LZ77. In: Giancarlo, R., Manzini,

G. (eds.) CPM 2011. LNCS, vol. 6661, pp. 41–54. Springer, Heidelberg (2011)

24. M¨akinen, V., Navarro, G.: Position-Restricted Substring Searching. In: Correa,
J.R., Hevia, A., Kiwi, M. (eds.) LATIN 2006. LNCS, vol. 3887, pp. 703–714.
Springer, Heidelberg (2006)

25. M¨akinen, V., Navarro, G.: Implicit Compression Boosting with Applications to
Self-indexing. In: Ziviani, N., Baeza-Yates, R. (eds.) SPIRE 2007. LNCS, vol. 4726,
pp. 229–241. Springer, Heidelberg (2007)

26. M¨akinen, V., Navarro, G.: Rank and select revisited and extended. Theor. Comp.

Sci. 387(3), 332–347 (2007)

27. M¨akinen, V., Navarro, G.: Dynamic entropy-compressed sequences and full-text

indexes. ACM Trans. Alg. 4(3), article 32 (2008)

28. Munro, I.: Tables. In: Chandru, V., Vinay, V. (eds.) FSTTCS 1996. LNCS,

vol. 1180, pp. 37–42. Springer, Heidelberg (1996)

29. Navarro, G.: Indexing text using the Ziv-Lempel trie. J. Discr. Alg. 2(1), 87–114

(2004)

30. Navarro, G., Nekrich, Y., Russo, L.: Space-eﬃcient data-analysis queries on grids.

CoRR abs/1106.4649v2 (2012)

31. Navarro, G., Puglisi, S.J.: Dual-Sorted Inverted Lists. In: Chavez, E., Lonardi, S.

(eds.) SPIRE 2010. LNCS, vol. 6393, pp. 309–321. Springer, Heidelberg (2010)

32. Navarro, G., Puglisi, S.J., Valenzuela, D.: Practical Compressed Document Retrieval.
 In: Pardalos, P.M., Rebennack, S. (eds.) SEA 2011. LNCS, vol. 6630, pp.
193–205. Springer, Heidelberg (2011)

The Wavelet Matrix

179

33. Navarro, G., Russo, L.M.S.: Space-Eﬃcient Data-Analysis Queries on Grids. In:
Asano, T., Nakano, S.-i., Okamoto, Y., Watanabe, O. (eds.) ISAAC 2011. LNCS,
vol. 7074, pp. 323–332. Springer, Heidelberg (2011)

34. Raman, R., Raman, V., Rao, S.: Succinct indexable dictionaries with applications

to encoding k-ary trees and multisets. In: Proc. 13th SODA, pp. 233–242 (2002)

35. Tischler, G.: On Wavelet Tree Construction. In: Giancarlo, R., Manzini, G. (eds.)

CPM 2011. LNCS, vol. 6661, pp. 208–218. Springer, Heidelberg (2011)

36. V¨alim¨aki, N., M¨akinen, V.: Space-Eﬃcient Algorithms for Document Retrieval.
In: Ma, B., Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 205–215. Springer,
Heidelberg (2007)

