Approximate Regular Expression Searching with

Arbitrary Integer Weights(cid:1)

Gonzalo Navarro

Dept. of Computer Science, Univ. of Chile. gnavarro@dcc.uchile.cl

Abstract. We present a bit-parallel technique to search a text of length
n for a regular expression of m symbols permitting k diﬀerences in worst
case time O(mn/ logk s), where s is the amount of main memory that
can be allocated. The algorithm permits arbitrary integer weights and
matches the best previous complexities, but it is much simpler and faster
in practice. In our way, we deﬁne a new recurrence for approximate
searching where the current values depend only on previous values.

1 Introduction and Related Work

The need to search for regular expressions arises in many text-based applications,
such as text retrieval, text editing and computational biology, to name a few. A
regular expression (RE) is a generalized pattern composed of (i) basic strings,
(ii) union, concatenation and Kleene closure of other REs [1]. We call m the
length of our RE, not counting operator symbols. The alphabet is denoted by
Σ, and n is the length of the text.

The traditional technique to search for a RE [1] ﬁrst builds a nondeterministic
ﬁnite automaton (NFA) and then converts it to a deterministic ﬁnite automaton
(DFA), which is ﬁnally used to search the text in O(n) time. This is worst-case
optimal in terms of n. The main problem has been always the preprocessing time
and space requirement to code the DFA, which can be as high as O(22m|Σ|) if
the classical Thompson’s NFA construction algorithm [10] is used. Thompson’s
construction produces up to 2m states, but it has interesting properties, such as
ensuring a linear number of edges and constant in/out-degree.

An alternative NFA construction is Glushkov’s [3,2]. Although it does not
provide the same regularities of Thompson’s, this construction has other useful
properties, such as producing the minimum number of states (m+1) and that all
the edges arriving at a node are labeled by the same character. The corresponding
DFA needs only O(2m|Σ|) space, which is signiﬁcantly less than the worst case
using Thompson’s NFA. Nevertheless, this is still exponential in m.

Two techniques have been classically used to cope with the space problem.
The ﬁrst is to use lazy DFAs, where the states are built only when they are
reached. This ensures that no more than O(n) extra space is necessary. The
second choice [10] is to directly use the NFA instead of converting it to deterministic.
 This requires only O(m) space, but the search time becomes O(mn).
Both approaches are slow in practice if the RE is large.
(cid:1) Partially supported by Fondecyt grant 1-020831.

T. Ibaraki, N. Katoh, and H. Ono (Eds.): ISAAC 2003, LNCS 2906, pp. 230–239, 2003.
c(cid:1) Springer-Verlag Berlin Heidelberg 2003

Approximate Regular Expression Searching with Arbitrary Integer Weights

231

Newer techniques have provided better space-time tradeoﬀs by using hybrids
between the NFA and the DFA. Based on the Four Russians technique, which
precomputes large tables that permit processing several automaton states in
one shot, it has been shown that O(mn/ log s) search time is possible using
O(s) space [4]. The use of Thompson’s automaton is essential for this approach
which, however, is rather complicated. Simpler solutions obtaining the same
complexities have been obtained later using bit-parallelism, a technique to pack
several NFA states in a single machine word and update them as a single state. A
ﬁrst solution [12], based on Thompson’s construction, uses a table of size O(22m)
that can be split into t tables of size O(22m/t) each, at a search cost of O(tn)
table inspections. A second solution [8] uses Glushkov’s automaton and uses t
tables of size O(2m/t) each, which is much more eﬃcient in space usage. In both
cases, O(mn/ log s) search time is obtained using O(s) space.

Several applications in computational biology, data mining, text retrieval,
etc. need an even more sophisticated form of searching: An integer threshold k
is given, so that we have to report the text substrings that can match the RE
after performing several character insertions, deletions and substitutions, whose
total cost or weight does not exceed k. Each operation may have a diﬀerent
weight depending on the characters involved. This problem is called “approximate 
regular expression searching”, as opposed to “exact” searching.

Instead of being just active or inactive, every NFA node has now k+2 possible
states, according to the weight of the diﬀerences needed to match the text (0 to
k, or more than k). If one applies the classical DFA construction algorithm, the
space requirement raises to O((k+2)2m) using Thompson’s NFA and O((k+2)m)
using Glushkov’s NFA. A dynamic programming based solution with O(mn) time
and O(m) space exists [5]. Although this is an achievement because it retains
the time complexity of the exact search version and handles real-valued weights,
it is still slow. The Four Russians technique has been gracefully extended to
this problem [13], obtaining O(mn/ logk s) time using O(s) space. Again, this
algorithm is rather complicated.

Since bit-parallel solutions have, for many related problems, yielded fast and
simple solutions, one may wonder what have they achieved here. For the case
of unitary costs (that is, all the weights are 1), bit-parallel solutions exist which
resort to simulating k + 1 copies of the NFA used for exact searching. They
achieve O(ktn) time using O(22m/t) space [12] or O(2m/t) space [6]. This yields
O(kmn/ log s) time using O(s) space, inferior to the achievement of the Four
Russians technique. Despite this worse complexity, bit-parallel solutions are by
far the fastest for moderate sized REs. Yet, they are restricted to unitary costs.
The aim of this paper is to overcome the technical problems that have prevented 
the existence of a simple O(mn/ logk s) time and O(s) space bit-parallel
solution to approximate RE searching with arbitrary integer weights. We build
over Glushkov’s NFA and represent the state of the search using m(cid:1)1+log2(k+2)(cid:2)
bits. We then use t tables of size O((k + 2)m/t) and reach O(tn) search time.

We use the following terminology for bit-parallel algorithms. A bit mask is
a sequence of bits, where the lowest bit is written at the right. Typical bit
operations are inﬁx “|” (bitwise or), inﬁx “&” (bitwise and), preﬁx “∼” (bit

