The Miracle of
Self-Indexing

Combining Text Compression and String Matching

Gonzalo Navarro

www.dcc.uchile.cl/gnavarro

gnavarro@dcc.uchile.cl

Department of Computer Science

University of Chile

Bit Sequences

Rank
Compressed Bitmaps

Sequences of Symbols and Wavelet Trees

Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Compact Data Structures

I They are data structures modiﬁed to use little space.
I Not just compression: they must retain their functionality

and direct access.

I Motivation: Improve performance thanks to memory

hierarchy.

I Especially if we can operate in RAM a structure that

otherwise would need the disk.

I In this talk I will focus on compact data structures for text,

where the success has been notorious.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Compressed Full-Text Self-Indexes

I Consider a text T [1, n] over an alphabet of size σ.
I It requires n log σ bits of space in plain form.

(we will use base-2 logarithms by default).

I Searching for patterns P[1, m] in T is a fundamental

problem.

I It can be done in O(n) time, but this can be unacceptable if

T is large.

I We can use an index over T .
I If T is made of natural language, under some restrictions,

a relatively small inverted index would do.

I But there are many sequences that cannot be handled this
way: DNA, proteins, Oriental languages, music sequences,
numeric signals, ...

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Compressed Full-Text Self-Indexes

I An index that works for any string is the sufﬁx array.
I But it requires n log n bits, way larger than n log σ.
I For relatively large texts, the sufﬁx array will not ﬁt in main

memory.

I And it will be rather slow to search on disk.
I This has been a dilemma for decades, with researchers
trying different tricks to reduce the constant of the space.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Compressed Full-Text Self-Indexes

I Suddenly, a miracle happened in 2000.
I It was discovered that the sufﬁx array was compressible...
I ... up to the space the compressed text would need.
I Within that space, not only it could offer indexed

searching...

I ... but also extracting any text substring.
I Thus the text was unnecessary and could be discarded.
I Hence the compressed index replaced the text, and was

called a self-index:

I A compressor with indexing plus, or
I An index able of reproducing the text.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Compressed Full-Text Self-Indexes

I There are many alternative self-indexes today.
I Despite they have opened a whole new area of research,

and proved competitive in practice...

I ... they are still surrounded by a veil of mystery.
I They are deemed too complicated and impractical by many

people, despite the open-source implementations being
out there: http://pizzachili.dcc.uchile.cl.

I This may come from the ﬁrst proposals, which were indeed

complex.

I Not anymore the case.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Compressed Full-Text Self-Indexes

I In this talk, I’ll do my best to unveil the mystery.
I I will choose one of the most elegant self-indexes: the

FM-index.

I I will start from the very basics, explaining only the

minimum necessary to understand how a very competitive
implementation works.

I I hope to expose the simplicity, elegance, and practicality

of this data structure...

I ... and encourage you to go for more yourselves.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Bit Sequences

I Consider a bit sequence B[1, n].
I We are interested in the following operation on B:

I rankb(B, i): how many times does b occur in B[1, i]?

I Note rank0(B, i) = i − rank1(B, i).
I By default let us assume b = 1.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Bit Sequences

Result

I rank can be answered in constant time.
I This is easy by storing all the answers in O(n log n) bits,

but one only needs

(cid:18)n · log log n

(cid:19)

n + O

log n

= n + o(n)

bits of space (the n bits for B[1, n] plus a sublinear extra).

I The solutions are practical.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

Rank in Constant Time

I We cut B into blocks of b = (log n)/2 bits.
I We store and array R[1, n/b] with the rank values at block

beginnings.

I As we need log n bits to store a rank value, the total of bits

used by R is
n
b

· log n =

n

(log n)/2

· log n = 2n

I Let us accept that space for now (it is more than promised).

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

I ¿How to compute rank(B, i) ?

I Decompose i = q · b + r, 0 ≤ r < b.
I The number of 1’s up to qb is R[q].
I We must count the 1’s in B[qb + 1, qb + r ].

I Assume we have a table T [0, 2b − 1][0, b − 1], such that

T [x, r ] = total of 1’s in x[1, r ]

where we see x as a stream of b bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

I Since each cell of T can take values in [0, b − 1], T needs

2b · b · log b = 2 log n
√

2

≤ 1
2

· log n
2

· (log log n − 1)

n log n log log n = o(n) bits.

For example, if n = 232, T just needs 512 KB.

I Then, the ﬁnal answer is obtained in constant time as:

R[q] + T [B[qb + 1..qb + b], r ]

I Good, but we spent 3n + o(n) bits...

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

G. Navarro

The Miracle of Self-Indexing

rank(B,13) = 7R10011101010000000110010011110100000001010011100101110111012000000011110000000111122014131095678721BBit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

Achieving o(n) extra bits

I We also cut B into superblocks of

s =

(log n)2

2

= b · log n bits.

I We store an array S[1, n/s] with the rank at the beginning

of superblocks.

I Now the values of R are stored adding just from the

beginning of the corresponding superblock:
R[q] = rank(B, qb) − S[bq/ log nc]

= rank(B, qb) − rank(B,bq/ log nc · log n)

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

I As we need log n bits to store a rank value in S, the total

number of bits used by S is

· log n =

n
s

n

(log n)2/2

· log n =

2n
log n = o(n)

I As the R values are stored relative to the superblock, they
can be only as large as s = O(log n)2, and thus only need
2 log log n bits. Thus R now occupies

· 2 log log n =

n
b

=

(log n)/2
4n · log log n

log n

n

· 2 log log n

= o(n) bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

I ¿How we compute rank(B, i) ?

I Decompose i = q · b + r, 0 ≤ r < b.
I Decompose i = q0 · s + r0, 0 ≤ r0 < s.
I Add the contents of three tables:

rank(B, i) = S[q0] + R[q] + T [B[qb + 1..qb + b], r ]

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

G. Navarro

The Miracle of Self-Indexing

T22R10011101010000000110010011110100BS00120120120345710rank(B,13) = 70000010100111001011101110120000000111100000001111Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank on Compressed Sequences

I In many applications, the sequence B[1, n] contains few or

many 1’s.

I Let us focus on the case where there are m << n 1’s.
I Binary entropy:

H0(B) =

m
n

log

n
m +

n − m

n

log

n

n − m

I We can have constant-time rank using just nH0(B) + o(n)

bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Compressed Representation

I Divide the sequence into blocks of b = (log n)/2 bits.
I Let ci be the number of 1’s in a block Bi.
I The number of distinct blocks of length b with ci 1’s is

and hence we will try to represent Bi using

(cid:19)
(cid:18)b
(cid:19)(cid:25)
(cid:18)b

ci

(cid:24)

log

ci

bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Compressed Representation

I The representation of Bi will be (ci , oi ), where

I The offset, oi, needs dlog(cid:0)b

I The class, ci, needs dlog(b + 1)e bits.

I The ci’s are of ﬁxed width, and take in total

ci

(cid:1)e bits.
(cid:18)n · log log n

(cid:19)

· dlog(b + 1)e = O

n
b

log n

I The oi’s are of variable width. We will concatenate them all.
I Later we see how to decode them.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Compressed Representation

I The concatenation of the oi’s takes

(cid:24)

n/bX

i=1

log

(cid:18)b

(cid:19)(cid:25)

ci

n/bX

≤

i=1

= log

≤ log

ci

log

(cid:19)
(cid:18)b
(cid:19)
(cid:18)b
n/bY
(cid:18)(n/b) · bPn/b
(cid:18) n
(cid:19)

i=1 ci

i=1

ci

(cid:19)

+ n/b

+ O(n/ log n)

+ O(n/ log n)

+ O(n/ log n)

= log
≤ nH0(B) + O(n/ log n) bits.

m

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Compressed Representation

I We have represented B using nH0(B) + o(n) bits!
I But how can we extract a block Bi in constant time?
I First problem: where is oi?

I We can store the positions in P[1, n/b]...
I ... but this requires (n/b) log n = 2n extra bits.
I We deﬁne superblocks of s = b · log n bits...
I ... and store P[1, n/s] only for superblocks.
I We will have P0[1, n/b] with pointers relative to the
I Since |oi| = O(log n), each P0[i] needs O(log log n) bits.
I Total: O(n log log n/ log n) bits.

superblock (like in rank).

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Compressed Representation

I Second problem: which block does (ci , oi ) represent?

I We will have a table W [0, 2b − 1] where all bitmaps of b bits

are stored grouped by class.

I The positions where each class begins in W will be

precomputed in an array

(cid:18)b

(cid:19)

c−1X

i=0

i

C[c] = 1 +

I W is sorted so that oi is the corresponding index within the

zone of class ci.

I Hence (ci , oi ) represents W [C[ci ] + oi ].
√
I These tables occupy O(
n log n) bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Compressed Representation

G. Navarro

The Miracle of Self-Indexing

2301001+1010011101010000000110010011110100B0005113110111311915cPP’24242400100o0110000110000001010100011101110111WCBit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Rank
Compressed Bitmaps

Rank

I The structures for rank occupy o(n) bits on top of B.
I They need constant-time access to blocks of B.
I This is what we have obtained with the compressed

representation!

I Hence we have obtained rank in constant time over the

compressed representation (to H0).

I More precisely, we use nH0(B) + O(n log log n/ log n) bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

Symbol Sequences

I Assume now we handle a sequence S = s1s2 . . . sn over

an alphabet Σ of size σ.

I A plain representation of S needs n log σ bits.
I We wish to solve rank over this sequence:

I rankc(S, i) = number of occurrences of c in S[1, i].

I How can we extend our results on bits?

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I Is an elegant solution that lets us store S[1, n]:

I Using n log σ + o(n log σ) bits.
I Solving rank in time O(log σ).
I Obtaining S[i] in time O(log σ).

I Has many other applications (geometry, binary relations,

etc.)

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I Assume we split the alphabet into two subsets of the same

size (or almost).

I We create a bitmap indicating to which subset each

symbol of S belongs to.

I We store that bitmap in the root of the wavelet tree.
I For the left/right subtree, we choose the symbols of S from

each subset.

I We continue recursively until each subset has just one

symbol.

I It is easy to see that all the bitmaps add up to n log σ bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

G. Navarro

The Miracle of Self-Indexing

l1llrdrl01000111lldlaaabaraabadalllra00000000000110111100_abdlr00000000000011_abaabaaaaabaabb111111111000_aaaaaaaaaaaaaaaaaaadlrrrdldll0Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I How we retrieve symbol S[i]?

I Look at B[i] in the root bitmap.
I If B[i] = 0,

I Go to the left subtree.
I The new position is i0 = rank0(B, i).

I If B[i] = 1,

I Go to the right subtree.
I The new position is i0 = rank1(B, i).

I When we arrive at a leaf, the corresponding symbol is S[i].

I Time: log σ evaluations of rank.
I Need to preprocess the bitmaps for rank queries.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

G. Navarro

The Miracle of Self-Indexing

000rlld011l1aaabaraabadalllra00000000000110111100_abdlr00000000000011_abaabaaaaabaabb111111111000_aaaaaaaaaaaaaaaaaaadlrrrdldllrank00l11llrdlBit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I How we compute rankc(S, i)?

I Let B be the root bitmap.
I If c belongs to the left subtree,

I Move to the left subtree.
I The new position is i0 = rank0(B, i).

I If c belongs to the right subtree,

I Move to the right subtree.
I The new position is i0 = rank1(B, i).

I When we arrive at a leaf, the answer is i.

I Time: log σ evaluations of rank.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

G. Navarro

The Miracle of Self-Indexing

aaabaraabadalllra00000000000110111100_abdlr00000000000011_abaabaaaaabaabb111111111000_aaaaaaaaaaaaaaaaaaadlrrrdldllrankrank   (S,11)’l’1l011llrd000rllld011l1Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I If the bitmaps are uncompressed, the space is

n log σ + o(n log σ).

I If we compress the bitmaps using the technique shown

before...

I Zero order entropy of a sequence: let there be nc

occurrences of symbol c in S[1, n], then

X

c∈Σ

nc
n

log

n
nc

H0(S) =

I Lower bound to any encoding of S that always assigns the

same code to the same symbol (e.g. Huffman).

I We will see that, by compressing the bitmaps of the

wavelet tree to zero-order, we compress the sequence to
zero-order as well.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I We will consider the successive levels of the wavelet tree.
I Let B[1, n] be the highest bits of the symbols.
I Say B has n0 0s and n1 1s.
I It is compressed to

nH0(B) = n0 log

n
n0

+ n1 log

n
n1

.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Wavelet Tree

I Consider now the subsequence S0[1, n0] of the left child

and B0 the bitmap of its next highest bit.

I Let n00 and n01 be its number of 0s and 1s, respectively.
I B0 is compressed to

n0H0(B0) = n00 log

n0
n00

+ n01 log

n0
n01

.

I Symmetrically with S1. Adding up the space for the ﬁrst

two levels we get

n00 log

n
n00

+ n01 log

n
n01

+ n10 log

n
n10

+ n11 log

n
n11

I If continuing up to level log σ, we get nH0(S).

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Texts

I Given an alphabet Σ of size σ...
I ... a text T [1, n] is a sequence over Σ.
I This is just a sequence, but we are interested in other

operations.

I Given a pattern P[1, m]:

I Count the number of occurrences of P in T (occ).
I Locate those occ occurrences in T .

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Sufﬁx Arrays

I Unlike inverted indexes, make no assumption on the text.
I Can retrieve any text substring.
I General model: consider the n sufﬁxes T [i, n] of T .
I Every substring of T is the preﬁx of a sufﬁx of T .
I This structures indexes the set of sufﬁxes of T and allows

one to ﬁnd all those sharing a given preﬁx.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Sufﬁx Arrays

I It is an array with the n text sufﬁxes in lexicographic order.
I Finding the substrings equal to P is the same as ﬁnding

the sufﬁxes that start with P.

I These form a lexicographical interval in the sufﬁx array.
I This interval can be binary searched in O(m log n) time.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

G. Navarro

The Miracle of Self-Indexing

217129201183151135174161910214618baraaaaaaaaalbrllbrd$Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Sufﬁx Arrays

I Yet, the sufﬁx array yields space problems.
I Uses about 4n bytes (12GB for the human genome).
I Compressing it is of interest.
I But... ¿can we compress a permutation?.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The Burrows-Wheeler Transform (BWT)

I Is a reversible permutation of T .
I It is used as a previous step to compression algorithms like

bzip2.

I Puts together symbols having the same context.
I It is enough to compress those symbols “put together” to

zero-order to achieve high-order entropy.

I Entropy of order k: if SA is the sequence of the symbols

that precede the occurrences of A in S, then
|SA|H0(SA)

Hk (S) =

X

A∈Σk

1
n

I Lower bound to encodings that consider the k symbols

preceding the one to encode (e.g. PPM).

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The Burrows-Wheeler Transform (BWT)

I Take all cyclic shifts of T .
I That is, titi+1 . . . tn−1$t1t2 . . . ti−1.
I The result is a matrix M of n × n symbols.
I Sort the rows lexicographically.
I M is essentially the list of sufﬁxes of T in this order:

M[i] = T [A[i] . . . n] · T [1 . . . A[i] − 1]

I The ﬁrst column, F , holds the ﬁrst characters of the

sufﬁxes: F [i] = S[rank(D, i)].

I The last column, L, is the BWT of T , T bwt = L.
I It is the sequence of symbols that precede the sufﬁxes

T [A[i]..].

L[i] = T bwt [i] = T [A[i] − 1]

(except if A[i] = 1, where T bwt = T [n] = $).

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

G. Navarro

The Miracle of Self-Indexing

alabar a la alabarda$labar a la alabarda$aabar a la alabarda$albar a la alabarda$alaar a la alabarda$alabr a la alabarda$alaba a la alabarda$alabara la alabarda$alabar  la alabarda$alabar ala alabarda$alabar a a alabarda$alabar a l alabarda$alabar a laalabarda$alabar a la labarda$alabar a la aabarda$alabar a la albarda$alabar a la alaarda$alabar a la alabrda$alabar a la alabada$alabar a la alabara$alabar a la alabard$alabar a la alabarda217129201183151135174161910214618$alabar a la alabarda a la alabarda$alabar alabarda$alabar a la la alabarda$alabar aa$alabar a la alabarda alabarda$alabar a la la alabarda$alabar abar a la alabarda$alabarda$alabar a la alalabar a la alabarda$alabarda$alabar a la ar a la alabarda$alabarda$alabar a la alabbar a la alabarda$alabarda$alabar a la alada$alabar a la alabarla alabarda$alabar a labar a la alabarda$alabarda$alabar a la ar a la alabarda$alabarda$alabar a la alabaTbwtTaraadl ll$ bbaar aaaaalabar a la alabarda$A1era "a"1era "d"2nda "r"9na "a"Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The Burrows-Wheeler Transform (BWT)

I How to revert the BWT?
I For all i, T = . . . L[i]F [i] . . ..
I We know L[1] = T [n − 1], since F [1] = $ = T [n].
I Where is c = L[1] in F ?
I All occurrences of c appear in the same order in F and L:

I Is the order given by the sufﬁx that follows c in T .

I That c is at F [C[c] + rankc(L, i)], where

C[c] = number of occurrences of symbols < c in T

I This is called LF-mapping, since it maps from L to F :

LF (i) = C(L[i]) + rankL[i](L, i)

I Then T [n − 2] = L[LF (1)], T [n − 3] = L[LF (LF (1))], etc.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I Uses the connection between the sufﬁx array and the BWT.
I Replaces the binary search by the more efﬁcient backward

search.

I To search for P[1, m] we start with pm.
I The segment of A corresponding to it is

A[C(pm) + 1, C(pm + 1)].

I In general, we will know that the occurrences of P[i + 1, m]

start at A[spi+1, epi+1]...

I ... and will use something similar to the LF-mapping to

obtain the zone A[spi , epi ] corresponding to P[i, m].

I We ﬁnish with sp1 and ep1.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I Assume we start with the segment A[spi+1, epi+1] of the

occurrences of P[i + 1, m].

I How we update it to the occurrences of P[i, m]?

I For a spi+1 ≤ j ≤ epi+1, M[j][1..m − i] = P[i + 1, m].
I The occurrences of P[i, m] in T appear as L[j] = pi in this

area, since T = . . . L[j] · M[j][1..m − i] . . .

I Hence the answer is the range of the LF (j) where L[j] = pi.

I This is computed simply as

spi = C(pi ) + rankpi (L, spi+1 − 1) + 1
epi = C(pi ) + rankpi (L, epi+1)

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

G. Navarro

The Miracle of Self-Indexing

217129201183151135174161910214618C($)=0C(_)=1C(r)=19C(l)=16C(d)=15C(a)=4 C(b)=13araadl_ll$_bbaar_aaaarab$aaaaaaaaabbdlllrraraadl ll$ bbaar aaaaalabar a la alabarda$TTbwt___FLABit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I After m iterations, we get the interval for P[1, m].
I The cost is 2m calls to rankc.
I Using a wavelet tree on T bwt = L,

I We get space nH0(T ) + o(n log σ).
I We count in time O(m log σ).

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

G. Navarro

The Miracle of Self-Indexing

___$1011_____$_$_11100011ab1101111$_abdlraaa$bbaaaaaabbaaaaaaaaa00000000011ab0100110110000100000araadl_ll$bbaaraaaa00a = 0, rank0(16) = 10a = 1, rank1(10) = 7a = 0, rank0(7) = 510rdllldlrr1lllddl0000111rank = 5Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I But, how to obtain A[i] and T [l, r ]?
I We will sample and store some cells of A.
I We take those A[i] pointing to positions of T which are

multiples of some b.

in an array A0[1, n/b].

I We store them in increasing order of i in contiguous form,

I ... and we have a bitmap B[1, n] marking the sampled is.
I The positions and the bitmap will occupy O( n
b log n) bits.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I Assume we want to ﬁnd out A[i] (but have not A).

I If B[i] = 1, then A[i] = A0[rank(B, i)].
I Else, if B[LF (i)] = 1, then A[LF (i)] = A0[rank(B, LF (i))],

A[i] = A[LF (i)] + 1.

I Else, ...
I If B[LF t (i)] = 1, then A[i] = A0[rank(B, LF t (i))] + t.

I This ends in at most b steps.
I Hence, we can know A[i] in time O(b log σ).
I For example, in time O(log1+ n), spending o(n log σ) extra

bits.

I Now we have replaced A!

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I Now we store the same sampling in another way.
I We store the i values by increasing position in T , in

E[1, n/b].

I Say we want to extract T [l, r ] (but have not T ).

I The ﬁrst sampled position after it is r0 = 1 + br /bc · b.
I And is pointed from A[i] = A[E[1 + br /bc]].
I We know T [r0 − 1] = L[i].
I We know T [r0 − 2] = L[LF (i)].
I ...
I We know T [l] = L[LF r0−l−1(i))].

I The total cost is O((b + r − l) log σ).
I For example, in time O((r − l) log σ + log1+ n), spending

o(n log σ) extra bits.

I Now we have replaced the text!

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I The O(log n) time can be improved to O( log σ
I The space is that of the wavelet tree.

log log n ) in theory.

I n log σ + o(n log σ) (like T ), without compression.
I nH0(T ) + o(n log σ) by compressing the bits.
I Many efforts have been carried out to reduce this to

nHk (T ) + o(n log σ), ﬁnally succeeding.

I Yet, it turned out that no effort was necessary!

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I Consider the t = σk partitions of the BWT by context of

length k

T bwt = S = S1S2 . . . St

I By the Hk formula,

nHk (T ) =

tX

i=1

|Si|H0(Si )

I Now, recall that the zero-order compression we achieved

for the wavelet tree was the sum of the zero-order
entropies of small blocks:

nH0(S) ≤ bH0(S1) + bH0(S2) + . . . + bH0(Sn/b)

where the Sj’s are the blocks of length b.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

The FM-Index

I Thus the wavelet tree compresses S1S2 . . . St to

H0(S1) + H0(S2) + . . . + H0(St )...

I ... plus some worst-case measure for the limits among

strings.

I The total size of the compressed wavelet tree is

nHk (T ) + O(σk log n).

I The second term is o(n log σ) for moderate k ≤ α logσ n,

for any constant 0 < α < 1.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Epilogue

I This FM-index, and many other self-indexes, are

implemented at mirrors http://pizzachili.dcc.uchile.cl
http://pizzachili.di.unipi.it.

I The implementations are freely accessible for any purpose,

and their practicality can be tested.

I We have published a practical survey considering most of

the currently available indexes:
Compressed Text Indexes: From Theory to Practice. ACM
Journal of Experimental Algorithmics (JEA) 13:article 12,
2009.

I And also a more conceptual survey:

Compressed Full-Text Indexes. ACM Computing Surveys
39(1), article 2, 61 pages, 2007.

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Epilogue

I This is, of course, not the end of the story.
I There are several problems, some totally, some partially,

and some not at all solved.

I Some examples of almost totally solved extensions:

I How to build the index in little space?
I How to handle a dynamic text collection? (slow)
I How to support more functionality, as in sufﬁx trees?

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Epilogue

I Some examples of only partially solved extensions:

I How to support document retrieval? (theoretical)
I How to compress highly repetitive collections? (some

I How to handle the index in secondary memory? (little

progress)

progress).

I And of course, we have all the other data structures!

G. Navarro

The Miracle of Self-Indexing

Bit Sequences
Sequences of Symbols and Wavelet Trees
Text Indexes

The Burrows-Wheeler Transform
The FM-Index

Epilogue

I A brave new world of algorithmic challenges is ahead:
I For those who love classical algorithmics, it is plenty of

opportunities to redesign classical data structures.

I For those who like compression and information theory, this
gives the new challenge of designing schemes that not only
can recover the data but also retain functionality and direct
access to it.

I For those trying to walk the thin path between sterile theory

and shallow practice, this is a marvellous opportunity to
make them work together and achieve miracles!

G. Navarro

The Miracle of Self-Indexing

