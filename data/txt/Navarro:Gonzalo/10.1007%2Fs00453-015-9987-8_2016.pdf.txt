Algorithmica (2016) 74:1082–1098
DOI 10.1007/s00453-015-9987-8

Optimal Encodings for Range Majority Queries
Gonzalo Navarro1 · Sharma V. Thankachan2

Received: 9 April 2014 / Accepted: 12 March 2015 / Published online: 21 March 2015
© Springer Science+Business Media New York 2015

Abstract We study the problem of designing a data structure that reports the positions
of the distinct τ -majorities within any range of an array A[1, n], without storing A.
A τ -majority in a range A[i, j], for 0 < τ < 1, is an element that occurs more than
τ ( j − i + 1) times in A[i, j]. We show that (n(cid:2)log(1/τ )(cid:3)) bits are necessary for
any data structure just able to count the number of distinct τ -majorities in any range.
Then, we design a structure using O(n(cid:2)log(1/τ )(cid:3)) bits that returns one position of
each τ -majority of A[i, j] in O((1/τ ) log logw(1/τ ) log n) time, on a RAM machine
with word size w (it can output any further position where each τ -majority occurs in
O(1) additional time). Finally, we show how to remove a log n factor from the time
by adding O(n log log n) bits of space to the structure.
Keywords Range majority queries · Encoding data structures ·
Succinct data structures

An early version of this article appeared in Proc. CPM 2014 [19].

Gonzalo Navarro: Partially funded by Millennium Nucleus Information and Coordination in Networks
ICM/FIC P10-024F, Chile.

B Gonzalo Navarro

gnavarro@dcc.uchile.cl

Sharma V. Thankachan
sharma.thankachan@gmail.com

1 Department of Computer Science, University of Chile, Santiago, Chile
2 Georgia Institute of Technology, Atlanta, GA, USA

123

Algorithmica (2016) 74:1082–1098

1083

1 Introduction
Given an array A[1, n] of n arbitrary elements, an array range query problem asks us
to build a data structure over A, such that whenever a range [i, j] with 1 ≤ i ≤ j ≤ n
arrives as an input, we can efﬁciently answer queries on the elements in A[i, j] [26].
Many array range queries arise naturally as subproblems of combinatorial problems,
and are also of direct interest in data mining applications. Well-known examples are
range minimum queries (RMQs, which seek the smallest element in A[i, j]) [2], top-k
queries (which report the k largest elements in A[i, j]) [4], range selection queries
(which report the k th largest element in A[i, j]) [7], and colored top-k queries (which
report the k largest distinct elements in A[i, j]) [17].

An encoding for array range queries is a data structure that answers the queries
without accessing A. This is useful when the values of A are not of interest themselves,
 and thus A may be deleted, potentially saving a lot of space. It is also useful
when array A does not ﬁt in main memory, so it can be kept in secondary storage
while a much smaller encoding can be maintained in main memory, speeding up
queries. In this setting, instead of reporting an element in A, we only report a position 
in A containing the element. Otherwise, in many cases we would be able to
reconstruct A via queries on the encodings, and thus the encodings could not be
small (e.g., A[i] would be the only answer to the range query A[i, i] for all the
example queries given above). As examples of encodings, RMQs can be solved in
constant time using just 2n + o(n) bits [12] and, using O(n log k) bits, top-k queries
can be solved in O(k) time [15] and range selection queries in O(log k/ log log n)
time [18].

Frequency-based array range queries, in particular variants of heavy-hitter-like
problems, are very popular in data mining. Queries such as ﬁnding the most frequent
element in a range (known as the range mode query) are known to be harder than
problems like RMQs. For range mode queries, known data structures with constant
query time require nearly quadratic space [21]. The best known linear-space solution
n/ log n) query time [5], and conditional lower bounds given in that
requires O(
paper show that a signiﬁcant improvement is highly unlikely.

√

Still, efﬁcient solutions exist for some useful variants of the range mode problem.
An example are approximate range mode queries, where we are required to output an
element whose number of occurrences in A[i, j] is at least 1/(1+ ) times the number
of occurrences of the mode in A[i, j] [3,14].
In this paper we focus on a popular variant of range mode queries called range τ -
majority queries, which ask to report any element that occurs more than τ ( j − i + 1)
times in A[i, j]. A version of the problem useful for encodings can be stated as follows
(other variants are possible).
Deﬁnition 1 Given an array A[1, n], a range τ -majority query receives a range [i, j]
and returns one position in the range where each τ -majority in A[i, j] occurs. A τ -
majority is any element that occurs more than τ ( j − i + 1) times in A[i, j]. When
τ = 1/2 we simply call it a majority.

Range majority queries can be answered in constant time by maintaining a linear
space (i.e., O(n)-word or O(n log n)-bit) data structure [9]. Similarly, range τ -majority

123

1084

Algorithmica (2016) 74:1082–1098

queries can be solved in time O(1/τ ) and linear space if τ is ﬁxed at construction time,
or O(n log log n) space (i.e., O(n log n log log n) bits) if τ is given at query time [1].
In this paper, we focus for the ﬁrst time on encodings for range τ -majority queries.
In this scenario, a valid question is how much space is necessary for an encoding that
correctly answers such queries (we recall that A itself is not available at query time).
We answer that question in Sect. 3, proving a lower bound for any encoding that solves
even a weaker query.
Theorem 1 Given a real number 0 < τ < 1, any encoding able to count the number
of range τ -majorities in any range A[i, j] must use (n(cid:2)log(1/τ )(cid:3)) bits.
Since when using O(n log n) bits we have sufﬁcient space to store A[1, n]1 (and
achieve the optimal O(1/τ ) time [1]), encodings for range τ -majorities are asymptotically 
interesting only for log(1/τ ) = o(log n).

In Sect. 4 we show how range τ -majority queries can be solved using O((n/τ ) log
log n) bits of space and O((1/τ ) log n) query time. In Sect. 5 we reduce the space to
the optimal O(n(cid:2)log(1/τ )(cid:3)) bits and slightly increase the time. After spending this
time, the structure can report any of the positions of any majority in optimal time (e.g.,
the leftmost position of each τ -majority in a negligible O(1/τ ) time). In Sect. 6 we
show how to build our structure in O(n log n) time. All the results hold on the RAM
model with word size w = (log n) bits.
Theorem 2 Given a real number 0 < τ < 1, there exists an encoding using the
optimal O(n(cid:2)log(1/τ )(cid:3)) bits that answers range τ(cid:6)
-majority queries, for any τ ≤
τ(cid:6) < 1, in time O((1/τ ) log logw(1/τ ) log n), where w = (log n) is the RAM word
size in bits. It can report any occ further occurrence positions of the majorities in
O(occ) time. The encoding can be built in O(n log n) time.
1/τ . We also note that the time depends on τ , not τ(cid:6)
obtain a query time that is a function of τ(cid:6)

We note that the query time is simply O((1/τ ) log n) for polylogarithmic values of
. In Sect. 6 we also show how to
, yet using O(n(cid:2)log2(1/τ )(cid:3)) bits of space.
Finally, in Sect. 7 we derive a new variant that may use more space but removes

the log n term from the time complexity.
Theorem 3 Given a real number 0 < τ < 1, there exists an encoding using
O(n(cid:2)log(1/τ )(cid:3) + n log log n) bits that answers range τ(cid:6)
-majority queries, for any
τ ≤ τ(cid:6) < 1, in time O((1/τ ) log logw(1/τ )), where w = (log n) is the RAM word
size in bits. It can report any occ further occurrence positions of the majorities in
O(occ) time. The encoding can be built in O(n log n) time.

By combining the results of Theorems 2 and 3, we obtain the combinations given

in Table 1.

2 Related Work

In this section we ﬁrst cover the state of the art for answering range τ -majority queries.
Then, we survey a few results on bitmap representation, and give a new result that will

1 Or an equivalent array where each element is replaced by an identiﬁer in [1, n].

123

Algorithmica (2016) 74:1082–1098

1085

Table 1 Space–time tradeoffs achieved

Condition
1/τ = ω(polylog n)
1/τ = (polylog n)
1/τ = o(polylog n)
1/τ = o(polylog n)
a Optimal space and time

Space (bits)
O(n(cid:2)log(1/τ )(cid:3))a
O(n(cid:2)log(1/τ )(cid:3))a
O(n(cid:2)log(1/τ )(cid:3))a
O(n log log n)

Query time

O((1/τ ) log logw(1/τ ))
O(1/τ )a
O((1/τ ) log n)
O(1/τ )a

be useful for this paper. Again, all these results hold on the RAM model with word
size w = (log n) bits.

2.1 Range Majorities

Range τ -majority queries were introduced by Karpinski and Nekrich [16], who presented 
an O(n/τ )-words structure with O((1/τ )(log log n)2) query time. Durocher et
al. [9] improved their word-space and query time to O(n(cid:2)log(1/τ )(cid:3)) and O(1/τ ),
respectively. Gagie et al. [13] presented another trade-off, where the space is
O(n(H + 1)) bits and the query time is O((1/τ ) log log n). Here H ≤ lg n denotes
the empirical entropy of the distribution of elements in A (we use lg to denote the
logarithm in base 2). The best current result in general is by Belazzougui et al. [1],
where the space is O(n) words and the query time is O(1/τ ). All these results assume
that τ is ﬁxed at construction time.
For the case where τ is also a part of the query input, data structures of space (in
words) O(n(H + 1)) and O(n log n) were proposed by Gagie et al. [13] and Chan
et al. [6], respectively. Very recently, Belazzougui et al. [1] brought down the space
occupancy to O(n log log σ ) words, where σ is the number of distinct elements in
A. The query time is O(1/τ ) in all cases. Belazzougui et al. [1] also presented a
compressed solution using n H + o(n log σ ) bits, with slightly higher query time. All
these solutions include a (sometimes compressed) representation of A, thus they are
not encodings. As far as we know, ours is the ﬁrst encoding for this problem.

For further reading, we recommend the recent survey by Skala [26].

2.2 Bitmap Representations
Let B[1, m] be a bitmap with n 1s. Operation rank(B, i ) returns, for any given parameter 
i, the number of 1s in B[1, i]. Operation select (B, j ) gives, for any parameter
j, the position of the j th 1 in B. Both operations can be solved in constant time with
data structures that use o(m) bits in addition to a plain representation of B [8]. Instead,
+ O(n) + o(m) bits while retaining constant
it is possible to compress B to n lg m
time for both operations [24]. This is most useful when n = o(m).
n
When n = o(m/ polylog m), even the o(m) extra bits of that compressed representation 
[24] are troublesome, and an Elias-Fano-based [10,11] compressed representation
+ O(n) bits, solves select in O(1) time and rank
[20] is useful. It requires n lg m
n

123

1086

Algorithmica (2016) 74:1082–1098

n

n

(cid:3) and H uses 2n + o(n) bits.

in O(log m
) time. The representation considers the positions of all the 1s in B,
(cid:3) bits of each xi in an array
xi = select (B, i ), and encodes the lowest b = (cid:2)lg m
n
L[1, n], L[i] = xi mod 2b. Then it deﬁnes a bitmap H[1, 2n] that encodes the highest
bits of the xi values: all the bits at positions i + (xi div 2b) are set in H. Bitmap
H is indexed for constant-time rank and select queries [8]. The space for L[1, n] is
n(cid:2)lg m
Now, select (B, j ) = 2b(select (H, j ) − j ) + L[i] can be computed in constant 
time. For rank(B, i ), we observe that the h th 0 in H represents the point
where the position B[2bh] is reached in the process of setting the 1s at positions
i + (xi div 2b), that is, xi−1 < 2bh ≤ xi . The number of 1s in H up to that position
is rank(B, 2bh). Therefore, if we write i = 2bh + l, then rank(B, i ) is between
j1 = rank(H, select0(H, h))+ 1 and j2 = rank(H, select0(H, h + 1)). Here, operation 
select0(H, h) gives the position of the h th 0 in H, and it is also computed
in constant time with a structure using o(n) bits [8]. Now we binary search for l in
L[ j1, j2], which is increasing in that range. The range is of length at most 2b, so the
search takes O(b) = O(log m
) time. The ﬁnal position j returned by the search is
rank(B, i ).
+ log s) on a RAM machine having
w-bit words by sampling, for each increasing interval of L of length more than s, one
value out of s. Predecessor data structures are built on the samples of each interval,
) bits. Then we ﬁrst run a predecessor query on L[ j1, j2],
taking at most O((n/s) log m
n
m
) [22], and ﬁnish with an O(log s)-time binary search
which takes time O(log logw
n
between the resulting samples.
+ n)
Lemma 1 A bitmap B[1, m] with n 1s can be stored in n log m
+log s),
bits, so that select queries take O(1) time and rank queries take O(log logw
for any s, on a RAM machine of w bits.

The time can be improved to O(log logw

m
n

+ O((n/s) log m

n

n

n

m
n

3 Lower Bounds

We derive a lower bound on the minimum size range τ -majority encodings may have,
even if we just ask them to count the number of distinct τ -majorities present in any
range. The idea is to show that we can encode a certain combinatorial object in the
array A, so that the object can be recovered via range τ -majority queries. Therefore,
in the worst case, the number of bits needed to solve such queries must be at least the
logarithm of the number of distinct combinatorial objects that can be encoded.
Consider a sequence of m permutations on [k]. There are k!m such sequences, thus
any encoding for them must use at least m lg(k!) bits in the worst case. Now consider
the following encoding. Array A will have length n = 4 · k · m. To encode the i th
permutation, πi = (x1 x2 . . . xk ), we will write the following chunk to array locations
A[4k(i − 1) + 1, 4ki]:

1, 2, 3, . . . , k, −1,−2,−3, . . . ,−2k, x1, x2, x3, . . . , xk .

We will set τ = 1/(2k+ 2) and perform τ -majority queries on parts of A to recover

any permutation.

123

Algorithmica (2016) 74:1082–1098

1087

Let us show how to obtain πi . Let C[1, 4k] = A[4k(i − 1) + 1, 4ki]. Consider an

interval of the form

C[(cid:9), 3k + g] = (cid:9), (cid:9) + 1, . . . , k,−1,−2, . . . ,−2k, x1, x2, . . . , xg,

for 1 ≤ (cid:9), g ≤ k. Note that x1, . . . , xg are the only values that may appear twice
in C[(cid:9), 3k + g], precisely, if they belong to {(cid:9), . . . , k}. Note that elements appearing
once in C[(cid:9), 3k + g] are not τ -majorities, since 1 ≤ τ (3k + g − (cid:9)+ 1) for any values
k, (cid:9), g. On the other hand, if an element appears twice in C[(cid:9), 3k + g], then it is a
τ -majority, since 2 > τ (3k + g − (cid:9) + 1) for any values k, (cid:9), g.
With this tool, we can discover x1 as follows. First, x1 is for sure a τ -majority in
C[1, 3k+1], since it appears twice. Now we query the range C[2, 3k+1], which lacks
number 1 compared to C[1, 3k + 1]. If there is no τ -majority, then x1 /∈ {2, . . . , k},
and we conclude that x1 = 1. If there is, then x1 ∈ {2, . . . , k} and we query the range
C[3, 3k + 1]. If there is no τ -majority, then x1 /∈ {3, . . . , k} and we conclude that
x1 = 2, and so on. The process is continued, if necessary, until reaching the range
C[k, 3k + 1], where we know that x1 = k.
To look for x2, we consider ranges of the form C[(cid:9), 3k+2], with identical reasoning.
This time, it is possible that element x1 is also counted as an answer, but since we
already know the value of x1, we simply subtract 1 from the count in any range
C[(cid:9), 3k + 2] with (cid:9) ≤ x1. This process continues analogously until we identify xk.
Example Consider encoding one permutation π = (3 1 2), of size k = 3 (i.e., m = 1).
Then we set τ = 1/8 and the array A[1, 12] is as follows:

1, 2, 3, −1,−2,−3,−4,−5,−6, 3, 1, 2

Now we will ﬁnd x1 (which is 3, but we do not know it yet). We know that A[1, 10]
has one τ -majority, since x1 must appear twice. Since A[2, 10] still has one τ -majority,
we know that x1 ∈ {2, 3}. And since A[3, 10] still has one τ -majority, we know that
x1 ∈ {3}, thus we learn x1 = 3.
Now let us ﬁnd x2. We know that A[1, 11] has two τ -majorities, since x1 and x2
must appear twice. Now, A[2, 11] has only one τ -majority, thus only one of {x1, x2}
is in {2, 3}. But we know x1 = 3, thus x2 /∈ {2, 3}, and we learn x2 = 1.

Finally, it can only be that x3 = 2.
Now, since n = 4km and τ = 1/(2k+2), we have that any encoding able to answer

the above queries requires at least

m lg (k!) ≥ m (k lg k − k lg e + 1) >

(cid:2)

(cid:2)

lg

n
4

1
2τ

(cid:3)
− 1

(cid:3)

− lg e

bits.2 This is (n(cid:2)log(1/τ )(cid:3)) as long as 1/τ is bounded from below by a constant
larger than 2 + 2e. Thus, to complete the proof, it is sufﬁcient to show that (n) is a
lower bound for any constant 1/τ ≤ 8, since 8 > 2 + 2e.

2 Bounding lg(k!) with integrals one obtains k lg(k/e) + 1 ≤ lg(k!) ≤ (k + 1) lg((k + 1)/e) + 1.

123

1088

Algorithmica (2016) 74:1082–1098

To show that (n) bits are necessary for any τ ≥ 1/8, consider encoding a bitmap
B[1, m] in an array A[1, 8m] so that, if B[i] = 0, then A[8(i−1)+1] = 1, A[8(i−1)+
2] = 2, and so on until A[8i] = 8. Instead, if B[i] = 1, then A[8(i − 1)+ 1, 8i] = 1.
Then, for any τ ≥ 1/8, there is a τ -majority in A[8(i − 1) + 1, 8i] iff B[i] = 1. As
there are 2m possible bitmaps B and our array is of length n = 8m, we need at least
m = n/8 = (n) bits for any encoding. Then the proof of Theorem 1 is complete.

4 An O((n/τ ) log log n) Bits Encoding for Range τ -Majorities

In this section we obtain an encoding using O((n/τ ) log log n) bits and solving τ -
majority queries in O((1/τ ) log n) time. In the next section we improve the space
usage. We assume that τ is ﬁxed at construction time. At query time, we will be able
to solve any τ(cid:6)

-majority query for any τ ≤ τ(cid:6) < 1.

4.1 The Basic Idea
Consider each distinct symbol x appearing in A[1, n]. Now consider the set Sx of
all the segments within [1, n] where x is a τ -majority (this includes, in particular,
all the segments [k, k] where A[k] = x). Segments in Sx may overlap each other.
Now let Ax[1, n] be a bitmap such that Ax[k] = 1 iff position k belongs to some
segment in Sx . We deﬁne a second bitmap related to x, Mx , so that if Ax[k] = 1, then
Mx[rank(Ax , k)] = 1 iff A[k] = x, where operation rank was deﬁned in Sect. 2.2.
Example Let our running example array be A[1, 7] = (cid:9)1 3 2 3 3 1 1(cid:10), and τ = 1/2.
Then we have the segments Sx :

S1 = {[1, 1],[6, 6],[7, 7],[6, 7],[5, 7]},
S2 = {[3, 3]},
S3 = {[2, 2],[4, 4],[5, 5],[4, 5],[2, 4],[3, 5],[4, 6],[2, 5],[1, 5],[2, 6]},

and the corresponding bitmaps Ax :

A1 = (cid:9)1 0 0 0 1 1 1(cid:10), A2 = (cid:9)0 0 1 0 0 0 0(cid:10), A3 = (cid:9)1 1 1 1 1 1 0(cid:10).

Finally, the corresponding bitmaps Mx are:

M1 = (cid:9)1 0 1 1(cid:10), M2 = (cid:9)1(cid:10), M3 = (cid:9)0 1 0 1 1 0(cid:10).

Then, the following result is not difﬁcult to prove.
Lemma 2 An element x is a τ(cid:6)
and 1 is a τ(cid:6)
-majority in A[i, j], then it is also a τ -majority. Thus, by deﬁnition,
Proof If x is a τ(cid:6)
[i, j] ∈ Sx , and therefore all the positions k ∈ [i, j] are set to 1 in Ax . Therefore,

-majority in A[i, j] iff Ax[k] = 1 for all i ≤ k ≤ j,

-majority in Mx[rank(Ax , i ), rank(Ax , j )].

123

Algorithmica (2016) 74:1082–1098

1089

the whole segment Ax[i, j] is mapped bijectively to Mx[rank(Ax , i ), rank(Ax , j )],
which is of the same length. Finally, the number of occurrences of x in A[i, j] is the
number of occurrences of 1 in Mx[rank(Ax , i ), rank(Ax , j )], which establishes the
result.
Conversely, if Ax[k] = 1 for all i ≤ k ≤ j, then A[i, j] is bijectively mapped
to Mx[rank(Ax , i ), rank(Ax , j )], and the 1s in this range correspond one to one
-majority in Mx[rank(Ax , i ),
with occurrences of x in A[i, j]. Therefore, if 1 is a τ(cid:6)
rank(Ax , j )], then x is a τ(cid:6)
(cid:11)(cid:12)
Example Value 1 is a majority in A[5, 7], and it holds that A1[5, 7] = (cid:9)1 1 1(cid:10) and
M1[rank(A1, 5), rank(A1, 7)] = M1[2, 4] = (cid:9)0 1 1(cid:10), where 1 is a majority.
Thus, with Ax and Mx we can determine whether x is a majority in a range.

-majority in A[i, j].

-majority in any A[i, j].

(cid:6) = rank(Ax , i ) and j

Lemma 3 It is sufﬁcient to have rank-enabled bitmaps Ax and Mx to determine, in
constant time, whether x is a τ(cid:6)
(cid:6) = rank(Ax , j ). If
Proof We use Lemma 2. We compute i
(cid:6) (cid:13)= j − i, then Ax[k] = 0 for some i ≤ k ≤ j and thus x is not a τ -majority
(cid:6) − i
j
in A[i, j], hence it is also not a τ(cid:6)
-majority. Otherwise, we ﬁnd out whether 1 is a
-majority in Mx[i
(cid:6) − 1) >
τ(cid:6)
(cid:6) − i
τ(cid:6)( j
To ﬁnd any position i ≤ k ≤ j where A[k] = x, we need the operation select (B, j ),
-majority in A[i, j], its leftmost
(cid:6) − 1) + 1). In general, for
(cid:6) − 1), we can retrieve the t th occurrence
(cid:11)(cid:12)

deﬁned in Sect. 2.2. Then, for example, if x is a τ(cid:6)
occurrence in A[i, j] is i − i
any 1 ≤ t ≤ rank(Mx , j
with i − i

(cid:6) + select (Mx , rank(Mx , i

(cid:6) + select (Mx , rank(Mx , i

(cid:6), j

(cid:6)], by checking whether rank(Mx , j

(cid:6)) − rank(Mx , i

(cid:6)) − rank(Mx , i

(cid:6) − 1) + t ).

(cid:6) + 1).

4.2 Coalescing the Bitmaps

We cannot afford to store (and probe!) all the bitmaps Ax and Mx for all x, however.
The next lemma is the ﬁrst step to reduce the total space to slightly superlinear.
Lemma 4 For any position A[k] = x there are at most 2(cid:2)1/τ(cid:3) 1s in Ax .
Proof Consider a process where we start with A[k] =⊥ for all k, and set the values
A[k] = x progressively. We will distinguish three kinds of changes.
(1) New segments around A[k] are created in Sx Setting A[k] = x creates in Sx all the
segments of the form[k−kl , k+kr] for 1 > τ (kr +kl +1), or kl +kr < 1/τ −1. Their
union is the area Ax[k −(cid:2)1/τ(cid:3)+ 2, . . . , k +(cid:2)1/τ(cid:3)− 2] = 1, which may increase the
number of 1s in Ax by up to 2(cid:2)1/τ(cid:3) − 3.
(2) Segments already covering A[k] are extended Any maximal segment [l, r] ∈ Sx
covering Ax[k] contains c > τ (r − l + 1) occurrences of x, but it holds that c ≤
τ (r − l + 2), otherwise there would also exist segments [l − 1, r] and [l, r + 1] in Sx ,
and [l, r] would not be maximal. Therefore, adding one more occurrence, A[k] = 1,
we get c + 1 ≤ τ (r − l + 2 + 1/τ ) occurrences in [l, r]. Now it holds that x may be

123

1090

Algorithmica (2016) 74:1082–1098

a τ -majority in segments [l − kl , r + kr] for all 0 ≤ kl + kr < 1 + 1/τ (i.e., where
c + 1 > τ (r − l + 1 + kl + kr ), using only that c + 1 ≤ τ (r − l + 2 + 1/τ )), and
therefore we can extend [l, r] to the left by up to (cid:2)1/τ(cid:3), or to the right by up to (cid:2)1/τ(cid:3).
(3) Segments reaching close to A[k] are extended The same reasoning as for the
previous case applies, even if [l, r] does not originally contain position k. There are
more restrictions, since now [l − kl , r + kr] must be so that it contains k, and the same
limit 0 ≤ kl +kr < 1+1/τ applies. Thus, in addition to being possible to extend them
by at most (cid:2)1/τ(cid:3) cells in either direction, position k must lie within the extended area.
Total extension The three cases above are superimposed. Let (cid:9)l and (cid:9)r the closest
positions (cid:9)l ≤ k ≤ (cid:9)r where Ax[(cid:9)l] = Ax[(cid:9)r] = 1. Then, if (cid:9)l = k, we can set
at most (cid:2)1/τ(cid:3) new 1s in Ax to the left of k by extending segments using case (2).
Otherwise, if k − (cid:9)l ≤ (cid:2)1/τ(cid:3), we can cover the area Ax[(cid:9)l + 1, . . . , k] and add up to
(cid:2)1/τ(cid:3)− (k − (cid:9)l ) further cells to the left, using case (3). Otherwise, if k − (cid:9)l > (cid:2)1/τ(cid:3),
we set (cid:2)1/τ(cid:3) − 2 cells to the left, apart from k, using case (1). The same reasoning
applies to the right, and therefore 2(cid:2)1/τ(cid:3) is an upper bound to the number of 1s in Ax
(cid:11)(cid:12)
produced by each new occurrence of x in A.
The lemma shows that all the Ax bitmaps add up to O(n/τ ) 1s, and thus the lengths
of all the Mx bitmaps add up to O(n/τ ) as well (recall that Mx has one position per 1
in Ax ). Therefore, we can store all the Mx bitmaps within O(n/τ ) bits of space. We
cannot, however, store all the Ax bitmaps, as they may add up to O(n2) 0s (note there
can be O(n) distinct symbols x), and we still cannot probe all the Ax bitmaps for all
x in o(n) time.
(cid:6)
Instead, we will coalesce all the bitmaps Ax into a smaller number of bitmaps A
r
(which will be called coalesced bitmaps). Coalescing works as follows. Let us write
[1, n] = 0 for
A[i, j] = b to mean A[(cid:9)] = b for all i ≤ (cid:9) ≤ j. We start with all A
all r. Then we take each maximal area of all 1s of each bitmap, Ax[i, j] = 1, choose
[i, j] = 1. That is, we copy the run of
some r such that A
(cid:6)
1s from Ax to some coalesced bitmap A
r such that the run does not overlap nor touch
other previous runs already copied (i.e., there must be at least one 0 between any two
(cid:6)
r where the areas of each
copied runs of 1s). We associate to each such A
Mx corresponding to each coalesced area of Ax are concatenated, in the same order
[it , jt] = 1, the t th left-to-right run of 1s in A
(cid:6)
r ,
of the coalesced areas. That is, if A
was copied from Ax , then Mx[rank(Ax , it ), rank(Ax , jt )] will be the t th segment
appended to M
(cid:6) = (cid:9)1 0 1 0 1 1 1(cid:10),

Example We can coalesce the whole bitmaps A1 and A2 into A
with the corresponding bitmap M
(cid:6)
r will replace the original bitmaps Ax and Mx .
At query time, we check for the area [i, j] of each coalesced bitmap using Lemma 3.
We cannot confuse the areas of different symbols x because we force that there is at
least one 0 between any two areas. We cannot report the same τ(cid:6)
-majority x in more
than one coalesced bitmap, as both areas should overlap on [i, j] and then they would
have been merged as a single area in Ax . If we ﬁnd one τ(cid:6)
-majority in one coalesced
bitmap, we know that there is a τ(cid:6)
-majority x and can spot all of its occurrences (or
the leftmost, if desired) in optimal time, even if we cannot know the identity of x.
Moreover, we will ﬁnd all the distinct τ(cid:6)

(cid:6) = (cid:9)1 1 0 1 1(cid:10).

(cid:6)
r a bitmap M

(cid:6)
r

[i −1, j +1] = 0, and set A

(cid:6)
r

The coalesced bitmaps A

(cid:6)
r and M

(cid:6)
r

(cid:6)
r .

(cid:6)
r

-majorities in this way.

123

Algorithmica (2016) 74:1082–1098

1091

4.3 Bounding the Number of Coalesced Bitmaps

This scheme will work well if we obtain just a few coalesced bitmaps overall. Next
we show how to obtain only O((1/τ ) log n) coalesced bitmaps.

(cid:6)

(cid:6)

τ

(cid:6)

(cid:6)

(cid:6)
(cid:6)

(cid:13)= x such that Ax(cid:6)[k] = 1. This means that x
, it must be that x
(cid:6)

Lemma 5 At most 2 log1+τ n distinct values of x can have Ax[k] = 1 for a given k.
Proof First, A[k] = x is a τ -majority in A[k, k], thus Ax[k] = 1. Now consider any
other element x
is a τ -majority in
some [i, j] that contains k. Since A[k] (cid:13)= x
is a τ -majority in
[i, k − 1] or in [k + 1, j] (or in both). We say x
is a left-majority in the ﬁrst case
and a right-majority in the second. Let us call y1, y2, . . . the x
values that are leftmajorities,
 and i1, i2, . . . the starting points of their segments (if they are τ -majorities
in several segments covering k, we choose one arbitrarily). Similarly, let z1, z2, . . .
values that are right-majorities, and j1, j2, . . . the ending points of their
be the x
segments. Assume the left-majorities are sorted by decreasing values of ir and the
right-majorities are sorted by increasing values of jr . If a same value x
appears in
both lists, we arbitrarily remove one of them. As an exception, we will start both lists
with y0 = z0 = x, with i0 = j0 = k.
It is easy to see by induction that yr must appear at least (1 + τ )r times in the
interval [ir , k] (or in [ir , k − 1], which is the same). This clearly holds for y0 = x.
Now, by the inductive hypothesis, values y0, y1, . . . , yr−1 appear at least (1+τ )0, (1+
τ )1, . . . , (1+τ )r−1 times within[ir−1, k−1] (which contains all the intervals), adding
up to (1+τ )r−1
. In order to be a leftmajority,
 element yr must appear strictly more than τ (k − ir−1) ≥ (1+ τ )r − 1 times
in [ir , k − 1], to outweight all the occurrences of the previous symbols. The case of
right-majorities is analogous.
This shows that there cannot be more than log1+τ n left-majorities and log1+τ n
(cid:11)(cid:12)

occurrences. Thus k − 1 − ir−1 + 1 ≥ (1+τ )r−1

τ

(cid:6)

right-majorities.

In the following it will be useful to deﬁne Cx as the set of maximal contiguous areas
of 1s in Ax . That is, Cx is obtained by merging all the segments of Sx that touch or
overlap. Note that segments of Cx do not overlap, unlike those of Sx . Since a segment
of Cx covers a position k iff some segment of Sx covers position k (and iff Ax[k] = 1),
it follows by Lemma 5 that any position is covered by at most 2 log1+τ n segments of
Cx of distinct symbols x.
Note that a pair of consecutive positions A[k] = x and A[k + 1] = y is also
covered by at most 2 log1+τ n such segments: the right-majorities for A[k] either are
y or are also right-majorities for A[k + 1], and those are already among the log1+τ n
right-majorities of A[k + 1]. And vice versa.
We obtain O(log1+τ n) coalesced bitmaps as follows. We take the union of all
the sets Cx of all the symbols x and sort the segments by their starting points. Then
we start ﬁlling coalesced bitmaps. We check if the current segment can be added to
an existing bitmap without producing overlaps (and leaving a 0 in between). If we
can, we choose any appropriate bitmap, otherwise we start a new bitmap. If at some
point we need more than 2 log1+τ n bitmaps, it is because all the last segments of the

123

1092

Algorithmica (2016) 74:1082–1098

(cid:6)

current 2 log1+τ n bitmaps overlap either the starting point of the current segment or
the previous position, a contradiction.
Example We have C1 = {[1, 1],[5, 7]}, C2 = {[3, 3]}, and C3 = {[1, 6]}. Now,
we take C1 ∪ C2 ∪ C3 = {[1, 1],[1, 6],[3, 3],[5, 7]}, and the process produces pre-
, corresponding to the set {[1, 1],[3, 3],[5, 7]}, and
cisely the coalesced bitmaps A
A3, corresponding to {[1, 6]}.
Note that in general the coalesced bitmaps may not correspond to the union of
complete original bitmaps Ax , but areas of a bitmap Ax may end up in different
coalesced bitmaps.
the coalescing process produces O(log1+τ n) = O((1/τ ) log n)

Therefore,

bitmaps. Consequently, we obtain O((1/τ ) log n) query time by simply checking the
coalesced bitmaps one by one using Lemma 3.

(cid:6)

Finally, representing the O((1/τ ) log n) coalesced bitmaps A

, which have total
length O((n/τ ) log n) and contain O(n/τ ) 1s, requires O((n/τ ) log log n) bits if we
use a compressed bitmap representation [24] that still offers constant-time rank and
still have total length
select queries (recall Sect. 2.2). The coalesced bitmaps M
O(n/τ ).

(cid:6)

This completes the ﬁrst part of our result. Next, we will reduce the space usage of

our encoding.

5 Reducing the Space to O(n(cid:2)log(1/τ )(cid:3)) Bits

We introduce a different representation of the coalesced bitmaps that allows us to store
them in O(n(cid:2)log(1/τ )(cid:3)) bits, while retaining the same mechanism described above.
We note that, although there can be O(n/τ ) bits set in the bitmaps Ax , each new
element x produces at most one new run of contiguous 1s (case (1) in the proof of
Lemma 4). Therefore there are at most n runs in total. We will use a representation of
coalesced bitmaps that takes advantage of these runs.
We will distinguish segments of Cx by their lengths, separating lengths by ranges
between (cid:2)2(cid:9)/τ(cid:3) and (cid:2)2(cid:9)+1/τ(cid:3) − 1, for any level 0 ≤ (cid:9) ≤ lg(τ n) (level 0 is special
in that it contains lengths starting from 1). In the process of creating the coalesced
bitmaps described in the previous section, we will have separate coalesced bitmaps for
inserting segments within each range of lengths; these will be called bitmaps of level
(cid:9). There may be several bitmaps of the same level. It is important that, even with this
restriction, our coalescing process will still generate O((1/τ ) log n) bitmaps, because
only O(1/τ ) coalesced bitmaps of each level (cid:9) will be generated.
Lemma 6 There can be at most 4/τ segments of any Cx , of length between (cid:2)2(cid:9)/τ(cid:3)
and (cid:2)2(cid:9)+1/τ(cid:3) − 1, covering a given position k, for any (cid:9).
Proof Any such segment must be contained in the area A[k − (cid:2)2(cid:9)+1/τ(cid:3) + 1, k +
(cid:2)2(cid:9)+1/τ(cid:3) − 1], and if x is a τ -majority in it, it must appear more than τ(cid:2)2(cid:9)/τ(cid:3) ≥ 2(cid:9)
times. There can be at most 4/τ different values of x appearing more than 2(cid:9) times in
(cid:11)(cid:12)
an area of length < 2(cid:9)+2/τ .

123

Algorithmica (2016) 74:1082–1098

1093

(cid:6)

(cid:6)

(cid:6)
1

(cid:6)
2

is all 1s, and A

[i] = 1 iff the i th chunk of A

(cid:6)[1, n] of level (cid:9). All of its 1s come in runs of
Consider a coalesced bitmap A
lengths at least b = (cid:2)2(cid:9)/τ(cid:3). We cut A
(cid:6)
into chunks of length b and deﬁne two bitmaps:
[1, n/b] will
[1, n/b] will have A
(cid:6)
A
[i] = 1 iff the i th chunk of A
1
has 0s and 1s. Note that, since the runs of
have A
1s are of length at least b, inside a chunk with 0s and 1s there can be at most one
01 and at most one 10, and the 10 can only come before the 01. Let p10[ j] be the
position, in the j th chunk with 0s and 1s, of the 1 preceding a 0, where p10[ j] = 0
if the chunk starts with a 0. Similarly, let p01[ j] be the position of the 0 preceding a
1, with p01[ j] = b if the chunk ends with a 0. It always holds that p10[ j] < p01[ j],
and the number of 1s in the chunk is r ( j ) = p10[ j]+ (b − p01[ j]). Also, the rank up
to position k in the chunk, r ( j, k), is k if k ≤ p10[ j], p10[ j] if p10[ j] < k ≤ p01[ j],
and p10[ j] + (k − p01[ j]) if k > p01[ j]. Then it holds that

(cid:6)
2

rank(A

(cid:6), i ) = b · r1 +

[1 + (cid:16)i /b(cid:17)] · k] otherwise,

if A

[1 + (cid:16)i /b(cid:17)] = 1,

(cid:6)
2

(cid:9)

⎞
⎠ +

⎛
⎝ r2(cid:6)
j=1

r ( j )

r (r2 + 1, k)
(cid:6)
A
1
,(cid:16)i /b(cid:17)), r2 = rank(A

(cid:6)
2

(cid:6)
1

(cid:6)
1 and A

. Then, we would have A

(cid:6)
2, and constant-time access and sums on p10 and p01.

,(cid:16)i /b(cid:17)), and k = i mod b. Note this can
where r1 = rank(A
be computed in constant time as long as we have constant-time rank data structures
on A
Example Using b = 2(cid:9) to make it more interesting, we would have three coalesced
(cid:6) = (cid:9)1 0 1 0 0 0 0(cid:10), of level (cid:9) = 0, for the segments [1, 1] and [3, 3];
bitmaps: A
(cid:6)(cid:6) = (cid:9)0 0 0 0 1 1 1(cid:10), of level (cid:9) = 1, for the segment [5, 7]; and A
(cid:6)(cid:6)(cid:6) = (cid:9)1 1 1 1 1 1 0(cid:10),
A
of level (cid:9) = 2, for the segment [1, 6]. Consider level (cid:9) = 0 and b = 2, and let us
= (cid:9)1 1 0 0(cid:10), p10 = (cid:9)1 1(cid:10), and
(cid:6)
focus on A
p01 = (cid:9)2 2(cid:10).
To have constant-time sums on p10 ( p01 is analogous), we store its values in a
j=1 p10[ j] to 1, for all r. Then
bitmap A
, r ) − r. We use a bitmap representation
we can recover
(cid:6)
[20] that solves select in constant time (recall Sect. 2.2). Let n
be the number of
(cid:6)
chunks with 0s and
. Then there are at most 2n
segments Cx represented in bitmap A
b 0s (as 0 ≤ p10[ j] ≤ b). The size of
1s, and A
(cid:6)((cid:9)+ log(1/τ ))) bits.
log b) = O(n
the bitmap representation [20] is in this case O(n
(cid:6)
2 are represented in plain form [8], requiring
On the other hand, bitmaps A
O(n/b) = O(nτ/2(cid:9)) bits.

= (cid:9)0 0 0 0(cid:10), A
10, where we set all the bits at positions r +(cid:10)

(cid:6)
10 contains at most 2n
(cid:6)
1 and A

j=1 p10[ j] = select (A

1s and 2n

(cid:10)

(cid:6)
10

(cid:6)
1

(cid:6)
2

(cid:6)

(cid:6)

(cid:6)

(cid:6)

(cid:6)

r

r

Considering that there are O(n/τ ) 1s overall, and that the runs of level (cid:9) are of
length at least 2(cid:9)/τ , we have that there can be at most n/2(cid:9) runs across the O(1/τ )
bitmaps of level (cid:9). Therefore, adding up the space over the bitmaps of level (cid:9), we have
O(n((cid:9) + log(1/τ ))/2(cid:9)) bits. Added over all the levels (cid:9), this gives O(n(cid:2)log(1/τ )(cid:3))
bits.

Let us now consider the representation of the coalesced bitmaps M

. They have
total length O(n/τ ) and contain n 1s overall, therefore using the representation of
Lemma 1 with s = 1, we have O(n(cid:2)log(1/τ )(cid:3)) bits of space. They solve rank queries
in time O(log logw(1/τ )), and select in constant time.

(cid:6)

123

1094

Algorithmica (2016) 74:1082–1098

As we have to probe O((1/τ ) log n) coalesced bitmaps M

in the worst case, this
raises our query time to O((1/τ ) log logw(1/τ ) log n). This concludes the proof of
Theorem 2, except for the construction time (see the next section).

(cid:6)

∗

In our previous work [19], we had obtained O((1/τ ) log n) time, but using
n) bits of space. It is not hard to obtain that time, using O(n/τ ) bits,
O((n/τ ) log
using plain rank/select structures
by simply representing the coalesced bitmaps M
[8], or even using O(n(cid:2)log(1/τ )(cid:3) + (n/τ )/ polylog n) bits, for any polylog n, using
compressed representations [23]. The extra O(log logw(1/τ )) time factor arises when
we insist in obtaining the optimal O(n(cid:2)log(1/τ )(cid:3)) bit space. We note that this time
penalty factor vanishes when 1/τ = wO(1), which includes the case where 1/τ grows
polylogarithmically with n.

(cid:6)

6 Construction

The most complex part of the construction of our encoding is to build the sets Cx .
Once these are built, the structures described in Sect. 5 can be easily constructed in
o(n log n) time:
1. The O(n) segments Cx belong to [1, n], so they are sorted by starting point in

O(n) time.

(cid:6)

3. The bitmaps A

2. We maintain a priority queue for each level (cid:9), containing the last segment of each
coalesced bitmap. We use the queue to ﬁnd the segment that ﬁnishes earliest in
order to try to add the new segment of Cx after it. We carry out, in total, O(n)
operations on those queues, and each contains O(1/τ ) elements, thus they take
total time O(n(cid:2)log(1/τ )(cid:3)) = o(n log n).
(cid:6)
10, are easily
built in O(n/b) = O(nτ/2(cid:9)) time. Added over the O(1/τ ) coalesced bitmaps of
level (cid:9) this is O(n/2(cid:9)), and added over all the levels (cid:9) this gives O(n) total time.
have O(n) 1s overall, so their representation (Lemma 1)
is also built in O(n) time, except for the predecessor structures, which need construction 
of deterministic dictionaries. This can be done in o(n log n) total time
[25].

of each level (cid:9), represented with A

4. The coalesced bitmaps M

(cid:6)
1, A

(cid:6)
2, A

(cid:6)
01 and A

(cid:6)

Now we show that the sets Cx can be built in O(n log n) time, thus ﬁnishing the

proof of Theorem 2.

We build the set of increasing positions Px where x appears in A, for each x, in
O(n log n) total time (the elements of A can be of any atomic type, so we only rely
on a comparison-based dictionary to maintain the set of different x values and their
Px lists). Now we build Cx from each Px using a divide-and-conquer approach, in
O(|Px| log|Px|) time, for a total construction time of O(n log n).
We pick the middle element k ∈ Px and compute in linear time the segment
[l, r] ∈ Cx that contains k. To compute l, we ﬁnd the leftmost element pl ∈ Px such
that x is a τ -majority in [ pl , kr], for some kr ∈ Px with kr ≥ k.
To ﬁnd pl, we note that it must hold that (w( pl , k−1)+w(k, kr ))/(kr− pl+1) > τ ,
where w(i, j ) is the number of occurrences of x in A[i, j]. The condition is equivalent
to w( pl , k − 1)/τ + pl − 1 > kr − w(k, kr )/τ . Thus we compute in linear time the

123

Algorithmica (2016) 74:1082–1098

1095

minimum value v of kr − w(k, kr )/τ over all those kr ∈ Px to the right of k, and then
traverse all those pl ∈ Px to the left of k, left to right, to ﬁnd the ﬁrst one that satisﬁes
w( pl , k − 1)/τ + pl + 1 > v, also in linear time. Once we ﬁnd the proper pl and its
corresponding kr , the starting position of the segment is slightly adjusted to the left of
pl, to be the smallest value that satisﬁes w( pl , kr )/(kr − l + 1) > τ , that is, l satisﬁes
l > −w( pl , kr )/τ + kr + 1, or l = kr − (cid:2)w( pl , kr )/τ(cid:3) + 2.
Once pr and then r are computed analogously, we insert [l, r] into Cx and continue
recursively with the elements of Px to the left of pl and to the right of pr . Upon return,
it might be necessary to join [l, r] with the rightmost segment of the left part and/or
with the leftmost segment of the right part, in constant time. The total construction
time is T (n) = O(n) + 2T (n/2) = O(n log n).
Building Multiple Structures In order to answer τ(cid:6)
τ(cid:6) < 1 in time related to 1/τ(cid:6)
for values τ(cid:6)(cid:6) = 1/2, 1/4, 1/8, . . . , 1/2
(cid:2)lg 1/τ(cid:3)
. Since τ(cid:6)/2 < τ(cid:6)(cid:6) ≤ τ(cid:6)
the structure built for τ(cid:6)(cid:6) = 1/2
(cid:2)lg 1/τ(cid:6)(cid:3)
O((1/τ(cid:6)(cid:6)) log logw(1/τ(cid:6)(cid:6)) log n) = O((1/τ(cid:6)) log logw(1/τ(cid:6)) log n).
bits, and the construction time is O(n(cid:2)log(1/τ )(cid:3) log n).
Corollary 1 Given a real number 0 < τ < 1, there exists an encoding using
O(n(cid:2)log2(1/τ )(cid:3)) bits that answers range τ(cid:6)
-majority queries, for any τ ≤ τ(cid:6) < 1,
in time O((1/τ(cid:6)) log logw(1/τ(cid:6)) log n), where w = (log n) is the RAM word size in
bits. The structure can be built in time O(n(cid:2)log(1/τ )(cid:3) log n).

-majority queries for any τ ≤
and not to 1/τ , we build the encoding of Theorem 2
-majority query is run on
, the query time is
As for the space, we build O((cid:2)log(1/τ )(cid:3)) structures, so we use O(n(cid:2)log2(1/τ )(cid:3))

. Then, a τ(cid:6)

7 A Faster Data Structure

In this section we show how, by adding O(n log log n) bits to our data structure,
we can slash a log n factor from the query time, that is, we prove Theorem 3. The
result, as discussed in the Introduction, yields the optimal query time O(1/τ ) when
1/τ = O(polylog n), although the resulting space may not be optimal anymore.

The idea is inspired by a previous non-encoding data structure for majority queries
[9]. Consider a value (cid:9). Then we will cut A into consecutive pieces of length 2(cid:9)
(said to be of level (cid:9)) in two overlapped ways: A[2(cid:9)k + 1, 2(cid:9)(k + 1)] and A[2(cid:9)k +
2(cid:9)−1 + 1, 2(cid:9)(k + 1) + 2(cid:9)−1], for all k ≥ 0. We carry out this partitioning for every
(cid:2)lg(1/τ )(cid:3) ≤ (cid:9) ≤ (cid:2)lg n(cid:3).
Note that there are O(n/2(cid:9)) pieces of level (cid:9), and any interval A[i, j] of length up
to 2(cid:9)/2 is contained in some piece P of level (cid:9). Now, given a query interval A[i, j], let
(cid:9) = (cid:2)lg( j − i + 1)(cid:3)+ 1. Then, not only A[i, j] is contained in a piece P of level (cid:9), but
also any τ -majority x in A[i, j] must be a τ/4-majority in P: Since j − i + 1 > 2(cid:9)/4,
x occurs more than τ ( j − i + 1) > (τ/4)2(cid:9) times in A[i, j], and thus in P.
Consider a τ/4-majority x in a given piece P of level (cid:9) that is also a τ -majority
for some range A[i, j] within P, where 2(cid:9)/4 < j − i + 1 ≤ 2(cid:9)/2. By construction
of our previous structures, there exists a maximal segment Cx that contains the range
(cid:6)] within P where x is a τ -majority, then there
[i, j]. If there is another range A[i
(cid:6), j
(cid:6)
x for the same x within P. By our construction,
exists another maximal segment C

123

1096

Algorithmica (2016) 74:1082–1098

(cid:6)
x

(cid:13)= Cx , then C

(cid:6)
if C
x is disjoint with Cx , and thus each of them contains at least
(τ/4)2(cid:9) distinct occurrences of x. Obviously, segments Cy for τ -majorities y (cid:13)= x
contain other (τ/4)2(cid:9) occurrences disjoint from those of x. Therefore, the number
of distinct maximal segments C that contain τ -majorities at any range A[i, j] (with
j − i + 1 > 2(cid:9)/4) within P is upper bounded by 4/τ . We will say those segments C
are relevant to P.

(cid:6)
r (and its companion M

Therefore, for each piece P of level (cid:9), we will store the index r of the coalesced
(cid:6)
r ) to which each maximal segment C that is relevant to
bitmap A
P belongs. Since there are at most 4/τ such coalesced bitmaps to record, out of a total
of O((1/τ ) log n) coalesced bitmaps, γ -codes on a differential encoding of the subset
values requires O((1/τ ) log log n) bits.3 Added up over the O(n/2(cid:9)) pieces of level
(cid:9)≥(cid:2)lg(1/τ )(cid:3) O((n/2(cid:9))(1/τ ) log log n) = O(n log log n)
(cid:9) ≥ (cid:2)lg(1/τ )(cid:3), this yields
bits.

(cid:10)

(cid:6)
r and M

This information reduces the search effort to that of verifying O(1/τ ) coalesced

r for the range [i, j], and thus to O((1/τ ) log logw(1/τ )) query
(cid:6)

bitmaps A
time. However, for ranges shorter than 1/τ , where no piece structure has been built,
we still have the original query time. To speed up this case, we build a second structure
where, for each element A[k], we identify the coalesced bitmap where the maximal
segment C A[k] containing the segment A[k, k] belongs, and store the identiﬁer r of
(cid:6)
(cid:6)
r ) associated with k. This requires
r (and M
the corresponding coalesced bitmap A
O(n(cid:2)log((1/τ ) log n)(cid:3)) = O(n(cid:2)log(1/τ )(cid:3) + n log log n) further bits, and allows
(cid:6)
(cid:6)
r ) for each of the O(1/τ ) positions
r (and M
checking only one coalesced bitmap A
that need to be checked.

To ﬁnish the proof we must consider the construction time. The second structure
(for short ranges) is easily built with the general structure, taking asymptotically the
same amount of time, by keeping track of which maximal segment C A[k] contains each
segment A[k, k] and which coalesced bitmap it is assigned. With this, the structure for
long ranges can be built as follows: for each position A[k] contained in a piece P of
level (cid:9), consider the maximal segment C A[k] that contains it and determine whether
where
it is relevant to P. A weak test for this is to consider the coalesced bitmap M
C A[k] is represented (which is precisely what the ﬁrst structure stores associated with
contains more than (τ/4)2(cid:9) 1s in the range of P. This must
k) and ask whether M
be the case if C A[k] is relevant to P. Although including the identiﬁer of each M
that
passes the test may add some nonrelevant ones, we still cannot include more than 4/τ
coalesced bitmaps in the set, as the 1s in the M

bitmaps are disjoint.

(cid:6)

(cid:6)

(cid:6)

(cid:6)

(cid:6)

(cid:6)

The rank operations on bitmaps M

take O(log logw(1/τ )) time, so we avoid
contains in the range of P. Instead, we perform
using them to count how many 1s M
a preprocessing pass over P as follows: We initialize to zero a set of O((1/τ ) log n)
(cid:6)
, and process P left to right. We increase the
counters, one per coalesced bitmap M
of each element A[k] in P. At the end, we
(cid:6)
counter associated with the bitmap M
know all the desired values. This takes O(2(cid:9)) time, and a similar postprocessing pass
clears the counter for the next piece.

3 We could also afford to store them in plain form, in O((1/τ )((cid:2)log(1/τ )(cid:3) + log log n)) bits.

123

Algorithmica (2016) 74:1082–1098

1097

Therefore, we process all the pieces P of level (cid:9) in time O(2(cid:9)), which amounts to
O(n) time per level. Added over all the levels, this gives O(n log n) total time. This
concludes the proof of Theorem 3.

8 Conclusions
A τ -majority query on array A[1, n] receives a range [i, j] and returns all the elements
appearing more than τ ( j − i + 1) times in A[i, j]. We have obtained the ﬁrst results
about encodings for answering range τ -majority queries. Encodings are data structures
that use less space than what is required to store A and answer queries without accessing
A at all. In the encoding scenario we do not report the τ -majorities themselves, but
one of their positions in A[i, j].
We have proved that (n(cid:2)log(1/τ )(cid:3)) bits are necessary for any such encoding,
even if it can only count the number of τ -majorities in any range. Then we presented 
an encoding that uses the optimal O(n(cid:2)log(1/τ )(cid:3)) bits, and answers queries in
O((1/τ ) log logw(1/τ ) log n) time in the RAM model with word size w = (log n)
bits. We also showed that this time can be divided by log n if we add O(n log log n)
bits to the space. This yields various space/time tradeoffs, shown in Table 1. Our
encoding can actually report any occurrence of each τ -majority, in optimal extra time.
The structure is built in O(n log n) time.

An open question is whether it is possible to achieve optimal query time within
optimal space for all values of 1/τ . As seen in Table 1, we reach this only for
log(1/τ ) = (log log n). This is also possible when log(1/τ ) = (log n), where
we leave the non-encoding scenario [1]. Instead, our results for log(1/τ ) between
log log n and log n have a small factor O(log logw(1/τ )) over the optimal time, and
those for log(1/τ ) below log log n either require nonoptimal O(n log log n) bits of
space, or an O(log n) factor over the optimal time. It is not clear whether combined
optimality can be reached.

Another open question is whether we can do better for weaker versions of the
problem we have not studied. For example, if we are only required to report any
occurrence of any τ -majority (or, even less, telling whether or not there exists a τ -
majority), our lower bound based on representing a bitmap B shows that (n) bits
are necessary, but we do not know if this bound is tight.

Acknowledgments We thank the reviewers for their valuable comments.

References

1. Belazzougui, D., Gagie, T., Navarro, G.: Better space bounds for parameterized range majority and
minority. In: Proc. 11th Annual Workshop on Algorithms and Data Structures (WADS), pp. 121–132
(2013)

2. Berkman, O., Vishkin, U.: Recursive star-tree parallel data structure. SIAM J. Comput. 22(2), 221–242

(1993)

3. Bose, P., Kranakis, E., Morin, P., Tang, Y.: Approximate range mode and range median queries. In: Proc.
22nd International Symposium on Theoretical Aspects of Computer Science (STACS), pp. 377–388
(2005)

123

1098

Algorithmica (2016) 74:1082–1098

4. Brodal, G., Fagerberg, R., Greve, M., López-Ortiz, A.: Online sorted range reporting. In: Proc. 20th

Annual International Symposium on Algorithms and Computation (ISAAC), pp. 173–182 (2009)

5. Chan, T., Durocher, S., Larsen, K., Morrison, J., Wilkinson, B.: Linear-space data structures for range
mode query in arrays. In: Proc. 29th International Symposium on Theoretical Aspects of Computer
Science (STACS), pp. 290–301 (2012)

6. Chan, T., Durocher, S., Skala, M., Wilkinson, B.: Linear-space data structures for range minority query
in arrays. In: Proc. 13th Scandinavian Symposium on Algorithmic Theory (SWAT), pp. 295–306 (2012)
7. Chan, T., Wilkinson, B.: Adaptive and approximate orthogonal range counting. In: Proc. 24th Annual

ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 241–251 (2013)

8. Clark, D.: Compact PAT trees. Ph.D. thesis, University of Waterloo, Canada (1996)
9. Durocher, S., He, M., Munro, I., Nicholson, P., Skala, M.: Range majority in constant time and linear

space. Inform. Comput. 222, 169–179 (2013)

10. Elias, P.: Efﬁcient storage and retrieval by content and address of static ﬁles. J. ACM 21, 246–260

(1974)

11. Fano, R.: On the number of bits required to implement an associative memory. Memo 61, Computer

Structures Group, Project MAC, MA (1971)

12. Fischer, J., Heun, V.: Space-efﬁcient preprocessing schemes for range minimum queries on static

arrays. SIAM J. Comput. 40(2), 465–492 (2011)

13. Gagie, T., He, M., Munro, I., Nicholson, P.: Finding frequent elements in compressed 2d arrays
and strings. In: Proc. 18th International Symposium on String Processing and Information Retrieval
(SPIRE), pp. 295–300 (2011)

14. Greve, M., Jørgensen, A., Larsen, K.D., Truelsen, J.: Cell probe lower bounds and approximations
for range mode. In: Proc. 37th International Colloquium on Automata, Languages and Programming
(ICALP), pp. 605–616 (2010)

15. Grossi, R., Iacono, J., Navarro, G., Raman, R., Satti, S.R.: Encodings for range selection and top-k

queries. In: Proc. 21st Annual European Symposium on Algorithms (ESA), pp. 553–564 (2013)

16. Karpinski, M., Nekrich, Y.: Searching for frequent colors in rectangles. In: Proc. 20th Canadian Conference 
on Computational Geometry (CCCG), pp. 11–14 (2008)

17. Karpinski, M., Nekrich, Y.: Top-k color queries for document retrieval. In: Proc. 22nd Annual ACMSIAM 
Symposium on Discrete Algorithms (SODA), pp. 401–411 (2011)

18. Navarro, G., Raman, R., Rao, S.S.: Asymptotically optimal encodings for range selection. In: Proc.
34th Annual Conference on Foundations of Software Technology and Theoretical Computer Science
(FSTTCS), pp. 291–302 (2014)

19. Navarro, G., Thankachan, S.: Encodings for range majority queries. In: Kulikov, A.S., Kuznetsov, S.O.,
Pevzner, P.A. (eds.) Proc. 25th Annual Symposium on Combinatorial Pattern Matching CPM. LNCS
8486, pp. 262–272, (2014)

20. Okanohara, D., Sadakane, K.: Practical entropy-compressed rank/select dictionary. In: Proc. 9th Workshop 
on Algorithm Engineering and Experiments (ALENEX), pp. 60–70 (2007)

21. Petersen, H., Grabowski, S.: Range mode and range median queries in constant time and sub-quadratic

space. Inform. Process. Lett. 109(4), 225–228 (2009)

22. P˘atra¸scu, M., Thorup, M.: Time-space trade-offs

for predecessor

search. CoRR (2008).

arXiv:cs/0603043v1

23. Pˇatra¸scu, M.: Succincter. In: Proc. 49th Annual IEEE Symposium on Foundations of Computer Science

(FOCS), pp. 305–313 (2008)

24. Raman, R., Raman, V., Rao, S.S.: Succinct indexable dictionaries with applications to encoding k-ary

trees, preﬁx sums and multisets. ACM Trans. Algorithms 3(4) Article 43 (2007)

25. Ruži´c, M.: Constructing efﬁcient dictionaries in close to sorting time. In: Aceto, L., Damgård, I., Ann
Goldberg, L., Halldórsson, M.M., Ingólfsdóttir, A., Walukiewicz, I. (eds.) Proc. 35th International
Colloquium on Automata, Languages and Programming ICALP. LNCS 5125, pp. 84–95 (part I) (2008)
26. Skala, M.: Array range queries. In: Brodnik, A., López-Ortiz, A., Raman, V., Viola A. (eds.) SpaceEfﬁcient 
Data Structures, Streams, and Algorithms. LNCS, pp. 333–350. Springer (2013)

123

