Fast and Compact Planar Embeddings(cid:2)

Leo Ferres1, Jos´e Fuentes2, Travis Gagie3, Meng He4, and Gonzalo Navarro2

1 Faculty of Engineering, Universidad del Desarrollo

2 CeBiB; Department of Computer Science, University of Chile

3 CeBiB; EIT, Diego Portales University

4 Faculty of Computer Science, Dalhousie University

Abstract. There are many representations of planar graphs but few are
as elegant as Tur´an’s (1984): it is simple and practical, uses only four
bits per edge, can handle multi-edges and can store any speciﬁed embedding.
 Its main disadvantage has been that “it does not allow eﬃcient
searching” (Jacobson, 1989). In this paper we show how to add a sublinear 
number of bits to Tur´an’s representation such that it supports fast
navigation, thus overcoming this disadvantage. Other data structures for
planar embeddings may be asymptotically faster or smaller but ours is
simpler, and that can be a theoretical as well as a practical advantage:
e.g., we show how our structure can be built eﬃciently in parallel.

1

Introduction

The rate at which we store data is increasing even faster than the speed and
capacity of computing hardware. Thus, if we want to use what we store eﬃciently,
we need to represent it in better ways. The surge in the number and complexity of
the maps we want to have available on mobile devices is particularly pronounced
and has resulted in a bewildering number of ways to store planar graphs. Each of
these representations has its disadvantages, however: e.g., some do not support
fast navigation, some are large, some cannot represent multi-edges or certain
embeddings, and some are complicated to build in practice, especially in parallel,
which is a concern when dealing with massive datasets.
Tutte [26] showed that representing a speciﬁed embedding of a connected
planar multi-graph with n vertices and m edges takes m lg 12 ≈ 3.58m bits in
the worst case. Tur´an [25] gave a very simple representation that uses 4m bits,
but Jacobson [15] noted that it “does not allow fast searching” and proposed

(cid:2) The second and ﬁfth authors received travel funding from EU grant H2020-MSCA-
RISE-2015 BIRDS GA No. 690941. The second, third and ﬁfth authors received
funding from Basal Funds FB0001, Conicyt, Chile. The third author received funding
from Academy of Finland grant 268324. Early parts of this work were done while the
third author was at the University of Helsinki and while the third and ﬁfth authors
were visiting the University of A Coru˜na. Many thanks to J´er´emy Barbay, Luca
Castelli Aleardi, Arash Farzan, Ian Munro, Pat Nicholson and Julian Shun. The
third author is grateful to the late David Gregory for his course on graph theory.

© Springer International Publishing AG 2017
F. Ellen et al. (Eds.): WADS 2017, LNCS 10389, pp. 385–396, 2017.
DOI: 10.1007/978-3-319-62127-2_33

385

L. Ferres et al.
386
one that instead uses O(m) bits and supports fast navigation. Keeler and Westbrook 
[17] noted in turn that “the constant factor in [Jacobson’s] space bound
is relatively large” and gave a representation that uses m lg 12 + O(1) bits when
the graph contains either no self-loops or no vertices with degree 1, but gave
up fast navigation again. Chiang, Lin and Lu [8] gave a representation that
uses 2m + 3n + o(m) bits with fast navigation, but it is based on orderly spanning 
trees; although all planar graphs can be represented with orderly spanning
trees, some planar embeddings cannot. Blelloch and Farzan [6] extended work by
Blandford et al. [5] and gave a representation that uses m lg 12 + o(m) bits with
fast navigation of any speciﬁed embedding, but it is complicated and has not
been implemented. Barbay et al. [3] gave a data structure that uses O(n) bits
to represent a simple planar graph on n nodes with fast navigation, but the hidden 
coeﬃcient is about 18. Other authors (see, e.g., [7, 13, 14]) have considered
special kinds of planar graphs, notably as tri-connected planar graphs and triangulations.
 We refer the reader to Munro and Nicholson’s [20] and Navarro’s [21,
Chapter 9] recent surveys for further discussion of compact data structures for
graphs.

In this paper we show how to add o(m) bits to Tur´an’s representation such
that it supports fast navigation: we can list the edges incident to any vertex in
counter-clockwise order using constant time per edge, and determine whether
two vertices are neighbours or ﬁnd a vertex’s degree in O(f (m))-time for any
given function f (m) ∈ ω(1). Our data structure is faster, smaller or more expressive 
than any of the structures listed above except Blelloch and Farzan’s,
and it is much simpler than theirs. Our structure’s simplicity is a theoretical
as well as a practical advantage, in that we can build it in parallel with linear
work and logarithmic span (albeit without support for fast neighbour and degree 
queries). We summarize our construction algorithm in this paper and will
provide details in a subsequent paper. In contrast, we do not have such eﬃcient
parallel algorithms for ﬁnding the book embeddings [27], orderly spanning trees
and triangulations of planar subdivisions required by, respectively, Jacobson’s,
Chiang et al.’s and Barbay et al.’s constructions. Blandford et al.’s and Blelloch
and Farzan’s constructions are based on ﬁnding small vertex separators [19] and,
although Kao et al. [16] designed a linear-work and logarithmic-span algorithm
for computing a cycle separator of a planar graph, both Blandford et al.’s and
Blelloch and Farzan’s constructions decompose the input graph by repeatedly
computing separators until each piece is suﬃciently small, which increases the
total work to O(n log n) even when this optimal parallel algorithm is used.

Tur´an chooses an arbitrary spanning tree of the graph, roots it at a vertex
on the outer face and traverses it, writing its balanced-parentheses representation 
as he goes and interleaving that with a sequence over a diﬀerent binary
alphabet, consisting of an occurrence of one character for the ﬁrst time he sees
each edge not in the tree and an occurrence of the other character for the second
time he sees that edge. These two sequences can be written as three sequences
over {0, 1}: one of length 2n − 2 encoding the balanced-parentheses representation 
of the tree; one of length 2m − 2n + 2 encoding the interleaved sequence;

Fast and Compact Planar Embeddings

387

and one of length 2m indicating how they are interleaved. Our extension of his
representation is based on the observation that the interleaved sequence encodes
the balanced-parentheses representation of the complementary spanning tree of
the dual of the graph. By adding a sublinear number of bits to each balancedparentheses 
representation, we can support fast navigation in the trees, and by
storing the sequence indicating the interleaving as a bitvector, we can support
fast navigation in the graph.

In Section 2 we brieﬂy describe bitvectors and the balanced-parentheses representation 
of trees, which are the building blocks of our extension of Tur´an’s
representation. For further discussion of these data structures, we again direct
the reader to Navarro’s text [21]. In Section 3 we prove the observation mentioned 
above. In Section 4 we describe our data structure and how we implement
queries. We summarize our parallel construction algorithm in Section 5 and report 
the results of our preliminary experiments.

2 Preliminaries

A bitvector is a binary string that supports the queries rank and select in addition
to random access, where rankb(i) returns the number of bits set to b in the
preﬁx of length (cid:12) of the string and selectb(j) returns the position of the jth bit
set to b. For convenience, we deﬁne selectb(0) = 0. There are many diﬀerent
implementations that represent a bitvector of length n in n + o(n) bits and
support random access, rank and select in constant time.

With bitvectors we can represent an ordered tree or forest on n vertices using
2n + o(n) bits and support natural navigation queries quickly. One of the most
popular such representations is as a string of balanced parentheses: we traverse
each tree from left to right, writing an opening parenthesis when we ﬁrst visit
a vertex (starting at the root) and a closing parenthesis when we leave it for
the last time (or, in the case of the root, when we ﬁnish the traversal). We
can encode the string of parentheses as a bitvector, with 0s encoding opening
parentheses and 1s encoding closing parentheses, and achieve the space bound
stated above while supporting each of the follow queries used by our solution in
constant time:

– match(i), locates the parenthesis matching the ith parenthesis,
– parent(v), returns the parent of v, given as its pre-order rank in the traversal,

or 0 if v is the root of its tree.

3 Spanning trees of planar graphs

It is well known that for any spanning tree T of a connected planar graph G,
∗
the edges dual to T are a spanning tree T
interdigitating; see Figure 1 for an illustration (including multi-edges and a self-
loop) and, e.g., [4, 11, 22] for discussions. If we choose T as the spanning tree of
G for Tur´an’s representation, then we store a 0 and a 1, in that order, for each
edge in T

. We now show that these bits encode a traversal of T

of the dual of G, with T and T

∗

∗

∗

.

388

L. Ferres et al.

4

C

G

7

8

E

6

A

F

5

D

H

1

2

B

3

2

3

4

H

G

1

5

6

A

E

F

7

8

C

B

D

T

(1, 2)
(2, 3)

(2, 3)
(2, 4)

(2, 4)

(1, 2)
(1, 5)
(5, 6)

(5, 6)

(1, 5)
(1, 7)

(7, 8)

(7, 8)

(1, 7)

G − T
(1, 3)

∗

T

(A, B)

(1, 3)

(A, B)

(4, 8)

(A, C)

(2, 6)

(C, D)

(2, 6)
(6, 8)

(C, D)
(C, E)

(5, 7)

(E, F)

(5, 7)

(E, F)

(6, 8)
(4, 8)
(7, 8)

(C, E)
(A, C)
(A, G)

(7, 8)

(A, G)

(1, 1)
(1, 1)

(A, H)
(A, H)

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28

Fig. 1. Top left: A planar embedding of a planar graph G, with a spanning tree T
of G shown in red and the complementary spanning tree T ∗
of the dual of G shown
in blue with dashed lines. Bottom left: The two spanning trees, with T rooted at
the vertex 1 on the outer face and T ∗
rooted at the vertex A corresponding to the
outer face. Right: The list of edges we process while traversing T starting at 1 and
processing edges in counter-clockwise order, with the edges in T shown in red and the
ones in G− T shown in black; the edges of T ∗
corresponding to the edges in G− T are
shown in blue.

Fast and Compact Planar Embeddings

389

Lemma 1. Consider any planar embedding of a planar graph G, any spanning
of the dual of G. If we
tree T of G and the complementary spanning tree T
perform a depth-ﬁrst traversal of T starting from any vertex on the outer face
of G and always process the edges (of the graph) incident to the vertex v we are
visiting in counter-clockwise order (starting from the edge immediately after the
one to v’s parent or, if v is the root of T , from immediately after any incidence
of the outer face), then each edge not in T corresponds to the next edge we cross
in a depth-ﬁrst traversal of T

∗

∗

.

∗

∗

∗

∗

starts at the vertex of the dual of G correProof.
 Suppose the traversal of T
sponding to the outer face of G. We now prove by induction that the vertex we
always corresponds to the face of G incident to the vertex we
are visiting in T
are visiting in T and to the previous and next edges in counter-clockwise order.
Our claim is true before we process any edges, since we order the edges
starting from an incidence of the outer face to the root of T . Assume it is still
true after we have processed i < m edges, and that at this time we are visiting
v in T and v
. First suppose that the (i + 1)st edge (v, w) we process is in
T . We note that w (cid:17)= v, since otherwise (v, w) could not be in T . We cross from
v to w in T , which is also incident to the face corresponding to v
. Now (v, w)
is the previous edge — considering their counter-clockwise order at w, starting
from (v, w) — and the next edge (which is (v, w) again if w has degree 1) is also
. This is illustrated on the left side of Figure 2. In fact, the next
incident to v
edge is the one after (v, w) in a clockwise traversal of the edges incident to the
face corresponding to v

in T

∗

∗

∗

∗

∗

.

∗

be the vertex in T

∗ (cid:17)= v
∗
in T

Now suppose (v, w) is not in T and let w

corresponding
to the face on the opposite side of (v, w), which is also incident to v. We note
∗
, since otherwise (v, w) would have to be in T . We cross from v
that w
∗
to w
. Now (v, w) is the previous edge — this time still considering their
counter-clockwise order at v — and the next edge (which may be (v, w) again
. This is illustrated on the right side
if it is a self-loop) is also incident to w
of Figure 2. In fact, the next edge is the one that follows (v, w) in a clockwise
traversal of the edges incident to the face corresponding to w

∗

∗

.

Since our claim remains true in both cases after we have processed i + 1
edges, by induction it is always true. In other words, whenever we should process
one of the vertices
next an edge e in G that is not in T , we are visiting in T
corresponding to the faces incident to e (i.e., one of the endpoints of the edge
in the dual of G that corresponds to e). Since we process each edge in G twice,
once at each of its endpoints or twice at its unique endpoint if it is a self-loop,
it follows that the list of edges we process that are not in T , corresponds to the
(cid:15)(cid:16)
list of edges we cross in a traversal of T

∗

∗

.

∗

We process the edges in counter-clockwise order so that the traversals of T
are from left to right and from right to left, respectively; processing
and T
them in clockwise order would reverse those directions. For example, for the
embedding in Figure 1, if we start the traversal of the red tree T at vertex 1 and
start processing the edges at (1, 3), then we process them in the order shown at
the right of the ﬁgure.

390

L. Ferres et al.

v

w

∗

v

u

x

y

u

v

∗

w

∗

v

w

Fig. 2. Left: If we process an edge (v, w) in T , then we move to w in our traversal of
T and the next edge, (w, x) in this case, is also incident to the vertex v∗
we are visiting
in our traversal of T ∗
to the
vertex w∗
corresponding to the face on the opposite side of (v, w) in G. The next edge,
(v, y) in this case, is also incident to w∗

. Right: If (v, w) is not in T , then in T ∗

we move from v∗

.

4 Data Structure

Our extension of Tur´an’s representation of a planar embedding of a connected
planar graph G with n vertices and m edges consists of the following components,
which take 4m + o(m) bits:

in the traversal of T described in Lemma 1, is in T ;

– a bitvector A[1..2m] in which A[i] indicates whether the ith edge we process
– a bitvector B[1..2(n − 1)] in which B[i] indicates whether the ith time we
process an edge in T during the traversal, is the second time we process that
edge;

– a bitvector B

[i] indicates whether the ith time
we process an edge not in T during the traversal, is the second time we
process that edge.

∗

[1..2(m− n + 1)] in which B

∗

∗

Notice B encodes the balanced-parentheses representation of T except that it
lacks the leading 0 and trailing 1 encoding the parentheses for the root. By
encodes the balanced-parentheses representation of a traversal of
Lemma 1, B
of the dual of G complementary to T (the right-to-left
the spanning tree T
, in fact) except that it also lacks the leading 0 and trailing 1
traversal of T
encode forests,
encoding the parentheses for the root. Therefore, since B and B
we can support match and parent with them.

∗

∗

∗

To build A, B and B

given the embedding of G and T , we traverse T as
in Lemma 1. Whenever we process an edge, if it is in T then we append a 1 to
A and append the edge to a list L; otherwise, we append a 0 to A and append
. When we have ﬁnished the traversal, we replace
the edge to another list L
each edge in L or L
by a 0 if it is the ﬁrst occurrence of that edge in that list,
∗
,
into B and B
and by a 1 if it is the second occurrence; this turns L and L
respectively. For the example shown in Figure 1, L and L
eventually contain
the edges shown in the columns labelled T and G − T , respectively, in the table
on the on the right side of the ﬁgure, and

∗

∗

∗

∗

∗

A[1..28] = 0110110101110010110100010100

B[1..14] = 00101100110011
∗
B

[1..14] = 01001001110101 .

Fast and Compact Planar Embeddings

391

We identify each vertex v in G by its pre-order rank in our traversal of T .

Consider the following queries:

ﬁrst(v): return i such that the ﬁrst edge we process while visiting v is the ith

we process during our traversal;

next(i): return j such that if we are visiting v when we process the ith edge
during our traversal, then the next edge incident to v in counter-clockwise
order is the one we process jth;

mate(i): return j such that we process the same edge ith and jth during our

traversal;

vertex(i): return the vertex v such that we are visiting v when we process the

ith edge during our traversal.

With these it is straightforward to reenact our traversal of T and recover the
embedding of G. For example, with the following queries we can list the edges
incident to the root of T in Figure 1 and determine whether they are in T :

mate(1) = 4
ﬁrst(1) = 1
mate(2) = 10
next(1) = 2
next(2) = 11
mate(11) = 17
next(11) = 18 mate(18) = 26

vertex(4) = 3
A[1] = 0
vertex(10) = 2 A[2] = 1
vertex(17) = 5 A[11] = 1
vertex(26) = 7 A[18] = 1 .

To see why we can recover the embedding from the traversal, consider that if
we have already correctly embedded the ﬁrst i edges processed in the traversal,
then we can embed the (i + 1)st correctly given its endpoints and its rank in the
counter-clockwise order at those vertices.

We now explain our constant-time implementations of ﬁrst, next, mate and
vertex. If m = 0 then ﬁrst(v) is undeﬁned, which we indicate by returning 0.
Otherwise, we ﬁrst process an edge at v immediately after ﬁrst arriving at v.
Since we identify v with its pre-order rank in our traversal of T and B lacks the
opening parenthesis for the root, while ﬁrst arriving at any vertex v other than

the root we write the (v − 1)st 0 in B and, thus, the B.select0(v − 1)st 1 in A.
If v is the root then ﬁrst(v) = 1 and so, since selectx(0) = 0, this case is also
handled by the formula below:

(cid:5)

ﬁrst(v) =

In our example,

A.select1(B.select0(v − 1)) + 1 if m ≥ 1

0

otherwise.

ﬁrst(5) = A.select1(B.select0(4)) + 1 = A.select1(7) + 1 = 12

and indeed the twelfth edge we process, (5, 6), is the ﬁrst one we process at
vertex 5.

If the ith edge we process is the last edge we process at a vertex v then
next(i) is undeﬁned, which we again indicate by returning 0. This is the case
when i = 2m, or A[i] = 1 and B[A.rank1(i)] = 1. Otherwise, if the ith edge we
process is not in T , then A[i] = 0, and we process the next edge at v one time

392

L. Ferres et al.

step later. Finally, if the ith edge e we process is in T and not the last one we
process at v, then we next process an edge at v immediately after returning to
v by processing e again at time mate(i). This is the case when A[i] = 1 and
B[A.rank1(i)] = 0. In other words,

next(i) =

mate(i) + 1 if A[i] = 1 and B[A.rank1(i)] = 0
0

otherwise.

if A[i] = 0 and i < 2m

⎧⎨⎩ i + 1

In our example, since A[12] = 1, B[A.rank1(12)] = B[8] = 0, the twelfth edge we
process is (5, 6) and it is also the ﬁfteenth edge we process,

next(12) = mate(12) + 1 = 16 ,

and indeed the second edge we process at vertex 5 is (5, 7).

To implement mate(i), we check A[i] and use rank to determine whether we
while processing the ith edge, and to ﬁnd that bit. We
wrote a bit in B or in B
use match to ﬁnd the bit encoding the matching parenthesis, and then use select
on A to ﬁnd the bit we wrote in A when we wrote that matching bit. Therefore,

∗

mate(i) =

∗

A.select0(B
A.select1(B.match(A.rank1(i)))

.match(A.rank0(i))) if A[i] = 0
otherwise.

To compute mate(12) for our example, since A[12] = 1,

mate(12)
= A.select1(B.match(A.rank1(12)))
= A.select1(B.match(8))
= A.select1(9)
= 15 .

(cid:5)

⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩

Suppose the ith edge e we process is not in T and we process it at vertex v.
If the preceding time we processed an edge in T was the ﬁrst time we processed
that edge, we then wrote a 0 in B, encoding the opening parenthesis for v;
otherwise, we then wrote a 1 in B, encoding the closing parenthesis for one of
v’s children. Now suppose e is in T . If that is the ﬁrst time we process e, we
move to the other endpoint w of e — which is a child of v — and write a 0 in
B, encoding the opening parenthesis for w. If it is the second time we process e,
then we write a 1 in B, encoding the closing parenthesis for v itself. Therefore,

vertex(i) =

B.rank0(A.rank1(i)) + 1

if A[i] = 0 and B[A.rank1(i)] = 0

B.parent(B.rank0(B.match(A.rank1(i)))) + 1

if A[i] = 0 and B[A.rank1(i)] = 1

B.parent(B.rank0(A.rank1(i))) + 1

if A[i] = 1 and B[A.rank1(i)] = 0

B.rank0(B.match(A.rank1(i))) + 1

otherwise.

Fast and Compact Planar Embeddings

393

In our example, since A[16] = 0 and B[A.rank1(16)] = B[9] = 1,

vertex(16)
= B.parent(B.rank0(B.match(A.rank1(16)))) + 1
= B.parent(B.rank0(B.match(9))) + 1
= B.parent(B.rank0(8)) + 1
= B.parent(5) + 1
= 5 ,

and indeed we process the sixteenth edge (5, 7) while visiting 5.

∗

We remind the reader that since B lacks parentheses for the root of T ,
B.parent(5) refers to the parent of the ﬁfth vertex in an in-order traversal of
T not including the root, i.e., the parent vertex 5 of vertex 6. Adding 1 includes
the root in the traversal, so the ﬁnal answer correctly refers to vertex 5. The
lack of parentheses for the root also means that, e.g., B.parent(4) refers to the
parent of vertex 5 and returns 0 because vertex 5 is the root of its own tree in
the forest encoded by B, without vertex 1. Adding 1 to that 0 also correctly
turns the ﬁnal value into 1, the in-order rank of the root. Of course, we have the
option of prepending and appending bits to A, B and B
to represent the roots
, but that slightly confuses the relationship between the positions of
of T and T
the bits and the time steps at which we process edges.
Clearly we can determine whether two vertices u and v are neighbours by
listing the neighbours of each in parallel in O(min(degree(u), degree(v))) time,
and we can ﬁnd degree(v) in O(degree(v)) time. Moreover, given a function
f (m) ∈ ω(1), we can make both kinds of queries take O(f (m)) time. To do
this, we store a bitvector marking the O(m/f (m)) = o(m) vertices with degree
at least f (m), which takes o(m) bits. To be able to answer neighbour queries
quickly, we consider the graph induced by those high-degree vertices and elimi-
(cid:4)
nate multi-edges and self-loops. The resulting simple graph G
is still planar —
so it has average degree less than 6 and thus o(m) edges — and preserves the
neighbour relation between those vertices. We can store G
using Blelloch and
Farzan’s representation or, since the neighbour relation does not depend on the
embedding, using one of the other compact representations of planar graphs that
supports constant-time neighbour queries, which also takes o(m) bits. To answer
neighbour(u, v) now, we check whether either u or v is low-degree and, if so, list
its neighbours in O(f (m)) time; if not, we query our auxiliary representation
in O(1) time. To be able to answer degree queries quickly, we simply store the
degrees of the high-degree vertices in unary using a bitvector, which takes o(m)
bits. To ﬁnd degree(v) now, we check whether v is low-degree and, if so, list and
count its incident edges; if not, we look up degree(v).

∗

(cid:4)

Summarizing our results so far, we have the following theorem:

Theorem 1. We can store a given planar embedding of a connected planar
graph G with m edges in 4m + o(m) bits such that later, given a vertex v, we can
list the edges incident to v in counter-clockwise order (optionally, starting at a

394

L. Ferres et al.

given edge e incident to v) using constant time per edge, and determine whether
two vertices are neighbours or ﬁnd a vertex’s degree in O(f (m))-time for any
given function f (m) ∈ ω(1).

5 Parallel Construction and Experiments

Due to space constraints, in this section we can only summarize our parallel
algorithm and then brieﬂy report the result of our experiments on construction 
and query times. We will provide the full details of the algorithm in the
subsequent paper mentioned in Section 1, of which a preprint is available at
http://arxiv.org/abs/1705.00415 .

We construct our extension of Tur´an’s representation in parallel as follows:
given a planar graph with a planar embedding G, we ﬁrst compute a spanning
tree T of G in parallel. In our experiments we used Bader and Cong’s algorithm 
[2] because it works well in practice, but its theoretical bounds are for
random graphs. To obtain good worst-case bounds, we could use Shiloach and
Vishkin’s [23] or Awerbuch and Shiloach’s [1] algorithms, which use linear work
with logarithmic span in the CRCW PRAM model. We recently learned that
Shun, Dhulipala and Blelloch’s [24] practical connectivity algorithm can be made
to return a spanning tree with linear work and polylogarithmic span. As a byproduct 
of the computation of T , we obtain an array C of length 2n − 2 that
stores the number of edges of G \ T between two consecutive edges in T , in
counter-clockwise order. Notice the starting vertex for the spanning tree must
be in the outer face of G.

∗

We construct bitvectors A, B and B

by performing a parallel Euler Tour
over T [9]. During the tour, we obtain B by writing a 0 for each forward (parent-
to-child) edge and a 1 for each backward (child-to-parent) edge. We obtain A
by counting the number of edges of G \ T between two consecutive edges of T
(stored in C). We represent the former with 0’s and the edges of T with 1’s.
The visiting order of edges of G \ T encoded in B
is implicit in the previous
Euler Tour. Therefore, with the Euler Tour and the array C, we have enough
information to compute the position of each bit in the bitvector B
. We can
decide if an edge of G \ T is a forward or backward edge by checking its relative
position and the position of its complement edge on the Euler tour. Finally, in
, we used Labeit et al.’s algorithm
order to support operations on A, B and B
for succinct bitvectors [18], and Ferres et al.’s algorithm for succinct trees [12].
We analyze our algorithm (after the computation of the spanning tree) in the
Dynamic Multithreading (DyM) model of parallel computation [10]. The DyM
model relies on two parameters: the work T1, i.e., the running time on a single
core; and the span T∞, i.e., the complexity of the intrinsically sequential part of
the parallel computation. The time Tp needed to execute the computation on p
cores is bounded by Tp = Θ(T1/p + T∞). The Euler tour and the array C can be
computed in parallel in T1 = O(n) and T∞ = O(lg n) time. Assigning values to A
and B can be done independently for each entry of the bitvectors, which gives us
takes T1 = O(m− n) and T∞ = O(1)
T1 = O(n) and T∞ = O(1) time, while B

∗

∗

∗

∗

Fast and Compact Planar Embeddings

395

time. Rank/select structures can be constructed in parallel with T1 = O(m)
and T∞ = O(lg m) time. Succinct trees can be constructed in T1 = O(m) and
T∞ = O(lg m) time.

Theorem 2. Given a spanning tree of a planar embedding, the compact representation 
from Theorem 1 (without the auxiliary data structures for fast neighbour
and degree queries) can be constructed in parallel with linear work and logarithmic 
span.

To provide some grounds for comparison, we also implemented a sequential
algorithm based on our parallel one, but instead of using Bader and Cong’s
algorithm, we used depth-ﬁrst search to compute T . This sequential implementation 
of Tur´an’s representation is simpler than our parallel algorithm running
on a single core, avoiding the additional steps needed for the parallel computation.
 To test both the sequential and parallel implementations, we synthetically
generated a planar graph (represented as an adjacency list) by computing the
Delaunay Triangulation of 25,000,000 random coordinates, yielding 25,000,000
vertices and 74,999,979 edges, with a minimum degree of 3 and a maximum
degree of 15. The experiments were carried out on a 28-core machine (two processors 
with 14 physical cores each) with hyperthreading turned on (for a total
of 56 cores), per-core L1 and L2 caches of sizes 64KB and 256KB, respectively
and a per-processor shared L3 cache of 35MB and a total of 768GB DDR3 RAM
memory.

Results show that the sequential algorithm took 71.8 seconds to construct
the representation of Theorem 1, while the parallel implementation took 5.4
seconds with 28 threads and 3.3 seconds with 56 threads. The space used by the
adjacency list representation was 1.02 GB, 117.3 bits per edge. The space used
by our compact representation was 44.7 MB, 5 bits per edge, which matches
Theorem 1. Memory consumption of our parallel algorithm peaked at 1.4 GB.

With respect to queries, we tested counting (number of neighbors) and
listing (list of neighbors in counter-clockwise order) queries. For the former, the
adjacency-list representation took 0.047 microseconds per node and the compact
representation took 4.6 microseconds per node. For listing, the adjacency-list
representation took 0.046 microseconds per node listed and the compact representation 
took 3.69 microseconds per node listed.

In summary, our parallel algorithm achieves a reasonable speed up in terms
of the number of threads and is an already order of magnitude faster than the sequential 
algorithm when using 28 threads; our compact representation is between
one and two orders of magnitude smaller than the adjacency-list representation,
but takes two orders of magnitude more time to answer queries. Our code and
datasets are available at https://users.dcc.uchile.cl/~jfuentess/pemb/ .

References

1. B. Awerbuch and Y. Shiloach. New connectivity and MSF algorithms for shuﬄeexchange 
network and PRAM. IEEE Trans. Computers, 36(10):1258–1263, 1987.

396

L. Ferres et al.

2. D. A. Bader and G. Cong. A fast, parallel spanning tree algorithm for symmetric
multiprocessors (SMPs). J. Parallel and Distributed Computing, 65:994–1006, 2005.
3. J. Barbay, L. C. Aleardi, M. He, and J. I. Munro. Succinct representation of labeled

graphs. Algorithmica, 62:224–257, 2012.

4. N. Biggs. Spanning trees of dual graphs. J. Comb. Theory, Series B, 11:127–131,

1971.

5. D. K. Blandford, G. E. Blelloch, and I. A. Kash. Compact representations of

separable graphs. In SODA, pages 679–688, 2003.

6. G. E. Blelloch and A. Farzan. Succinct representations of separable graphs. In

CPM, pages 138–150, 2010.

7. Castelli Aleardi, L, O. Devillers, and G. Schaeﬀer. Succinct representations of

planar maps. TCS, 408:174–187, 2008.

8. Y.-T. Chiang, C.-C. Lin, and H.-I. Lu. Orderly spanning trees with applications.

SIAM J. Comp., 34:924–945, 2005.

9. G. Cong and D. A. Bader. The Euler tour technique and parallel rooted spanning

tree. In ICPP, pages 448–457, 2004.

10. T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Multithreaded algorithms.
 In Introduction to Algorithms, pages 772–812. MIT Press, 2009.

11. D. Eppstein. Dynamic generators of topologically embedded graphs. In SODA,

pages 599–608, 2003.

12. L. Ferres, J. Fuentes-Sep´ulveda, M. He, and N. Zeh. Parallel construction of succinct 
trees. In SEA, pages 3–14, 2015.

13. ´E. Fusy, G. Schaeﬀer, and D. Poulalhon. Dissections, orientations, and trees with
applications to optimal mesh encoding and random sampling. TALG, 4:19, 2008.
14. X. He, M. Kao, and H. Lu. Linear-time succinct encodings of planar graphs via

canonical orderings. SIAM J. Discrete Math., 12:317–325, 1999.

15. G. Jacobson. Space-eﬃcient static trees and graphs.

In FOCS, pages 549–554,

1989.

16. M. Kao, S. Teng, and K. Toyama. An optimal parallel algorithm for planar cycle

separators. Algorithmica, 14:398–408, 1995.

17. K. Keeler and J. Westbrook. Short encodings of planar graphs and maps. DAM,

58:239–252, 1995.

18. J. Labeit, J. Shun, and G. E. Blelloch. Parallel lightweight wavelet tree, suﬃx

array and FM-index construction. In DCC, pages 33–42, 2016.

19. R. J. Lipton and R. E. Tarjan. A separator theorem for planar graphs. SIAM J.

Applied Math., 36:177–189, 1979.

20. J. I. Munro and P. K. Nicholson. Compressed representations of graphs. In Encyclopedia 
of Algorithms, pages 382–386. Springer, 2016.

21. G. Navarro. Compact Data Structures: A Practical Approach. Cambridge University 
Press, 2016.

22. T. R. Riley and W. P. Thurston. The absence of eﬃcient dual pairs of spanning

trees in planar graphs. Electronic J. Comb., 13, 2006.

23. Y. Shiloach and U. Vishkin. An o(log n) parallel connectivity algorithm. J. Algorithms,
 3(1):57–67, 1982.

24. J. Shun, L. Dhulipala, and G. E. Blelloch. A simple and practical linear-work

parallel algorithm for connectivity. In SPAA, pages 143–153, 2014.

25. G. Tur´an. On the succinct representation of graphs. DAM, 8:289–294, 1984.
26. W. T. Tutte. A census of planar maps. Canadian J. Math., 15:249–271, 1963.
27. M. Yannakakis. Embedding planar graphs in four pages. JCSS, 38:36–67, 1989.

