7
1
0
2

 
l
u
J
 

0
1

 
 
]
S
D
.
s
c
[
 
 

1
v
9
6
7
2
0

.

7
0
7
1
:
v
i
X
r
a

Compressed Representation of Dynamic Binary

Relations with Applications✩

Nieves R. Brisaboaa, Ana Cerdeira-Penaa, Guillermo de Bernardo∗,a,

Gonzalo Navarrob

aDatabase Laboratory, University of A Coru˜na, Spain.

bDepartment of Computer Science, University of Chile, Chile.

Abstract

We introduce a dynamic data structure for the compact representation of
binary relations R ⊆ A × B. The data structure is a dynamic variant of the
k2-tree, a static compact representation that takes advantage of clustering
in the binary relation to achieve compression. Our structure can eﬃciently
check whether two objects (a, b) ∈ A × B are related, and list the objects of
B related to some a ∈ A and vice versa. Additionally, our structure allows
inserting and deleting pairs (a, b) in the relation, as well as modifying the
base sets A and B. We test our dynamic data structure in diﬀerent contexts,
including the representation of Web graphs and RDF databases. Our experiments 
show that our dynamic data structure achieves good compression
ratios and fast query times, close to those of a static representation, while
also providing eﬃcient support for updates in the represented binary relation.

✩Funded in part by European Union’s Horizon 2020 research and innovation programme 
under the Marie Sklodowska-Curie grant agreement No 690941 (project BIRDS).
G. Navarro was partially funded by a Google Research Award Latin America and by
Fondecyt [1-140796]. N. Brisaboa, A. Cerdeira-Pena, and G. de Bernardo were partially
funded by MINECO (PGE, CDTI, and FEDER) [TIN2013-46238-C4-3-R, IDI-20141259,
ITC-20151305, ITC-20151247, TIN2015-69951-R, ITC-20161074, TIN2016-78011-C4-1-
R] by ICT COST Action IC1302; and by Xunta de Galicia (co-funded with ERDF)
[GRC2013/053, Centro singular de investigaci´on de Galicia accreditation 2016-2019]. An
early partial version of this article appeared in Proc DCC’12 [1].

∗Corresponding author
Email addresses: brisaboa@udc.es (Nieves R. Brisaboa), acerdeira@udc.es (Ana

Cerdeira-Pena), gdebernardo@udc.es (Guillermo de Bernardo),
gnavarro@dcc.uchile.cl (Gonzalo Navarro)

Preprint submitted to Information Systems

July 11, 2017

Key words: Compression, Dynamic Binary Relations, k2-tree

1. Introduction

Binary relations arise everywhere in Computer Science: graphs, matchings,
 discrete grids or inverted indexes in document retrieval are just some
examples. Consider a binary relation between two sets A and B, deﬁned as
a subset R ⊆ A × B. Typical operations of interest in a binary relation are:
determine whether a pair (a, b) is in R, ﬁnd all the elements b ∈ B such that
(a, b) ∈ R, given a ∈ A, and vice versa. More sophisticated ones aim, for
example, at retrieving all pairs (a, b) ∈ R where a ∈ [a1, a2] and b ∈ [b1, b2].
Web graphs, where nodes are Web pages and relations are hyperlinks, can
be seen as a binary relation between two (usually equal) sets of Web pages A
and B. In this context, basic binary relation operations are translated into
queries to ﬁnd the direct or reverse neighbors of a node. The “range” query
involving all pairs (a, b) ∈ R where a ∈ [a1, a2] and b ∈ [b1, b2] can be used to
retrieve all the links between two Web sites, considering that Web pages are
sorted lexicographically and therefore all pages in a Web site are consecutive
in an ordering of the base sets.
In the context of document retrieval, an
inverted index can be seen as a binary relation between a set of documents
D and a set of terms (usually words) Σ. In this context, we can use binary
relation operations to ﬁnd all the documents where a term w appears (all
d ∈ D where (w, d) ∈ R ⊆ D × Σ) or to ﬁnd whether a term appears in a
document (checking if (w, d) ∈ R).

In addition to the previous examples, other multidimensional data can be
naturally represented as collections of binary relations. A usual case occurs
when a dataset contains “labeled” relations between two base sets (that is,
the relation itself has a property or label);
in this case, a 3-dimensional
dataset can actually be seen as a collection of binary relations, one for each
value in the third dimension. A good example of this kind of datasets are
RDF (Resource Description Framework) graphs. RDF is a standard for the
representation of knowledge in the Web of Data. RDF graphs are labeled
graphs with a set of subject (origin) nodes S, a set of target (object) nodes
and a set of predicates (labels) P . An edge in an RDF graph represents a
property of element s, given by predicate p and with value o. A usual strategy
to store and query these datasets is to apply a vertical partitioning strategy
[2] to divide the data by predicate, since the number of predicates is generally

2

small. Through vertical partitioning, an RDF graph can be transformed into
a collection of binary relations Rp ⊆ (S, O) for each p ∈ P , representing the
valid pairs (s, o) for each predicate.

There are two natural ways to represent binary relations: a binary adjacency 
matrix or an adjacency list. On large binary relations, reducing space
while retaining functionality is crucial in order to operate eﬃciently in main
memory. Therefore, simple representations such as plain adjacency matrices
are usually unfeasible in these datasets. On the other hand, simple adjacency
lists can eﬃciently compress sparse binary relations, but an adjacency list
representation usually lacks the ability to answer queries symmetrically, or
to eﬃciently retrieve information on ranges of elements. The limitations of
simple data structures has led to diﬀerent proposals for compressing general
binary relations [3], as well as speciﬁc ones such as Web graphs [4].

Brisaboa et al. [5] introduced a compact data structure called k2-tree.
It was initially proposed for the compression of Web graphs, where it was
shown to be very competitive (see also [6]). Since then, it has also been
successfully applied to other domains such as RDF databases [7] and social
networks [6]. In fact, k2-trees can be used for the representation of general
binary relations and take advantage of clustering in the binary matrix to
achieve compression. They support elegantly all the described operations
(simple and sophisticated) as instances of the most general range query.

However, just like the other compressed representations of graphs and
binary relations, k2-trees are essentially static. This discourages their use
in cases where the binary relation changes due to the insertion or deletion
of pairs (a, b) (e.g., adding or removing edges in a graph) or of elements in
A and B (e.g., adding or removing graph nodes, or words or documents in
inverted indexes).

Dynamic representations of compact data structures are usually aﬀected
by a slowdown factor over the equivalent static data structure [8, Chapter
12]. For example, a dynamic bitmap has a lower bound of Ω( log n
log log n ) for many
operations that static bitmaps solve in O(1). Another example exists in 2dimensional 
grids, that are queried by k2-trees: range reporting queries have
a complexity of O( log n
log log n ) in a static representation, but a lower bound of
Ω(( log n
log log n )2) exists in a dynamic approach. Hence dynamic representations of
a structure like the k2-tree are expected to be slower, and larger, than a static
representation, in many cases.
In practice, in applications where update
operations are required, the slowdown factor of the dynamic representation

3

and the frequency of updates become key to determine which is the best
approach.

In this paper we introduce the dk2-tree, a dynamic version of the k2-tree.
Our data structure achieves space utilization close to that of the static structure,
 and allows the insertion and deletion of pairs and elements in the sets
(i.e., changing bits and inserting/deleting rows/columns in the binary ma-
trix). Our experiments show that dk2-trees achieve good space/time tradeoﬀs 
in comparison with the equivalent static representation. In Web graphs,
where k2-trees obtained good compression results and query times, our dynamic 
representation obtains query times less than twice those of the static
representation. Our results also show that, depending on the characteristics
of the datasets, update operations in the dk2-tree can also be as eﬃcient as
queries.

We apply our proposal to the representation of RDF databases, where
static k2-trees were competitive with state-of-the-art alternatives but lacked
the update capabilities usually required in this kind of graphs [9]. We show
that our representation can easily answer all queries supported by static
k2-trees using similar algorithms, while providing update capabilities. Our
dynamic data structure only requires a 20-50% space overhead to store the
dataset, and requires less than twice the query times of the equivalent static
representation to answer most of the queries. We choose RDF databases as
an example where static k2-trees have already been used but are limited by
their static nature. However, there are several other application domains
where the use of a dynamic data structure for the compact representation
of binary relations could also be worthwhile: time-evolving regions (e.g. oil
stains), communication networks, social graphs, etc.

2. Related Work

2.1. Previous Concepts

In this section we present some necessary background to better understand 
our contribution and to make the manuscript self-contained.

2.1.1. Rank and select over bitmaps

Bit vectors (often referred to as bitmaps, bit strings, etc.) supporting
rank and select operations [10] are the basis of many other succinct data
structures. We next describe them in detail.

4

Let be B[1, n] a binary sequence of size n. Then rank and select are

deﬁned as:

• rankb(B, p) = i if the number of occurrences of the bit b from the

beginning of B up to position p is i.

• selectb(B, i) = p if the i-th occurrence of the bit b in the sequence B is

at position p.

Given the importance of these two operations in the performance of other
succinct data structures, like full-text indexes [11], many strategies have been
developed to eﬃciently implement rank and select.

Jacobson [10] proposed an implementation for this problem able to compute 
rank in constant time.
It is based on a two-level directory structure.
 The ﬁrst-level directory stores rankb(B, p) for every p multiple of
s = ⌊log n⌋ ⌊log n/2⌋. The second-level directory holds, for every p multiple 
of b = ⌊log n/2⌋, the relative rank value from the previous multiple of
s. Following this approach, rank1(B, p) can be computed in constant time
adding values from both directories: the ﬁrst-level directory returns the rank
value until the previous multiple of s. The second-level directory returns
the number of ones until the previous multiple of b. Finally, the number of
ones from the previous multiple of b until p is computed sequentially over
the bit vector. This computation can be performed in constant time using a
precomputed table that stores the rank values for all possible block of size
b. As a result, rank can be computed in constant time. The select operation 
can be solved using binary searches in O(log log n) time. The sizes
s and b are carefully chosen so that the overall space required by the auxiliary 
dictionary structures is o(n): O(n/ log n) for the ﬁrst-level directory,
O(n log log n/ log n) for the second-level directory and O(log n log log n) for
the lookup table. Later works by Clark [12] and Munro [13] obtained constant 
time complexity also for the select operation, using additional o(n)
space. For instance, Clark proposed a new three-level directory structure
that solved select1, and could be duplicated to also answer select0.

The previous proposals solve the problem, at least in theory, of adding
rank and select support over a bit vector using o(n) additional bits. However,
further work was devoted to obtain even more compressed representations,
taking into account the actual properties of the binary sequence [14, 15, 16].
Another alternative study, called gap encoding, aims to compress the binary 
sequences when the number of 1 bits is small. It is based on encoding

5

the distances between consecutive 1 bits. Several developments following this
approach have been presented [17, 18, 19, 20, 21].

2.1.2. ETDC and DETDC
End-Tagged Dense Code (ETDC). It is a semi-static statistical byte-oriented
encoder/decoder [22, 23], that achieves very good compression and decompression 
times while keeping similar compression ratios to those obtained by
Plain Huﬀman [24] (the byte-oriented version of Huﬀman [25] that obtains
optimum byte-oriented preﬁx codes).

Consider a sequence of symbols D = d1 . . . dn.

In a ﬁrst pass ETDC
computes the frequency of each diﬀerent symbol in the sequence, and creates 
a vocabulary where the symbols are placed according to their overall
frequency in descending order. ETDC assigns to each entry of the vocabulary 
a variable-length code, that will be shorter for the ﬁrst entries of the
vocabulary (more frequent symbols). Then, in a second pass, each symbol of
the original sequence is replaced by the corresponding variable-length code.
The key idea in ETDC is to mark the end of each codeword (variablelength 
code): the ﬁrst bit of each byte will be a ﬂag, set to 1 if the current
byte is the last byte of a codeword, or 0 otherwise. The remaining 7 bits in
the byte are used to assign the diﬀerent values sequentially, which makes the
codeword assignment extremely simple in ETDC. Consider the symbols of
the vocabulary, that are stored in descending order by frequency: the ﬁrst 128
(27) symbols will be assigned 1-byte codewords, the next 1282 symbols will be
assigned 2-byte codewords, and so on. The codewords are assigned depending
only on the position of the symbol in the sorted vocabulary. The simplicity of
the code assignment is the basis for the fast compression and decompression
times of ETDC. In addition, its ability to use all the possible combinations
of 7 bits to assign codewords makes it very eﬃcient in space. Notice also that
ETDC can work with a diﬀerent chunk size for the codewords: in general, we
can use any chunk of size b, using 1 bit as ﬂag and the remaining b − 1 bits
to assign codes, hence having 2b−1 codewords of 1 chunk, 22(b−1) codewords
of 2 chunks and so on. Nevertheless, bytes are used as the basic chunk size
(b = 8) in most cases for eﬃciency.

Dynamic End-Tagged Dense Code (DETDC). It is an adaptive (one-pass)
version of ETDC [26]. As an adaptive mechanism, it does not require to preprocess 
and sort all the symbols in the sequence before compression. Instead,
it maintains a vocabulary of symbols that is modiﬁed according to the new

6

symbols received by the compressor.

The solution of DETDC for maintaining an adaptive vocabulary is to keep
the vocabulary of symbols always sorted by frequency. This means that new
symbols are always appended at the end of the vocabulary (with frequency
1), and existing symbols may change their position in the vocabulary when
their frequency changes during compression.

The process for encoding a message starts by reading the message sequentially.
 Each symbol read is looked up in the vocabulary, and processed
depending on whether it is found or not:

• If the symbol is not found in the vocabulary it is a new symbol, therefore
it is appended at the end of the vocabulary with frequency 1. The
encoder writes the new codeword to the output, followed by the symbol
itself. The decoder can identify a new symbol because its codeword is
larger than the decoder’s vocabulary size, and add the new symbol to
its own vocabulary.

• If the symbol is found in the vocabulary, the encoder simply writes
its codeword to the output. After writing to the output, the encoder
updates the frequency of the symbol (increasing it by 1) and reorders
the vocabulary if necessary. Since the symbol frequency has changed
from f to f + 1, it is moved to the region where symbols with frequency
f +1 are stored in the vocabulary. This reordering process is performed
swapping elements in the vocabulary. The key of DETDC is that the
encoder and the decoder share the same model for the vocabulary and
update their vocabulary in the same way, so changes in the vocabulary
during compression can be automatically performed by the decoder
using the same algorithms without transmitting additional information.

DETDC and its variants are able to obtain very good results to compress
natural language texts, obtaining compression very close to original ETDC
without the ﬁrst pass required by the semi-static approach.

2.2. The k2-tree

A k2-tree is conceptually a k2-ary tree built by recursively partitioning a
binary matrix. At each partitioning step, the current matrix of size n × n is

7

divided into k2 submatrices of size n/k × n/k 1. Figure 1 shows a 10 × 10
binary matrix, virtually expanded to size 16 × 16, and the conceptual k2-tree
that represents it, for k = 2. The submatrices are numbered from 0 to k2-1,
starting from left to right and top to bottom. The ﬁrst level of the tree
contains one node with k2 children, representing the k2 submatrices in which
the original matrix is divided following a quadtree-like subdivision. Each
node is represented using a single bit: 1 if the submatrix has at least one
cell with value 1, or 0 otherwise. A 0 child means that there are no ones
in the corresponding submatrix, and it has no children. The decomposition
continues recursively for each 1 child until the current submatrix is full of
zeros or we reach the individual cells of the original matrix. The underlying
conceptual tree is in fact an MX-Quadtree [27], that recursively decomposes
the space in four quadrants stopping only when the region is fully empty (all
cells set to 0) or when the maximum precision is reached (individual cells of
the adjacency matrix). Hence, a k2-tree that uses k = 2 can be seen as a
compact and eﬃcient representation of this conceptual quadtree.

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

1

1

1

0

0

0

0

0

0

0

0

0

0

0

1

0

0

0

0

0

0

0

0

0

0

0
0

0
0

0
0

0
0

0
0

0
1

0
1

0
0

0
0

0
0

0

0

0

0

0

0

0
0

0
0

0
1

0
0

0
0

0
0

0
0

0
0

0
0

0
0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

0

1

1

1

0

1

1

0

1

1

0

1

0

0 1 0 0

0

1

1

0

1

0

0 1

0

1

0

1

0

0

1

0

1

0 1

0

1

1

0

0

0011

0011

0010

0010

0001

0010

0100

0010 1000

0010 1010

T = 1110 1101 1010 0100 0110 1001 0101 0010 1010 1100

L = 0011 0011 0010 0010 0001 0010 0100 0010 1000 0010 1010

Figure 1: Example of k2-tree for a binary matrix using k = 2.

This conceptual tree is implemented using two bit arrays: T contains the
bits for all the levels of the tree except for the last one, taken in a levelwise
traversal of the tree. L stores the bits of the last level of the tree.

1The size of the matrix is assumed to be a power of k. If n is not a power of k, we use
instead n′ = k⌈log n⌉, the next power of k. Conceptually, the matrix is expanded with new
zero-ﬁlled rows and columns until it reaches n′ × n′.

8

The k2-tree allows navigation of the conceptual tree using only the bitmap
representations thanks to a basic property: given any internal node in the
k2-tree (a position pos in T ),
its k2 children will be located at pos′ =
rank1(T, pos) × k2, because each bit set to one adds k2 bits to the next
level and bits set to zero do not have descendants. If the position exceeds
the length of T , L[pos′ − |T |] is used. A rank structure is built over T to
provide an eﬃcient rank1 operation. All query operations are based on this
basic navigation of the conceptual tree.

To access a cell of the matrix, the tree is navigated from the root until
a 0 is found or the last level is reached. At each level, the child whose
submatrix contains the target cell is selected. If the bit value of that node
is 0 we know the cell in the region is a 0, and navigation ends. If the value
is 1, we proceed recursively to the appropriate children. For instance, let us
suppose we want to retrieve the value of the cell at row 9, column 6 in the
matrix of Figure 1. The path to reach that cell has been highlighted in the
conceptual k2-tree. To perform this navigation2, we would start at the root
of the tree (position 0 in T ). In the ﬁrst level, we need to access the third
child (oﬀset 2), since we are accessing the bottom-left quadrant; hence we
access position 2 in T . Since T [2] = 1, we know we are in an internal node.
Its children will begin at position rank1(T, 2) × k2 = 12, where we ﬁnd the
bits 0100. In this level we must access the second child (oﬀset 1), so we check
T [12 + 1] = T [13] = 1. Again, we are at an internal node, and its children
are located at position rank1(T, 13) × k2 = 9 × 4 = 36. We have reached the
third level of the conceptual tree, and we need to access now the second child
(oﬀset 1). Again, T [36 + 1] = 1, so we compute the position of its children
using p = rank1(T, 36) × 4 = 80. Now p is higher than the size of T (40), so
the k2 bits will be located at position p − |T | = 80 − 40 = 40 in L. Finally,
in L we ﬁnd the k2 bits 1010, and need to check the third element. We ﬁnd
a 1 in L and return the result.

In addition to the retrieval of a single cell of the matrix, k2-trees can
perform other operations eﬃciently: with some additional calculations, we
can modify the basic search to ﬁnd all the ones in a row/column, or a range
[a1,a2]-[b1,b2]. To do this, at each level of the k2-tree we must access all
the children of the current node that overlap the region we are interested in,
traversing all the branches of the tree that intersect the region of interest.

2We refer the reader to [28] for speciﬁc implementation details.

9

The cost to perform a general range reporting query in a k2-tree, over a region
of size p×q, is bounded by the size of the region and the number occ of results
found. The upper bound for the query time is O(p + q + (occ + 1)k logk s),
where s is the size of the longest side of the matrix [8, Section 10.2.1].

2.2.1. Improvements

Several enhancements have been proposed to obtain better compression
results in the k2-tree (see [29]). The ﬁrst modiﬁcation is the use of diﬀerent
values of k in diﬀerent levels of the k2-tree. By using a bigger k for the
ﬁrst levels and a smaller value for the remaining ones, one can achieve better
query times (because the k2-tree’s height is reduced) with good space results.
This is called a hybrid k2-tree representation.

Another major improvement proposed over basic k2-trees is the use of a
compression method for the bitmap L. In this approach, the lowest levels of
the k2-tree are grouped, yielding submatrices of size k′ × k′ (for instance, to
use 8 × 8 submatrices as the last level of the tree instead of 2 × 2). These
submatrices are sorted according to their overall frequency and stored in
a matrix vocabulary Lvoc. Then, the bitmap L is replaced by a sequence
of variable-length codes Lseq. The variable-length codes are assigned using
(s,c)-Dense Codes [30], and Lseq is encoded using Direct Access Codes [31] to
provide direct access to any entry in the sequence. This variant can reduce
signiﬁcantly the size of the representation while showing similar query times.

3. The dynamic k2-tree: dk2-tree

3.1. Data structures

The conceptual k2-tree is represented, in its static variant, using two bit
arrays, T and L. In our dynamic version, we represent T and L with two
trees, that we call Ttree and Ltree. Our approach to represent the k2-tree using
these trees is called dk2-tree. Our trees, Ttree and Ltree, are in fact practical
implementations of dynamic bit vectors [32] replacing the static bitmaps T
and L. The leaves of Ttree and Ltree contain roughly the bits in T and L,
while the internal nodes provide access to arbitrary positions and also act as
a dynamic rank structure.

Consider a static k2-tree representation (bitmaps T and L). To build a
dk2-tree representation from it, we partition T and L in blocks of up to B
bits. The generated blocks will be the leaves of Ttree and Ltree. The internal
nodes of our trees contain a set of entries that allow us to access the leaves

10

T: 1110  1101 1010 0100  0110 1001 0101 0010 1010 1100

N1

28 / 15

12 / 5

N2

16 / 9 12 / 6

12 / 5

N3

N6

8 / 6

8 / 3

4 / 2

8 / 4

8 / 3

4 / 2

N4

N5

N7

1110 1101

1010 0100

0110

1001 0101 

0010 1010 

1100

L: 0011 0011 0010 0010 0001 0010 0100 0010 1000 0010 1010

24

20

8

8

8

8

8

4

0011 0011

0010 0010

0001 0010

0100 0010

1000 0010

1010

Figure 2: Dynamic k2-tree representation.

for query and update operations. Each entry in Ttree is of the form hb, o, P i,
where b and o are counters and P is a pointer to the corresponding child
node. The values b and o in each entry will allow us to eﬃciently access
and perform rank operations in the dynamic bitmaps. If P points to a leaf
node, the counters will store the number b of bits stored in the leaf and the
number of them that are ones (o). If P points to an internal node, b and o
will contain the sum of all the band 
o-counters in the child node. Internal
nodes in Ltree are very similar, but entries only store values hb, P i, since rank
support in L is not needed. Figure 2 shows a dk2-tree representation for the
k2-tree of Figure 1. Values of band 
o-counters are represented in the nodes,
and pointers are visually represented.

The nodes of Ttree and Ltree may in general be partially empty. Each
node has a maximum and minimum capacity and may contain any number
of bits or entries between those parameters. A size ﬁeld is added to keep
the current size of a node. In leaf nodes, this ﬁeld contains the number of
bits stored in the block. In internal nodes, it stores the number of ﬁxed-size

11

entries used. The tree is completely balanced, and nodes may be split or
merged when the contents change. The behavior of Ttree and Ltree on update
operations will be explained in more detail in Section 3.3.

3.2. Query algorithms

All the queries supported by k2-trees are based on access and rank operations 
over the bitmaps T and L. As explained before, our tree structures,
Ttree and Ltree, are essentially dynamic replacements for the static bitmaps.
By providing basic support for these two simple operations in the bitmaps
stored by Ttree and Ltree, all the queries supported by static k2-trees can be
directly supported by our dk2-tree.

The navigation of a conceptual k2-tree is based on a sequence of access
operations, to check the value of a node, followed by possible rank operations
to locate its children. The access operation, that is trivial in a static bitmap,
is decomposed in our Ttree and Ltree in two steps: ﬁrst, an operation ﬁndLeaf
is used to locate the leaf that contains the desired bitmap, and the oﬀset
in the leaf node where the bit should be; then, we access the leaf node’s
bitmap to retrieve the actual values. This ﬁndLeaf operation also computes
information about the number of ones up to the beginning of the leaf node,
to allow eﬃcient computation of rank operations if necessary.

Two slightly diﬀerent algorithms are used to access a leaf in Ttree and
Ltree, but the essential steps are the same. Starting at the root of Ttree or
Ltree, the entries of the current node are checked from left to right, accumulating 
the values of band 
o-counters in two variables, bbefore and obefore, until
we exceed the desired position p. The algorithms proceed to the corresponding 
child node that would contain p. When a leaf node is found, the values
of bbefore and obefore contain the bit count and rank to the left of the node.

Once ﬁndLeaf returns the leaf node Nℓ that contains the desired position,
we can access the desired bit at position p − bbefore in the bitmap of the leaf
node (Tℓ). If the bit has value 0, navigation ends. Otherwise, and assuming
we are still in the upper levels of the conceptual k2-tree, we would need to
locate its children, that will be located at position rank1(Ttree, p) × k2. The
rank value is computed as obefore + rank1(Tℓ, p − bbefore).

The rank operation in Tℓ can still be a costly operation for relatively
large node sizes. In order to speed up the local rank operation inside the
leaves of Ttree (rankLeaf operation), we add a small rank structure to each
leaf of Ttree. This rank structure is simply a set of counters that stores
the number of ones in each block of ST bits. ST determines the number of

12

samples that are stored in each leaf and provides a space/time tradeoﬀ for
the local rank operation inside the leaves of Ttree. Using this modiﬁed leaf
structure, rank1(Tℓ, p) is obtained adding the values of all samples previous
to position p and performing a sequential counting operation only from the
last sampled position3.

3.2.1. Improving access times

An actual query in a k2-tree involves usually a top-down traversal, following 
a number of branches of the conceptual tree. This top-down traversal
actually translates into a set of accesses to the bitmaps T and L. These accesses 
follow a well-deﬁned pattern, starting at the beginning of the bitmap
and accessing new positions left to right.

Taking advantage of this property, we propose an alternative strategy to
navigate the dk2-tree. In this strategy, to access a position in Ttree or Ltree
we start the search from the previously accessed leaf instead of the root node.
Instead of a ﬁxed number of internal nodes to be traversed top-down, the
new algorithm will ﬁrst traverse the tree bottom-up until a descendant of the
new node is found, and then continue top-down as the original algorithm.
This method aims at taking advantage of the access patterns in the k2-tree
bitmaps, since many accesses, especially in upper levels, will be located in
the same or very close leaf nodes in Ttree.

To be able to start search from a previously accessed leaf node, a new
ﬁndLeaf ∗ operation must store a small array containing information about
the last traversed path.
levelData[Ttree.depth] is kept, that stores for each
level of Ttree, an entry hN, e, s, b, oi, where N is the Ttree node accessed at
that level, e the entry that was traversed, s is the number of bits covered by
N and b and o are the values of bbefore and obefore. A similar array is kept for
Ltree, only ignoring the o values in each entry.

The path information from the previous call allows ﬁndLeaf ∗ to determine
whether the current leaf node contains the new desired position. If it does,
the method returns immediately. Otherwise, the parent node is checked
recursively until we ﬁnd an internal node that “covers” the new position.
From that point on, the algorithm behaves exactly like the original ﬁndLeaf
and its top-down traversal.

3With a cost comparable to that of many practical static rank structures.

13

3.3. Update operations

In addition to the queries supported by static k2-trees, dk2-trees must
support update operations over the binary relation. First, relations between
existing elements may be created or deleted (changing zeros of the adjacency
matrix into ones and vice versa). Additionally, dk2-trees support changes
in the base sets of the binary relation (new rows/columns can be added to
the binary adjacency matrix, and existing rows/columns can be removed as
well).

3.3.1. Changing the contents of the binary matrix

Changes in the binary matrix represented by a k2-tree lead to a set of
modiﬁcations in the conceptual tree representation, essentially the creation or
removal of branches in this conceptual k2-tree. We will describe the changes
caused in the conceptual tree and its bitmap representation. Then we will
explain how these changes in the bitmaps are implemented over the data
structures Ttree and Ltree.

In order to insert a new 1 in a binary matrix represented with a k2-tree,
we need to make sure that an appropriate path exists in the conceptual tree
that reaches the cell. The insertion procedure begins searching for the cell
that has to be inserted, until a 0 is found in the conceptual tree. Two cases
may occur:

• If the 0 is found in the last level of the conceptual tree, the 0 is simply
replaced by a 1 to mark the new value of the cell and the update is
complete.

• If the 0 is found in the upper levels of the conceptual tree, a new path
must be created in the conceptual tree until the last level is reached.
First, the 0 is replaced with a 1 as in the previous case. Then, groups
of k2 bits must be added in the lower levels. After replacing the 0 with
a 1, a rank operation is performed to compute the position where its
children should be located. Then k2 0 bits are added as children, and
the one that “covers” the position inserted is set to 1. The procedure
continues recursively until it reaches the last level in the conceptual
tree.

Notice that there is still a third scenario corresponding to the case where a
1 already exists in the cell to be inserted. However we do not consider it, as in
this case the element is already inserted (and the appropriate path is already

14

present as well), hence no change is actually made in the representation.
Figure 3 shows an example of insertion in a conceptual tree. At a given
level in the conceptual tree a 0 is found and replaced with a 1, and a new
path is created adding k2 bits to all the following levels. The new branch
is highlighted in gray and the changes in the bitmaps of the k2-tree are also
highlighted.

             1                                                  1                                   1              0

1                1        0             1                         1       0         1        0            0   1  0  0              

1

0

1

1

0

1

0

0 1

0

1

0

1

0

0

1

0

1

0 1

0

0100

1

1 0

0

0011

0011

0010

0010

0001

0010

0100

0010 1000

0010

0010 1010

1

T = 1110  1101 1010 0100   0110 1001 0101 0010 1010 0100 1100
L = 0011 0011 0010 0010 0001 0010 0100 0010 1000 0010 0010 1010

Figure 3: Insert operation in a k2-tree: changes in the conceptual tree.

To change a 1 into a 0 in the binary matrix, we need to set to 0 the bit
of the last level that corresponds to the cell. Then, the current branch of the
conceptual tree must be checked and updated if necessary. First, we locate
the position of the cell to be deleted in the tree. The bit (node) corresponding
to that cell is set to 0. After this, we check the k2 − 1 bits corresponding to
the siblings of that node. If at least one of the bits is set to 1 the procedure
ends. However, if all of them are set to 0, this means that there are no 1s
remaining in the current branch: we need to delete the complete group of k2
0 bits, move one level up in the conceptual tree and set the bit corresponding
to their parent node to 0. We recursively repeat the same procedure upwards
until a group of non-zero k2 bits is found.

Summarizing the previous explanation,

in order to support insertions
and deletions in the conceptual dk2-tree we only need to provide three basic
update operations in the dynamic bitmaps Ttree and Ltree: ﬂipping the value
of a single bit, adding k2 bits at a given position and removing k2 bits starting

15

at a given position. For example, Algorithm 1 shows the complete process of
insertion of new 1s in the matrix.

Algorithm 1 Insert operation

function insert(tree, r, c)

p ← 0
mode ← Search
for l ← 0 to tree.nlevels - 1 do

5:

10:

15:

20:

25:

p ← computeChild(p, r, c, l)
(Nℓ, bbefore, obefore) ← ﬁndLeaf (Ttree, p)
Tℓ ← Nℓ.data
if mode = Search then

if access(Tℓ, p − bbefore) = 0 then

flip(Tℓ, p − bbefore)
mode ← Append

end if

else

append4(Tℓ, p − bbefore)
flip(Tℓ, p − bbefore)

end if
rank ← obefore + rank1(Tℓ, p − bbefore)
p ← rank × k2

end for

l ← tree.nlevels
p ← p − tree.Ttree.length
p ← computeChild(p, r, c, l)
(Nℓ, bbefore) ← ﬁndLeaf (Ltree, p)
Tℓ ← Nℓ.data
if mode = Search then

if access(Tℓ, p − bbefore) = 0 then

flip(Tℓ, p − bbefore)
mode ← Append

end if

30:

else

append4(Tℓ, p − bbefore)
flip(Tℓ, p − bbefore)

end if

end function

⊲ rank1(tree, p)

To ﬂip a single bit in Ttree or Ltree, we ﬁrst retrieve the leaf node Nℓ. The
bit is changed in the bitmap of Nℓ and its local rank directory is updated
(simply adding or subtracting 1 to the value of the appropriate counter).
Finally, if we are updating Ttree, the o-counters in the entries followed in the
path to Nℓ must be updated to reﬂect the change.

To add k2 bits at a given position in Nℓ, the k2 bits are inserted in the
bitmap of Nℓ directly, and the counters in the rank directory of Nℓ must
be updated accordingly (in this case, all the counters from the position in
Nℓ where the insertion has been done until the end of Nℓ bitmap must be
updated, since the bitmap is displaced). After updating Nℓ, the band


16

16 / 6

Ttree

28 / 15

16

12 / 5

16 / 9

10

12 / 6

16 / 6

12 / 5

8 / 6

8 / 3

4

4 / 2

8 / 4

8 / 3

8 / 3

4 / 2

1110 1101

1010 0100

0110 

1001 0101 

0010 1010 

 0100 1100

1

Ltree

24

20

24

8

8

8

8

8

12

4

0011 0011

0010 0010

0001 0010

0100 0010

1000 0010 0010

1010

Figure 4: Insert operation in a dk2-tree: changes in the data structures.

o-counters of its ancestors are also updated accordingly (the band 
o-counters
are increased by k2 and 1 respectively). Notice that we only update the band 
o-counters of the entries in the path to Nℓ because only those entries are
aﬀected by changes in the bitmap of Nℓ.

When a leaf of Ttree or Ltree reaches its maximum node size we split it
in two nodes, always keeping groups of k2 sibling bits in the same leaf. This
change is propagated to the parent of the leaf node, causing the insertion of
a new entry pointing to the new node and updating the band 
o-counters
accordingly. Eventually, internal nodes may also be split, evenly splitting
their entries in two new nodes.

To achieve better space utilization the dk2-tree can store nodes of diﬀerent
maximum sizes. Given a base node size B, we allow a number e of partial
expansions of the node before splitting it. Hence, Ttree and Ltree may contain
nodes of size B, B + B
e+1 (class-0, · · · , class-e nodes). If a node
overﬂows, its contents are reallocated in a node of the next class. If a fullyexpanded 
node overﬂows, it is split into two class-0 nodes.

e+1, · · · , B + (e)B

17

3.3.2. Changes in the rows/columns of the adjacency matrix

The dk2-tree also supports the insertion of new rows/columns in the adjacency 
matrix it represents, as well as deletion of existing rows/columns.

The insertion of new rows/columns to the adjacency matrix is trivial in
many cases in the dk2-tree. Note that if the size of the matrix is not a power
of k it is virtually expanded to the next power of k to represent it with a
k2-tree. Therefore, in a k2-tree we usually have unused rows and columns
that can be made available. If the size of the matrix is exactly a power of k
we can easily add new unused rows expanding the matrix. To do this, we add
a new root node to the conceptual k2-tree: its ﬁrst child will be the current
root and its k2-1 remaining children will be 0. This virtually increases the
size of the matrix from kn ×kn to kn+1 ×kn+1. This operation simply requires
the insertion of k2 bits 1000 at the beginning of Ttree.

To delete an existing row/column, the procedure is symmetric to the
insertion. The last row/column of the matrix can be removed by updating
the actual size of the matrix and zeroing out all its cells. Rows/columns
at other positions may be deleted logically, by adding these positions to a
list of deleted rows and columns after zeroing all their cells. This deleted
rows/columns could be reused later when new rows/columns are inserted, by
just taking one from the list.

3.4. Analysis

As previously stated in Section 1, dynamic representations of compact
data structures are usually aﬀected by a slowdown factor that limits their
overall eﬃciency when compared to a static representation. The static k2-tree
is essentially a LOUDS-based cardinal tree, and a dynamic representation of
a LOUDS tree has a slowdown factor of O(ω) to perform range queries [8,
Section 12.5.2]. In the RAM model, we can assume this to mean a slowdown
of O(log n) for any dynamic representation of a LOUDS tree.

Note that in Section 3.2.1 we described an optimization that takes into
account the access pattern in the k2-tree (accesses to the tree are not random 
when performing queries; they follow a well-deﬁned pattern with many
consecutive accesses to close positions). This reduces the overall cost from
the original O(C log n) (where C is the cost of the static representation,
described in Section 2.2) to O(C log n
C ), improving the result especially for
costly queries.

Update operations over LOUDS cardinal trees require O(logk n) updates,
in blocks of k bits [8, Section 12.4.1]. The time required for an update opera18


tion becomes O(ω) if k = O(ω2). As this is a rather permissive value for k in
practice, we may consider the update cost over the dynamic representation
to be O(log n logk n).

4. Improved compression with a matrix vocabulary

Recall from Section 2.2.1 that the k2-tree space results can be improved
using a matrix vocabulary to compress the bitmap L. This improvement
replaces the plain bitmap L with a sequence of variable-length codes and a
matrix vocabulary. In this section we introduce a similar proposal for dk2trees.
 In this proposal, the leaves in Ltree will store a sequence of variablelength 
matrix identiﬁers encoded using ETDC [22, 23].

Note that the management of a matrix vocabulary is much more complex
in the dk2-tree: we should be able to add and remove entries from the vocabulary,
 as well as eﬃciently check whether a given matrix already exists in
the vocabulary. Also, when Ltree stores a sequence of codewords, the actual
number of bits and ones in a leaf is no longer the same as the logical values
stored in band 
o-counters of its parent entry. This does not aﬀect the tree
structure because the actual size of each leaf node is stored in the size ﬁeld
of its header, and this is the value used to determine when to expand or split
a leaf, while the values in the counters are still used as before to access the
appropriate leaf.

To store the matrix vocabulary we built a simple implementation that
stores a hash table H to look up matrices. An array V stores the position in
H where each matrix is stored. Finally, we add another array F that stores
the frequency of each matrix. An additional list V empty stores the codewords
that are not being currently used.

Figure 5 shows an example with a complete vocabulary representation.
The leaves of Ltree (bottom, nodes N2 and N3) store a sequence of variablelength 
codes represented with ETDC (we consider 2-bit chunks in this simpliﬁed 
example). Notice that the band 
o-counters in internal node N1 still
refer to the logical size of the leaf: the entry pointing to N2 marks it as
containing 64 bits (4 submatrices of size 4 × 4) and 5 ones. The submatrices
are stored in a hash table that contains for each matrix its oﬀset in the vocabulary 
(that can be easily translated into its ETDC codeword). V points
to the entry in H for each vocabulary codeword, and F stores its frequency.
To access a position in Ltree when using a matrix, we obtain a logical
oﬀset in the leaf from ﬁndLeaf . To retrieve the actual bit, we sequentially

19

Figure 5: Dynamic vocabulary management: vocabulary (top) and Ltree (bottom).

traverse the sequence of variable-length codes in the leaf. When we ﬁnd the
code that contains the desired position, we translate the codeword into an
array index, and V is used to retrieve the actual matrix in H. For example,
suppose we want to access position 21 in the example of Figure 5. Our
ﬁndLeaf operation would take us to node N2, oﬀset 21. To obtain the actual
matrix we would traverse the codes in N2, taking into account the actual
size of each submatrix (16 bits), so our oﬀset would be at position 5 in the
second submatrix. We go over the code 10 and ﬁnd the second code 0010. To
ﬁnd the actual matrix, we convert this code to an oﬀset (2) and access V [2]
to locate the position in H where the matrix is actually stored (3, second
non-empty position). Finally, in H we can access bit 5 in the matrix bitmap
(0).

The main diﬀerence with a static implementation is the need to sequentially 
traverse the list of variable-length codes. We can reduce the overhead
of this sequential traversal adding to the leaves of Ltree a set of samples that
store the actual oﬀset in bytes of each SL-th codeword. The idea is similar to
the sampling used for rank in the leaves of Ttree. With this improvement, to
locate a given position we can simply use the samples to locate the previous
sampled codeword and then start the search from the sampled position.

20

4.1. Update operations

Update operations in Ltree, when using a matrix vocabulary, require us
to add, remove or modify variable-length codes from the leaves of Ltree. All
the update operations start by ﬁnding the real location in the node where
the variable-length code should be added/removed/modiﬁed.

To insert groups of k2 bits we need to add a new codeword. The matrix
corresponding to the new codeword is looked up in H, adding it to the
vocabulary if it did not exist and increasing its frequency in F . Then, the
codeword for the matrix is inserted in the leaf, updating the counters in the
node and its ancestors.

To remove groups of k2 bits in a leaf node of Ltree a codeword must be
removed: we locate the codeword in Ltree, decrease its frequency in F and
then we remove the code from the leaf node, updating ancestors accordingly.
If the frequency of the codeword reaches 0, the corresponding index in V is
added to V empty. When new entries must be added to the vocabulary V empty
will be checked to reuse previous entries and new codes will only be used
when V empty is empty.

To change the value of a bit in Ltree we need to replace existing codewords.
First, the matrix for the current codeword is retrieved in H and its frequency
is decreased in F . We look up the new matrix in H. Again, if it already
existed, its frequency is increased, and if it is new, it is added to H and its
frequency set to 1. Then, the codeword corresponding to the new matrix is
inserted in Ltree replacing the old codeword.

Following the example of Figure 5, suppose that we need to set to 1
the bit at position 21 in Ltree. ﬁndLeaf would take us to N2, where we
have to access the second bytecode 00 10 at oﬀset 5. This bytecode (C2)
corresponds to oﬀset 2 in the ETDC order. We would access V [2] to retrieve
the corresponding matrix. The operation would require us to transform the
matrix as follows:

0000
0111
0000
0000

0000
0011
0000
0000

−→

The new submatrix already exists, at position 3 in V with frequency 1.
Hence, we would need to update the leaf node replacing the old codeword
00 10 with the new codeword C3: 00 11. The vocabulary would also be
updated, decreasing the frequency of C2 to 1 and increasing the frequency
of C3 to 2.

21

4.2. Handling changes in the frequency distribution

The compression achieved by the matrix vocabulary depends heavily on
the evolution of the matrix frequencies. As the distribution of the submatrices 
changes the eﬃciency of the variable-length codes will degrade. The
simplest approach to mitigate this problem is to use a precomputed vocabulary 
from a fraction of the matrix to obtain a reasonably good frequency
distribution.

To obtain the best compression results, when the frequency of a submatrix
changes too much its codeword should also be changed to obtain the best
compression results. This is a process similar to the vocabulary adjustment
in dynamic ETDC (DETDC [26, 33]). However, in a dk2-tree, to change
the codeword of a submatrix, we must also update all the occurrences of
the codeword in the leaves of Ltree. Therefore, a space/time tradeoﬀ exists
between vocabulary size and update cost.

To maintain a compression ratio similar to that of static k2-trees we can
use simple heuristics to completely rebuild Ltree and the matrix vocabulary:
rebuild every p updates or count the number of inversions in F . To rebuild
Ltree, we must sort the matrices in H according to their actual frequency and
compute the new optimal codes for each matrix. Then we have to traverse
all the leaves in Ltree from left to right, replacing the old codes with optimal
ones. Notice that the replacement can not be executed completely in place,
because the globally optimal codes may be worse locally, but the complete
process should require only a small amount of additional space. After Ltree
is rebuilt, the old vocabulary is simply replaced with the optimal values.

Instead of using the simple heuristics to rebuild the matrix vocabulary,
we can keep track of how good the current compression is. To guarantee
that the compression of Ltree is never too far from the optimum, we can keep
track of the actual optimum vocabulary. To do this, we propose an enhanced
vocabulary representation, similar to the adaptive encoding used in DETDC.
In our case it would be unfeasible to change the actual vocabulary each time
the length of a codeword changes, but we store the optimal vocabulary to
know exactly the amount of space that would be gained using an optimal
vocabulary.

To this aim we store, in addition to H and F , a permutation VP between
the current vocabulary and the optimal one: VP (i) gives the optimal position
of the codeword at oﬀset i, while VP −1(i) gives the current position given the
optimal position. This permutation will allow us to keep V and F always
sorted in descending order of frequency (that is, according to the optimal

22

Figure 6: Extended vocabulary to keep track of the optimal codewords.

vocabulary). Figure 6 shows the data structures required to represent the
same vocabulary of Figure 5 using the new method.

In this representation, we obtain the matrix for a codeword as in the
previous version; the only diﬀerence is that we ﬁrst obtain the oﬀset of the
codeword in the optimal vocabulary and then we use VP −1 to compute the
oﬀset in the current vocabulary. Also, to ﬁnd the matrix for a given codeword
we compute the optimal oﬀset for the codeword using VP and then use V
to ﬁnd the position of the matrix.

To keep track of the changes in frequencies, we also build an array, Top,
that stores, for each diﬀerent frequency, the position in V of the ﬁrst codeword 
with that frequency. The array Top is used to swap codewords when
frequencies change, as it is performed in DETDC. If the frequency of a matrix 
at index i in V changes from f to f + 1, the new optimum position
for it would be the position Top[f ]. The indexes in V , VP and H would
be updated to reﬂect the change. The case when the frequency of a matrix
decreases from f to f − 1 is symmetric: we swap the current position of the
matrix with Top[f − 1] + 1, updating the corresponding indexes in F and
VP .

The use of the extra data structures allows us to control precisely how

23

much space is being wasted at any moment. This means that we can set a
threshold rebLtree and rebuild Ltree when the ratio sizecur
sizeopt

surpasses it.

In order to physically store all the data structures required for the dynamic 
vocabulary, we resort to simple data structures that can be easily
updated. H is a simple hash table backed by an array. V and F are extendible 
arrays. If we want to set the threshold rebLtree we need additional
data structures for VP and Top. Top can be implemented using an extendible 
array and two extendible arrays can store VP and its inverse. The
goal of these representations is to provide eﬃcient update times (recall that
each update operation in the dk2-tree will always lead to a change in Ltree,
that will cause at least one frequency change in the vocabulary).

5. Experimental Evaluation

In this section we experimentally test the eﬃciency of the dk2-tree in
order to demonstrate its capabilities to answer simple queries in space and
time close to those of the static k2-tree data structure.

First, we will study the diﬀerent parameters of the dk2-tree and their eﬀect
in compression and query eﬃciency. Then, we will show the eﬃciency when
compared to the equivalent static data structure in the original application
domain of k2-trees: Web graph representation. Finally, Section 6 will be
devoted to describe the application of dk2-trees to the representation of RDF
datasets, where the k2-tree has been already used and dynamic operations
are of interest.
In this context, we will compare our representation with
state-of-the-art alternatives including a similar static approach based on k2trees.


All the experiments in this article were run on an AMD-Phenom-II X4
955@3.2 GHz, with 8GB DDR2 RAM. The operating system is Ubuntu 12.04.
All our code is written in C and compiled with gcc version 4.6.2 with full
optimizations enabled.

5.1. Parameter tuning

The main parameters used to settle the eﬃciency of the dk2-tree are the
sampling period s in the leaves of Ttree (ST ) and Ltree (SL), the block size B
on the nodes and the number of partial expansions e; the value k′ in the last
level is also important when a matrix vocabulary is used for L. We will ﬁrst
focus on the eﬀect of the ﬁrst parameters, and then study the eﬀect of the
matrix vocabulary independently.

24

)

B
M

(
 

e
c
a
p
S

 20

 15

 10

 5

 

Size(MB)
Creation time
Rebuild time

32

64

128

256

Sampling period (s)

 4

 3

 2

 1

)
e
g
d
e

/
s
d
n
o
c
e
s
o
r
c
m

i

(
 
e
m
T

i

)

B
M

(
 

e
c
a
p
S

 20

 15

 10

 5

 

Size(MB)
Creation time
Rebuild time

128256 512

1024

2048

 4

 3

 2

 1

)
e
g
d
e

/
s
d
n
o
c
e
s
o
r
c
m

i

(
 
e
m
T

i

 

Size(MB)
Creation time
Rebuild time

Block size (B)

 4

 3

 2

 1

8

)
e
g
d
e
/
s
d
n
o
c
e
s
o
r
c
m

i

(
 
e
m
T

i

)

B
M

(
 
e
c
a
p
S

 20

 15

 10

 5

1

2
Different block sizes (e+1)

4

6

Figure 7: Evolution of space/time results of the dk2-tree changing the parameters s, B
and e.

We use for our experiments a Web graph dataset, eu-2005 4, a small graph
with 19 million edges. The results of parameter tuning are similar for other
datasets used in following sections. We do not use a matrix vocabulary in
this ﬁrst example. Figure 7 shows the evolution of the dk2-tree size and the
creation and rebuild time depending on each parameter. The dk2-tree size,
in MB, is the overall memory used by the data structure. The creation time
is the time to build the dk2-tree from a plain representation inserting each
edge separately, so it provides an estimation of the average update time of
the structure. Finally, the rebuild time is the time to retrieve all the 1s in the
adjacency matrix in a single range query covering the complete matrix, and

4Dataset from the WebGraph project, that comprises some Web graphs gathered by
UbiCrawler [34]. These datasets are made available to the public by the members of
the Laboratory for Web Algorithmics (http://law.di.unimi.it) at the Universit`a Degli
Studi Di Milano.

25

it is shown as a rough estimation of the expected evolution of query times.
Both times are shown in microseconds per element inserted/retrieved.

The top-left plot in Figure 7 shows the results obtained for diﬀerent values
of the sampling interval s, with ﬁxed B = 512 bytes and #classes = e+1 = 4,
but the tradeoﬀ is similar for diﬀerent values. Smaller values of s increase
the size of the trees slightly, but a considerable reduction in query time is
obtained. Additionally, update operations can also be improved by using
smaller values of s. Even though blocks with more samples are more costly
to update when their contents change, the recomputation of the samples is
only performed if the node contents actually change. On the other hand,
the rankLeaf operation must always be performed at all the levels of the
conceptual tree, and its cost is signiﬁcantly reduced when using smaller values
of s. Therefore, a small sampling period can be used to obtain faster access
times with only a minor increase in the size of the dk2-tree.

The top-right plot in Figure 7 shows the results for diﬀerent values of B,
for ﬁxed s = 128 bytes and #classes = e + 1 = 4. The block size B provides
a clear space/time tradeoﬀ: small values of B yield bigger dk2-trees due to
the amount of overhead to store many smaller nodes, while larger values of
B make updates become more costly. Query times are not very diﬀerent
depending on B for usual values. In our experiments we will choose values
of B = 256 or B = 512 to obtain good space results with small penalties in
update times.

The bottom plot of Figure 7 shows the evolution with e for ﬁxed s = 128
and B = 512. If we use a single block size (e + 1 = 1), the node utilization is
low and the ﬁgure shows poor space results, but even for a relatively small
number of block sizes the space results improve fast with only minor changes
in the creation and rebuild times.

After measuring the basic parameters of the dk2-tree data structure, we
focus on the analysis of the matrix vocabulary variant. We build a dk2-tree
for several Web graph datasets with and without a matrix vocabulary and
for diﬀerent values of the parameter k′. We compare the static and dynamic
representations in two diﬀerent Web graph datasets5: the indochina-2004
dataset, with 200 million edges, and the uk-2002 dataset, with 300 million
edges. In all cases we built a hybrid variant of the k2-tree or the dk2-tree,
with k = 4 in the ﬁrst 5 levels of decomposition and k = 2 in the remaining

5Again, datasets obtained from the WebGraph project (http://law.di.unimi.it).

26

levels. For the variants with matrix vocabulary, we test the values k′ = 4
and k′ = 8. In the dk2-tree we choose a block size B = 512, e = 3 (4 diﬀerent
block sizes) and s = 128. The static k2-tree representation uses a sampling
factor of 20 for its rank data structures, hence requiring an additional 5%
space.

We use in the dk2-tree the most complex version of the matrix vocabulary,
 that keeps track of the optimum vocabulary and rebuilds the complete
vocabulary when the total size is 20% worse than the optimum. Additionally,
we set a threshold of 100 KB for the size of Ltree, so that the vocabulary is
only checked (and rebuilt if necessary) when Ltree reaches that size. We also
consider in the dk2-tree two diﬀerent scenarios: the space required by the
simplest version of the vocabulary (dynamic) and the total space required to
keep track of the optimum vocabulary (dynamic-complete).

)

B
M

(
 

e
c
a
p
S

 140

 120

 100

 80

 60

 40

indochina-2004

static
dynamic
dynamic-complete

uk-2002

static
dynamic
dynamic-complete

 400

 350

 300

 250

 200

 150

 100

)

B
M

(
 

e
c
a
p
S

noVoc

K’=4

K’=8

Matrix vocabulary

noVoc

K’=4

K’=8

Matrix vocabulary

Figure 8: Space utilization of static and dynamic k2-trees with diﬀerent matrix vocabularies 
in Web graphs.

Figure 8 shows the evolution of the space utilization for both datasets
required by original k2-trees (static) and a dk2-tree (dynamic). Note that
the dk2-tree space utilization is always close to that of the static k2-tree
when no matrix vocabulary is used (noV oc). The space overhead of dk2trees,
 around 20%, is mostly due to the space utilization of the nodes of Ttree
and Ltree.

Static k2-trees obtain better compression for larger values of k’, reaching
their best space utilization when k′ = 8. On the other hand, the dk2-tree
improves its space results only for small k’. Note also that the variant that
keeps track of the optimum vocabulary (dynamic−complete) is always bigger
than the simpler approach.
In fact, in our experiments the graphs were

27

only rebuilt once, when the size of Ltree reached the threshold, showing that
once a small fragment of the adjacency matrix has been built the resulting
matrix vocabulary becomes good enough to compress the overall matrix with
a relatively small penalty in space. Hence, the size of the additional data
structures required to keep track of the optimum vocabulary is higher than
the space reduction of the vocabulary itself. Considering these results, a
simpler strategy to maintain a “good” matrix vocabulary (such as using a
predeﬁned matrix vocabulary extracted from experience or simply rebuilding
after x operations) may be the best approach in many domains. On the other
hand, the strategy to keep track of the optimum vocabulary could still be
of application in domains where the relative size of the matrix vocabulary is
expected to be of small size.

5.2. Query and update times

In this section we extend the previous analysis of the dk2-tree measuring

the eﬃciency of our proposal in terms of query and update times.

To measure the query eﬃciency, we focus on the representation of Web
graphs, the original application domain of the static k2-tree. We choose the
most usual query in this domain, namely, the successor query that asks for
the direct neighbors of a speciﬁc node (all the cells with value 1 in a speciﬁc
row of the adjacency matrix). For each dataset we run successor queries for
all the nodes in the dataset and measure the average query times in µs/query.

)
y
r
e
u
q
/
s
o
r
c
m

i

(
 
s
e
m

i
t
 
y
r
e
u
Q

 140
 120
 100
 80
 60
 40
 20
 0

indochina-2004

static
dynamic

noVoc

K’=4

K’=8

Matrix vocabulary

)
y
r
e
u
q
/
s
o
r
c
m

i

(
 
s
e
m

i
t
 
y
r
e
u
Q

 500

 400

 300

 200

 100

 0

uk-2002

static
dynamic

noVoc

K’=4

K’=8

Matrix vocabulary

Figure 9: Time to retrieve the successors of a node in a static k2-tree and a dk2-tree.
Query times in µs/query.

As shown in Figure 9, the dk2-tree is always slower than a static representation.
 Comparing the dk2-tree version that obtained the best space

28

results (k′ = 4) with the best static k2-tree version (k′ = 8), the dk2-tree is
50-80% slower than the static data structure. This diﬀerence in query times
is signiﬁcant, but for speciﬁc scenarios where update operations are frequent,
the dk2-tree turns out to be a reasonable solution especially if we consider
the slowdown that aﬀects any dynamic representation, and the limitations
of its static version.

The cost of update operations in the dk2-tree depends on several factors,
such as the choice of parameters B and s. The characteristics of the dataset
also have a great inﬂuence in its k2-tree and dk2-tree representation, since the
clusterization of 1s lead to a better compression of the data. In the dk2-tree,
the clusterization of 1s and the sparsity of the adjacency matrix also aﬀect
update times: when new 1s must be inserted and they are far apart from any
other existing 1, the insertion operation must insert k2 bits in many levels of
the conceptual k2-tree, which increases the cost of the operation. Therefore,
insertion costs are expected to be higher on average when datasets are very
sparse.

To measure this eﬀect of the distance between 1s on update costs, we
choose to use synthetic datasets. Since we aim to evaluate the insertion
cost depending on the level of the conceptual tree where that insertion is
performed, synthetic data allow us to speciﬁcally control that without depending 
on other features of speciﬁc real Web graphs that were used instead.
We create a set of very sparse synthetic datasets. In them, 1s are inserted
every 2d rows and 2d columns, so that the k2-tree representation has a unary
path of length d to each edge. Table 1 shows a summary with the basic information 
of the datasets. We choose the separation for the diﬀerent dataset
sizes so that all the datasets have the same number of edges (4,194,304).

Dataset #rows/columns Separation between 1s (2d) # k2-tree levels
synth 22
22
24
synth 24
synth 26
26

2,048 (d = 11)
8,192 (d = 13)
32,768 (d = 15)

4,194,304
16,777,216
67,108,864

Table 1: Synthetic sparse datasets used to measure insertion costs.

We measure the insertion cost with these datasets, depending on the
number of levels ℓ that must be created in the conceptual k2-tree to insert
the new 1. We compare the insertion costs for ℓ ∈ [0, 10]. For each dataset
and value of ℓ, we create a set of 200,000 cells of the matrix that require
exactly ℓ new levels in the conceptual tree.
In this experiments we use a

29

simple setup with a single block size. Additionally, we compute the cost to
query the new cells over the unmodiﬁed synthetic datasets. These queries
are an approximation of the insertion cost that is actually due to locating
the node of the conceptual k2-tree where we must start the insertion.

Insertion and query times

Cost of updating the structure

)
n
o
i
t
a
r
e
p
o
/
s
o
r
c
m

i

(
 
s
e
m

i
t
 
y
r
e
u
q

/

n
o

i
t
r
e
s
n

I

 40

 35

 30

 25

 20

 15

 10

 5

 0

 0

 1

 2

insert - synth_22
insert - synth_24
insert - synth_26
query - synth_22
query - synth_24
query - synth_26

)
t
r
e
s
n
i
/
s
o
r
c
m

i

(
 
s
e
m

i
t
 
e

t

a
d
p
U

 20

 15

 10

 5

 0

 4

 3
 7
Levels of separation (l)

 5

 6

 8

 9

 10

 0

 1

 2

synth_22
synth_24
synth_26

 8

 9

 10

 4

 3
 7
Levels of separation (l)

 5

 6

Figure 10: Insertion and query times (left) and estimation of update cost (right) in the
dk2-tree varying ℓ.

Figure 10 (left) shows the evolution of insertion and query times,

in
µs/edge, in the diﬀerent datasets. When ℓ is small (new 1s are inserted
very close to existing 1s), insertion and query times are almost identical. As
ℓ increases the insertion cost becomes higher while query times become lower
because the ﬁrst 0 in the conceptual tree (the node where insertion should
start) is found in upper levels of the tree. Figure 10 (right) shows an estimation 
of the actual cost devoted to update the tree depending on ℓ, and
computed by subtracting query times from insertion times. Notice that it is
0 for small ℓ and steadily increases with ℓ.

Our overall results suggest that insertion times in the dk2-tree can be
very close to query times if the represented dataset has some properties that
are also desirable for compression, particularly the clustering of 1s in the
binary matrix. The evolution of insertion times shows that insertions at the
upper levels of the tree may be several times more costly than insertions in
the lower levels of the tree. However, insertions in the upper levels of the
tree should be very infrequent in most of the datasets where a dk2-tree will
be used, since compression in k2-trees also degrades when matrices have no
clusterization at all.

30

6. Representation of RDF databases

RDF (Resource Description Framework ) [35] has become an increasingly
popular language recommended by the W3C for the description of facts in the
Web of Data. It follows a graph-based data model, in which the information
is represented as a set of triples. Each triple is an edge of a labeled graph,
and represents a property of a resource using a subject S (element of interest,
or source node), a predicate P (property of the element, or edge label), and
an object O (value of the property, or target node). These (S,P,O) triples
can be queried using a standard graph-matching language named SPARQL
[36]. This language is built on top of triple patterns, that is, RDF triples
in which each component may be a variable (variables are preceded, in the
pattern, by the symbol ?): (S, P, O), (?S, P, O), (?S, ?P, O), etc. Yet, more
complex queries can be created by joining sets of triple patterns.

Many diﬀerent proposals have appeared in recent years to eﬃciently store
and query RDF datasets. Many of these so called “RDF stores” are based on
relational databases, creating speciﬁc database structures to store the triple
patterns in the RDF data [37, 38]. Other particular solutions rely on speciﬁc
data structures designed to compactly store the data while allowing eﬃcient
query operations [39, 40, 41, 42].

RDF datasets can be built from snapshots of data and therefore stored
in static form. However,
in many cases new information is continuously
appearing and must be incorporated into the dataset to keep it updated. In
these cases, a purely static representation of the dataset is unfeasible, since
a way to eﬃciently update the contents in the RDF dataset is needed. Most
of the relational approaches for RDF storage can handle update operation.
However, speciﬁc compact representations usually lack the same ﬂexibility,
but still some proposals exist, like X-RDF-3X [43], a dynamic evolution of
the existing multi-indexing native solution RDF-3X.

A representation of RDF datasets based on k2-trees, called k2-triples, has
been presented in [44]. This representation uses a collection of k2-trees to
represent the triples corresponding to each predicate in the RDF dataset.
This representation was proved to be very competitive in space and query
times with state-of-the-art alternatives. However, this proposal was limited
to a static context due to the static nature of k2-trees.

In this section we propose a dynamic representation of RDF datasets
based on dk2-trees, that simply replaces static k2-tree representations with a
dk2-tree per predicate. We aim to demonstrate that a representation based

31

on the dk2-tree can obtain query times close to the static k2-triples approach,
but more importantly that the dk2-tree representation provides the basis to
perform update operations on the RDF dataset, which are actually expected
operations in real applications.

6.1. Our proposal

Our proposal simply replaces the static k2-tree representation in k2-triples
with a dk2-tree per predicate. We consider a partition of the RDF dataset
by predicate, and build a dk2-tree for each predicate in the dataset. For each
predicate we consider a matrix storing all relations between subjects and
objects with that predicate. All matrices will contain the same rows/columns,
where subject-objects (elements that appear as both subjects and objects in
any triple) will be located together in the ﬁrst rows/columns of the matrix
and the remaining rows (columns) of the matrices will contain the remaining
subjects (objects)6.

Our proposal based on dk2-trees aims to solve the representation of the
structural part of an RDF dataset. We assume that additional data structures 
must be used to store vocabularies of subjects, objects and predicates
and map them with rows/columns of the matrices represented by dk2-trees.
The creation of a dynamic and eﬃcient dictionary representation to manage
large collections of URIs and literal values is a complex problem, since the
vocabulary may constitute a large part of the total size of an RDF dataset
[45].

As previously stated, the main query operations in RDF datasets are
based on triple-pattern matching. These triple patterns can be easily translated 
into a collection of simple queries in one or more of the k2-trees used
to store the complete RDF dataset. Hence, our proposal can directly answer 
all triple pattern queries: (S, P, O) and (S, ?P, O) queries are actually
cell retrieval queries (involving one dk2-tree or all the dk2-trees in the collection,
 respectively), (S, P, ?O), (S, ?P, ?O), (?S, P, O) and (?S, ?P, O) are
row/column queries and (?S, P, ?O) is a full range retrieval query that asks
for all the cells in a dk2-tree.

Triple patterns can usually be joined to build more complex queries. Join
operations involve matching multiple triple patterns with a common element.

6Notice that we follow the same subject-object arrangement than that used by the
static approach, thus assuming the use of a similar strategy to create the vocabulary of
terms.

32

For instance, the query (?S, P1, O1) ⊲⊳ (?S, P2, O2) represents all the subjects
that relate to O1 with predicate P1 and to O2 with predicate P2. The join
variable is marked with an ?, and is a common element to both triple patterns.
In static k2-triples, three diﬀerent strategies were proposed to solve triple
patterns, and all of them can be also used in our dk2-trees:

• Independent evaluation separates any join operation in two triple pattern 
queries and a simple merge that intersects the results of both
queries. The adaptation to dk2-trees is trivial using the basic operations 
explained.

• Chain evaluation chains the execution, solving ﬁrst one of the triple
pattern and then restricting the second pattern to the results of the
ﬁrst.

• Interactive evaluation is a more complex operation, in which two k2trees 
are traversed simultaneously. The basic elements of this strategy
include a synchronized traversal of the conceptual trees. Regardless
of the type or complexity of the join operation, the essential steps of
interactive evaluation are based on the access to one or more nodes in
the conceptual trees of diﬀerent k2-trees, operations that are directly
supported by dk2-trees.

6.1.1. Update operations using dk2-trees

Our proposal is able to answer all the basic queries supported by k2-triples
simply replacing static k2-trees by dk2-trees. Next, we will show that update
operations in RDF datasets can also be easily supported by our proposal.
This is presented as a proof of concept of the applicability of dk2-trees to
this domain, even though our proposal focuses only on the representation of
the triples.

The most usual update operation in an RDF dataset is probably the insertion 
of new triples, either one by one or, more frequently, in small collections
corresponding to new information retrieved or indexed regularly. The insertion 
of new triples in an existing RDF database involves several operations
in our representation based on dictionary encoding:

• First, the values of the subject, predicate and object of the new triple
must be searched in the dictionary, and added if necessary. If all the
elements existed in the dictionary the new triple is stored as a new
entry in the dk2-tree corresponding to its predicate.

33

• If the triple corresponds to a new predicate, a new empty dk2-tree can

be created to store the new subject-object pair.

• If the subject and/or object are new, we must add a new row/column to
all the dk2-trees. As explained before, this operation is usually trivial in
dk2-trees. In the worst case, we must increase the size of the matrices,
an operation (with a cost comparable to the insertion of a new 1 in the
matrix) that must be repeated in all the dk2-trees.

The removal of triples to correct or delete wrong information is a typical
update operation in RDF datasets, as well. The possible changes when triples
are removed are similar to the insertion case: when triples are removed we
may need to simply remove a 1 from a dk2-tree or remove a row/column
(marking it as unused) if the subject/objects has no associated triples.

We assume in our representation that subject-object elements are stored
together in the top-left region of the matrices, so that join operations do not
need to perform additional computations. This allows us to focus on triple
pattern queries and ignore the eﬀect of an RDF vocabulary. However, the
insertion of triples may cause a subject (object) to become a subject-object,
and the deletion of triples may transform a subject-object in just a subject
or object. A simple solution to avoid the problem in the dynamic case would
be to use a diﬀerent setup where rows/columns of the matrices would contain
all the elements (subjects and objects) instead of storing only subjects in the
rows and objects in the columns. It should have small eﬀect in the overall
compression, since k2-trees and dk2-trees depend mostly on the number and
distribution of the 1s in the matrix than on the matrix size.

In order to follow the original setup with subject-object elements in the
ﬁrst rows/columns of the matrix, when a subject (object) becomes a subjectobject 
we need to move it to the beginning of the matrix. This requires
ﬁnding all the 1s in the corresponding row (column), allocating a new row
and column at the beginning of the matrix and inserting the 1s in the same
locations in the new row (column). Note that, even though we only described
the ability of dk2-trees to add new rows at the end of the matrix, the process
can be trivially extended to add rows at the beginning: given an n×n matrix,
let us assume we place elements starting from the center instead of doing it
from the ﬁrst row/column. With this setup, we can add new subject-object
elements from the center towards the top-left corner (thus, expanding the
matrix towards the top-left corner), and append new subjects and objects
in the usual way (towards the bottom-right corner). That is, we can expand

34

our virtual matrix to add subjects and objects as usual, but also attach new
subject-object elements in unused rows/columns in the upper-left section of
the matrix. This change has small eﬀect on compression (the elements are
still grouped essentially in the same way) and allows us to keep the list of
subject-object elements together, hence following the same ordering of the
static representation.

6.2. Experimental evaluation on RDF datasets

We compare our proposal based on dk2-trees with the static data structures 
used in k2-triples and its enhanced version, k2-triples+, presented in
[44]. The goal of these experiments is to demonstrate the eﬃciency of dk2trees 
in this context, and their ability to act as the basis for a dynamic
compact representation of RDF databases. Note that in [44] k2-triples were
already proved to be competitive with state-of-the-art representations, both
in compression and query times. We will compare the space results and query
times of dynamic and static representations to show that dk2-trees can store
RDF datasets with a reduced overhead over the space and time requirements
of a static representation.

6.2.1. Experimental setup

We experimentally compare our dynamic representation with the equivalent 
one using static k2-trees. We use a collection of RDF datasets of very
diﬀerent sizes and number of triples, and also include datasets with few and
many diﬀerent predicates7. Table 2 shows a summary with some information
about the datasets used. The dataset jamendo8 stores information about
Creative Commons licensed music; dblp9 stores information about computer
science publications; geonames 10 stores geographic information; ﬁnally, dbpedia 
11 is a large dataset that extracts structured information from Wikipedia.
As shown in Table 2, the number of predicates is small in all datasets except 
dbpedia, that is also the largest dataset and will be the best example to
measure the scalability of queries with variable predicate.

7The datasets and general experimental setup used are based on the experimental
evaluation in [44], where k2-triples and k2-triples+ are tested. We use the same datasets
and query sets in our tests.

8http://dbtune.org/jamendo
9http://dblp.l3s.de/dblp++.php
10http://download.geonames.org/all-geonames-rdf.zip
11http://wiki.dbpedia.org/Downloads351

35

Collection
jamendo

dblp

geonames
dbpedia

#triples #predicates #subjects
335,926
1,049,639
2,840,639
46,597,620
112,235,492
8,147,136
18,425,128
232,542,405

28
27
26
39,672

#objects
440,604
19,639,731
41,111,569
65,200,769

Table 2: RDF datasets used in our experiments.

We build our dynamic representation following the same procedure used
for static k2-trees, and a similar setup. Elements that are both subject and
object in any triple pattern are grouped in the ﬁrst rows/columns of the
matrices. We use a hybrid k2-tree representation, with k = 4 in the ﬁrst
5 levels of decomposition and k = 2 in the remaining levels. The dk2-tree
uses a sampling factor s = 128 in the leaf blocks, while static k2-trees use a
single-level rank implementation that samples every 20 integers (80 bytes).
In dk2-trees we use a block size B = 512 and e + 1 = 4 diﬀerent block sizes.
We test query times in all the approaches for all possible triple patterns 
(except (?S, ?P, ?O), that simply retrieves the complete dataset) and
some join queries involving just 2 triple patterns. We use the experimental 
testbed12 in [44] to directly compare our representation with k2-triples.
To test triple patterns, we use a query set including 500 random triple patterns 
for each dataset and pattern. To test join operations we use query sets
including 50 diﬀerent queries, randomly selected from a larger group of 500
random queries and divided in two groups: 25 have a number of results above
the average and 25 have a number of results below the average.

The experimental evaluation of join operations is expected to yield similar
comparison results to triple patterns, considering the fact that the implementation 
of the diﬀerent strategies to answer join queries is identical in dk2-trees
and static k2-trees. As a proof of concept of the applicability of dk2-trees
in more complex queries, we will experimentally evaluate dk2-trees, and k2triples 
to answer join operations (?V, P1, O1) ⊲⊳ (?V, P2, O2) (join 1 : only
the join variable is undetermined) and (?V, P1, O1) ⊲⊳ (?V, ?P2, O2) (join 2 :
one of the predicates is variable). Notice that each join type can lead to 3
diﬀerent join operations depending on whether the join variable is subject
or object in each of the triple patterns:
for example, join 1 can be of the

12The full testbed is available at http://dataweb.infor.uva.es/queries-k2triples.tgz

36

form (?V, P1, O1) ⊲⊳ (?V, P2, O2) (S-S), (S1, P1, ?V ) ⊲⊳ (?V, P2, O2) (S-O) and
(S1, P1, ?V ) ⊲⊳ (S2, P2, ?V ) (O-O).

6.2.2. Space results

We compare the space requirements of our dynamic representation, based
on dk2-trees, with k2-triples and its improvement, k2-triples+, in all the studied 
datasets. We select the k2-tree representations that obtain the best compression 
results: static k2-trees used in k2-triples and k2-triples+ use a matrix
vocabulary with k′ = 8; dk2-trees do not use a matrix vocabulary. Table 3
shows the total space requirements on the diﬀerent collections studied.

Collection
jamendo

dblp

geonames
dbpedia

k2-triples
0.74
82.48
152.20
931.44

k2-triples+
1.28
99.24
188.63
1,178.38

dk2-trees
1.61
125.34
242.60
1,151.90

Table 3: Space results for all RDF collections (sizes in MB).

Our dynamic representation is signiﬁcantly larger than the equivalent
static version, k2-triples, in all the datasets. In jamendo, a very small dataset,
the dynamic representation requires more than twice the space of k2-triples.
However, the overhead required by the dynamic version is smaller in larger
datasets and particularly in dbpedia. The dk2-tree with no matrix vocabulary
is also able to store the dataset with an overhead below 50% extra in the dblp
and geonames datasets. Even though the overhead is signiﬁcant, the results
are still relevant since k2-triples was proved to be several times smaller than
other RDF stores like MonetDB and RDF-3X in these datasets (at least 4
times smaller than MonetDB, the second-best approach in space, in all the
datasets except dbpedia [44]).

In the dbpedia dataset our proposal has a space overhead around 20% over
k2-triples, and becomes smaller than the k2-triples+ static representation.
This result is mostly due to the characteristics of the dbpedia dataset, that
contains many predicates with few triples. The static representations based
on k2-triples store a static k2-tree representation for each diﬀerent predicate,
each one containing its own matrix vocabulary. The utilization of a matrix
vocabulary does not improve compression in these matrices. However, most
of the cost of the representation is in the matrices with many triples, so the
matrix vocabulary still obtains the best results overall.

37

6.2.3. Query times
Triple patterns. We ﬁrst measure the eﬃciency of our dynamic proposal in
comparison with k2-triples to answer simple queries (triple patterns) in all
the studied datasets. The results for all the datasets are shown in diﬀerent
tables: Table 4 shows the results for jamendo; Table 5, the results for dblp;
Table 6, for geonames and Table 7, for dbpedia. For each dataset we show the
query times of k2-triples, k2-triples+ (only in queries with variable predicate)
and our equivalent dynamic representation of k2-triples. The last row of each
table shows the ratio between our dynamic representation and k2-triples, as
an estimation of the relative eﬃciency of dk2-trees.

k2-triples
k2-triples+
Dynamic
Ratio

1.0

4.6

102.8

6954.1

S, P, O S, P, ?O ?S, P, O ?S, P, ?O S, ?P, O S, ?P, ?O ?S, ?P, O
29.3
10.0
28.4
0.97

39.4
23.6
34.6
0.88

4.9
1.1
6.0
1.22

12788.5
1.84

235.6
2.29

1.9
1.88

4.8
1.06

Table 4: Query times for triple patterns in jamendo. Times in µs/query.

Solution
k2-triples
k2-triples+
Dynamic
Ratio

S, P, O S, P, ?O ?S, P, O
1016.4

79.8

1.2

6.5
5.54

92.9
1.16

2776.3
2.73

?S, P, ?O S, ?P, O S, ?P, ?O ?S, ?P, O
187.5
771061.6
140.8
247.9
1.32

1294.1
1102.1
1421.8
1.10

3.6
1.7
14.0
3.87

1450058.3
1.88

Table 5: Query times for triple patterns in dblp. Times in µs/query.

Solution
k2-triples
k2-triples+
Dynamic
Ratio

S, P, O S, P, ?O ?S, P, O
4588.0

59.4

1.2

9.4
7.71

79.6
1.34

9544.2
2.08

?S, P, ?O S, ?P, O S, ?P, ?O ?S, ?P, O
1603677.4
273.7
139.0
423.5
1.55

1192.9
915.9
1514.7
1.27

2958262.4
1.84

2.9
1.4
17.9
6.11

Table 6: Query times for triple patterns in geonames. Times in µs/query.

In most of the datasets and queries, query times of dk2-trees are between
1.2 and 2 times higher than in k2-triples. The results in Table 4 for the
dataset jamendo show some anomalies, with the dk2-tree performing faster
than a static representation. However, due to the reduced size of the dataset

38

Solution
k2-triples
k2-triples+
Dynamic
Ratio

1.1

441.4

S, P, O S, P, ?O ?S, P, O ?S, P, ?O S, ?P, O S, ?P, ?O ?S, ?P, O
29447.7
518.3
57051.8
1.94

54497.4
2216.7
83340.2
1.53

7960.3
1.4
23045.4
2.90

10.5

1859.5

19.1
1.82

3870.7
2.08

6.6
6.21

561.9
1.27

Table 7: Query times for triple patterns in dbpedia. Times in µs/query.

we shall disregard these results and focus on the larger datasets. The results
in Table 5, Table 6 and Table 7 show very diﬀerent query times but the ratios
shown in each table are very similar in all three datasets.

Our results evidence that dk2-trees are several times slower than static k2trees 
in triple patterns that are implemented with single-cell retrieval queries
(i.e. patterns (S, P, O) and (?S, P, ?O)). Particularly, dk2-trees are 5.5-7.7
times slower than static k2-trees to answer (S, P, O) queries. In this queries,
the cost of accessing Ttree and Ltree is very high since a single position is
accessed per level of the tree.

In all the remaining patterns, i.e. those that are translated into row/column

or full-range queries in one or many k2-trees, dk2-trees are much more competitive 
with static k2-trees, obtaining query times less than 2 times slower
than k2-triples in most cases. These diﬀerences are mostly due to the indexed
representation used in dk2-trees, that avoids complete traversals of Ttree or
Ltree when many close positions are accessed in each query. In all these patterns,
 multiple positions are accessed at each level of the dk2-tree, in many
cases these positions are actually in the same leaf node of Ttree or Ltree, so
the additional cost of traversing Ttree or Ltree is greatly diminished.

Let us focus now on the eﬀect of the additional indexes used in k2-triples+.
In the datasets with few predicates, that are the most usual RDF datasets,
k2-triples+ is around 1.5-3 times faster than k2-triples, hence up to 10 times
faster than dk2-trees in (S, ?P, O) queries and up to 3 times faster in the remaining 
patterns with variable predicate. In the dbpedia dataset, the relative
eﬃciency of k2-triples+ is much more signiﬁcant, reducing query times by several 
orders of magnitude. This makes dk2-trees much slower than k2-triples+
in this dataset to answer patterns with variable predicate.

Join operations. Next we test the eﬃciency of dk2-trees in comparison with
k2-triples to answer join queries. Considering the results obtained with single
triple patterns, and in order to better show the relative eﬃciency of our dynamic 
representation, we focus on the join operations that are more selective,

39

or require more selective operations in the matrices.

We start our experiments with join 1 ((?V, P1, O1) ⊲⊳ (?V, P2, O2)). We
test the 3 diﬀerent join strategies applied to this join: i) independent evaluation 
requires two row/column queries in diﬀerent k2-trees and an intersection
of the results; ii) in chain evaluation, we run a row/column query in the k2tree 
corresponding to P1 and for each result v obtained we run a single cell
retrieval in the k2-tree for P2; iii) the interactive evaluation runs two synchronized 
row/column queries in both k2-trees. We test all the join categories
S-O, S-S and O-O and query sets with few results (small) or more results
(big).

Figure 11 shows the results for join 1. Given the signiﬁcant diﬀerences in
query times between datasets, strategies and even query sets, we normalize
all the results so that the query times of static k2-trees are always at the same
level. The height of the bar for the static representation will always be 1,
and the bar for the dk2-tree representation shows the actual overhead of our
dynamic representation. The actual query times in the static representation
are also displayed, in ms/query.

Results show that dk2-trees are very competitive with k2-triples in most of
the datasets and strategies: independent evaluation (left plots of Figure 11)
yields the worst results for dk2-trees, that are 3-4 times slower than k2-triples
in most of the query sets, except on the larger dataset dbpedia where our
solution is on average less than 2 times slower than static k2-trees. In chain
evaluation dk2-trees are less than 2 times slower than a static representation
in most of the datasets and query sets. Finally, if we use the interactive
evaluation strategy dk2-trees are able to obtain query times very close to
static k2-trees in most of the cases.

Averaging the results in all the datasets and query sets for each evaluation
strategy, dk2-trees are 3.5 times slower than static k2-trees in the independent
evaluation strategy, 2.6 times slower using the chain evaluation strategy and
only 27% slower using the interactive evaluation strategy. Even though the
results vary signiﬁcantly between datasets and query sets, the overall results
show that dk2-trees are able to support the query operation with a reasonable
overhead in space and query times.

Join queries with variable predicate. Next we analyze our proposal in join
operations with variable predicates. We compare dk2-trees with static k2triples 
and k2-triples+ (static-DACs) to answer the join 2 ((?V, P1, O1) ⊲⊳
(?V, ?P2, O2)), that involves a variable predicate.

40

Independent evaluation

Chain evaluation

Interactive evaluation

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

static
dynamic

3
7
0

.

0

2
2
3

.

3

8
0
9

.

0

0
6
2

.

4

5
0
0

.

0

8
2
1

.

0

SO

SS OO SO

Small

SS OO
Big

    

static
dynamic

2
8
6

.

2

4
7
7

.

1
7

8
8
3

.

6
2

2
6
6

.

0
4
2

5
7
0

.

0

2
2
8

.

0

SO

SS OO SO

Small

SS OO
Big

    

static
dynamic

0
0
1

.

1

9
6
3

.

1
3

5
6
1

.

2
1

1
3
2

.

2
6

8
5
1

.

0

6
8
3

.

0

SO

SS OO SO

Small

SS OO
Big

    

static
dynamic

4
1
3

.

4

7
3
5

.

8
2
1

3
3
3

.

2

4
5
5

.

8
8

0
3
8

.

1

7
2
4

.

5

SO

SS OO SO

Small

SS OO
Big

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

static
dynamic

9
1
0

.

0

0
2
0

.

0

8
7
3

.

0

0
7
2
2
3

.

5
1
0

.

0

6
4
0

.

0

SO

SS OO SO

Small

SS OO
Big

jamendo

    

static
dynamic

8
1
0

.

0

1
2
0

.

0

9
7
6

.

1

8
6
9

.

5
3
8
2

SO

SS OO SO

Small

dblp
    

6
4
0

.

0

3
5
4

.

0

SS OO
Big

static
dynamic

3
6
1

.

0

1
0
4

.

0

4
5
2

.

5
3

4
0
4

.

9
6
7

5
8
0

.

0

4
0
2

.

0

SO

SS OO SO

Small

SS OO
Big

geonames

    

static
dynamic

9
6
0

.

1

7
7
1

.

0

6
1
0

.

0

3
4
9

.

0

7
6
8

.

0

6
7
1

.

1

SO

SS OO SO

Small

SS OO
Big

dbpedia

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

static
dynamic

8
0
0

.

0

2
1
0

.

0

9
1
1

.

0

0
1
8

.

6

1
2
0

.

0

0
7
0

.

0

SO

SS OO SO

Small

SS OO
Big

    

static
dynamic

2
2
0

.

0

1
5
0

.

0

1
0
5

.

0

2
7
7

.

2
9
2

3
5
0

.

0

8
0
5

.

0

SO

SS OO SO

Small

SS OO
Big

    

static
dynamic

2
1
0

.

0

7
6
0

.

1

9
9
1

.

0

1
0
5

.

2
6
1

1
3
1

.

0

3
0
3

.

0

SO

SS OO SO

Small

SS OO
Big

    

static
dynamic

5
3
8

.

0

7
0
3

.

0

0
2
0

.

0

0
1
3

.

0

1
1
1

.

1

6
0
6

.

1

SO

SS OO SO

Small

SS OO
Big

Figure 11: Comparison of static and dynamic query times in join 1 in all the studied
datasets and query types. Results are normalized by static query times. Query times of
the static representation are shown in ms/query.

The results are shown in Figure 12. Bar heights are also normalized by
the static query times in these graphs. Again, we obtain diverse results in
the comparison depending on the dataset, the evaluation strategy and the
query set. In spite of the varying results, dk2-trees show again an overhead in
query time limited by a small factor: our dynamic representation is between
1.5 and 3 times slower than k2-triples.

If we compare dk2-trees with the best static representation, that is now

41

Independent evaluation

Chain evaluation

Interactive evaluation

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

static-DACs
static
dynamic

1
6

.

9

SO

3
2

.

2
3
1

8
0

.

0

7
1

.

0

4
0

.

0

6
0

.

0

SS OO SO

Small

SS OO
Big

Independent evaluation

static-DACs
static
dynamic

5
0

.

0

3
3

.

0

7
9

.

6
1

0
9

.

6
3

2
0

.

0

2
0

.

0

SO

SS OO SO

Small

SS OO
Big

Independent evaluation

static-DACs
static
dynamic

5
1

.

6
8
1

SO

1
3

.

5
9
5
6
1

1
9

.

0

0
4

.

4
3
1

5
0

.

0

3
1

.

0

SS OO SO

Small

SS OO
Big

Independent evaluation

static-DACs
static
dynamic

1
0

.

0

0
1

.

0

3
2

.

1

1
5

.

8
8
1
2

0
0

.

9
4

8
6

.

4
9
2

SO

SS OO SO

Small

SS OO
Big

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

static-DACs
static
dynamic

6
3
2
6

.

SO

7
9
3
8

.

6
1

.

0

6
3

.

0

6
0

.

0

8
0

.

0

SS OO
Big

Small

SS OO SO
jamendo
Chain evaluation

static-DACs
static
dynamic

1
0

.

0

6
7

.

0

0
8

.

4
5

4
1

.

3
2

3
0

.

0

5
0

.

0

SO

3
5

.

2

SO

SS OO SO

Small

dblp

SS OO
Big

Chain evaluation

static-DACs
static
dynamic

1
9

.

2
5
2

4
4

.

0

2
4

.

5

2
1

.

0

5
3

.

0

SS OO
Big

Small

SS OO SO
geonames
Chain evaluation

static-DACs
static
dynamic

6
0

.

0

0
1

.

0

5
9

.

3

7
4

.

7
6

3
1

.

0
2

2
7

.

0
4

SO

SS OO SO

Small

dbpedia

SS OO
Big

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

 7
 6
 5
 4
 3
 2
 1
 0

static-DACs
static
dynamic

8
1
8
7

.

SO

4
4

.

2

SO

5
4

.

5
4

SO

2
7

.

8
0
1

7
2

.

1

4
6

.

1

6
1

.

0

0
5

.

0

SS OO SO

Small

SS OO
Big

Interactive evaluation

static-DACs
static
dynamic

7
5

.

3
3

5
2

.

4
3

7
6

.

6
6
1

3
7

.

2
1

5
8

.

1
7
1

SS OO SO

Small

SS OO
Big

Interactive evaluation

static-DACs
static
dynamic

4
5

.

8
4
2

0
6

.

0

1
8

.

3

6
1

.

1

2
4

.

2

SS OO SO

Small

SS OO
Big

Interactive evaluation

static-DACs
static
dynamic

4
7

.

0

6
0

.

3

3
2

.

1
1

3
2

.

8
5

9
5

.

5
3

5
3

.

0
0
1

SO

SS OO SO

Small

SS OO
Big

Figure 12: Comparison of static and dynamic query times in join 2 in all the studied
datasets and query types. Results are normalized by query times of k2-triples. Query
times of the static representation are shown in ms/query.

k2-triples+, the overhead required by the dynamic representation becomes
larger. Notice that in Figure 12 there are some query sets for which the
query times of k2-triples+ (static-DACs) are so much lower than k2-triples
that the result for k2-triples+ is not even visible in the plot. This is consistent
with the results obtained in triple patterns, where the use of S-P and O-P
indexes in k2-triples+ resulted in a major improvement. However, in many
cases the improvement obtained by k2-triples+ is not so signiﬁcant and dk242


trees are still reasonably close in query times.

7. Conclusions

The compact representation of static binary relations can be useful in
many contexts, but in many application areas relations may be subject to
frequent changes. We have introduced the dk2-tree, a representation of binary
relations with support for update operations. The dk2-tree is an evolution
of the k2-tree, an inherently static data structure that obtained great compression 
and query times in diﬀerent types of binary relations. Our dynamic
representation is able to obtain good compression and query times, relatively
close to those of static k2-trees, and provides at the same time support for the
most usual update operations: insertion and deletion of pairs in the binary
relation, and also changes in the base sets A and B of the relation.

Our experimental evaluation shows that the dk2-tree, even though it has a
signiﬁcant overhead compared with the static representation, is able to obtain
results close enough to those of the static representation to be competitive in
areas where the original static representation was already eﬃcient. In particular,
 we demonstrate that our representation obtains compression results
close to a static data structure in Web graphs, and we study the overhead
required in the representation of RDF graphs. Our representation performs
in general at the same order of magnitude than static k2-trees in this domain,
where state-of-the-art alternatives are orders of magnitude larger or slower.
Additionally, in many operations and datasets the overhead required by our
representation becomes small enough (around 20% space or time overhead
in diﬀerent cases) to be a good representation even in a context of dynamic
binary relations with low rate of changes.

References

[1] N. R. Brisaboa, G. de Bernardo, G. Navarro, Compressed dynamic binary 
relations, in: Proc. Data Compression Conference (DCC), 2012,
pp. 52–61.

[2] D. J. Abadi, A. Marcus, S. R. Madden, K. Hollenbach, Scalable Semantic 
Web data management using vertical partitioning, in: Proc. 33rd
International Conference on Very Large Data Bases (VLDB), 2007, pp.
411–422.

43

[3] J. Barbay, F. Claude, G. Navarro, Compact rich-functional binary relation 
representations, in: Proc. 9th Latin American Theoretical Informatics 
Symposium (LATIN), 2010, pp. 170–183.

[4] P. Boldi, S. Vigna, The WebGraph Framework I: Compression tech-
in: Proc. 12th International World Wide Web Conference

niques,
(WWW), ACM Press, 2003, pp. 595–601.

[5] N. R. Brisaboa, S. Ladra, G. Navarro, k2-Trees for compact Web graph
representation, in: Proc. 16th International Symposium on String Processing 
and Information Retrieval (SPIRE), 2009, pp. 18–30.

[6] F. Claude, S. Ladra, Practical representations for web and social graphs,
in: Proc. 20th ACM Conference on Information and Knowledge Management 
(CIKM), 2011, pp. 1185–1190.

[7] S. ´Alvarez-Garc´ıa, N. R. Brisaboa, J. D. Fern´andez, M. A. Mart´ınezPrieto,
 Compressed k2-Triples for full-in-memory RDF engines,
in:
Proc. 17th Americas Conference on Information Systems (AMCIS),
2011.

[8] G. Navarro, Compact Data Structures – A practical approach, Cambridge 
University Press, 2016, iSBN 978-1-107-15238-0. 570 pages.

[9] T. K¨afer, A. Abdelrahman, J. Umbrich, P. O’Byrne, A. Hogan, Observing 
Linked Data Dynamics, in: Proc. 12th International Semantic Web
Conference (ISWC), 2013, pp. 213–227.

[10] G. Jacobson, Succinct static data structures, Ph.D. thesis, Carnegie

Mellon University, Pittsburgh, PA, USA (1989).

[11] G. Navarro, V. M¨akinen, Compressed full-text indexes, ACM Computing 
Surveys 39 (1) (2007) art. 2.

[12] D. Clark, Compact pat trees, Ph.D. thesis, University of Waterloo, Ontario,
 Canad´a (1996).

[13] J. I. Munro, Tables, in: Proc. 16th Conference of Foundations of Software 
Technology and Theoretical Computer Science (FSTTCS), 1996,
pp. 37–42.

44

[14] R. Pagh, Low redundancy in static dictionaries with o(1) worst case
lookup time, in: Proc. 26th International Colloquium on Automata,
Languages and Programming (ICALP), 1999, pp. 595–604.

[15] R. Raman, V. Raman, S. Rao, Succinct indexable dictionaries with applications 
to encoding k-ary trees and multisets, in: Proc. 13th ACMSIAM 
Symposium on Discrete Algorithms (SODA), 2002, pp. 233–242.

[16] D. Okanohara, K. Sadakane, Practical entropy-compressed rank/select
dictionary, in: Proc. 9th Workshop on Algorithm Engineering and Experiments 
(ALENEX), 2007.

[17] K. Sadakane, New text indexing functionalities of the compressed suﬃx

arrays, Journal of Algorithms 48 (2) (2003) 294–313.

[18] R. Grossi, A. Gupta, J. S. Vitter, When indexing equals compression:
experiments with compressing suﬃx arrays and applications, in: Proc.
15th ACM-SIAM Symposium on Discrete Algorithms (SODA), 2004,
pp. 636–645.

[19] D. K. Blandford, G. E. Blelloch, Compact representations of ordered
sets, in: Proc. 15th ACM-SIAM Symposium on Discrete Algorithms
(SODA), 2004, pp. 11–19.

[20] A. Gupta, W.-K. Hon, R. Shah, J. S. Vitter, Compressed data struc-
tures: Dictionaries and data-aware measures, in: Proc. 16th Data Compression 
Conference (DCC), 2006, pp. 213–222.

[21] V. M¨akinen, G. Navarro, Rank and select revisited and extended, Theoretical 
Computer Science 387 (3) (2007) 332–347.

[22] N. R. Brisaboa, E. L. Iglesias, G. Navarro, J. R. Param´a, An eﬃcient
compression code for text databases, in: Proc. 25th European Conference 
on IR Research (ECIR), 2003, pp. 468–481.

[23] N. R. Brisaboa, A. Fari˜na, G. Navarro, J. R. Param´a, Lightweight natural 
language text compression, Information Retrieval 10 (1) (2007) 1–33.

[24] E. Silva de Moura, G. Navarro, N. Ziviani, R. Baeza-Yates, Fast and
ﬂexible word searching on compressed text, ACM Transactions on Information 
Systems 18 (2) (2000) 113–139.

45

[25] D. Huﬀman, A method for the construction of minimum-redundancy
codes, Proceedings of the Institute of Radio Engineers 40 (9) (1952)
1098–1101.

[26] N. R. Brisaboa, A. Fari˜na, G. Navarro, J. R. Param´a, Eﬃciently decodable 
and searchable natural language adaptive compression, in: Proc.
28th ACM SIGIR Conference on Research and Development in Information 
Retrieval, 2005, pp. 234–241.

[27] H. Samet, The quadtree and related hierarchical data structures, ACM

Comput. Surv. 16 (2) (1984) 187–260.

[28] N. R. Brisaboa, S. Ladra, G. Navarro, Compact representation of Web
graphs with extended functionality, Information Systems 39 (2014) 152
– 174.

[29] S. Ladra, Algorithms and compressed data structures for information

retrieval, Ph.D. thesis, University of A Coru˜na (2011).

[30] N. R. Brisaboa, A. Fari˜na, G. Navarro, J. Param´a, Lightweight natural

language text compression, Information Retrieval 10 (2007) 1–33.

[31] N. R. Brisaboa, S. Ladra, G. Navarro, Directly addressable variablelength 
codes, in: Proc. 16th International Symposium on String Processing 
and Information Retrieval (SPIRE), 2009, pp. 122–130.

[32] R. Raman, V. Raman, S. S. Rao, Succinct dynamic data structures, in:
Proc. 7th International Workshop on Algorithms and Data Structures
(WADS), 2001, pp. 426–437.

[33] N. R. Brisaboa, A. Fari˜na, G. Navarro, J. Param´a, Dynamic lightweight
text compression, ACM Transactions on Information Systems (TOIS)
28 (3) (2010) 10:1–10:32.

[34] P. Boldi, B. Codenotti, M. Santini, S. Vigna, UbiCrawler: A scalable
fully distributed web crawler, Software: Practice and Experience (SPE)
34 (8) (2004) 711–726.

[35] F. Manola, E. Miller, RDF Primer, W3C Recomm.,

2004,

www.w3.org/TR/rdf-primer/.

46

[36] S. Harris, A. Seaborne, SPARQL 1.1 Query Language, W3C Recomm.,

2013, http://www.w3.org/TR/sparql11-query/.

[37] D. J. Abadi, A. Marcus, S. R. Madden, K. Hollenbach, Sw-store: a
vertically partitioned DBMS for Semantic Web data management, The
International Journal on Very Large Data Bases 18 (2) (2009) 385–406.

[38] L. Sidirourgos, R. Goncalves, M. Kersten, N. Nes, S. Manegold, Columnstore 
support for RDF data management: not all swans are white, Proc.
VLDB Endowment 1 (2) (2008) 1553–1563.

[39] T. Neumann, G. Weikum, The RDF-3X engine for scalable management

of RDF data, The VLDB Journal 19 (1) (2010) 91–113.

[40] J. D. Fern´andez, M. A. Mart´ınez-Prieto, C. Guti´errez, A. Polleres,
M. Arias, Binary RDF representation for publication and exchange
(HDT), Web Semantics: Science, Services and Agents on the World
Wide Web 19 (2013) 22 – 41.

[41] J. Urbani, J. Maassen, N. Drost, F. Seinstra, H. Bal, Scalable RDF data
compression with MapReduce, Concurrency and Computation: Practice
and Experience 25 (1).

[42] J. Urbani, S. Dutta, S. Gurajada, G. Weikum, KOGNAC: eﬃlarge 
knowledge graphs, CoRR abs/1604.04795,

cient encoding of
http://arxiv.org/abs/1604.04795.

[43] T. Neumann, G. Weikum, x-rdf-3x: Fast querying, high update rates,
and consistency for rdf databases, Proc. VLDB Endowment 3 (1-2)
(2010) 256–263.

[44] S. ´Alvarez-Garc´ıa, N. R. Brisaboa, J. D. Fern´andez, M. A. Mart´ınezPrieto,
 G. Navarro, Compressed vertical partitioning for eﬃcient RDF
management, Knowledge and Information Systems 44 (2) (2015) 439–
474.

[45] M. A. Mart´ınez-Prieto, J. D. Fern´andez, R. C´anovas, Compression of
RDF dictionaries, in: Proc. 27th Annual ACM Symposium on Applied
Computing (SAC), 2012, pp. 340–347.

47

