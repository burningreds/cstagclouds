Faster Top-k Document Retrieval

in Optimal Space(cid:4)

Gonzalo Navarro1 and Sharma V. Thankachan2

1 Department of Computer Science, University of Chile, Chile

2 Department of Computer Science, Louisiana State University, USA

gnavarro@dcc.uchile.cl

thanks@csc.lsu.edu

Abstract. We consider the problem of retrieving the k documents from
a collection of strings where a given pattern P appears most often. We
show that, by representing the collection using a Compressed Suﬃx Array
CSA, a data structure using the asymptotically optimal |CSA| + o(n) bits
can answer queries in the time needed by CSA to ﬁnd the suﬃx array
interval of the pattern plus O(k lg2 k lg n) accesses to suﬃx array cells,
for any constant  > 0. This is lg n/ lg k times faster than the only
previous solution using optimal space, lg k times slower than the fastest
structure that uses twice the space, and lg2 k lg n times the lower-bound
cost of obtaining k document identiﬁers from the CSA. To obtain the
result we introduce a tool called the sampled document array, which can
be of independent interest.

1

Introduction

The problem of top-k document retrieval is that of preprocessing a text collection
so that, given a search pattern P [1, m] and a threshold k, we retrieve the k
documents most “relevant” to P , for some deﬁnition of relevance. This is the
basic problem of search engines and forms the core of the Information Retrieval
(IR) ﬁeld [5].

The inverted index has been highly successful to solve those top-k queries in
many IR scenarios. However, inverted indexes are bound to text collections that
can be easily segmented into “words”, so that only whole words can be queried,
and the distinct words form a reasonably small set. Inverted indexes store, for
each word, the list of the documents where it appears, with the associated relevance.
 Such a structure is not easily applicable in highly synthetic languages like
Finnish or German, where long words are built from particles, and even less in
languages where word separators are absent and can only be inferred from the
meaning, like Chinese, Korean, etc. Out of resorting to complex segmentation
heuristics, a simple solution for those cases is to treat the text as an uninterpreted 
sequence of symbols and look for any substring in those sequences. The
model of a collection of documents (strings) where one can ﬁnd those where a

The original version of this chapter was 
corrected. The Erratum to this chapter is available at DOI:
(cid:2) Funded in part by Fondecyt Grant 1-110066.
O. Kurland, M. Lewenstein, and E. Porat (Eds.): SPIRE 2013, LNCS 8214, pp. 255–262, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

10.1007/978-3-319-02432-5 33

 The copyright line was incorrect. This has been

re iv eds

:

256

G. Navarro and S.V. Thankachan

pattern string is relevant is also appealing in other applications like bioinformatics,
 chemoinformatics, software repositories, multimedia databases, and so
on. Supporting document retrieval queries on those general string collections has
proved much more challenging.

Suﬁx trees [24] and suﬃx arrays [13] are useful tools to search string collections.
 However, these structures solve the pattern matching problem: they can
count or list all the occ individual occurrences of P in the collection. Obtaining
the k most relevant documents from that set requires time proportional to occ,
usually much much larger than k. Only relatively recently [12,8,11,18,22] was
this problem solved satisfactorily, ﬁnally reaching the optimal time O(m + k).
Those solutions, like suﬃx trees, have the drawback of requiring O(n lg n) bits of
space on a collection of length n, whereas the collection itself would require no
more than n lg σ bits, if σ is the alphabet size. In practice these indexes require
many times the text size, which renders them impractical on moderate and large
text collections.

For the pattern matching problem, the space issue began to be solved in year
2000. Recent Compressed Suﬃx Arrays (CSAs) eﬃciently answer queries within
space asymptotically equal not only to n lg σ bits, but to the size of the compressed 
text collection [17]. Moreover, those CSAs can retrieve any substring of
any document and hence replace the collection: they can be regarded as compressors 
that support queries. We call their space |CSA|, which can be tought of
as the minimum space in which the text collection can be represented.

A similar result for top-k document retrieval has been more elusive. In their
seminal paper, Hon et al. [11] showed that, if the relevance is taken as the number
of times P appears in the document (a popular choice in IR), the collection
can be represented in 2|CSA| + o(n) bits so that queries are solved in time
O(m lg lg σ + k lg4+ n), for any constant  > 0 (this complexity assumes that
the CSA searches for P in time O(m lg lg σ) and computes a cell of the suﬃx
array or its inverse in time O(lg1+ n); there exists such a CSA achieving highorder 
entropy compression of the text [1]). After several time improvements that
still used 2|CSA| + o(n) bits [6,3], Hon et al. [10] achieved the best time to
date, O(m lg lg σ + k lg k lg1+ n). Finally, Tsur [23] reduced the space to the
asymptotically optimal |CSA| + o(n) bits, yet with higher time, O(m lg lg σ +
k lg k lg2+ n).
In this paper we (almost) obtain the best from both solutions. We maintain
the space in the optimal |CSA| + o(n) bits, and obtain search time O(m lg lg σ +
k lg2 k lg1+ n), almost lg n times faster than the current space-optimal solution
and only a lg k factor away from the fastest one (that uses twice the space). To
obtain the result, we introduce a data structure called the sampled document
array, which may have independent interest.

2 Compressed Top-k Retrieval Indexes
Consider a collection of D strings {T1, T2, . . . , TD} over alphabet [1, σ], called
documents, concatenated into a text T [1, n] = T1$T2$ . . . TD$, where $ = 0 is a

Faster Top-k Document Retrieval in Optimal Space

257

special symbol. Consider the suﬃx tree [24] of T , the suﬃx array [13] A[1, n] of
T , and a Compressed Suﬃx Array [17] CSA that is able to (1) given a pattern
P [1, m], ﬁnd the area A[sp, ep] of suﬃxes starting with P in time tsearch(m),
and (2) given a position i, compute A[i] in time tSA. For example, there is a
CSA with tsearch(m) = O(m lg lg σ) and tSA = O(lg1+ n) for any constant  > 0
and using |CSA| = nHh(T )(1 + o(1)) + o(n) bits of space [1], and another with
tsearch(m) = O(m) and tSA = O(lg n) using |CSA| = nHh(T )(1+o(1))+O(n) bits
of space, where Hh(T ) ≤ lg σ is the per-symbol h-th order empirical entropy of

T [14] (this is a lower bound on compressibility using any reasonable statistical
model). In this paper we focus on the top-k (most frequent documents) retrieval
problem: given a pattern P [1, m], return the k documents where P appears most
often. As explained, this is a reasonable relevance measure, especially when just
one pattern is involved.

Each suﬃx tree leaf (or suﬃx array cell) can be associated to the document
Td where the corresponding suﬃx starts. We call tf(v, d) the number of leaves
associated to document d that descend from suﬃx tree node v (i.e., the number
of times the string label of v appears in document d). Then the top-k retrieval
problem can be solved by ﬁrst ﬁnding the locus v of pattern P , and then retrieving 
the k documents d with highest tf(v, d) values. Note that the problem could
be solved by attaching the answer to any suﬃx tree node, but the space would
be O(kn lg n) bits, and work only up to the chosen k value. Now we describe the
solutions we build on to obtain our result.

Hon, Shah and Vitter’s Solution. Hon et al.’s [11] structure is built (in
principle) for a ﬁxed k value. We choose a grouping factor b = k lg2+ n and
mark every bth leaf in the suﬃx tree (we use a slightly simpliﬁed description of
their method [19]). Then we mark the lowest common ancestor (LCA) of every
consecutive pair of marked leaves. The tree of marked nodes is called τk and
has O(n/b) nodes. For every marked suﬃx tree node v, we store the k pairs
(d, tf(v, d)) with highest tf(v, d). Hon et al. prove that any locus node v contains
one maximal marked node u so that there are at most 2b leaves covered by v but
not by u (we will denote v \ u that leaf set). Therefore they traverse those leaves
using the CSA, and for each one they (1) compute the corresponding document
d, (2) compute the frequency tf(v, d), (3) add d to the top-k list (or correct its
frequency from tf(u, d) to tf(v, d) if d was already stored in the precomputed
top-k list of u).

To carry out (1) on the ith suﬃx tree leaf, they ﬁrst compute A[i] in O(tSA)
time, and then convert it into a document number by storing a bitmap B[1, n]
that marks with a 1 the document beginnings in T [20]. So the document is
d = rank(B, A[i]), where rank(B, j) counts the number of 1s in B[1, j]. Since B
has D 1s, it can be represented using D lg(n/D) + O(D) + o(n) bits, which is
o(n) if D = o(n), and answer rank queries in constant time [21]. To carry out
(2) they need additional |CSA| bits (see Sadakane [20]), and time O(tSA lg n).
The node u ∈ τk is found using the CSA plus a constant-time LCA on τk

for the leftmost and rightmost marked leaves in [sp, ep], whereas the leaves
covered by v are simply [sp, ep]. Thus the total query time is O(tsearch(m) +

258

G. Navarro and S.V. Thankachan

b tSA lg n) = O(tsearch(m) + k tSA lg3+ n). On the two CSAs we have mentioned,
this is O(tsearch(m) + k lg4+ n).

As

the space for τk

storing the top-k list needs O(k lg n) bits,

is
O((n/b)k lg n) = O(n/ lg1+ n) bits. One τk tree is stored for each k power of 2,
so that at query time we increase k to the next power of 2 and solve the query
within the same time complexity. Summed over all the powers of 2, the space
becomes O(n/ lg n) = o(n) bits. Therefore the total space is 2|CSA| + o(n) bits.
Several subsequent improvements [6,3,10] reduced the time to O(tsearch(m) +
k tSA lg k lg n), yet still using 2|CSA| + o(n) bits of space, that is, twice the space
of an optimal (under the hth order empirical entropy model) representation of the
collection. Only this year [23] the space was reduced to the optimal |CSA| + o(n)
bits, yet the time raises to O(tsearch(m) + k tSA lg k lg1+ n).

√
(cid:3) \ u, only O(

Tsur’s Optimal-Space Index. Building on ideas of Belazzougui et al. [3], Tsur
[23] managed to reduce the space to the asymptotically optimal |CSA|+o(n) bits.
(cid:3) ∈ τk be the parent of u in τk, that is, its nearest marked ancestor in the
Let u
suﬃx tree. Tsur proved that, from the O(b) leaves of u
bk) have
(cid:3)
a chance to become part of the top-k list for a locus node v between u
and u.
Thus, they simply store those candidate documents, and their frequency in u,
associated to u. When one traverses the O(b) leaves in v \ u, one (1) computes
the document d as before, (2) if it is not stored as a candidate for u one can just
ignore it, (3) if it is in the list then one just increases its frequency by 1. At the
end one has enough information to answer the top-k query, without the need of
the second |CSA| bits to compute frequencies below v.
√
If b = k(cid:4), the number of candidates is t = O(

(cid:4)). One can
encode them eﬃciently by storing, for each candidate d, the position of one leaf
(cid:3) \ u. Those leaf positions are sorted
corresponding to d in the area covered by u
and stored diﬀerentially: Let 0 < p1 < p2 < . . . < pt < 2b be the ordered
positions, then one encodes x1, x2, . . . , xt, where xi = pi − pi−1 (p0 = 0) using,

bk) = O(k

√

√

(cid:4)

√
(cid:4) lg (cid:4)) bits by the
(cid:4) lg (cid:4)) bits (the

2 lg xi = O(t lg(b/t)) = O(k

Therefore, the space for top-k answers plus candidates is O(k lg n + k

say, γ-codes [4], which occupy
log-sum inequality. The frequencies are encoded in O(k lg n + k
method is not relevant here).

√
√
(cid:4) lg (cid:4))
√
bits, and the total space for a ﬁxed k equals O((n/b)(k lg n + k
(cid:4) lg (cid:4))) =
(cid:4))) bits. By choosing (cid:4) = lg k lg1+ n, and since lg k ≤ lg n,
O(n((lg n)/(cid:4)+(lg (cid:4))/
this is O(n/(lg k lg/2 n)). Added over all the k values that are powers of 2, this
is O(n/ lg/2 n)

i=1 1/i = O(n lg lg D/ lg/2 n) = o(n) bits.

The total time is O(tsearch(m) + b tSA) = O(tsearch(m) + k tSA lg k lg1+ n). For

(cid:4)

lg D

the two CSAs we have described, this is O(tsearch(m) + k lg k lg2+ n).

Hon, Shah, Thankachan and Vitter’s Fastest Index. Hon et al. [10]
obtained the fastest solution to date using 2|CSA| + o(n) bits of space. For this
sake they consider two independent blocking values, c < b. For block value b
they build the τk trees as before. For block value c they build another set of
marked trees ρk. These trees are ﬁner-grained than the τk trees. Now, given the
locus node v, there exists a maximal node w ∈ ρk contained in v, and a maximal

Faster Top-k Document Retrieval in Optimal Space

259

node u ∈ τk contained in w. The key idea is to build a list of top-k to top-2k

candidates by joining the precomputed results of w and u, and then correct this
result by traversing O(c) suﬃx tree leaves.

Since we have a maximal node u ∈ τk contained in any node w ∈ ρk, we
can encode the top-k list of w only for the documents that are not already in
the top-k list of u. Note that a document must appear at least once in w \ u
if it is in the top-k list of w but not in that of u. Thus the additional top-k
candidates of w can be encoded using O(k lg(b/k)) bits, by storing as before one
of their positions in w \ u, and encoding the sorted positions diﬀerentially. The
frequencies do not need to be encoded, since they can be recomputed as for any
other candidate.

The space for a τk tree is O((n/b)k lg n) = O(n/ lg1+ n) bits using b =
k lg2+ n, which added over all the powers of 2 for k gives O(n/ lg n) = o(n)
bits, as before. For the ρk trees they require O((n/c)k lg(b/k)) bits, which using
c = k lg k lg n gives O(n lg lg n/(lg k lg n)) bits. Added over the powers of 2 for
k this gives O(n lg lg n/ lg n)
i=1 1/i = O(n lg lg n lg lg D/ lg n) = o(n) bits.
The time is dominated by that of traversing O(c) cells. Using some speedups
[3] over the basic technique [11], the time is O(tSA lg lg n) per cell, for a total
of O(tsearch(m) + k tSA lg k lg n) for any constant  > 0. Over the two CSAs we
have described, this is O(tsearch(m) + k lg k lg1+ n).

(cid:4)

lg D

3 A Faster Space-Optimal Representation

We build upon the schemes of Tsur [23] and Hon et al. [10]. We will use the
dual marking mechanism of Hon et al., with trees τk and ρk, and make it work
without using the second |CSA| bits. Without this data, the structure gives us
the top-k list of the maximal node w ∈ ρk that is below the locus v, but not

√

their frequencies. Similarly, when we traverse the O(c) extra cells to correct the
top-k list, we have no way to compute the frequency of the documents d found
in v \ w.

√
In order to cope with the second problem, we will use the idea of Tsur: there
ck) candidates that can make it to the top-k list. If c = k(cid:4),
can be only O(
this is O(k
(cid:4)). Thus we can record their identities by means of their sorted and
(cid:4) lg lg n)
diﬀerentially encoded positions along O(c) leaves, in total space O(k
bits. Now we need a mechanism to store the frequencies, both of the top-k
(cid:4)) candidates. For this sake we introduce a new data
elements and of the O(k
structure.

√

√

3.1 The Sampled Document Array

The document array E[1, n] of T contains at E[i] the document to which A[i]
belongs [15]. It is a convenient structure but it requires n lg D bits of space. We
store just a sampled version of it.

Deﬁnition 1. The sampled document array is an array E
] that stores
every sth occurrence of each document d in E, for a sampling step s. That is, if

[1, n

(cid:3)

(cid:3)

260

G. Navarro and S.V. Thankachan

rankd(E, i) is the number of times d occurs in E[1, i], the cell E[i] is stored in
E

iﬀ rankE[i](E, i) is a multiple of s. Note that n

(cid:3) ≤ n/s.

(cid:3)

(cid:3)

To E

(cid:3)

we associate a bitmap S[1, n] that marks the positions in E that are

sampled in E

. The following lemma follows easily.

(cid:3)

Lemma 1. Let x be the number of occurrences of a document d in E[sp, ep],
[rank(S, sp− 1) + 1, rank(S, ep)].
and let y be the number of occurrences of d in E
Then (y − 1)s < x < (y + 1)s.
Proof. The area E[sp, ep] includes y sampled occurrences of d. For the last y− 1,
their s − 1 preceding non-sampled occurrences are also in E[sp, ep]. The s − 1
occurrences preceding the ﬁrst sampled one could be before sp, and thus x ≥
(y− 1)s + 1. Alternatively, all the ys occurrences corresponding to the y sampled
ones could be in the range, which could also include up to s − 1 non-sampled
occurrences to their right, yet their sampled successor could be after ep, thus
x ≤ ys + (s − 1).
(cid:13)(cid:14)

(cid:3)

(cid:3)

lg D) and computes rankd(E

To use this lemma we store E
(cid:3)

o(n
in compressed form [21] so that it requires n
supports rank(S, i) in constant time. We use s = lg2 n, thus n
and the space for both E
compute y in Lemma 1 as rankd(E
time O(lg lg D).

using a representation [7] that requires n
lg D+
(cid:3)
, i) in time O(lg lg D). Further, we represent S
) + o(n) bits and
= O(n/ lg2 n)
and S is o(n). Using this representation, we can
, rank(S, sp − 1)) in

, rank(S, ep)) − rankd(E

) + O(n

lg(n/n

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

3.2 Completing the Index

ck) frequencies, which dominate the total space of O(k

To retrieve any tf(w, d) for a top-k document in node w ∈ ρk, we use S and
(cid:3)

to compute the approximation ys in time O(lg lg D), and then need to store
E
only O(lg s) = O(lg lg n) bits in w to correct this approximate count. Each

top-k documents that appear in the top-k list of its maximal descendant node

node w ∈ ρk stores (the correction of) the frequency information of both its
u ∈ τk, and those that do not (in fact, we do not need frequency information
√
associated to τk nodes). Similarly, we need to compute tf(w, d) for any of the
√
O(
ck) candidates to top-k in w, thus we must also store (the correction of)
those O(
(cid:4) lg lg n) bits.
With this information we can discard the second |CSA| bits of Hon et al. [10].
√
√
(cid:4) lg lg n) =
(cid:4)) = O(n lg lg n/(lg k lg/2 n)) bits. Adding over all the powers of
i=1 1/i = O(n lg lg n lg lg D/ lg/2 n) = o(n)

O(n lg lg n/
2 for k yields O(n lg lg n/ lg/2 n)
bits. Thus the total space is |CSA| + o(n) bits.

We use (cid:4) = lg2 k lg n. The space for one ρk tree is O((n/c)k

√
At query time we store the top-k documents of w, plus the O(

ck) candidates,
together with their frequencies in w, in a dictionary using the document identiﬁers 
as keys. Then we traverse the O(c) cells of v\w, accessing the CSA to deter-
√
mine each document identiﬁer d. If d is not in the dictionary, it can be discarded,
ck) elements
otherwise we increment its frequency. At the end, we scan the O(

(cid:4)

√

lg D

Faster Top-k Document Retrieval in Optimal Space

261

of the dictionary and keep the k largest ones. The cost is dominated by computing 
the O(c) CSA cells, plus O(lg lg D) time per cell to compute rankd(E
, i) and
O(1) to operate the dictionary1. This adds up to O(k(tSA + lg lg D) lg2 k lg n),
and the latter term absorbs the lg lg D.

(cid:3)

Theorem 1. The top-k most frequent documents problem, on a collection of
length n, for a pattern of length m, can be solved using |CSA| + D lg(n/D) +
O(D) + o(n) bits and in O(tsearch(m) + k tSA lg2 k lg n) time, for any constant
 > 0. Here CSA is a compressed suﬃx array over the collection, tsearch(m) is
the time CSA takes to ﬁnd the suﬃx array interval of the pattern, and tSA is the
time it takes to retrieve any suﬃx array cell.

We also give two simpliﬁcations using recent CSAs [1,2] whose size is related to

Hh, the per-symbol empirical entropy of the text collection, for any h ≤ α lgσ n

and any constant 0 < α < 1. For the second, since it uses O(n) extra bits, we
set a smaller c = k(lg k lg lg n lg lg D)2.

Corollary 1. The top-k most frequent documents problem, when D = o(n), can
be solved using nHh(1 + o(1)) + o(n) bits and in O(m lg lg σ + k lg2 k lg1+ n)
time, for any constant  > 0.

Corollary 2. The top-k most frequent documents problem can be solved using
nHh(1 + o(1)) + O(n) bits and in O(m + k lg n(lg k lg lg n lg lg D)2) time.

4 Final Remarks

Reaching asymptotic space optimality (under the hth order empirical entropy
model) for top-k document retrieval indexes is a very recent achievement. In this
work we have improved the time of that space-optimal solution [23]. Our time
complexity is a lg2 k lg n factor away from the minimum time required to obtain
k document identiﬁers using the CSAs, and a lg k factor away from the fastest
available solution that uses 2|CSA| + o(n) bits [10].

It is natural to ask if those limits can be reached. Especially if the ﬁrst limit
is matched, this problem could be ﬁnally considered closed in the scenario of
using optimal space based on CSAs. We believe, however, that a lg k factor in
the time is the unavoidable price of allowing k to be speciﬁed at query time,
whereas reaching the time of the currently fastest solution [10] seems feasible.

The other natural question is how much space is necessary to obtain the
optimal O(m + k) time. The best current space used to achieve this time is
O(n(lg D + lg σ)) [18]. While it seems that n lg D bits are unavoidable in this
case, there have been some eﬀorts to use only |CSA| + n lg D + o(n lg D) bits [9].
However the time achieved is not yet the optimal.

√

1 For example, we can bucket the universe [1, D] in chunks of lg2 D elements, and store
lg D and height O(1) for the elements falling in each chunk. The
a B-tree of arity
bucket structure adds up to o(D) bits, which can be taken as part of the index. The
B-trees are operated in constant time because they store only O(lgδ D lg lg D) bits
ck lg n) = O(k lg k lg1+/2 n) bits, which
per internal node. They occupy overall O(
is the space we use to answer the query. See [16, App. E] for more details.

√

262

G. Navarro and S.V. Thankachan

References

1. Barbay, J., Gagie, T., Navarro, G., Nekrich, Y.: Alphabet partitioning for compressed

rank/select and applications. In: Proc. 21st ISAAC, Part II, pp. 315–326 (2010)

2. Belazzougui, D., Navarro, G.: Alphabet-independent compressed text indexing. In:

Proc. 19th ESA, pp. 748–759 (2011)

3. Belazzougui, D., Navarro, G., Valenzuela, D.: Improved compressed indexes for

full-text document retrieval. J. Discr. Alg. 18, 3–13 (2013)

4. Bell, T., Cleary, J., Witten, I.: Text compression. Prentice-Hall (1990)
5. B¨uttcher, S., Clarke, C., Cormack, G.: Information Retrieval: Implementing and

Evaluating Search Engines. MIT Press (2010)

6. Gagie, T., K¨arkk¨ainen, J., Navarro, G., Puglisi, S.J.: Colored range queries and

document retrieval. Theo. Comp. Sci. 483, 36–50 (2013)

7. Golynski, A., Munro, I., Rao, S.: Rank/select operations on large alphabets: a tool

for text indexing. In: Proc. 17th SODA, pp. 368–373 (2006)

8. Hon, W.-K., Patil, M., Shah, R., Bin Wu, S.: Eﬃcient index for retrieving top-k

most frequent documents. J. Discr. Alg. 8(4), 402–417 (2010)

9. Hon, W.-K., Shah, R., Thankachan, S.V.: Towards an optimal space-and-querytime 
index for top-k document retrieval. In: K¨arkk¨ainen, J., Stoye, J. (eds.) CPM
2012. LNCS, vol. 7354, pp. 173–184. Springer, Heidelberg (2012)

10. Hon, W.-K., Shah, R., Thankachan, S., Vitter, J.: Faster compressed top-k document 
retrieval. In: Proc. 23rd DCC, pp. 341–350 (2013)

11. Hon, W.-K., Shah, R., Vitter, J.: Space-eﬃcient framework for top-k string retrieval

problems. In: Proc. 50th FOCS, pp. 713–722 (2009)

12. Hon, W.-K., Shah, R., Wu, S.-B.: Eﬃcient index for retrieving top-k most frequent

documents. In: Proc. 16th SPIRE, pp. 182–193 (2009)

13. Manber, U., Myers, G.: Suﬃx arrays: a new method for on-line string searches.

SIAM J. Comp. 22(5), 935–948 (1993)

14. Manzini, G.: An analysis of the Burrows-Wheeler transform. J. ACM 48(3),

407–430 (2001)

15. Muthukrishnan, S.: Eﬃcient algorithms for document retrieval problems. In: Proc

13th SODA, pp. 657–666 (2002)

16. Navarro, G.: Spaces, trees and colors: The algorithmic landscape of document retrieval 
on sequences. CoRR, arXiv:1304.6023v5 (2013)

17. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Comp. Surv. 39(1),

art 2 (2007)

18. Navarro, G., Nekrich, Y.: Top-k document retrieval in optimal time and linear

space. In: Proc. 23rd SODA, pp. 1066–1078 (2012)

19. Navarro, G., Valenzuela, D.: Space-eﬃcient top-k document retrieval. In: Klasing,

R. (ed.) SEA 2012. LNCS, vol. 7276, pp. 307–319. Springer, Heidelberg (2012)

20. Sadakane, K.: Succinct data structures for ﬂexible text retrieval systems. J. Discr.

Alg. 5, 12–22 (2007)

21. Raman, R., Raman, V., Srinivasa Rao, S.: Succinct indexable dictionaries with applications 
to encoding k-ary trees, preﬁx sums and multisets. ACM Trans. Alg. 3(4),
art 43 (2007)

22. Shah, R., Sheng, C., Thankachan, S.V., Vitter, J.S.: Top-k document retrieval in
external memory. In: Bodlaender, H.L., Italiano, G.F. (eds.) ESA 2013. LNCS,
vol. 8125, pp. 803–814. Springer, Heidelberg (2013)

23. Tsur, D.: Top-k document retrieval in optimal space. Inf. Proc. Lett. 113(12),

440–443 (2013)

24. Weiner, P.: Linear pattern matching algorithm. In: Proc. 14th Annual IEEE Symposium 
on Switching and Automata Theory, pp. 1–11 (1973)

