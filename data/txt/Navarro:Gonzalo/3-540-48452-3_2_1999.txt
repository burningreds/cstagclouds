A General Practical Approach to Pattern

Matching over Ziv-Lempel Compressed Text

Gonzalo Navarro1 and Mathieu Ra(cid:14)not2

1 Dept. of Computer Science, University of Chile.

Blanco Encalada 2120, Santiago, Chile.

gnavarro@dcc.uchile.cl.

Partially supported by Fondecyt grant 1-990627.

2 Institut Gaspard Monge, Cit(cid:19)e Descartes,

Champs-sur-Marne, 77454 Marne-la-Vall(cid:19)ee Cedex 2, France.

raffinot@monge.univ-mlv.fr

Abstract. We address the problem of string matching on Ziv-Lempel
compressed text. The goal is to search a pattern in a text without uncompressing 
it. This is a highly relevant issue to keep compressed text
databases where e(cid:14)cient searching is still possible. We develop a general 
technique for string matching when the text comes as a sequence of
blocks. This abstracts the essential features of Ziv-Lempel compression.
We then apply the scheme to each particular type of compression. We
present the (cid:12)rst algorithm to (cid:12)nd all the matches of a pattern in a text
compressed using LZ77. When we apply our scheme to LZ78, we obtain
a much more e(cid:14)cient search algorithm, which is faster than uncompressing 
the text and then searching on it. Finally, we propose a new hybrid
compression scheme which is between LZ77 and LZ78, being in practice
as good to compress as LZ77 and as fast to search in as LZ78.

1 Introduction

String matching is one of the most pervasive problems in computer science, with
applications in virtually every area. It is also one of the oldest and richest area of
development. The string matching problem is: given a pattern P = p1:::pm and a
text T = t1:::tu, both sequences of symbols over a (cid:12)nite alphabet (cid:6) of size (cid:27), (cid:12)nd
all the occurrences of P in T . There are many algorithms to solve this problem,
from classical to very recent [19, 8, 4, 14, 27, 9, 25]. The complexity of this
problem is O(u) in the worst case and O(u log(m)=m) on average, where u = jTj
and m = jPj, and there exist variants of [8, 9] which achieve this complexity. In
practice, however, [27, 25] are the fastest algorithms in most cases.

Another old and rich area in computer science is text compression. Its aim is
to exploit the redundancies of the text to reduce its space usage. There are many
di(cid:11)erent compression schemes [5], among which the Ziv-Lempel family [31, 32]
is one of the best in practice because of their good compression ratios combined
with e(cid:14)cient compression and decompression times. Other compression schemes
are Hu(cid:11)man coding [15] and arithmetic coding [29], among others.

M. Crochemore, M. Paterson (Eds.): CPM’99, LNCS 1645, pp. 14{36, 1999.
c(cid:13) Springer-Verlag Berlin Heidelberg 1999

A General Practical Approach to Pattern Matching

15

Today’s textual databases are an excellent example of applications where
both problems are crucial: the texts should be kept compressed to save space
and I/O time, and they should be e(cid:14)ciently searched. Surprisingly, these two
combined requirements are not easy to achieve together, as the only solution
before the 90’s was to process queries by uncompressing the texts and then
searching into them.

The compressed matching problem was (cid:12)rst de(cid:12)ned by Amir and Benson [1]
as the task of performing string matching in a compressed text without decompressing 
it. Given a text T , a corresponding compressed string Z = z1 : : : zn, and
a pattern P , the compressed matching problem consists in (cid:12)nding all occurrences
of P in T , using only P and Z. A naive algorithm, which (cid:12)rst decompresses the
string Z and then performs standard string matching, takes time O(u + m).
An optimal algorithm takes worst-case time O(n + m), where n = jZj. In [2], a
new criterion, called extra space, for evaluating compressed matching algorithms,
was introduced. According to the extra space criterion, algorithms should use at
most O(n) extra space, optimally O(m) in addition to the n-length compressed
(cid:12)le.
We de(cid:12)ne now a variation where we are required to report all the matching
positions. That is, given P and Z, report all the jxj such that T = xP y. The
optimal algorithm for this problem takes O(m + n + R) time, where R is the
number of matches.

Two di(cid:11)erent approaches have emerged in the last years to combine compression 
and searching in textual databases. A (cid:12)rst one is strongly oriented to
natural language texts, which are assumed to be composed of words which follow 
some statistical rules. The basic idea is to compress the text using Hu(cid:11)man,
where the words instead of the characters are taken as the symbols [7, 22]. As
Hu(cid:11)man assigns a (cid:12)xed code to each symbol, searching a given string is a matter
of compressing it and searching it in the compressed text using a classical string
matching algorithm with minor modi(cid:12)cations [24, 23]. Despite its simplicity, this
approach is very e(cid:11)ective on natural language text, with better compression ratios 
than those of the Ziv-Lempel family, and search time which is between 2
and 8 times faster than the fastest algorithms for standard string matching over
the uncompressed text. They are also able to search for complex patterns (such
as regular expressions) and allow errors in the matches, provided that words are
p
matched against words. The average search time for a simple pattern is close to
u), which is the same space
O(m + n log(u=n)=(u=n)). The extra space is O(
necessary to decompress the text. A weakness of this scheme is that it does not
work well on small texts (say, less than 10 Mb), since in that case the vocabulary
is almost as big as the text itself. Also, it can be applied only to natural language
texts.

Another practical approach is an ad-hoc technique [20], which however is
not so fast, obtains compression ratios of near 70% (against 30% to 40% of
Ziv-Lempel algorithms), and relies on the ASCII encoding.

The second line of research considers Ziv-Lempel compression, which is based
on (cid:12)nding repetitions in the text and replacing them with references to similar

