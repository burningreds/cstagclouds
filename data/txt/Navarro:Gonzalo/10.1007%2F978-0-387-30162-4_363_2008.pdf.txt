818 S

Sequential Approximate String Matching

24. Leighton, T., Rao, S.: Multicommodity max-flow min-cut theorems 
and their use in designing approximation algorithms.
J. ACM 46(6), 787–832 (1999)

25. Leong, T., Shor, P., Stein, C.: Implementation of a combinatorial
multicommodity flow algorithm. In: Johnson, D.S., McGeoch,
C.C. (eds.) Network flows and matching. DIMACS Series in Discrete 
Mathematics and Theoretical Computer Science, vol. 12,
pp. 387–406. AMS, Providence (1991)

26. Linial, N., London, E., Rabinovich, Y.: The geometry of graphs
and some of its algorithmic applications. Comb. 15(2), 215–
245 (1995)

27. Shahrokhi, F., Matula, D.W.: The maximum concurrent flow

problem. J. ACM 37(2), 318–334 (1990)

28. Shmoys, D.B.: Cut problems and their applications to divide-
and-conquer. In: Hochbaum, D.S. (ed.) Approximation algorithms 
for NP-hard problems, pp. 192–235. PWS Publishing
Company, Boston, MA (1997)

Sequential Approximate
String Matching
2003; Crochemore, Landau, Ziv-Ukelson
2004; Fredriksson, Navarro

GONZALO NAVARRO
Department of Computer Science, University of Chile,
Santiago, Chile

Keywords and Synonyms
String matching allowing errors or diﬀerences; Inexact
string matching; Semiglobal or semilocal sequence similarity


Problem Definition
Given a text string T = t1t2 : : : tn and a pattern string
P = p1p2 : : : pm, both being sequences over an alphabet ˙
of size (cid:3), and given a distance function among strings d
and a threshold k, the approximate string matching (ASM)
problem is to ﬁnd all the text positions that ﬁnish a socalled 
approximate occurrence of P in T, that is, compute
the setfj;9i; 1  i  j; d(P; ti : : : t j)  kg. In the sequential 
version of the problem T, P, and k are given together,
whereas the algorithm can be tailored for a speciﬁc d.

The solutions to the problem vary widely depending
on the distance d used. This entry focuses on a very popular 
one, called Levenshtein distance or edit distance, deﬁned
as the minimum number of character insertions, deletions,
and substitutions necessary to convert one string into the
other. It will also pay some attention to other common
variants such as indel distance, where only insertions and

deletions are permitted and is the dual of the longest common 
subsequence lcs (d(A; B) = jAj + jBj (cid:2) 2 (cid:3) lcs(A; B));
and Hamming distance, where only substitutions are permitted.


A popular generalization of all the above is the
weighted edit distance, where the operations are given positive 
real-valued weights and the distance is the minimum
sum of weights of a sequence of operations converting
one string into the other. The weight of deleting a character 
c is written w(c ! (cid:2)), that of inserting c is written
w((cid:2) ! c), and that of substituting c by c0 6= c is written
w(c ! c0). It is assumed w(c ! c) = 0 and the triangle
inequality, that is, w(x ! y) + w(y ! z) (cid:6) w(x ! z) for
any x; y; z 2 ˙ [ f(cid:2)g. As the distance may now be asymmetric,
 it is ﬁxed that d(A; B) is the cost of converting A
into B. Of course any result for weighted edit distance applies 
to edit, Hamming and indel distances (collectively
termed unit-cost edit distances) as well, but other reductions 
are not immediate.

Both worstand 
average-case complexity are considered.
 For the latter one assumes that pattern and text are
randomly generated by choosing each character uniformly
and independently from ˙. For simplicity and practicality,
m = o(n) is assumed in this entry.

Key Results
The most ancient and versatile solution to the problem 
[13] builds over the process of computing weighted
edit distance. Let A = a1a2 : : : am and B = b1b2 : : : bn be
two strings. Let C[0 : : : m; 0 : : : n] be a matrix such that
C[i; j] = d(a1 : : : ai ; b1 : : : b j). Then it holds C[0; 0] = 0
and

C[i; j] = min(C[i (cid:2) 1; j] + w(ai ! (cid:2)); C[i; j (cid:2) 1]

+ w((cid:2) ! b j); C[i (cid:2) 1; j (cid:2) 1] + w(ai ! b j)) ;
where C[i;(cid:2)1] = C[(cid:2)1; j] = 1 is assumed. This matrix is
computed in O(mn) time and d(A; B) = C[m; n]. In order 
to solve the approximate string matching problem, one
takes A = P and B = T, and sets C[0; j] = 0 for all j, so that
the above formula is used only for i > 0.

Theorem 1 (Sellers 1980 [13]) There exists an O(mn)
worst-case time solution to the ASM problem under
weighted edit distance.

The space is O(m) if one realizes that C can be computed
column-wise and only column j (cid:2) 1 is necessary to compute 
column j. As explained, this immediately implies that
searching under unit-cost edit distances can be done in
O(mn) time as well. In those cases, it is quite easy to comSequential 
Approximate String Matching

S 819

pute only part of matrix C so as to achieve O(kn) averagetime 
algorithms [14].

Yet, there exist algorithms with lower worst-case complexity 
for weighted edit distance. By applying a ZivLempel 
parsing to P and T, it is possible to identify regions 
of matrix C corresponding to substrings of P and T
that can be computed from other previous regions corresponding 
to similar substrings of P and T [5].

Theorem 2 (Crochemore et al. 2003 [5]) There exists
an O(n + mn/ log(cid:12) n) worst-case time solution to the ASM
problem under weighted edit distance. Moreover, the time
is O(n + mnh/ log n), where 0  h  log (cid:3) is the entropy
of T.

This result is very general, also holding for computing
weighted edit distance and local similarity (see section on
applications). For the case of edit distance and exploiting 
the unit-cost RAM model, it is possible to do better.
On one hand, one can apply a four-Russian technique:
All the possible blocks (submatrices of C) of size t (cid:4) t, for
t = O(log(cid:12) n), are precomputed and matrix C is computed
block-wise [9]. On the other hand, one can represent each
cell in matrix C using a constant number of bits (as it can
diﬀer from neighboring cells by ˙ 1) so as to store and
process several cells at once in a single machine word [10].
This latter technique is called bit-parallelism and assumes
a machine word of (cid:9)(log n) bits.

Theorem 3 (Masek and Paterson 1980 [9]; Myers
1999 [10]) There exist O(n + mn/(log(cid:12) n)2) and O(n +
mn/ log n) worst-case time solutions to the ASM problem
under edit distance.

Both complexities are retained for indel distance, yet not
for Hamming distance.

For unit-cost edit distances, the complexity can depend 
on k rather than on m, as k < m for the problem
to be nontrivial and usually k is a small fraction of m (or
even k = o(m)). A classic technique [8] computes matrix
C by processing in constant time diagonals C[i + d; j + d],
0  d  s, along which cell values do not change. This is
possible by preprocessing the suﬃx trees of T and P for
Lowest Common Ancestor queries.

Theorem 4 (Landau and Vishkin 1989 [8]) There exists
an O(kn) worst-case time solution to the ASM problem under 
unit-cost edit distances.

Other solutions exist which are better for small k, achieving 
time O(n(1 + k4/m)) [4]. For the case of Hamming
distance, one can achieve improved results using convolutions 
[1].

p

There

exist
k log k) and O(n(1 + k3/m) log k) worst-case time

Theorem 5 (Amir et al. 2004 [1])
O(n
solution to the ASM problem under Hamming distance.
The last result for edit distance [4] achieves O(n) time if k
is small enough (k = O(m1/4)). It is also possible to achieve
O(n) time on unit-cost edit distances at the expense of an
exponential additive term on m or k: The number of different 
columns in C is independent of n, so the transition
from every possible column to the next can be precomputed 
as a ﬁnite-state machine.
Theorem 6 (Ukkonen 1985 [14]) There exists an
O(n + m min(3m; m(2m(cid:3))k)) worst-case time solution to
the ASM problem under edit distance.
Similar results apply for Hamming and indel distance,
where the exponential term reduces slightly according to
the particularities of the distances.

The worst-case complexity of the ASM problem is of
course ˝(n), but it is not known if this can be attained
for any m and k. Yet, the average-case complexity of the
problem is known.
Theorem 7 (Chang and Marr 1994 [3]) The average-case
complexity of the ASM problem is (cid:9)(n(k + log(cid:12) m)/m) under 
unit-cost edit distances.
It is not hard to prove the lower bound as an extension 
to Yao’s bound for exact string matching [15].
p
The lower bound was reached in the same paper [3],
for k/m < 1/3 (cid:2) O(1/
p
(cid:3)). This was improved later to
k/m < 1/2 (cid:2) O(1/
(cid:3)) [6] using a slightly diﬀerent idea.
The approach is to precompute the minimum distance
to match every possible text substring (block) of length
O(log(cid:12) m) inside P. Then, a text window is scanned backwards,
 block-wise, adding up those minimum precomputed 
distances. If they exceed k before scanning all the
window, then no occurrence of P with k errors can contain 
the scanned blocks and the window can be safely slid
over the scanned blocks, advancing in T. This is an example 
of a ﬁltration algorithm, which discards most text areas
and applies an ASM algorithm only over those areas that
cannot be discarded.
Theorem 8 (Fredriksson and Navarro 2004 [6]) There
exists an optimal-on-average solution to the ASM probp

lem under edit distance, for any k/m  1(cid:2)e/
(cid:12) = 1/2 (cid:2)
p
2(cid:2)e/
p
O(1/
The result applies verbatim to indel distance. The same
complexity is achieved for Hamming distance, yet the limit
on k/m improves to 1 (cid:2) 1/(cid:3). Note that, when the limit
k/m is reached, the average complexity is already (cid:9)(n). It

(cid:3)).

(cid:12)

820 S

Sequential Circuit Technology Mapping

is not clear up to which k/m limit could one achieve linear
time on average.

Applications
The problem has many applications in computational biology 
(to compare DNA and protein sequences, recovering 
from experimental errors, so as to spot mutations or
predict similarity of structure or function), text retrieval
(to recover from spelling, typing or automatic recognition 
errors), signal processing (to recover from transmission 
and distortion errors), and several others. See [11] for
a more detailed discussion.

Many extensions of the ASM problem exist, particularly 
in computational biology. For example, it is possible
to substitute whole substrings by others (called generalized
edit distance), swap characters in the strings (string matching 
with swaps or transpositions), reverse substrings (reversal 
distance), have variable costs for insertions/deletions
when they are grouped (similarity with gap penalties), and
look for any pair of substrings of both strings that are suﬃciently 
similar (local similarity). See for example Gusﬁeld’s
book [7], where many related problems are discussed.

Open Problems
The worst-case complexity of the problem is not fully understood.
 For unit-cost edit distances it is (cid:9)(n) if m =
O(min(log n; (log(cid:12) n)2)) or k = O(min(m1/4; logm(cid:12) n)).
For weighted edit distance the complexity is (cid:9)(n) if
m = O(log(cid:12) n). It is also unknown up to which k/m value
p
can one achieve O(n) average time; up to now this has been
achieved up to k/m = 1/2 (cid:2) O(1/

(cid:3)).

Experimental Results
A thorough survey on the subject [11] presents extensive
experiments. Nowadays, the fastest algorithms for edit distance 
are in practice ﬁltration algorithms [6,12] combined
with bit-parallel algorithms to verify the candidate areas 
[2,10]. Those ﬁltration algorithms work well for small
enough k/m, otherwise the bit-parallel algorithms should
be used stand-alone. Filtration algorithms are easily extended 
to handle multiple patterns searched simultaneously.


URL to Code
Well-known packages oﬀering eﬃcient ASM are agrep
(http://webglimpse.net/download.html,
top-level subdirectory 
agrep/) and nrgrep (http://www.dcc.uchile.cl/
~gnavarro/software).

Cross References
(cid:2) Approximate Regular Expression Matching is the more

complex case where P can be a regular expression;
(cid:2) Indexed Approximate String Matching refers to the

case where the text can be preprocessed;

(cid:2) Local Alignment (with Concave Gap Weights) refers to

a more complex weighting scheme of interest in
computational biology.

(cid:2) Sequential Exact String Matching is the simpliﬁed

version where no errors are permitted;

Recommended Reading
1. Amir, A., Lewenstein, M., Porat, E.: Faster algorithms for string
matching with k mismatches. J. Algorithms 50(2), 257–275
(2004)

2. Baeza-Yates, R., Navarro, G.: Faster approximate string matching.
 Algorithmica 23(2), 127–158 (1999)

3. Chang, W., Marr, T.: Approximate string matching and local
similarity. In: Proc. 5th Annual Symposium on Combinatorial 
Pattern Matching (CPM’94). LNCS, vol. 807, pp. 259–273.
Springer, Berlin, Germany (1994)

4. Cole, R., Hariharan, R.: Approximate string matching: A simpler

faster algorithm. SIAM J. Comput. 31(6), 1761–1782 (2002)

5. Crochemore, M., Landau, G., Ziv-Ukelson, M.: A subquadratic
sequence alignment algorithm for unrestricted scoring matrices.
 SIAM J. Comput. 32(6), 1654–1673 (2003)

6. Fredriksson, K., Navarro, G.: Average-optimal single and multiple 
approximate string matching. ACM J. Exp. Algorithms
9(1.4) (2004)

7. Gusfield, D.: Algorithms on strings, trees and sequences. Cambridge 
University Press, Cambridge (1997)

8. Landau, G., Vishkin, U.: Fast parallel and serial approximate

string matching. J. Algorithms 10, 157–169 (1989)

9. Masek, W., Paterson, M.: A faster algorithm for computing

string edit distances. J. Comput. Syst. Sci. 20, 18–31 (1980)

10. Myers, G.: A fast bit-vector algorithm for approximate string
matching based on dynamic progamming. J. ACM 46(3), 395–
415 (1999)

11. Navarro, G.: A guided tour to approximate string matching.

ACM Comput. Surv. 33(1), 31–88 (2001)

12. Navarro, G., Baeza-Yates, R.: Very fast and simple approximate

string matching. Inf. Proc. Lett. 72, 65–70 (1999)

13. Sellers, P.: The theory and computation of evolutionary dis-

tances: pattern recognition. J. Algorithms 1, 359–373 (1980)

14. Ukkonen, E.: Finding approximate patterns in strings. J. Algorithms 
6, 132–137 (1985)

15. Yao, A.: The complexity of pattern matching for a random

string. SIAM J. Comput. 8, 368–387 (1979)

Sequential Circuit
Technology Mapping
1998; Pan, Liu

PEICHEN PAN
Magma Design Automation, Inc., Los Angeles, CA, USA

