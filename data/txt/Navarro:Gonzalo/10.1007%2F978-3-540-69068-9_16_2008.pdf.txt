An(other) Entropy-Bounded

Compressed Suﬃx Tree

Johannes Fischer1, Veli M¨akinen2,(cid:2), and Gonzalo Navarro1,(cid:2)(cid:2)

1 Dept. of Computer Science, Univ. of Chile

{jfischer|gnavarro}@dcc.uchile.cl

2 Dept. of Computer Science, Univ. of Helsinki, Finland

vmakinen@cs.helsinki.fi

Abstract. Suﬃx trees are among the most important data structures
in stringology, with myriads of applications. Their main problem is space
usage, which has triggered much research striving for compressed representations 
that are still functional. We present a novel compressed suﬃx
tree. Compared to the existing ones, ours is the ﬁrst achieving at the
same time sublogarithmic complexity for the operations, and space usage 
which goes to zero as the entropy of the text does. Our development
contains several novel ideas, such as compressing the longest common
preﬁx information, and totally getting rid of the suﬃx tree topology, expressing 
all the suﬃx tree operations using range minimum queries and
a new primitive called next/previous smaller value in a sequence.

1 Introduction

Suﬃx trees are probably the most important structure ever invented in stringology.
 They have been said to have “myriads of virtues” [2], and also have myriads
of applications in many areas, most prominently bioinformatics [13]. One of the
main drawbacks of suﬃx trees is their considerable space requirement, which is
usually close to 20n bytes for a sequence of n symbols, and at the very least 10n
bytes [17]. For example, the Human genome, containing approximately 3 billion 
bases, could easily ﬁt in the main memory of a desktop computer (as each
DNA symbol needs just 2 bits). However, its suﬃx tree would require 30GB to
60GB, too large to ﬁt in normal main memories. Although there has been some
progress in managing suﬃx trees in secondary storage [15] and it is an active
area of research [16], it will always be faster to operate in main memory.

This situation has stimulated research on compressed representations of suﬃx
trees, which operate in compressed form. Even if many more operations are
needed to carry out the operations on the compressed representation, this is
clearly advantageous compared to having to manage it on secondary memory.
A large body of research focuses on compressed suﬃx arrays [22], which oﬀer a

(cid:2) Funded by the Academy of Finland under grant 119815.
(cid:2)(cid:2) Partially funded by Millennium Institute for Cell Dynamics and Biotechnology,

Grant ICM P05-001-F, Mideplan, Chile.

P. Ferragina and G. Landau (Eds.): CPM 2008, LNCS 5029, pp. 152–165, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008

An(other) Entropy-Bounded Compressed Suﬃx Tree

153

reduced suﬃx tree functionality. Especially, they miss the important suﬃx-link
operation. The same restrictions apply to early compressed suﬃx trees [21,12].
The ﬁrst fully-functional compressed suﬃx tree is due to Sadakane [26]. It
builds on top of a compressed suﬃx array [25] that uses 1
 nH0 + O(n log log σ)
bits of space, where H0 is the zero-order entropy of the text T1,n, σ is the size of
the alphabet of T , and 0 <  < 1 is any constant. In addition, the compressed
suﬃx tree needs 6n+ o(n) bits of space. Most of the suﬃx tree operations can be
carried out in constant time, except for knowing the string-depth of a node and
the string content of an edge, which take O(log n) time, and moving to a child,
which costs O(log n log σ). One could replace the compressed suﬃx array they
use by Grossi et al.’s [11], which requires less space: 1
 nHk+o(n log σ) bits for any
k ≤ α logσ n, where Hk is the k-th empirical entropy of T [19] and 0 < α < 1 is

1−
any constant. However, the O(log n) time complexities become O(log
σ n log σ)
[11, Thm. 4.1]. In addition, the extra 6n bits in the space complexity remain,
despite any reduction in the compressed suﬃx array. This term can be split into
2n bits to represent (with a bitmap called Hgt) the longest common preﬁx (LCP)
information, plus 4n bits to represent the suﬃx tree topology with parentheses.
Many operations are solved via constant-time range minimum queries (RMQs)
over the depths in the parentheses sequence. An RMQ from i to j over a sequence
S[1, n] of numbers asks for rmqS(i, j) := argmini≤(cid:5)≤jS[(cid:5)].

Russo et al. [24] recently achieved fully-compressed suﬃx trees, that is, requiring 
nHk + o(n log σ) bits of space (with the same limits on k as before), which
is essentially the space required by the smallest compressed suﬃx array, and
asymptotically optimal under the k-th entropy model. The main idea is to sample 
some suﬃx tree nodes and use the compressed suﬃx array as a tool to ﬁnd
nearby sampled nodes. The most adequate compressed suﬃx array for this task
is the alphabet-friendly FM-index [6]. The time complexities for most operations
are logarithmic at best, more precisely, between O(log n) and O(log n log log n).
Others are slightly costlier, e.g. moving to a child costs an additional O(log log n)
factor, and some less common operations are as costly as O((log n log log n)2).
We present a new fully-compressed suﬃx tree, by removing the 6n term in
Sadakane’s space complexity. The space we achieve is not as good as that of
Russo et al., but most of our time complexities are sublogarithmic. More precisely,
 our index needs nHk(2 log 1
 + O(1)) + o(n log σ) bits of space. Note
that, although this is not the ideal nHk, it still goes to zero as Hk → 0, unlike
Hk
the incompressible 6n bits in Sadakane’s structure. Our solution builds on two
novel algorithmic ideas to improve Sadakane’s compressed suﬃx tree.

+ 1

1. We show that array Hgt, which encodes LCP information in 2n bits [26],
actually contains 2R runs, where R is the number of runs in ψ [22]. We show
how to run-length compress Hgt into 2R log n
R + O(R)+ o(n) bits while retaining
constant-time access. In order to relate R with nHk, we use the result R ≤
nHk + σk for any k [18], although sometimes it is extremely pessimistic (in
particular it is useful only for Hk < 1, as obviously R ≤ n). This gives the
nHk(2 log 1
+ O(1)) upper bound to store Hgt (and the real space is always
≤ 2n bits).
Hk

154

J. Fischer, V. M¨akinen, and G. Navarro

2. We get rid of the suﬃx tree topology and identify suﬃx tree nodes with
suﬃx array intervals. All the tree traversal operations are simulated with RMQs
on LCP (represented with Hgt), plus a new type of queries called “Next/Previous
Smaller Value”, that is, given a sequence of numbers S[1, n], ﬁnd the ﬁrst cell
in S following/preceding i whose value is smaller than S[i].1 We show how to
solve these queries in sublogarithmic time while spending only o(n) extra bits of
space on top of S. We believe this operation might have independent interest,
and the challenge of achieving constant time with sublinear space remains open.

2 Basic Concepts
The suﬃx tree S of a text T1,n over an alphabet Σ of size σ is a compact trie
storing all the suﬃxes Ti,n where the leaves point to the corresponding i values
[2,13]. For convenience we assume that T is terminated with a special symbol,
so that all lexicographical comparisons are well deﬁned. For a node v in S, π(v)
denotes the string obtained by reading the edge-labels when walking from the
root to v (the path-label of v [24]). The string-depth of v is the length of π(v).

Deﬁnition 1. A suﬃx tree representation supports the following operations:
– Root(): the root of the suﬃx tree.
– Locate(v): the suﬃx position i if v is the leaf of suﬃx Ti,n, otherwise null.
– Ancestor(v, w): true if v is an ancestor of w.
– SDepth(v)/TDepth(v): the string-depth/tree-depth of v.
– Count(v): the number of leaves in the subtree rooted at v.
– Parent(v): the parent node of v.
– FChild(v)/NSibling(v): the alphabetically ﬁrst child/next sibling of v.
– SLink(v): the suﬃx-link of v; i.e., the node w s.th. π(w) = β if π(v) = aβ

for a ∈ Σ.
for α ∈ Σi).

depth ≥ d.

– SLinki(v): the iterated suﬃx-link of v; (node w s.th. π(w) = β if π(v) = αβ

– LCA(v, w): the lowest common ancestor of v and w.
– Child(v, a): the node w s.th. the ﬁrst letter on edge (v, w) is a ∈ Σ.
– Letter(v, i): the ith letter of v’s path-label, π(v)[i].
– LAQs(v, d)/LAQt(v, d): the highest ancestor of v with string-depth/treeExisting 
compressed suﬃx tree representations include a compressed full-text
index [22,25,11,6], which encodes in some form the suﬃx array SA[1, n] of T ,
with access time tSA. Array SA is a permutation of [1, n] storing the pointers
to the suﬃxes of T (i.e., the Locate values of the leaves of S) in lexicographic
−1 in time
order. Most full-text indexes also support access to permutation SA
O(tSA), as well as the eﬃcient computation of permutation ψ[1, n], where ψ(i) =
−1[SA[i] + 1] for 1 ≤ i ≤ n if SA[i] (cid:6)= n and SA
−1[1] otherwise. ψ(i) is
SA
1 Computing NSVs/PSVs on the ﬂy has been considered in parallel computing [3], yet

not in the static scenario.

An(other) Entropy-Bounded Compressed Suﬃx Tree

155

computed in time tψ, which is at most O(tSA), but usually less. Compressed
suﬃx tree representations also include array LCP[1, n], which stores the length
of the longest common preﬁx (lcp) between consecutive suﬃxes in lexicographic
order, LCP[i] = |lcp(TSA[i−1],n, TSA[i],n)| for i > 1 and LCP[1] = 0. The access
time for LCP is tLCP.

We make heavy use of the following complementary operations on bit arrays:
rank(B, i) is the number of bits set in B[1, i], and select(B, j) is the position of
the j-th 1 in B. Bit vector B[1, n] can be preprocessed to answer both queries in
constant time using o(n) extra bits of space [20]. If B contains only m bits set,
m + O(m +
then the representation of Raman et al. [23] compresses B to m log n
n log log n

) bits of space and retains constant-time rank and select queries.

log n

3 Compressing LCP Information

Sadakane [26] describes an encoding of the LCP array that uses 2n+o(n) bits. The
encoding is based on the fact that values i+LCP[i] are nondecreasing when listed
−1[j]],
in text position order: Sequence S = s1, . . . , sn−1, where sj = j + LCP[SA
is nondecreasing.
To represent S, Sadakane encodes each diff(j) = sj−sj−1 in unary: 1 0diff(j),
where s0 = 0 and 0d denotes repetition of 0-bit d times. This encoding, call it U
(similar to Hgt [26]), takes at most 2n bits. Thus LCP[i] = select(U, j +1)− j−1,
where j = SA[i], is computed in time O(tSA).

Let us now consider how to represent U in a yet more space-eﬃcient form,
i.e., in nHk(2 log 1
+ O(1)) + o(n) bits, for small enough k. The result follows
Hk
from the observation (to be shown below) that the number of 1-bit runs in U is
bounded by the number of runs in ψ. We call a run in ψ a maximal sequence of
consecutive i values where ψ(i) − ψ(i − 1) = 1 and TSA[i−1] = TSA[i], including
one preceding i where this does not hold [18]. Note that an area in ψ where the
diﬀerences are not 1 corresponds to several length-1 runs. Let us call R ≤ n the
overall number of runs.

(cid:2)

r

(cid:2)

r

(cid:2)
r

We will represent U in run-length encoded form, coding each maximal run of
both 0 and 1 bits. We show soon that there are at most R 1-runs, and hence at
most R 0-runs (as U starts with a 1). If we encode the 1-run lengths o1, o2, . . . and
the 0-run lengths z1, z2, . . . separately (cf. Sect. 3.2 in [5]), it is easy to compute
i=1 oi < j and then answering
select(U, j) by ﬁnding the largest r such that
i=1 zi. This so-called searchable partial sums problem is
select(U, j) = j +
easy to solve. Store bitmap O[1, n] setting the bits at positions
i=1 oi, hence
i=1 oi < j} = rank(O, j − 1). Likewise, bitmap Z[1, n] representing
max{r,
the zi’s solves
i=1 zi = select(Z, r). Since both O and Z have at most R 1’s,
O plus Z can be represented using 2R log n
We now show the connection between runs in U and runs in ψ. Let us call
position i a stopper if i = 1 or ψ(i) − ψ(i − 1) (cid:6)= 1 or TSA[i−1] (cid:6)= TSA[i]. Hence ψ
has exactly R stoppers by the deﬁnition of runs in ψ. Say now that a chain in ψ
is a maximal sequence i, ψ(i), ψ(ψ(i)), . . . such that each ψj(i) is not a stopper
except the last one. As ψ is a permutation with just one cycle, it follows that in

R + O(R + n log log n

) bits [23].

(cid:2)
r

(cid:2)

r

log n

156

J. Fischer, V. M¨akinen, and G. Navarro

−1[1]], 0 ≤ j < n, we will ﬁnd the R stoppers, and hence there

the path of ψj[SA
are also R chains in ψ [10].
We now show that each chain in ψ induces a run of 1’s of the same length in
U. Let i, ψ(i), . . ., ψ(cid:5)(i) be a chain. Hence ψj(i)−ψj(i−1) = 1 for 0 ≤ j < (cid:5). Let
x = SA[i − 1] and y = SA[i]. Then SA[ψj(i − 1)] = x + j and SA[ψj(i)] = y + j.
Then LCP[i] = |lcp(TSA[i−1],n, TSA[i],n)| = |lcp(Tx,n, Ty,n)|. Note that Tx+LCP[i] (cid:6)=
−1[y + LCP[i]] = ψLCP[i](i) is a stopper, thus (cid:5) ≤ LCP[i].
Ty+LCP[i], and hence SA
Moreover, LCP[ψj(i)] = |lcp(Tx+j,n, Ty+j,n)| = LCP[i]− j ≥ 0 for 0 ≤ j < (cid:5). Now
−1[y+j]] = y+j+LCP[ψj(i)] = y+j+LCP[i]−j =
consider sy+j = y+j+LCP[SA
y + LCP[i], all equal for 0 ≤ j < (cid:5). This produces (cid:5) − 1 diff values equal to 0,
that is, a run of (cid:5) 1-bits in U. By traversing all the chains in the cycle of ψ we
sweep S left to right, producing at most R runs of 1’s and hence at most R runs
of 0’s. (Note that even an isolated 1 is a run with (cid:5) = 1.) Since R ≤ nHk + σk
for any k [22], we obtain the bound nHk(2 log 1
) for any
k ≤ α logσ n and any constant 0 < α < 1. Although our somewhat crude upper
Hk
bounds do not show it, our representation is asymptotically never larger than
the original Hgt.

+ O(1)) + O( n log log n

log n

4 Next-Smaller and Prev-Smaller Queries

In this section we consider queries next smaller value (NSV) and previous smaller
value (PSV), and show that they can be solved in sublogarithmic time using only
a sublinear number of extra bits on top of the raw data. We make heavy use of
these queries in the design of our new compressed suﬃx tree, and also believe
that they can be of independent interest.

Deﬁnition 2. Let S[1, n] be a sequence of elements drawn from a set with a
total order (cid:7) (where one can also deﬁne a ≺ b ⇔ a (cid:7) b ∧ b (cid:6)(cid:7) a). We deﬁne
the query next smaller value and previous smaller value as follows: NSV(S, i) =
min{j, (i < j ≤ n ∧ S[j] ≺ S[i]) ∨ j = n + 1} and PSV(S, i) = max{j, (1 ≤ j <
i ∧ S[j] ≺ S[i]) ∨ j = 0}, respectively.
The key idea to solve these queries reminds that for ﬁndopen and ﬁndclose operations 
in balanced parentheses, in particular the recursive version [9]. However,
there are several diﬀerences because we have to deal with a sequence of generic
values, not parentheses.

We will describe the solution for NSV, as that for PSV is symmetric. For
shortness we will write NSV(i) for NSV(S, i). We split S[1, n] into consecutive
blocks of b values. A position i will be called near if NSV(i) is within the same
block of i. The ﬁrst step when solving a NSV query will be to scan the values
S[i + 1 . . . b · (cid:12)i/b(cid:13)], that is from i + 1 to the end of the block, looking for an
S[j] ≺ S[i]. This takes O(b) time and solves the query for near positions.
Positions that are not near are called far. We note that the far positions
within a block, i1 < i2 . . . < is form a nondecreasing sequence of values S[i1] (cid:7)
S[i2] . . . (cid:7) S[is]. Moreover, their NSV values form a nonincreasing sequence
NSV(i1) ≥ NSV(i2) . . . ≥ NSV(is).

b

b

(cid:4)

, i

An(other) Entropy-Bounded Compressed Suﬃx Tree

157

A far position i will be called a pioneer if NSV(i) is not in the same block of
NSV(j), being j the largest far position preceding i (the ﬁrst far position is also
a pioneer). It follows that, if j is the last pioneer preceding i, then NSV(i) is in
the same block of NSV(j) ≥ NSV(i). Hence, to solve NSV(i), we ﬁnd j and then
scan (left to right) the block S[(cid:12)NSV(j)/b(cid:13)− b + 1 . . . NSV(j)], in time O(b), for
the ﬁrst value S[j

(cid:4)] ≺ S[i].

log n
n

b

(cid:4)] (n

) + O( n log n

) + O( n log log n

log n

b + n log log n

log n

Because S
(cid:4) = rank(R, i) in S

So the problem boils down to eﬃciently ﬁnding the pioneer preceding each position 
i, and to storing the answers for pioneers. We mark pioneers in a bitmap
P [1, n]. We note that, since there are O(n/b) pioneers overall [14], P can be
represented using O( n log b
) bits of space [23]. With this representation,
 we can easily ﬁnd the last pioneer preceding a far position i, as
j = select(P, rank(P, i)). We could now store the NSV answers for the pio-
(cid:4) = O(n/b)), so that if j is a pioneer then
neers in an answer array A[1, n
NSV(j) = A[rank(P, j)]. This already gives us a solution requiring O( n log b
) +
O( n log log n
) bits of space and O(b) time. For example, we can have
O(

log log n) bits of space and O(log n log log n) time.
We can do better by recursing on the idea. Instead of storing the answers ex-
(cid:4)[1, 2n
(cid:4)] containing
plicitly in array A, we will form a (virtual) reduced sequence S
(cid:4) is not explicitly
all the pioneer values i and their answers NSV(i). Sequence S
stored. Rather, we set up a bitmap R[1, n] where the selected values in S are
(cid:4)[i] = S[select(R, i)]. Again, this can
marked. Hence we can retrieve any value S
be computed in constant time using O( n log b
) bits to represent R [23].
(cid:4) is a subsequence of S, it holds that the answers to NSV in S
(cid:4)
are the same answers mapped from S. That is, if i is a pioneer in S, mapped
(cid:4) = rank(R, NSV(i)), then
to i
(cid:4) − 1] correspond to values
(cid:4) = NSV(S
j
within S[i+1 . . . NSV(i)−1], which by deﬁnition of NSV are not smaller than S[i].
Hence, we can ﬁnd NSV(i) for pioneers i by the corresponding recursive query
, rank(R, i))). We are left with the problem
on S
of solving queries NSV(S
(cid:4) into blocks of b values. Near positions in S
(cid:4)
(cid:4) is not explicitly
are solved in O(b) time by scanning the block. Recall that S
stored, but rather we have to use select on R to get its values from S. For far
positions we deﬁne again pioneers, and solve NSV on far positions in time O(b)
using the answer for the preceding pioneer. Queries for pioneers are solved in a
/b) = O(n/b2).
third level by forming the virtual sequence S
We continue the process recursively for r levels before storing the explicit
answers in array A[1, n(r)], n(r) = O(n/br). We remark that the P (cid:5) and R(cid:5)
bitmaps at each level (cid:5) map positions directly to S, not to the reduced sequence
of the previous level. This permits accessing the S(cid:5)[i] values at any level (cid:5) in
constant time, S(cid:5)[i] = S[select(R(cid:5), i)]. The pioneer preceding i in S(cid:5) is found
(cid:4) = select(R(cid:5), i), then ﬁnding the preceding pioneer
by ﬁrst mapping to S with i
(cid:4))), and ﬁnally mapping
directly in the domain of S, j
the pioneer back to S(cid:5) by j = rank(R(cid:5), j

(cid:4), and NSV(i) is mapped to j
(cid:4) + 1 . . . j

(cid:4)), because any value in S

(cid:4), NSV(i) = select(R, NSV(S

(cid:4) = select(P (cid:5), rank(P (cid:5), i

We proceed again by splitting S

(cid:4)(cid:4)[1, 2n

(cid:4)(cid:4)], n

(cid:4)(cid:4) = O(n

(cid:4)

(cid:4)

(cid:4)

, i).

(cid:4)[i

(cid:4)).

158

J. Fischer, V. M¨akinen, and G. Navarro

Let us now analyze the time and space of this solution. Because we pay O(b)
time at each level and might have to resort to the next level in case our position 
is far, the total time is O(rb) because the last level is solved in constant
time. As for the space, all we store are the P (cid:5) and R(cid:5) bitmaps, and the ﬁnal 
array A. Array A takes O( n log n
) bits. As there are O(n/b(cid:5)) elements in
S(cid:5), both P (cid:5) and R(cid:5) require O( n
) bits of space (actually P (cid:5)
is about half the size of R(cid:5)). The sum of all the P (cid:5) and R(cid:5) takes order of
(cid:2)

b(cid:3) log(b(cid:5)) + n log log n

log n

(cid:3)

(cid:4)

(cid:3)

br

n

b(cid:3) log(b(cid:5)) + n log log n

1≤(cid:5)≤r
We now state the main result of this section.

= O

n log b

log n

b + r n log log n

log n

(cid:4)

.

Theorem 1. Let S[1, n] be a sequence of elements drawn from a set with a
total order, such that access to any S[i] and any comparison S[i] ≺ S[j] can
be computed in constant time. Then, for any 1 ≤ r, b ≤ n, it is possible to
build a data structure on S taking O( n log b
) bits, so that
queries NSV and PSV can be solved in worst-case time time O(rb). In particular,
for any f(n) = O( log n
f(n)) bits of extra space and
O(f(n) log log n) time.

log log n), one can achieve O( n

b + r n log log n

log n + n log n

br

b = O( n

f(n) ) implies b = Ω(f(n) log f(n)). Also, n log n

Proof. The general formula for any r, b has been obtained thruoghout this section.
f(n) ). Then
As for the formulas in terms of f(n), let us set the space limit to O( n
f(n) ) implies r ≥
n log b
log b (log log n + log f(n) − O(1)). Thus it is best to
log log n+log f(n)−O(1)
log f(n)+log log f(n) (log log n +
log n =
and since b = Ω(f(n) log f(n)),
(cid:3)(cid:4)

minimize b. By setting b = f(n) log f(n), we get rb =
log f(n) − O(1)) = Θ(f(n)(log log n + log f(n))). The ﬁnal constraint is r n log log n
O( n
yields the condition f(n) = O( log n

f(n) ), which, by substituting r = log log n+log f(n)

log log n ). Thus log log n + log f(n) = O(log log n).

. Hence rb ≥ b

br = O( n

f(n) log f(n)

log b

log b

Note that, if one is willing to spend 4n + o(n) bits of extra space, the operations
can be solved in constant time. The idea is to reduce PSV and NSV queries to
O(1) ﬁndopen and ﬁndclose operations in balanced parentheses [9]. For NSV,
for 1 ≤ i ≤ n + 1 in this order, write a ’(’ and then x ’)’s if there are x cells
S[j] for which NSV(j) = i. The resulting sequence B is balanced if a ﬁnal ’)’ is
appended, and NSV(i) can be obtained by rank(B, f indclose(B, select(B, i))),
where a 1 in B represents ’(’. PSV is symmetric, needing other 2n + o(n) bits.

5 An Entropy-Bounded Compressed Suﬃx Tree
Let v be a node in the (virtual) suﬃx tree S for text T1,n. As in previous works
[1,4,24], we represent v by an interval [vl, vr] in SA such that SA[vl, vr] are exactly 
the leaves in S that are in the subtree rooted at v. Let us ﬁrst consider
internal nodes, so vl < vr. Because S does not contain unary nodes, it follows
from the deﬁnition of LCP that at least one entry in LCP[vl +1, vr] is equal to the
string-depth h of v; such a position is called h-index of [vl, vr]. We further have

An(other) Entropy-Bounded Compressed Suﬃx Tree

159

ψ

vr

ψ
PSV
x

NSV

y

k

h−1

vl

h

RMQ

(x+1,y)

Fig. 1. Left: Illustration to the representation of suﬃx tree nodes. The lengths of the
bars indicate the LCP values. All leaves in the subtree rooted at v = [vl, vr] share
a longest common preﬁx of length at least h. Right: Schematic view of the SLink
operation. From v, ﬁrst follow ψ, then perform an RMQ to ﬁnd an (h− 1)-index k, and
ﬁnally locate the deﬁning points of the desired interval by a PSV/NSV query from k.

LCP[vl] < h, LCP[i] ≥ h for all vl < i ≤ vr, and LCP[vr + 1] < h. Fig. 1 (left)
illustrates. We state the easy yet fundamental

Lemma 1. Let [vl, vr] be an interval in SA that corresponds to an internal node
v in S. Then the string-depth of v is h=LCP(k), where k =rmqLCP(vl + 1, vr).
For leaves v = [vl, vl], the string-depth of v is simply given by n − SA[vl] + 1.

5.1 Range Minimum Queries in Sublinear Space

As Lemma 1 suggests, we wish to preprocess LCP such that rmqLCP can be
answered in sublogarithmic time, using o(n) bits of additional space. A wellknown 
strategy [7,26] divides LCP iteratively into blocks of decreasing size n >
b1 > b2 > ··· > br. On level i, 1 ≤ i ≤ r, compute all answers to rmqLCP that
exactly span over blocks of size bi, but not over blocks of size bi−1 (set b0 = n
) log(bi−1)) bits of space
for handling the border case). This takes O( n
if the answers are stored relative to the beginning of the blocks on level i − 1,
bi
)(cid:15)
and if we only precompute queries that span 2j blocks for all j ≤ (cid:14)log( bi−1
(this is suﬃcient because each query can be decomposed into at most 2 possibly
overlapping sub-queries whose lengths are a power of 2).

log( bi−1
bi

bi

A general range minimum query is then decomposed into at most 2r + 1 nonoverlapping 
sub-queries q1, . . . , q2r+1 such that q1 and q2r+1 lie completely inside
of blocks of size br, q2 and q2r exactly span over blocks of size br, and so on. q1
and q2r+1 are solved by scanning in time O(br),2 and all other queries can be
answered by table-lookups in total time O(r). The ﬁnal answer is obtained by
comparing at most 2r + 1 minima.

The next lemma gives a general result for RMQs using o(n) extra space.

2 The constant-time solutions [26,7] also solve q1 and q2r+1 by accessing tables that

require Θ(n) bits.

160

J. Fischer, V. M¨akinen, and G. Navarro

Lemma 2. Having constant-time access to elements in an array A[1, n], it is
possible to answer range minimum queries on A in time O(f(n)(log f(n))2) using
f(n)) bits of space, for any f(n) = Ω(log[r] n) and any constant r, where
O( n
log[r] n denotes r applications of log to n.

Proof. We use r+1 = O(1) levels 1 . . . r+1, so it is suﬃcient that n
f(n) )
for all 1 ≤ i ≤ r + 1, where b0 = n. From the condition n
bi
f(n) ) we get
b1 = Θ(f(n) log2 n) (the smallest possible bi values are best). From n
f(n) )
b2
we get b2 = Θ(f(n) log2 b1) = Θ(f(n)(log f(n) + log log n)2). In turn, from n
log2 b2 =
b3
f(n) ) we get b3 = Θ(f(n) log2 b2) = Θ(f(n)(log f(n)+log log log n)2). This continues
O( n
until br+1 = Θ(f(n) log2 br) = Θ(f(n)(log f(n) + log[r+1] n))2 = Θ(f(n) log2 f(n)). (cid:3)(cid:4)

log2 bi−1 = O( n

log2 b1 = O( n

log2 b0 = O( n

b1

5.2 Suﬃx-Tree Operations

Now we have all the ingredients for navigating in the suﬃx tree. The operations
are described in the following; the intuitive reason why an RMQ is often followed
by a PSV/NSV-query is that the RMQ gives us an h-index of the (yet unknown)
interval, and the PSV/NSV takes us to the delimiting points of this interval.
Apart from tSA, tLCP, and tψ, we denote by trmq and tpnsv the time to solve,
respectively, RMQs or NSV/PSV queries (both on LCP from now on, hence they
will be multiplied by tLCP).
Root/Count/Ancestor: Root() returns interval [1, n], Count(v) is simply
vr − vl + 1, Ancestor(w, v) is true iﬀ wl ≤ vl ≤ vr ≤ wr. These take O(1) time.
SDepth(v)/Locate(v): According to Lemma 1, SDepth(v) can be computed
in time O(trmq · tLCP) for internal nodes, and both operations need time O(tSA)
for leaves. One knows in constant time that v = [vl, vr] is a leaf iﬀ vl = vr.
Parent(v): If v is the root, return null. Else, since the suﬃx tree is compact,
the string-depth of Parent(v) must be either LCP[vl] or LCP[vr + 1], whichever
is greater [24]. So, by setting k = if LCP[vl] > LCP[vr + 1] then vl else vr + 1,
the parent interval of v is [PSV(k), NSV(k) − 1]. Time is O(tpnsv · tLCP).
FChild(v): If v is a leaf, return null. Otherwise, because the minima in [vl, vr]
are v’s h-indices [7], the ﬁrst child of v is given by [vl, rmq(vl + 1, vr) − 1],
assuming that RMQs always return the leftmost minimum in the case of ties
(which is easy to arrange). Time is O(trmq · tLCP).
NSibling(v): First move to the parent of v by w = Parent(v). If vr = wr,
return null, since v does not have a next sibling. If vr + 1 = wr, v’s next sibling
is a leaf, so return [wr, wr]. Otherwise, return [vr + 1, rmq(vr + 2, wr) − 1]. The
overall time is O((trmq + tpnsv) · tLCP).
SLink(v): If v is the root, return null. Otherwise, ﬁrst follow the suﬃx links
of the leaves vl and vr, x = ψ(vl) and y = ψ(vr). Then locate an h-index of the
target interval by k = rmq(x + 1, y); see Lemma 7.5 in [1] (the ﬁrst character
of all strings in {TSA[i],n : vl ≤ i ≤ vr} is the same, so the h-indices in [vl, vr]

An(other) Entropy-Bounded Compressed Suﬃx Tree

161
appear also as (h − 1)-indices in [ψ(vl), ψ(vr)]). The ﬁnal result is then given by
[PSV(k), NSV(k) − 1]. Time is O(tψ + (tpnsv + trmq) · tLCP)). See Fig. 1 (right).
SLinki(v): Same as above with x = ψi(vl) and y = ψi(vr). If the ﬁrst Letter
of x and y are diﬀerent, then the answer is Root. Otherwise we go on with k as
−1[SA[v] + i]
before. Computing ψi can be done in O(tSA) time using ψi(v) = SA
[24]. Time is thus O(tSA + (tpnsv + trmq) · tLCP).
LCA(v, w): If one of v or w is an ancestor of the other, return this ancestor
node. Otherwise, w.l.o.g., assume vr < wl. The h-index of the target interval is
given by an RMQ between v and w [26]: k = rmq(vr + 1, wl). The ﬁnal answer
is again [PSV(k), NSV(k) − 1]. Time is O((trmq + tpnsv) · tLCP).
Child(v, a): If v is a leaf, return null. Otherwise, the minima in LCP[vl + 1, vr]
deﬁne v’s child-intervals, so we need to ﬁnd the position p ∈ [vl + 1, vr] where
LCP[p] = mini∈[vl+1,vr] LCP[i], and TSA[p]+LCP[p] = Letter([p, p], LCP[p] + 1) =
a. Then the ﬁnal result is given by [p, rmq(p + 1, vr) − 1], or null if there is
no such position p. To ﬁnd this p, split [vl, vr] into three sub-intervals [vl, x −
1], [x, y − 1], [y, vr], where x (y) is the ﬁrst (last) position in [vl, vr] where a
block of size br starts (br is the smallest block size for precomputed RMQs,
recall Sect. 5.1). Intervals [vl, x − 1] and [y, vr] can be scanned for p in time
O(trmq · (tLCP + tSA)). The big interval [x, y − 1] can be binary-searched in time
O(log σ·tSA), provided that we also store exact median positions of the minima in
the precomputed RMQs [26] (within the same space bounds). The only problem
is how these precomputations are carried out in O(n) time, as it is not obvious
how to compute the exact median of an interval from the medians in its left and
right half, respectively. However, a solution to this problem exists [8, Sect. 3.2].
Overall time is O((tLCP + tSA) · trmq + log σ · tSA).
Letter(v, i): If i = 1 we can easily solve the query in constant time with very little 
extra space. Mark in a bitmap C[1, n] the ﬁrst suﬃx in SA starting with each
diﬀerent letter, and store in a string L[1, σ] the diﬀerent letters that appear in
T1,n in alphabetical order. Hence, if v = [vl, vr], Letter(v, 1) = L[rank(C, vl)].
L requires O(σ log σ) bits and C, represented as a compressed bitmap [23], re-
) bits of space. Hence both add up to O(σ log n +
quires O(σ log n
) bits. Now, for i > 1, we just use Letter(v, i) = Letter(ψi−1(vl), 1),
n log log n
in time O(min(tSA, i· tψ)). We remark that L and C are already present, in some
form, in all compressed text indexes implementing SA [11,25,6].
TDepth(v): Tree-depth can be maintained while performing some traversal operations 
such as FChild, Child, Parent, LAQt, but not others.

However, there is also a direct way to support TDepth, using nHk(2 log 1
Hk

+
O(1))+o(n) further bits of space. The idea is similar to Sadakane’s representation
of LCP [26]: the key insight is that the tree depth can decrease by at most 1 if we
move from suﬃx Ti,n to Ti+1,n (i.e., when following ψ). Deﬁne TDE[1, n] such
that TDE[i] holds the tree-depth of the LCA of leaves SA[i] and SA[i−1] (similar
−1[1])] + k)k=0,1,...,n−1
to the deﬁnition of LCP). Then the sequence (TDE[ψk(SA
is nondecreasing and in the range [1, n], and can hence be stored using 2n + o(n)

σ + n log log n

log n

log n

162

J. Fischer, V. M¨akinen, and G. Navarro

bits. Further, the repetitions appear in the same way as in Hgt (Sect. 3), so the
resulting sequence can be compressed to nHk(2 log 1
+ O(1)) + o(n) bits using
the same mechanism as for LCP. The time is thus O(trmq · tLCP). For leaves we
Hk
can do in O(tSA) time by TDepth(v) = 1 + max(TDE[SA[v]], TDE[SA[v + 1]]).
LAQs(v, d): Let u = [ul, ur] = LAQs(v, d) denote the (yet unknown) result.
Because u is an ancestor of v, we must have ul ≤ vl and vr ≤ ur. We further
know that LCP[i] ≥ d for all ul < i ≤ ur. Thus, ul is the largest position in [1, vl]
with LCP[ul] < d. So the search for ul can be conducted in a binary manner
by means of RMQs: Letting k = rmq((cid:14)vl/2(cid:15), vl), we check if LCP[k] ≥ d. If so,
ul cannot be in [(cid:14)vl/2(cid:15), vl], so we continue searching in [1,(cid:14)vl/2(cid:15) − 1]. If not,
we know that ul must be in [(cid:14)vl/2(cid:15), vl], so we continue searching in there. The
search for ur is handled symmetrically. Total time is O(log n · trmq · tLCP).
LAQt(v, d): The same idea as for LAQs can be applied here, using the array
TDE instead of LCP, and RMQs on TDE. Time is also O(log n · trmq · tLCP).

6 Discussion

GCSA uses |GCSA| = (1 + 1

 )nHk + O( n log log n

The ﬁnal performance of our compressed suﬃx tree (CST) depends on the compressed 
full-text index used to implement SA. Among the best choices we have
Sadakane’s compressed suﬃx array (SCSA) [25], which is not so attractive for
its O(n log log σ) extra bits of space in a context where we are focusing on using
o(n) extra space. The alphabet-friendly FM-index (AFFM) [6] gives the best
space, but our CST over AFFM is worse than Russo et al.’s CST (RCST) [24]
both in time and space. Instead, we focus on using Grossi et al.’s compressed
suﬃx array (GCSA) [11], which is larger than AFFM but lets our CST achieve
better times than RCST. (Interestingly, RCST does not beneﬁt from using the
larger GCSA.) Our resulting CST is a space/time tradeoﬀ between Sadakane’s
CST (SCST) [26] and RCST. Within this context, it makes sense to consider
SCST on top of GCSA, to remove the huge O(n log log σ) extra space of SCSA.
logσ n ) bits of space for any
k ≤ α logσ n and constant 0 < α < 1, and oﬀers times tψ = O(1) and tSA =
O(log n log1− σ). On top of |GCSA|, SCST needs 6n + o(n) bits, whereas
our CST needs nHk(2 log 1
+ O(1)) + o(n) extra bits. Our CST times are
Hk
tLCP = tSA, whereas trmq and tpnsv depend on how large is o(n). Instead, RCST
needs |AF F M| + o(n) bits, where |AF F M| = nHk + O( n log log n
logσ n ) + O( n log n
)
bits, for some γ = ω(logσ n), to maintain the extra space o(n log σ). AFFM oﬀers
times tψ = O(1 + log σ
log log n)). In addition, RCST uses
o(n) = O( n log n

log log n) and tSA = O(γ(1 + log σ
) bits for a parameter δ = ω(logσ n).

An exhaustive comparison is complicated, as it depends on , γ, δ, σ, the
nature of the o(n) extra bits in our CST, etc. In general, our CST loses to RCST
if they use the same amount of space, yet our CST can achieve sublogarithmic
times by using some extra space, whereas RCST cannot. We opt for focusing on
a particular setting that exhibits this space/time tradeoﬀ. The reader can easily
derive other settings. We focus on the case σ = O(1) and all extra spaces not

δ

γ

An(other) Entropy-Bounded Compressed Suﬃx Tree

163

Table 1. Comparison between ours and alternative compressed suﬃx trees. The column
labeled ‘General’ assumes tψ ≤ tSA = tLCP. All other columns further assume σ = O(1),
and that the extra spaces is O(

).

n

log(cid:2)

n

Operation

Our suﬃx tree

General

over GCSA [11]

Other suﬃx trees

SCST [26]

RCST [24]

1

1

1

1

tSA

tSA · trmq
tSA · tpnsv
tSA · trmq

Root,Count,
Ancestor
Locate
SDepth
Parent
FChild
NSibling
SLink,LCA
SLinki
Child
Letter
TDepth
LAQs
LAQt
(∗) Our CST needs other nHk(2 log 1
Hk

tSA(trmq + tpnsv)
tSA(trmq + tpnsv)
tSA(trmq + tpnsv)
tSA(trmq + log σ)
tSA
tSA · trmq
(cid:2)
log+
tSA · trmq · log n log1++
tSA · trmq · log n (∗) log1++

log n
log n

log n
(cid:2)
n(log log n)2
log+
(cid:2)
log+
n log log n
(cid:2)
n(log log n)2
log+
(cid:2)
log+
n(log log n)2
(cid:2)
n(log log n)2
log+
(cid:2)
n(log log n)2
log+
(cid:2)
n(log log n)2
log+
log n
n(log log n)2
(cid:2)
n(log log n)2 Not supp.
(cid:2)
n(log log n)2

log n
log n
log n

1
1
1
1

(∗)

1

1

(cid:2)
log1+
(cid:2)
log1+
(cid:2)
log1+
(cid:2)
log1+
(cid:2)
log1+
(cid:2)
log1+
(cid:2)
log1+

n
n
n
n
n
n
n

(cid:2)
log1+
(cid:2)
log2+2
(cid:2)
log1+
(cid:2)
log2+2

n
n
n
n

(cid:2)
log1+

n log log n

+ O(1)) + o(n) extra bits to implement TDepth and LAQt.

(cid:4)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

n

n
log(cid:2)

) bits, for constant 0 < 

n log log n. RCST’s γ and δ are O(log1+

n in Thm. 1 and Lemma 2). Thus, our times are trmq = log

< 1 (so f(n) =
related to entropy limited to O(
n(log log n)2
log
and tpnsv = log
n). Table 1 shows
a comparison under this setting. The ﬁrst column also summarizes the general
complexities of our operations, with no assumptions on σ nor extra space except
tψ ≤ tSA = tLCP, as these are intrinsic of our structure.
Clearly SCST is generally faster than the others, but it requires 6n + o(n)
non-compressible extra bits on top of |CSA|. RCST is smaller than the others,
but its time is typically O(log1+
< 1. The space of
(cid:4).
our CST is in between, with typical time O(logλ n) for any constant λ >  + 
This can be sublogarithmic when +
< 1. To achieve this, the space used in the
entropy-related part will be larger than 2(1 + log 1
)nHk. With less than that
Hk
space our CST is slower than the smaller RCST, but using more than that space
our CST can achieve sublogarithmic times (except for level ancestor queries),
being the only compressed suﬃx tree achieving it within o(n) extra space.

n) for some constant 0 < 

Still, we remark that our scheme is not so attractive on large alphabets. If
σ = Θ(nβ) for constant β, then our extra space includes a term Θ(n log log n),
just as in the CST, while the latter is clearly faster.
Acknowledgments. JF wishes to thank Volker Heun and Enno Ohlebusch for
interesting discussions on this subject.

(cid:4)

(cid:4)

164

J. Fischer, V. M¨akinen, and G. Navarro

References

1. Abouelhoda, M., Kurtz, S., Ohlebusch, E.: Replacing suﬃx trees with enhanced

suﬃx arrays. J. Discrete Algorithms 2(1), 53–86 (2004)

2. Apostolico, A.: The myriad virtues of subword trees. In: Combinatorial Algorithms

on Words. NATO ISI Series, pp. 85–96. Springer, Heidelberg (1985)

3. Berkman, O., Schieber, B., Vishkin, U.: Optimal doubly logarithmic parallel algorithms 
based on ﬁnding all nearest smaller values. J. Algorithms 14(3), 344–370
(1993)

4. Cole, R., Kopelowitz, T., Lewenstein, M.: Suﬃx trays and suﬃx trists: structures
for faster text indexing. In: Bugliesi, M., Preneel, B., Sassone, V., Wegener, I. (eds.)
ICALP 2006. LNCS, vol. 4051, pp. 358–369. Springer, Heidelberg (2006)

5. Delpratt, O., Rahman, N., Raman, R.: Engineering the louds succinct tree representation.
 In: `Alvarez, C., Serna, M.J. (eds.) WEA 2006. LNCS, vol. 4007, pp.
134–145. Springer, Heidelberg (2006)

6. Ferragina, P., Manzini, G., M¨akinen, V., Navarro, G.: Compressed representations

of sequences and full-text indexes. ACM TALG (article 20) 3(2) (2007)

7. Fischer, J., Heun, V.: A new succinct representation of RMQ-information and
improvements in the enhanced suﬃx array. In: Chen, B., Paterson, M., Zhang, G.
(eds.) ESCAPE 2007. LNCS, vol. 4614, pp. 459–470. Springer, Heidelberg (2007)
8. Fischer, J., Heun, V.: Range median of minima queries, super cartesian trees, and

text indexing (2007) (manuscript),
www.bio.ifi.lmu.de/∼fischer/fische101range.pdf

9. Geary, R., Rahman, N., Raman, R., Raman, V.: A simple optimal representation

for balanced parentheses. Theoretical Computer Science 368, 231–246 (2006)

10. Gonz´alez, R., Navarro, G.: Compressed text indexes with fast locate. In: Ma, B.,
Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 216–227. Springer, Heidelberg
(2007)

11. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed text indexes. In:

Proc. 14th SODA, pp. 841–850 (2003)

12. Grossi, R., Vitter, J.: Compressed suﬃx arrays and suﬃx trees with applications to
text indexing and string matching. SIAM J. on Computing 35(2), 378–407 (2006)
13. Gusﬁeld, D.: Algorithms on Strings, Trees and Sequences: Computer Science and

Computational Biology. Cambridge University Press, Cambridge (1997)

14. Jacobson, G.: Space-eﬃcient static trees and graphs. In: Proc. 30th FOCS, pp.

549–554 (1989)

15. K¨arkk¨ainen, J., Rao, S.: Full-text indexes in external memory. In: Meyer, U.,
Sanders, P., Sibeyn, J.F. (eds.) Algorithms for Memory Hierarchies. LNCS,
vol. 2625, ch.7, pp. 149–170. Springer, Heidelberg (2003)

16. Ko, P., Aluru, S.: Optimal self-adjusting trees for dynamic string data in secondary
storage. In: Ziviani, N., Baeza-Yates, R. (eds.) SPIRE 2007. LNCS, vol. 4726, pp.
184–194. Springer, Heidelberg (2007)

17. Kurtz, S.: Reducing the space requirements of suﬃx trees. Software: Practice and

Experience 29(13), 1149–1171 (1999)

18. M¨akinen, V., Navarro, G.: Succinct suﬃx arrays based on run-length encoding.

Nordic J. of Computing 12(1), 40–66 (2005)

19. Manzini, G.: An analysis of the Burrows-Wheeler transform. J. of the ACM 48(3),

407–430 (2001)

20. Munro, I.: Tables. In: Chandru, V., Vinay, V. (eds.) FSTTCS 1996. LNCS,

vol. 1180, pp. 37–42. Springer, Heidelberg (1996)

An(other) Entropy-Bounded Compressed Suﬃx Tree

165

21. Munro, I., Raman, V., Rao, S.: Space eﬃcient suﬃx trees. J. of Algorithms 39(2),

22. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Computing Sur-

205–222 (2001)

veys (article 2) 39(1) (2007)

23. Raman, R., Raman, V., Rao, S.: Succinct indexable dictionaries with applications
to encoding k-ary trees and multisets. In: Proc. 13th SODA, pp. 233–242 (2002)
24. Russo, L., Navarro, G., Oliveira, A.: Fully-compressed suﬃx trees. In: Proc. 8th

LATIN 2008. LNCS, vol. 4957, pp. 362–373. Springer, Heidelberg (2008)

25. Sadakane, K.: New text indexing functionalities of the compressed suﬃx arrays. J.

of Algorithms 48(2), 294–313 (2003)

26. Sadakane, K.: Compressed suﬃx trees with full functionality. Theory of Computing

Systems (to appear, 2007), doi:10.1007/s00224-006-1198-x

