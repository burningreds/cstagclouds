Reducing the Space Requirement of LZ-Index(cid:2)

Diego Arroyuelo1, Gonzalo Navarro1, and Kunihiko Sadakane2

1 Dept. of Computer Science, Universidad de Chile

{darroyue, gnavarro}@dcc.uchile.cl

2 Dept. of Computer Science and Communication Engineering,

Kyushu University, Japan
sada@csce.kyushu-u.ac.jp

Abstract. The LZ-index is a compressed full-text self-index able to represent 
a text T1...u, over an alphabet of size σ = O(polylog(u)) and
with k-th order empirical entropy Hk(T ), using 4uHk(T ) + o(u log σ)
bits for any k = o(logσ u). It can report all the occ occurrences of a
pattern P1...m in T in O(m3 log σ + (m + occ) log u) worst case time. Its
main drawback is the factor 4 in its space complexity, which makes it
larger than other state-of-the-art alternatives. In this paper we present
two diﬀerent approaches to reduce the space requirement of LZ-index.
In both cases we achieve (2 + )uHk(T ) + o(u log σ) bits of space, for
any constant  > 0, and we simultaneously improve the search time to
O(m2 log m + (m + occ) log u). Both indexes support displaying any subtext 
of length (cid:4) in optimal O((cid:4)/ logσ u) time. In addition, we show how
the space can be squeezed to (1 + )uHk(T ) + o(u log σ) to obtain a
structure with O(m2) average search time for m (cid:2) 2 logσ u.

1 Introduction and Previous Work

Given a sequence of symbols T1...u (the text) over an alphabet Σ of size σ, and
given another (short) sequence P1...m (the search pattern) over Σ, the full-text
search problem consists in ﬁnding all the occ occurrences of P in T .

Applications of full-text searching include text databases in general, which
typically contain natural language texts, DNA or protein sequences, MIDI pitch
sequences, program code, etc. A central goal of modern text databases is to
provide fast access to the text using as little space as possible. Yet, these goals are
opposed: to provide fast access we must build an index on the text, increasing
the space requirement. The main motivation of using little space is to store
the indexes of very large texts entirely in main memory. This can compensate
for signiﬁcant CPU time to access them. In recent years there has been much
research on compressed text databases, focusing on techniques to represent the
text and the index using little space, yet permitting eﬃcient text searching.

A concept related to text compression is the k-th order empirical entropy of
a sequence T , denoted Hk(T ) [9]. The value uHk(T ) is a lower bound to the

(cid:3) Supported in part by CONICYT PhD Fellowship Program (ﬁrst author) and Fondecyt 
Grant 1-050493 (second author) and the Grant-in-Aid of the Ministry of Education,
 Science, Sports and Culture of Japan (third author).

M. Lewenstein and G. Valiente (Eds.): CPM 2006, LNCS 4009, pp. 318–329, 2006.
c(cid:2) Springer-Verlag Berlin Heidelberg 2006

Reducing the Space Requirement of LZ-Index

319

number of bits needed to compress T using any compressor that encodes each
symbol considering only the context of k symbols that precede it in T . It holds
0 (cid:3) Hk(T ) (cid:3) Hk−1(T ) (cid:3) ··· (cid:3) H0(T ) (cid:3) log σ (log means log2 in this paper).
The current trend on compressed text databases is compressed full-text selfindexing.
 A self-index allows searching and retrieving any part of the text without 
storing the text itself. A compressed index requires space is proportional
to the compressed text size. Then a compressed full-text self-index replaces the
text with a more space-eﬃcient representation of it, which at the same time
provides indexed access to the text. This is an unprecedented breakthrough in
text indexing and compression. Some compressed self-indexes are [16, 4, 7, 5].

The LZ-index [14] is another compressed full-text self-index, based on the
Ziv-Lempel [18] parsing of the text. If the text is parsed into n phrases by the
LZ78 algorithm, then the LZ-index takes 4n log n(1 + o(1)) bits of space, which
is 4 times the size of the compressed text, i.e. 4uHk(T ) + o(u log σ) bits, for any
k = o(logσ u) [8, 4]. The LZ-index answers queries in O(m3 log σ+(m+occ) log n)
worst case time. The index can also reproduce a context of length (cid:4) around an
occurrence found (and in fact any sequence of phrases) in O((cid:4) log σ) time, or
obtain the whole text in time O(u log σ).

However, in practice the space requirement of LZ-index is relatively large
compared with competing schemes: 1.2–1.6 times the text size versus 0.6–0.7
and 0.3–0.8 times the text size of CS-Array [16] and FM-index [4], respectively.
Yet, the LZ-index is faster to report and to display the context of an occurrence.
Fast displaying of text substrings is very important in self-indexes, as the text
is not available otherwise.

In this paper we study how to reduce the space requirement of LZ-index, using
two diﬀerent approaches. The ﬁrst one, a navigational scheme approach, consists
in reducing the redundancy among the diﬀerent data structures that conform
the LZ-index. These data structures allow us moving among data representations.
 In this part we deﬁne new data structures allowing the same navigation,
yet reducing the original redundancy. In the second approach we combine the
balanced parentheses representation of Munro and Raman [13] of the LZ78 trie
with the xbw transform of Ferragina et al. [3], whose powerful operations are
useful for the LZ-index search algorithm.

Despite these approaches are very diﬀerent, in both cases we achieve (2 +
)uHk(T )+o(u log σ) bits of space, for any constant  > 0, and we simultaneously
improve the search time to O(m2 log m + (m + occ) log n) (worst case). In both
cases we also present a version requiring (1 + )uHk(T ) + o(u log σ) bits, with
average search time O(m2) if m (cid:2) 2 logσ n. In all cases, the worst case time to
display a context of length (cid:4) around any occurrence found is optimal O((cid:4)/ logσ u).
Note that, just as LZ-index, our data structures are the only compressed fulltext 
self-indexes of size O(uHk(T )) able of spending O(log n) time per occurrence 
reported, if σ = Θ(polylog(u)). Other data structures achieving the same
or better complexity for reporting occurrences either are of size O(uH0(T )) bits
[16], or they achieve it for constant-size alphabets [4], or for quite large alphabets 
(log σ = Θ(log n)) [7, Theorem 4.1]. The case σ = O(polylog(u)), which

320

D. Arroyuelo, G. Navarro, and K. Sadakane

represents moderate-size alphabets, is very common in practice and does not
ﬁt in the above cases. Our data structures are not competitive against schemes
requiring about the same space [7, 5] for counting the number of occurrences of
P in T . Yet, in many practical situations, it is necessary to report the occurrence 
positions as well as displaying their contexts. In this aspect, LZ-index is
superior.

2 The LZ-Index Data Structure

0 . . . Br

Assume that the text T1...u has been compressed using the LZ78 [18] algorithm
into n + 1 phrases1 T = B0 . . . Bn, such that B0 = ε (the empty string); ∀k (cid:3)= (cid:4),
Bk (cid:3)= B(cid:3); and ∀k (cid:2) 1, ∃(cid:4) < k, c ∈ Σ, Bk = B(cid:3) · c. To ensure that Bn is not
a preﬁx of another Bi, we append to T a special symbol “$” (cid:3)∈ Σ, assumed to
be smaller than any other symbol. We say that i is the phrase identiﬁer corresponding 
to Bi, 0 (cid:3) i (cid:3) n. The following data structures conform the LZ-index
[14]:
LZTrie: The trie of all the phrases B0 . . . Bn. Given the properties of LZ78
compression, this trie has exactly n + 1 nodes, each corresponding to a string.
n. In this trie there could
RevTrie: The trie of all the reverse strings Br
be internal nodes not representing any phrase. We call these nodes “empty”.
Node: A mapping from phrase identiﬁers to their node in LZTrie.
Range: A data structure for two-dimensional searching in the space [0 . . . n] ×
k), pos(Bk+1)), k ∈ 0 . . . n − 1}, where
[0 . . . n]. We store the points {(revpos(Br
} and pos is the lexicographical
revpos is the lexicographic position in {Br
0 . . . Br
position in {B0 . . . Bn}. For each such point, the corresponding k value is stored.
n
Each of these four structures requires n log n(1 + o(1)) bits of space if they
are represented succinctly, for example, using the balanced parentheses representation 
[13] for the tries. For Range, a data structure of Chazelle [2] permits
two-dimensional range searching in a grid of n pairs of integers in the range
[0 . . . n] × [0 . . . n], answering queries in O((occ + 1) log n) time, where occ is
the number of occurrences reported, and requiring n log n(1 + o(1)) bits. As
n log u = uHk(T ) + O(kn log σ) (cid:3) u log σ for any k [8], the ﬁnal size of the
LZ-index is 4uHk(T ) + o(u log σ) bits for k = o(logσ u). The succinct representation 
given in the original work [14] implements (among others) the operations
parent(x) (which gets the parent of node x) and child(x, α) (which gets the child
of node x with label α ∈ Σ) both in O(log σ) time for LZTrie, and O(log σ)
and O(h log σ) time respectively for RevTrie, where h is the depth of node x
in RevTrie. The operation ancestor(x, y), which is used to ask if node x is an
ancestor of node y, is implemented in O(1) time both in LZTrie and RevTrie.
These operations are basically based on rank/select operations on bit vectors.
Given a bit vector B1...n, we deﬁne the function rank0(B, i) (similarly rank1)
as the number of 0s (1s) occurring up to the i-th position of B. The function
select0(B, i) (similarly select1) is deﬁned as the position of the i-th 0 (1) in B.
1 According to [18],

logσ u ; thus, n log u (cid:3) u log σ always holds.

√

u (cid:3) n (cid:3) u

Reducing the Space Requirement of LZ-Index

321

These operations can be supported in constant time and requiring n + o(n) bits
[11], or H0(B) + o(n) bits [15].

Let us consider now the search algorithm for a pattern P1...m [14]. We distinguish 
three types of occurrences of P in T , depending on the phrase
layout:
1. The occurrence lies inside a single phrase (there are occ1 occurrences of
this type). Given the properties of LZ78, every phrase Bk containing P is formed
by a shorter phrase B(cid:3) concatenated to a symbol c. If P does not occur at the
end of Bk, then B(cid:3) contains P as well. We want to ﬁnd the shortest possible
phrase B in the LZ78 referencing chain for Bk that contains the occurrence
of P . This phrase B ﬁnishes with the string P , hence it can be easily found
by searching for P r in RevTrie in O(m2 log σ) time. Say we arrive at node v.
(cid:3) descending from v in RevTrie (including v itself) corresponds to
Any node v
a phrase terminated with P . Thus we traverse and report all the subtree of
(cid:3). Occurrences of type 1 are located in
the LZTrie node corresponding to each v
O(m2 log σ + occ1) time;
2. The occurrence spans two consecutive phrases, Bk and Bk+1, such
that a preﬁx P1...i matches a suﬃx of Bk and the suﬃx Pi+1...m matches a
preﬁx of Bk+1 (there are occ2 occurrences of this type): P can be split at any
position, so we have to try them all. The idea is that, for every possible split,
we search for the reverse pattern preﬁx in RevTrie and for the pattern suﬃx in
LZTrie. Now we have two ranges, one in the space of reversed strings (phrases
ﬁnishing with the ﬁrst part of P ) and one in that of the normal strings (phrases
starting with the second part of P ), and need to ﬁnd the phrase pairs (k, k + 1)
such that k is in the ﬁrst range and k + 1 is in the second range. This is what
the range searching data structure is for. Occurrences of type 2 are located in
O(m3 log σ + (m + occ2) log n) time; and
3. The occurrence spans three or more phrases, Bk . . . B(cid:3), such that
Pi...j = Bk+1 . . . B(cid:3)−1, P1...i−1 matches a suﬃx of Bk and Pj+1...m matches a
preﬁx of B(cid:3) (there are occ3 occurrences of this type): For this part, the LZ78 algorithm 
guarantees that every phrase represents a diﬀerent string. Hence, there
is at most one phrase matching Pi...j for each choice of i and j. This fact severely
limits the number of occurrences of this class that may exist, occ3 = O(m2). The
idea is to identify maximal concatenations of phrases Pi...j = Bk . . . B(cid:3) contained
in the pattern, and thus determine whether Bk−1 ﬁnishes with P1...i−1 and B(cid:3)+1
starts with Pj+1...m. If this is the case we can report an occurrence. We ﬁrst
search for every pattern substring in LZTrie, in O(m2 log σ) time. Then, the
O(m2) maximal concatenations of phrases are obtained in O(m2 log m) worst
case time and O(m2) time on average. Finally, each of those maximal concatenations 
is veriﬁed in O(m log σ) time using operation parent for Bk. Overall,
occurrences of type 3 are located in O(m3 log σ) time.

Note that each of the occ = occ1 + occ2 + occ3 possible occurrences of P lies
exactly in one of the three cases above. Overall, the total search time to report
the occ occurrences of P in T is O(m3 log σ + (m + occ) log n). Finally, we can
uncompress and display the text of length (cid:4) surrounding any occurrence reported

322

D. Arroyuelo, G. Navarro, and K. Sadakane

in O((cid:4) log σ) (as long as this context spans an integral number of phrases) time,
and uncompress the whole text T in O(u log σ) time.

3 LZ-Index as a Navigation Scheme

In the practical implementation of LZ-index [14, see Tech.Report], the Range
data structure is replaced by RNode, which is a mapping from phrase identiﬁers
to their node in RevTrie. Now occurrences of type 2 are found as follows: For
1...i in RevTrie
every possible split P1...i and Pi+1...m of P , assume the search for P r
yields node vrev, and the search for Pi+1...m in LZTrie yields node vlz. Then, we
check each phrase k in the subtree of vrev and report it if N ode[k + 1] descends
from vlz. Each such check takes constant time. Yet, if the subtree of vlz has less
elements, we do the opposite: Check phrases from vlz in vrev, using RNode. Unlike
when using Range, now the time to solve occurrences of type 2 is proportional
to the smallest subtree size among vrev and vlz, which can be arbitrarily larger
than the number of occurrences reported. That is, by using RNode we have
no worst-case guarantees at search time. However, the average search time for
occurrences of type 2 is O(n/σm/2). This is O(1) for long patterns, m (cid:2) 2 logσ n.
The RNode data structure requires uHk(T ) + o(u log σ) bits, and so this version
of LZ-index also requires 4uHk(T ) + o(u log σ) bits, for any k = o(logσ u).

Both LZTrie and RevTrie use originally the balanced parentheses representation 
[13], in which every node, represented by a pair of opening and closing
parentheses, encloses its subtree. When we replace Range by RNode structure,
the result is actually a “navigation” scheme that permits us moving back and
forth from trie nodes to the corresponding preorder positions2, both in LZTrie
and RevTrie. The phrase identiﬁers are common to both tries and permit moving
from one trie to the other.

Figure 1 (left) shows the navigation scheme. Dashed arrows are asymptotically
“for free” in terms of memory, since they are followed by applying rank on the
corresponding parentheses structure. The other four arrows are in fact the four
main components in the space usage of the index: Array of phrase identiﬁers in
LZTrie (ids) and in RevTrie (rids), and array of LZTrie nodes for each phrase
(Node) and RevTrie nodes for each phrase (RNode). The structure is symmetric
and we can move from any point to any other.

The structure, however, is redundant, in the sense that the number of arrows
is not minimal. We start by deﬁning the following reduced scheme for LZ-index:
LZTrie: The Lempel-Ziv trie, implemented with the following data structures:
- par0...2n and lets: The tree shape of LZTrie according to the dfuds representation 
[1], which requires 2n + n(cid:6)log σ(cid:7) + o(n) + O(log log σ) bits to support
the operations parent(x), child(x, α), subtree size (including the root of the sub-
tree), and node degree, all of them in O(1) time. It also supports the operation

2 In the representation [13], the preorder position of a node is the number of opening
parentheses before the one representing the node. This is rank0 at the node position
in the bit sequence representing the parentheses, if bit 1 represents ‘)’.

Reducing the Space Requirement of LZ-Index

323

child(x, i) in constant time, which gets the i-th child of node x. To get this representation,
 we perform a preorder traversal on the trie, and for every node reached
we write its degree in unary using parentheses (for example, 3 reads ‘((()’ and
it is writen ‘0001’), What we get is almost a balanced parentheses representation
(we only need to add a ﬁctitious ‘(’ at the beginning of the sequence). A node
of degree d is represented by the position of the ﬁrst of the (d + 1) parentheses
corresponding to the node. Given a node in this representation, say at position
i, its preorder position can be computed by rank1(par, i). Given a preorder position 
p, the corresponding node is computed by select1(par, p) + 1. With this
representation we can compute all the operations required by LZTrie [14] in
O(1) time, including ancestor(x, y) 3. The symbols labeling the arcs of the trie
are represented implicitly. We denote by lets(i) the symbol corresponding to the
node at position select0(par, i) + 1 (i.e., the symbol with preorder position i),
which is computed in constant time.

- ids0...n: The array of LZ78 phrase identiﬁers in preorder. We use the rep-
−1

resentation of Munro et al. [12] for ids such that the inverse permutation ids
can be computed in O(1/) time, requiring (1 + )n log n bits4.
RevTrie: The PATRICIA tree [10] of the reversed LZ78 phrases, which is implemented 
with the following data structures

- rpar0...2n(cid:2) and rlets: The RevTrie structure represented using dfuds [1],
(cid:3) (cid:3) 2n nodes, because empty
compressing empty unary paths and thus ensuring n
(cid:3)) +
non-unary nodes still exist. The space requirement is 2n
O(log log σ) bits to support the same functionalities as LZTrie. - B0...n(cid:2): A bit
(cid:3)(1 + o(1)) bits [11].
vector supporting rank and select queries, and requiring n
The j-th bit of B is 1 iﬀ the node with preorder position j in rpar is not an
empty node, otherwise the bit is 0. Given a position p in rpar corresponding to
a RevTrie node, the corresponding bit in B is B[rank1(rpar, p)].

(cid:3)(cid:6)log σ(cid:7) + o(n

(cid:3) + n

- R0...n: A mapping from RevTrie preorder positions to LZTrie preorder po-
−1(rids[i]). R is implemented using the succinct
sitions deﬁned as R[i] = ids
data structure for permutations of Munro et al. [12], requiring (1 + )n log n
−1 in O(1/) worst-case time. Given a pobits 
to represent R and compute R
sition i in rpar corresponding to a RevTrie node, the corresponding R value is
R[rank1(B, rank1(rpar, i))].

- skips0...n(cid:2): The PATRICIA tree skips of the nodes in preorder, using log log u
bits per node and inserting empty unary nodes when the skip exceeds log u. In
this way, one out of log u empty unary nodes could be explicitly represented.
In the worst case there are O(u) empty unary nodes, of which O(u/ log u)
(cid:3), which translates into
are explicitly represented. This adds O(u/ log u) to n
O( u(log σ+log log u)

) = o(u log σ) bits overall.

Fig. 1 (right) shows the resulting navigation scheme. The search algorithm
remains the same since we can map preorder positions to nodes in the new rep3 
As ancestor(x, y) ≡ rank1(par, x) (cid:3) rank1(par, y) (cid:3) rank1(par, x) +
subtreesize(par, x) − 1.
4 This data structure ensures that one ﬁnds the inverse after following the permutation

log u

O(1/) times.

324

D. Arroyuelo, G. Navarro, and K. Sadakane

node in
LZTrie

rank

position in
LZTrie

Node

RNode

phrase
identifier

ids

rids

node in
RevTrie

rank

position in
RevTrie

node in
LZTrie

select

rank

−1

ids

phrase
identifier

node in
RevTrie
rank

select

position in
LZTrie

ids

R
R−1

position in
RevTrie

Fig. 1. The original (left) and the reduced (right) navigation structures over index
components

resentation of the tries (and vice versa), and we can simulate rids[i] = ids[R[i]],
−1
RN ode[i] = select1(rpar, R
(i)) +1, all of which take constant time.

−1(i))) + 1, and N ode[i] = select1(par, ids

−1(ids

The space requirement is (2+)n log n+3n log σ+2n log log u+8n+o(u log σ) =
(2+)n log n+o(u log σ) bits if log σ = o(log u). As n log u = uHk(T )+O(kn log σ)
for any k [8], the space requirement is (2 + )uHk(T ) + o(u log σ) bits, for any
k = o(logσ u). The child operation on RevTrie can now be computed in O(1) time,
versus the O(h log σ) time of the original LZ-index [14]. Hence, the occ occurrences
of P can be reported in O( m2
Reducing Further. To simplify notation, given a LZTrie node with preorder
position R[i], suppose that operation parent(R[i]) gives the preorder position of
its parent.

σm/2 ) average time, for 0 <  < 1.

 + n

−1(parent(R[i])).

Deﬁnition 1. We deﬁne function ϕ as ϕ(i) = R
That is, let ax (a ∈ Σ) be the i-th string in RevT rie. Then, ϕ(i) = j, where
the j-th string in RevT rie is x. Thus ϕ is a suﬃx link function in RevT rie. As
xRa must be a LZT rie phrase, by the LZ78 parsing it follows that xR is also a
LZT rie phrase and thus x is a RevT rie phrase. Hence, every non-empty node
in RevT rie has a suﬃx link.

Let us show how to compute R using only ϕ. We deﬁne array L1...n such that
L[i] = lets(R[i]). As L[i] is the ﬁrst character of the i-th string in RevTrie, we
have that L[i] (cid:3) L[j] whenever i (cid:3) j, and L can be divided into σ runs of equal
(cid:3) of σ log σ bits and a bit vector
symbols. Thus L can be represented by an array L
LB of n + o(n) bits, such that LB[i] = 1 iﬀ L[i] (cid:3)= L[i − 1], for i = 2 . . . n, and
LB[1] = 0 (this position belongs to the text terminator “$”). For every i such
(cid:3)[rank1(LB, i)] = L[i]. Hence, L[i] can be computed
that LB[i] = 1, we store L
(cid:3)[rank1(LB, i)] in O(1) time. To simplify the notation assume that, given a
as L
LZTrie position R[i], operation child(R[i], α) yields the LZTrie preorder position
belonging to the child (by symbol α) of the node corresponding to R[i].
Lemma 1. Given 0 (cid:3) i (cid:3) n, the value R[i] can be computed by the following
recurrence:

(cid:2)

R[i] =

child(R[ϕ(i)], L[i]) if i (cid:3)= 0
if i = 0
0

Reducing the Space Requirement of LZ-Index

325

Proof. R[0] = 0 holds from the fact that the preorder position corresponding
to the empty string, both in LZTrie and RevTrie, is 0. To prove the other
part we note that if x is the parent in LZTrie of node y with preorder position 
R[i], then the symbol labeling the arc connecting x to y is L[i]. That is,
child(parent(R[i]), L[i]) = R[i]. The lemma follows from this fact and replacing
(cid:8)(cid:9)
ϕ(i) by its deﬁnition (Def. 1) in the recurrence.
As in the case of function Ψ of Compressed Suﬃx Arrays [16], we can prove the
following lemma for function ϕ, which is the key to compress R.
Lemma 2. For every i < j, if lets(R[i]) = lets(R[j]), then ϕ(i) < ϕ(j).
Proof. Let strr(i) denote the i-th string in the lexicographically sorted set of
reversed strings. Note that strr(i) < strr(j) iﬀ i < j. If i < j and lets(R[i]) =
lets(R[j]) (i.e., strr(i) and strr(j) start with the same symbol, as their reverses
end with the same symbol), then strr(ϕ(i)) < strr(ϕ(j)) (as strr(ϕ(i)) is strr(i)
(cid:8)(cid:9)
without its ﬁrst symbol), and thus ϕ(i) < ϕ(j).
Corollary 1. ϕ can be partitioned into at most σ strictly increasing sequences.
(cid:3), and use them to compute a given value
As a result, we replace R by ϕ, LB and L
R[i]. According to Lemma 1, we can represent ϕ using the idea of Sadakane [16],
requiring nH0(lets) + O(n log log σ) bits and allowing to access ϕ(i) in constant
time, and hence we replace the n log n-bit representation of R by the nH0(lets) +
O(n log log σ) + n + O(σ log σ) + o(n) bits representation of ϕ, LB and L
The time to compute R[i] is now O(|strr(i)|), which actually corresponds to
traversing LZTrie from the root with the symbols of strr(i) in reverse order.
(cid:3), plus a bit vector RB of n + o(n)
But we can store n values of R in an array R
bits indicating which values of R have been stored, ensuring that R[i] can be
computed in O(1/) time and requiring n log n extra bits. To determine the R
values to be explicitly stored, for each LZTrie leaf we traverse the upward path
to the root, marking one out of O(1/) nodes, and stopping the procedure for
the current leaf when we reach the root or when we reach an already marked
−1(j)] = 1.
node. If the node to mark is at preorder position j, then we set RB[R
After we mark the positions of R to be stored, we scan RB sequentially from
(cid:3)[rank1(RB, i)] = R[i].
left to right, and for every i such that RB[i] = 1, we set R
Then, we free R since R[i] can be computed by:

(cid:3).

(cid:2)

R[i] =

child(R[ϕ(i)], L
(cid:3)[rank1(RB, i)]
R

(cid:3)[rank1(LB, i)]) if RB[i] = 0
if RB[i] = 1

−1 before freeing R can be used

Note that the same structure used to compute R
under this scheme, with cost O(1/2) (recall footnote 6).
Theorem 1. There exists a compressed full-text self-index requiring (1 + )
uHk(T ) + o(u log σ) bits of space, for σ = O(polylog(u)), any k = o(logσ u)
and any constant 0 <  < 1, and able to report the occ occurrences of a pattern 
P1...m in a text T1...u in O( m2
2σm/2 ) average time, which is O(m2) if
m (cid:2) 2 logσ n. It can also display a text substring of length (cid:4) in O((cid:4)(1 + 1
 logσ (cid:3) ))
worst-case time.

2 + n

326

D. Arroyuelo, G. Navarro, and K. Sadakane

The bound O((cid:4)(1 + 1
 logσ (cid:3) ) in the displaying time holds from the fact that we
−1 each time we
perform (cid:4) parent operations, and we must pay O(1/) to use ids
pass to display the next (previous) phrase, which in the (very) worst case is done
O((cid:4)/ logσ (cid:4)) times. We still assume that these (cid:4) symbols form whole phrases.

We can get worst case guarantees in the search process by adding Range, the
two-dimensional range search data structure deﬁned in Section 2. Occurrences
of type 2 can now be solved in O(m2 + (m + occ) log n) time.

Theorem 2. There exists a compressed full-text self-index requiring (2 + )
uHk(T ) + o(u log σ) bits of space, for σ = O(polylog(u)), any k = o(logσ u)
and any constant 0 <  < 1, and able to report the occ occurrences of a pattern 
P1...m in a text T1...u in O(m2(log m + 1
 ) =
O(m2 log m + (m + occ) log n) worst-case time. It can also display a text substring 
of length (cid:4) in O((cid:4)(1 + 1

2 ) + (m + occ) log n + occ

 logσ (cid:3))) worst-case time.

4 Using the xbw Transform to Represent LZTrie

A diﬀerent idea to reduce the space requirement of LZ-index is to use the xbw
transform of Ferragina et al. [3] to represent the LZTrie. This succinct representation 
supports the operations parent(x), child(x, i), and child(x, α), all of
them in O(1) time and using 2n log σ + O(n) bits of space. The representation
also allows subpath queries, a very powerful operation which, given a string s,
returns all the nodes x such that s is a suﬃx of the string represented by x. We
represent LZ-index with the following data structures:

Balanced parentheses LZTrie: The trie of the Lempel-Ziv phrases, storing
- par : The balanced parentheses representation [13] of LZTrie. In order to
index the LZTrie leaves with xbw, we have to add a dummy child to each. In
(cid:3) (cid:3) 2n nodes. The space requirement is 4n + o(n) bits in
this way, the trie has n
the worst case if we use the Munro and Raman representation [13]. We use the
bit 0 to represent ‘(’ and 1 to represent ‘)’. In this way, the preorder position of
a node is computed by a rank0 query, and the node corresponding to a preorder
position by a select0 query, both in O(1) time.

- ids : The array of LZ78 phrase identiﬁers in preorder, represented by the data
structure of Munro et al. [12], such that we can compute the inverse permutation
−1 in O(1/) time, requiring (1 + )n log n bits.
ids
xbw LZTrie: The xbw representation [3] of the LZTrie, where the nodes are
lexicographically sorted according to their upward paths in the trie. We store

- Sα : The array of symbols labeling the arcs of the trie. In the worst case
LZTrie has 2n nodes (because of the dummy leaves we add), and then this array
requires 2n log σ bits.

- Slast : A bit array such that Slast[i] = 1 iﬀ the corresponding node in LZTrie

is the last child of its parent. The space requirement is 2n(1 + o(1)) bits.
Pos: A mapping from xbw positions to the corresponding preorder positions.
In the worst case there are 2n such positions, and so the space requirement is

Reducing the Space Requirement of LZ-Index

327

2n log (2n) bits. We can reduce this space to n log (2n) bits by storing in an
(cid:3) one out of O(1/) values of P os, such that P os[i] can be computed
array P os
in O(1/) time. We need a bit vector P osB of 2n(1 + o(1)) bits indicating which
values of P os have been stored. Assume we need compute P os[i], for a given
(cid:3)[rank1(P osB, i)].
xbw position i. If P osB[i] = 1, then such value is stored at P os
Otherwise, we simulate a preorder traversal in xbw from node at xbw position
i, until P osB[j] = 1, for a xbw position j. Once this j is found, we map to
(cid:3)[rank1(P osB, j)]. If d is the number of steps
the preorder position j
(cid:3) − d is the
in preorder traversal from xbw position i to xbw position j, then j
preorder position corresponding to the node at xbw position i. We also need to
−1, which can be done in O(1/2) time under this scheme, requiring
compute P os
n log (2n) extra bits if we use the representation of [12].
Range: A range search data structure in which we store the point k (belonging
to phrase identiﬁer k) at coordinate (x, y), where x is the xbw position of phrase
k and y is the preorder position of phrase k + 1. We use the data structure of
Chazelle [2] requiring n log n(1 + o(1)) bits, as for the original LZ-index.

(cid:3) = P os

The total space requirement is (2+)n log n(1+o(1))+2n log σ+(8+)n+o(n)
bits, which is (2+)uHk(T )+o(u log σ) bits if log σ = o(log u) and k = o(logσ u).
We depict now the search algorithm for pattern P . For occurrences of type
1, we perform a subpath query for P to obtain the interval [x1, x2] in the xbw
of LZTrie corresponding to all the nodes whose phrase ends with P . For each
position i ∈ [x1, x2], we can get the corresponding node in the parentheses
representation using select0(par, P os[i]), and then we traverse the subtrees of
these nodes and report all the identiﬁers found, as done with the usual LZ-index.
To solve occurrences of type 2, for every possible partition P1...i and Pi+1...m
of P , we traverse the xbw from the root, using operation child(x, α) with the
symbols of Pi+1...m. Once this is found, say at xbw position i, we switch to
the preorder tree (parentheses) using select0(par, P os[i]), to get the node vlz
whose subtree has the preorder interval [y1, y2] of all the nodes that start with
Pi+1...m. Next we perform a subpath query for P1...i in xbw, and get the xbw
interval [x1, x2] of all the nodes that ﬁnish with P1...i (we have to replace xr ←
rank1(Slast, xr) to avoid counting the same node multiple times, see [3]). Then,
we search structure Range for [x1, x2]×[y1, y2] to get all phrase identiﬁers k such
that phrase k ﬁnishes with P1...i and phrase k + 1 starts with Pi+1...m.

For occurrences of type 3, one could do mostly as with the original LZTrie
(navigating the xbw instead), so as to ﬁnd all the nodes equal to substrings
of P in O(m2) time. Then, for each maximal concatenation of phrases Pi...j =
Bk+1 . . . B(cid:3)−1 we must check that phrase B(cid:3) starts with Pj+1...m and that phrase
Bk ﬁnishes with P1...i−1. The ﬁrst check can be done in constant time using
−1. As we have searched for all substrings of P in the trie, we know the
ids
preorder interval of descendants of Pj+1...m, thus we check whether the node at
−1((cid:4)) belongs to that interval. The second check can also
preorder position ids
be done in constant time, by determining whether k is in the xbw interval of
−1(k)).
P1...i−1 (that is, Bk ﬁnishes with P1...i−1). The xbw position is P os

−1(ids

328

D. Arroyuelo, G. Navarro, and K. Sadakane

To display the text around an occurrence, we use ids

−1 to ﬁnd the preorder
position of the corresponding phrase, and then we use parent on the parentheses
to ﬁnd the symbols in the upward path. To know the symbol, we have to use
P os

−1 to go to the xbw position and read Sα.
For the search time, occurrences of type 1 cost O(m + occ/), type 2 cost
O(m2 + m/ + m(occ + log n)), and type 3 cost O(m2(log m + 1
2 )). Thus, we
have achieved Theorem 2 again with radically diﬀerent means. The displaying
time is O((cid:4)/2), but it can also become O((cid:4)(1 + 1
 logσ (cid:3) )) if we store the array of
symbols in the balanced parentheses LZTrie, which adds o(u log σ) bits of space.
We can get a version requiring (1+)uHk(T )+o(u log σ) bits and O(m2) average
reporting time if m (cid:2) 2 logσ n (as in Theorem 1) if we solve occurrences of type
2 similarly as we handled occurrences of type 3, and dropping Range.

5 Displaying Text Substrings

LZ-index is able to report occurrences in the format (k, oﬀset), where k is the
phrase in which the occurrence starts and oﬀset is the distance between the
beginning of the occurrence and the end of the phrase. However, we can report 
occurrences as text positions by adding a bit vector V1...u that marks the
n phrase beginnings. Then rank1(V, i) is the phrase number i belongs to, and
select1(V, j) is the text position of the j-th phrase. Such V can be represented
with H0(V ) + o(u) (cid:3) n log (u/n) + o(u) (cid:3) n log log u + o(u) = o(u log σ) bits
[15]. We can also add, to both proposed indexes, an operation for displaying a
subtext Ti...i+(cid:3)−1 for any given position i, in optimal O((cid:4)/ logσ u) time.

A compressed data structure [17] to display any text substring of length
Θ(logσ u) in constant time, turns out to have similarities with LZ-index. We
take advantage of this similarity to plug it within our index, with some modiﬁcations,
 and obtain improved time to display text substrings. They proposed
auxiliary data structures of o(u log σ) bits to LZTrie to support this operation
eﬃciently. Given a position i of the text, we ﬁrst ﬁnd the phrase including the
position i by using rank1(V, i), then ﬁnd the node of LZTrie that corresponds to
−1. Then displaying a phrase is equivalent to outputting the
the phrase using ids
path going from the node to the root of LZTrie. The auxiliary data structure,
of size O(n log σ) = o(u log σ) bits, permits outputting the path by chunks of
Θ(logσ u) symbols in O(1) time per chunk. In addition, we can now display not
only whole phrases, but any text substring within this complexity. The reason
is that any preﬁx of a phrase is also a phrase, and it can be found in constant
time by using a level-ancestor query [6] on the LZTrie.

We modify this method to plug into our indexes. In their original method
[17], if more than one consecutive phrases have length less than (logσ u)/2 each,
their phrase identiﬁers are not stored. Instead the substring of the text including
those phrases are stored without compression. This guarantees eﬃcient displaying 
operation without increasing the space requirement. However this will cause
the problem that we cannot ﬁnd patterns including those phrases. Therefore in
our modiﬁcation we store both the phrases themselves and their phrase identiﬁers.
 The search algorithm remains as before. To decode short phrases we can

Reducing the Space Requirement of LZ-Index

329

just output the explicitly stored substring including the phrases. For each phrase
√
with length at most (logσ u)/2, we store a substring of length log u containing
√
the phrase. Because there are at most O(
u) such phrases, we can store the subu 
log u) = o(u) bits. These auxiliary structures work as long as
strings in O(
we can convert a phrase identiﬁer into a preorder position in LZtrie in constant
time. Hence they can be applied to all the data structures in Sections 3 and 4.
Theorem 3. The indexes of Theorem 1 and Theorem 2 (and those of Section 4)
can be adapted to display a text substring of length (cid:4) surrounding any text position 
in optimal O(

logσ u ) worst case-time.

(cid:3)

References

1. D. Benoit, E. Demaine, I. Munro, R. Raman, V. Raman, and S.S. Rao.

Representing trees of higher degree. Algorithmica, 43(4):275–292, 2005.

2. B. Chazelle. A functional approach to data structures and its use in multidimensional 
searching. SIAM J. on Computing, 17(3):427–462, 1988.

3. P. Ferragina, F. Luccio, G. Manzini, and S. Muthukrishnan. Structuring labeled

trees for optimal succinctness, and beyond. Proc. FOCS, pp. 184–196, 2005.

4. P. Ferragina and G. Manzini.

Indexing compressed texts.

J. of the ACM

54(4):552–581, 2005.

5. P. Ferragina, G. Manzini, V. M¨akinen, and G. Navarro. An alphabet-friendly
FM-index. Proc. SPIRE, LNCS 3246, pp. 150–160, 2004. Extended version to
appear in ACM TALG.

6. R. Geary, R. Raman, and V. Raman. Succinct ordinal trees with level-ancestor

queries. Proc. SODA, pp. 1–10, 2004.

7. R. Grossi, A. Gupta, and J. S. Vitter. High-order entropy-compressed text

indexes. Proc. SODA, pp. 841–850, 2003.

8. R. Kosaraju and G. Manzini. Compression of low entropy strings with Lempel-Ziv

algorithms. SIAM J. on Computing, 29(3):893–911, 1999.

9. G. Manzini. An analysis of the Burrows-Wheeler transform. J. of the ACM

48(3):407–430, 2001.

10. D. R. Morrison. Patricia – practical algorithm to retrieve information coded in

alphanumeric. J. of the ACM 15(4):514–534, 1968.

11. I. Munro. Tables. Proc. FSTTCS, LNCS 1180, pp. 37–42, 1996.
12. I. Munro, R. Raman, V. Raman, and S.S. Rao.

Succinct representations of

permutations. Proc. ICALP, LNCS 2719, pp. 345–356, 2003.

13. J. I. Munro and V. Raman. Succinct Representation of Balanced Parentheses and

14. G. Navarro.

Static Trees. SIAM J. on Computing, 31(3):762–776, 2001.
Indexing text using the Ziv-Lempel trie.

Journal of Discrete
Algorithms (JDA), 2(1):87–114, 2004. See also TR/DCC-2003-0, Dept. of CS, U.
Chile. ftp://ftp.dcc.uchile.cl/pub/users/gnavarro/jlzindex.ps.gz.

15. R. Raman, V. Raman, and S. Rao. Succinct indexable dictionaries with applications 
to encoding k-ary trees and multisets. Proc. SODA, pp. 233–242, 2002.

16. K. Sadakane. New Text Indexing Functionalities of the Compressed Suﬃx Arrays.

J. of Algorithms, 48(2):294–313, 2003.

17. K. Sadakane and R. Grossi. Squeezing Succinct Data Structures into Entropy

Bounds. Proc. SODA, pp. 1230–1239, 2006.

18. J. Ziv and A. Lempel. Compression of individual sequences via variable–rate

coding. IEEE Trans. Information Theory, 24(5):530–536, 1978.

