176 C

Compressed Text Indexing

Theorem 4 (Grossi, Gupta, and Vitter 2003 [2]) The
Compressed Suﬃx Array of Grossi, Gupta, and Vitter is
a self-index occupying 1
(cid:2) nHk + o(n log (cid:3)) bits, and supporting 
retrieval of values A[i] and A(cid:2)1[j] in O(log1+(cid:2) n) time,
counting of pattern occurrences in O(m log (cid:3) + log2+(cid:2) n)
time, and displaying any substring of T of length ` in
O(`/ log(cid:12) n + log1+(cid:2) n) time. Here 0 < (cid:2)  1 is an arbitrary 
constant, k  ˛ log(cid:12) n for some constant 0 < ˛ < 1.
In the above, value k must be ﬁxed before building the index.
 Later, they notice that a simple coding of (cid:17)-values
yields the same nHk bound without the need of ﬁxing k
beforehand [1].

Finally, compressed suﬃx arrays work as building
blocks to solve other CFTI problems. For example,
Sadakane [11] has created a fully functional compressed
suﬃx tree by plugging in the compressed suﬃx array
and the space-eﬃcient suﬃx tree of Munro, Raman, and
Rao [8]. This compressed suﬃx tree occupies O(n log (cid:3))
bits of space, simulating all suﬃx tree operations with at
most O(log n) slowdown.

Applications
The application domains are the same as for the classical 
suﬃx arrays and trees, with the additional advantage
of scaling up to signiﬁcantly larger data sets.

URL to Code
See the corresponding Compressed Text Indexing entry
for references to compressed suﬃx array implementations
and http://www.cs.helsinki.ﬁ/group/suds/cst for an implementation 
of Sadakane’s compressed suﬃx tree.

Cross References
(cid:2) Compressed Text Indexing
(cid:2) Sequential Exact String Matching
(cid:2) Text Indexing

Recommended Reading
1. Foschini, L., Grossi, R., Gupta, A., Vitter, J.S.: When indexing
equals compression: Experiments with compressing suffix arrays 
and applications. ACM Trans. Algorithms 2(4), 611–639
(2006)

2. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed
In: Proc. 14th Annual ACM-SIAM Symposium
text indexes.
on Discrete Algorithms (SODA), Baltimore, 12–14 January,
pp. 841–850 (2003)

3. Grossi, R., Vitter, J.: Compressed suffix arrays and suffix trees
with applications to text indexing and string matching. SIAM
J. Comput. 35(2), 378–407 (2006)

4. Jacobson, G.: Space-efficient static trees and graphs. In: Proc.
30th IEEE Symposium on Foundations of Computer Science
(FOCS), Research Triangle Park, 30 October – 1 November,
pp. 549–554 (1989)

5. Manber, U., Myers, G.: Suffix arrays: a new method for on-line

string searches. SIAM J. Comput. 22(5), 935–948 (1993)

6. Manzini, G.: An analysis of the Burrows-Wheeler transform.

J. ACM 48(3), 407–430 (2001)

7. Munro,

I.: Tables.

In: Proc. 16th Conference on Foundations 
of Software Technology and Theoretical Computer Science 
(FSTTCS). LNCS, vol. 1180, Hyderabad, 18–20 December,
pp. 37–42 (1996)

8. Munro, I., Raman, V., Rao, S.: Space efficient suffix trees. J. Algorithms 
39(2), 205–222 (2001)

9. Navarro, G., Mäkinen, V.: Compressed full-text indexes. ACM

Comput. Surv. 39(1), Article 2 (2007)

10. Sadakane, K.: New text indexing functionalities of the compressed 
suffix arrays. J. Algorithms 48(2), 294–313 (2003)

11. Sadakane, K.: Compressed suffix trees with full functionality.

Theor. Comput. Syst. 41, 589–607 (2007)

Compressed Text Indexing
2005; Ferragina, Manzini
VELI MÄKINEN1, GONZALO NAVARRO2
1 Department of Computer Science,

University of Helsinki, Helsinki, Finland

2 Department of Computer Science,
University of Chile, Santiago, Chile

Keywords and Synonyms
Space-eﬃcient text indexing; Compressed full-text indexing;
 Self-indexing

Problem Definition
Given a text string T = t1t2 : : : tn over an alphabet ˙ of
size (cid:3), the compressed text indexing (CTI) problem asks to
replace T with a space-eﬃcient data structure capable of
eﬃciently answering basic string matching and substring
queries on T. Typical queries required from such an index
are the following:
(cid:7) count(P): count how many times a given pattern string
(cid:7) locate(P): return the locations where P occurs in T.
(cid:7) display(i, j): return T[i; j].

P = p1p2 : : : pm occurs in T.

Key Results
An elegant solution to the problem is obtained by exploiting 
the connection of Burrows-Wheeler Transform
(BWT) [1] and Suﬃx Array data structure [9]. The sufﬁx 
array SA[1; n] of T is the permutation of text positions 
(1 : : : n) listing the suﬃxes T[i; n] in lexicographic

order. That is, T[SA[i]; n] is the ith smallest suﬃx. The
BWT is formed by (1) a permutation Tbwt of T deﬁned
as Tbwt[i] = T[SA[i] (cid:2) 1], where T[0] = T[n], and (2) the
number i(cid:4) = SA(cid:2)1[1].

A property of the BWT is that symbols having the same
context (i. e., string following them in T) are consecutive in
Tbwt. This makes it easy to compress Tbwt achieving space
close to high-order empirical entropies [10]. On the other
hand, the suﬃx array is a versatile text index, allowing for
example O(m log n) time counting queries (using two binary 
searches on SA) after which one can locate the occurrences 
in optimal time.

Ferragina and Manzini [3] discovered a way to combine 
the compressibility of the BWT and the indexing
properties of the suﬃx array. The structure is essentially
a compressed representation of the BWT plus some small
additional structures to make it searchable.

We ﬁrst focus on retrieving arbitrary substrings from
this compressed text representation, and later consider
searching capabilities. To retrieve the whole text from the
structure (that is, to support display(1; n)), it is enough
to invert the BWT. For this purpose, let us consider a table
LF[1; n] deﬁned such that if T[i] is permuted to Tbwt[j]
and T[i (cid:2) 1] to Tbwt[j0] then LF[j] = j0. It is then immediate 
that T can be retrieved backwards by printing
Tbwt[i(cid:4)] (cid:3) Tbwt[LF[i(cid:4)]] (cid:3) Tbwt[LF[LF[i(cid:4)]]] : : : (by deﬁnition 
Tbwt[i(cid:4)] corresponds to T[n]).

To represent array LF space-eﬃciently, Ferragina and
Manzini noticed that each LF[i] can be expressed as fol-
lows:
Lemma 1 (Ferragina and Manzini 2005 [3]) LF[i] =
C(c) + rankc(i), where c = Tbwt[i], C(c) tells how many
times symbols smaller than c appear in Tbwt and rankc(i)
tells how many times symbol c appears in Tbwt[1; i].
General display(i, j) queries rely on a regular sampling
of the text. Every text position of the form j0 (cid:3) s, being s
the sampling rate, is stored together with SA(cid:2)1[j0 (cid:3) s], the
suﬃx array position pointing to it. To solve display(i, j)
we start from the smallest sampled text position j0 (cid:3) s > j
and apply the BWT inversion procedure starting with
SA(cid:2)1[j0 (cid:3) s] instead of i*. This gives the characters in reverse 
order from j0 (cid:3) s (cid:2) 1 to i, requiring at most j (cid:2) i + s
steps.

that

It also happens that the very same two-part expression 
of LF[i] enables eﬃcient count(P) queries.
The idea is
the
suﬃx array, say SA[spi ; epi], such that
the suﬃxes
T[SA[spi ]; n]; T[SA[spi + 1]; n]; : : : ; T[SA[epi ]; n] are
the only ones containing P[i; m] as a preﬁx, then one
can compute the new range SA[spi(cid:2)1; epi(cid:2)1] where

if one knows

the range of

Compressed Text Indexing

C 177

the suﬃxes contain P[i (cid:2) 1; m] as a preﬁx, as fol-
lows: spi(cid:2)1 = C(P[i (cid:2) 1]) + rankP[i(cid:2)1](spi (cid:2) 1) + 1 and
epi(cid:2)1 = C(P[i (cid:2) 1]) + rankP[i(cid:2)1](epi). It is then enough
to scan the pattern backwards and compute values C() and
rankc() 2m times to ﬁnd out the (possibly empty) range
of the suﬃx array where all the suﬃxes start with the complete 
P. Returning ep1 (cid:2) sp1 + 1 solves the count(P) query
without the need of having the suﬃx array available at all.
For locating each such occurrence SA[i], sp1  i 
ep1, one can compute the sequence i, LF[i], LF[LF[i]],
: : :, until LF k[i] is a sampled suﬃx array position and thus
it is explicitly stored in the sampling structure designed for
display(i, j) queries. Then SA[i] = SA[LF k[i]] + k. As we
are virtually moving sequentially on the text, we cannot do
more than s steps in this process.

Now consider the space requirement. Values C() can
be stored trivially in a table of (cid:3) log2 n bits. Tbwt[i] can
be computed in O((cid:3)) time by checking for which c is
rankc(i) 6= rankc(i (cid:2) 1). The sampling rate can be chosen 
as s = (cid:9)(log1+(cid:2) n) so that the samples require o(n)
bits. The only real challenge is to preprocess the text for
rankc() queries. This has been a subject of intensive research 
in recent years and many solutions have been proposed.
 The original proposal builds several small partial
sum data structures on top of the compressed BWT, and
achieves the following result:
Theorem 2 (Ferragina and Manzini 2005 [3]) The
CTI problem can be solved using a so-called FMIndex 
(FMI), of size 5nHk + o(n log (cid:3)) bits, that supports
count(P) in O(m) time, locate(P) in O((cid:3) log1+(cid:2) n) time
per occurrence, and display(i, j) in O((cid:3)(j (cid:2) i + log1+(cid:2) n))
time. Here Hk is the kth order empirical entropy of
T, (cid:3) = o(log n/ log log n), k  log(cid:12) (n/ log n) (cid:2) !(1), and
(cid:2) > 0 is an arbitrary constant.
The original FM-Index has a severe restriction on the alphabet 
size. This has been removed in follow-up works.
Conceptually, the easiest way to achieve a more alphabetfriendly 
instance of the FM-index is to build a wavelet
tree [5] on Tbwt. This is a binary tree on ˙ such that
each node v handles a subset S(v) of the alphabet, which
is split among its children. The root handles ˙ and each
leaf handles a single symbol. Each node v encodes those
positions i so that Tbwt[i] 2 S(v). For those positions,
node v only stores a bit vector telling which go to the left,
which to the right. The node bit vectors are preprocessed
for constant time rank1() queries using o(n)-bit data structures 
[6, 12]. Grossi et al. [4] show that the wavelet tree
built using the encoding of [12] occupies nH0 + o(n log (cid:3))
bits. It is then easy to simulate a single rankc() query by
log2 (cid:3) rank1() queries. With the same cost one can obtain

178 C

Compressing Integer Sequences and Sets

Tbwt[i]. Some later enhancements have improved the time
requirement, so as to obtain, for example, the following re-
sult:
Theorem 3 (Mäkinen and Navarro 2005 [7]) The CTI
problem can be solved using a so-called Succinct Suﬃx
Array (SSA), of size nH0 + o(n log (cid:3)) bits, that supports
count(P) in O(m(1 + log (cid:3)/ log log n)) time, locate(P) in
O(log1+(cid:2) n log (cid:3)/ log log n) time per occurrence, and dis-
play(i, j) in O((j (cid:2) i + log1+(cid:2) n) log (cid:3)/ log log n) time. Here
H0 is the zero-order entropy of T, (cid:3) = o(n), and (cid:2) > 0 is an
arbitrary constant.
Ferragina et al. [2] developed a technique called compression 
boosting that ﬁnds an optimal partitioning of Tbwt
such that, when one compresses each piece separately using 
its zero-order model, the result is proportional to the
kth order entropy. This can be combined with the idea of
SSA by building a wavelet tree separately for each piece
and some additional structures in order to solve global
rankc() queries from the individual wavelet trees:
Theorem 4 (Ferragina et al. [4]) The CTI problem can
be solved using a so-called Alphabet-Friendly FM-Index
(AF-FMI), of size nHk + o(n log (cid:3)) bits, with the same time
complexities and restrictions of SSA with k  ˛ log(cid:12) n, for
any constant 0 < ˛ < 1.
A very recent analysis [8] reveals that the space of the plain
SSA is bounded by the same nHk + o(n log (cid:3)) bits, making
the boosting approach to achieve the same result unnecessary 
in theory. In practice, implementations of [4, 7] are
superior by far to those building directly on this simplifying 
idea.

Applications
Sequence analysis in Bioinformatics, search and retrieval 
on oriental and agglutinating languages, multimedia 
streams, and even structured and traditional database
scenarios.

URL to Code and Data Sets
Site Pizza-Chili http://pizzachili.dcc.uchile.cl or http://
pizzachili.di.unipi.it contains a collection of standardized
library implementations as well as data sets and experimental 
comparisons.

Cross References
(cid:2) Burrows–Wheeler Transform
(cid:2) Compressed Suﬃx Array
(cid:2) Sequential Exact String Matching
(cid:2) Text Indexing

Recommended Reading
1. Burrows, M., Wheeler, D.: A block sorting lossless data compression 
algorithm. Technical Report 124, Digital Equipment
Corporation (1994)

2. Ferragina, P., Giancarlo, R., Manzini, G., Sciortino, M.: Boosting 
textual compression in optimal linear time. J. ACM 52(4),
688–713 (2005)

3. Ferragina, P. Manzini, G.: Indexing compressed texts. J. ACM

52(4), 552–581 (2005)

4. Ferragina, P., Manzini, G., Mäkinen, V., Navarro, G.: Compressed
representation of sequences and full-text indexes. ACM Trans.
Algorithms 3(2) Article 20 (2007)

5. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed
text indexes. In: Proc. 14th Annual ACM-SIAM Symposium on
Discrete Algorithms (SODA), pp. 841–850 (2003)

6. Jacobson, G.: Space-efficient static trees and graphs. In: Proc.
30th IEEE Symposium on Foundations of Computer Science
(FOCS), pp. 549–554 (1989)

7. Mäkinen, V., Navarro, G.: Succinct suffix arrays based on runlength 
encoding. Nord. J. Comput. 12(1), 40–66 (2005)

8. Mäkinen, V., Navarro, G.: Dynamic entropy-compressed sequences 
and full-text indexes.
In: Proc. 17th Annual Symposium 
on Combinatorial Pattern Matching (CPM). LNCS,
vol. 4009, pp. 307–318 (2006) Extended version as TR/DCC-
2006-10, Department of Computer Science, University of Chile,
July 2006

9. Manber, U., Myers, G.: Suffix arrays: a new method for on-line

string searches. SIAM J. Comput. 22(5), 935–948 (1993)

10. Manzini, G.: An analysis of the Burrows-Wheeler transform.

J. ACM 48(3), 407–430 (2001)

11. Navarro, G., Mäkinen, V.: Compressed full-text indexes. ACM

Comput. Surv. 39(1) Article 2 (2007)

12. Raman, R., Raman, V., Rao, S.: Succinct indexable dictionaries
with applications to encoding k-ary trees and multisets. In:
Proc. 13th Annual ACM-SIAM Symposium on Discrete Algorithms 
(SODA), pp. 233–242 (2002)

Compressing Integer Sequences
and Sets
2000; Moffat, Stuiver
ALISTAIR MOFFAT
Department of Computer Science and Software
Engineering, University of Melbourne,
Melbourne, VIC, Australia

Problem Definition
Suppose that a message M = hs1; s2; : : : ; sni of length
n = jMj symbols is to be represented, where each symbol
si is an integer in the range 1  si  U, for some upper
limit U that may or may not be known, and may or may
not be ﬁnite. Messages in this form are commonly the output 
of some kind of modeling step in a data compression
system. The objective is to represent the message over a binary 
output alphabetf0; 1g using as few as possible output

