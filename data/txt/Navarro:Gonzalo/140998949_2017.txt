SIAM J. COMPUT.
Vol. 46, No. 1, pp. 80–113

c(cid:13) 2017 Society for Industrial and Applied Mathematics

TIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL∗

GONZALO NAVARRO† AND YAKOV NEKRICH‡

Abstract. Let D be a collection of D documents, which are strings over an alphabet of size σ,
of total length n. We describe a data structure that uses linear space and reports k most relevant
documents that contain a query pattern P , which is a string of length p packed in p/ logσ n words, in
time O(p/ logσ n + k). This is optimal in the RAM model in the general case where log D = Θ(log n),
and involves a novel RAM-optimal suﬃx tree search. Our construction supports an ample set
of important relevance measures, such as the number of times P appears in a document (called
term frequency), a ﬁxed document importance, and the minimal distance between two occurrences
of P in a document. When log D = o(log n), we show how to reduce the space of the data structure
from O(n log n) to O(n(log σ + log D + log log n)) bits, and to O(n(log σ + log D)) bits in the case
of the popular term frequency measure of relevance, at the price of an additive term O(logε
σ n)
in the query time, for any constant ε > 0. We also consider the dynamic scenario, where documents 
can be inserted and deleted from the collection. We obtain linear space and query time
O(p(log log n)2/ logσ n + log n + k log log k), whereas insertions and deletions require O(log1+ε n)
time per symbol, for any constant ε > 0. Finally, we consider an extended static scenario where
an extra parameter par(P, d) is deﬁned, and the query must retrieve only documents d such that
par(P, d) ∈ [τ1, τ2], where this range is speciﬁed at query time. We solve these queries using linear
space and O(p/ logσ n + log1+ε n + k logε n) time, for any constant ε > 0. Our technique is to translate 
these top-k problems into multidimensional geometric search problems. As a bonus, we describe
some improvements to those problems.

Key words. text retrieval, string collections, suﬃx trees, geometric data structures

AMS subject classiﬁcation. 68W32

DOI. 10.1137/140998949

1. Introduction. The design of eﬃcient data structures for document (i.e.,
string) collections that can report those containing a query pattern P is an important
problem studied in the information retrieval and pattern matching communities (see,
e.g., a recent survey [52]). Due to the steadily increasing volumes of data, it is often
necessary to generate a list L(P ) of the documents containing a string pattern P in
decreasing order of relevance. Since the list L(P ) can be very large, in most cases we
are interested in answering top-k queries, that is, reporting only the ﬁrst k documents
from L(P ) for a parameter k given at query time.

Inverted ﬁles [15, 43, 9] that store lists of documents containing certain keywords
are frequently used in practical implementations of information retrieval methods.
However, inverted ﬁles only work when query patterns belong to a ﬁxed predeﬁned
set of strings (keywords). The suﬃx tree [71], a handbook data structure known since
1973, uses linear space (i.e., O(n) words, where n is the total length of all the doc-
uments) and ﬁnds all the occ occurrences of a pattern P in O(p + occ) time, where
p = |P|. Surprisingly, the general document listing problem, that is, the problem of reporting 
all the documents that contain an arbitrary query pattern P , was not studied

∗Received by the editors December 5, 2014; accepted for publication (in revised form) December 6,
2016; published electronically February 8, 2017. An early partial version of this article appeared in
Proceedings of SODA, ACM, New York, 2012 [53].

lennium Nucleus Information and Coordination in Networks ICM/FIC RC130003, Chile.

http://www.siam.org/journals/sicomp/46-1/99894.html
Funding: This research was partially funded by Fondecyt Grant 1-140796, Chile, and by Mil-
†Department of Computer Science, University of Chile, Santiago, Chile (gnavarro@dcc.uchile.cl).
‡Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada N2L
3G1 (yakov.nekrich@googlemail.com). This work was done while the author was at the University
of Kansas.

80

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

81

until the end of the 1990s. Suﬃx trees and other data structures for standard pattern
matching queries do not provide a satisfactory solution for the document listing problem 
because the same document may contain many occurrences of P . Matias et al. [47]
described the ﬁrst data structure for document listing queries; their structure uses
O(n) words of space and reports all docc documents that contain P in O(p log D+docc)
time, where D is the total number of documents in the collection. Muthukrishnan [51]
presented a data structure that uses O(n) words of space and answers document listing 
queries in O(p + docc) time. Muthukrishnan [51] also initiated the study of more
sophisticated problems in which only documents that contain P and satisfy some further 
criteria are reported. In the K-mining problem, we must report documents in
which P occurs at least K times; in the K-repeats problem, we must report documents
in which at least two occurrences of P are within a distance K. He described O(n)-
and O(n log n)-word data structures that answer K-mine and K-repeats queries, respectively,
 both in O(p + occ) time, where occ is the number of reported documents.
A problem not addressed by Muthukrishnan, and arguably the most important
one for information retrieval, is the top-k document retrieval problem: report k most
highly ranked documents for a query pattern P in decreasing order of their ranks.
The ranking is measured with respect to the so-called relevance of a string P for a
document d. A basic relevance measure is tf (P, d), the number of times P occurs in d.
Two other important examples are mindist(P, d), the minimum distance between two
occurrences of P in d, and docrank (d), an arbitrary static rank assigned to a document
d. Some more complex measures have also been proposed. Hon et al. [37] presented
a solution for the top-k document retrieval problem for the case when the relevance
measure is tf (P, d). Their data structure uses O(n log n) words of space and answers
queries in O(p + k + log n log log n) time. Later, Hon, Shah, and Vitter [41] presented
a general solution for a wide class of relevance measures. Their data structure uses
linear space and needs O(p + k log k) time to answer a top-k query. A recent O(n)
space data structure [42] enables us to answer top-k queries in O(p + k) time when the
relevance measure is docrank (d). However, that result cannot be extended to other
more important relevance measures.

Our results. Hon, Shah, and Vitter’s results [41] are an important achievement,
In this paper we describe a linear space data
but their time is not yet optimal.
structure that answers top-k document queries in O(p/ logσ n + k) time, where σ is
the alphabet size of the collection and P comes packed in p/ logσ n words. This is
optimal in the Θ(log n)-word RAM model we use, unless the collection has very few
documents, that is, log D = o(log n) (i.e., D = o(nε) for any constant ε > 0). We
support the same relevance measures as Hon, Shah, and Vitter [41].

Theorem 1. Let D be a collection of strings (called documents) of total length
n over an integer alphabet [1, σ], and let w(S, d) be a function that assigns a numeric
weight to string S in document d, so that w(S, d) depends only on the set of starting
positions of occurrences of S in d. Then there exists an O(n)-word space data structure
that, given a string P of length p and an integer k, reports k documents d containing
P with highest w(P, d) values, in decreasing order of w(P, d), in O(p/ logσ n+k) time.
The time is online in k.

Note that the weighting function is general enough to encompass measures tf (P, d),
mindist(P, d), and docrank (d). As stated, our solution is online in k: It is not necessary 
to specify k beforehand; our data structure can simply report documents in
decreasing relevance order until all the documents are reported or the query processing
is terminated by a user.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php82

GONZALO NAVARRO AND YAKOV NEKRICH

An online top-k solution using the tf measure solves the K-mining problem in
optimal time and linear space. An online top-k solution using mindist measure solves
the K-repeats problem in optimal time and linear space. We remind the reader that
Muthukrishnan [51] had solved the K-repeats problem using O(n log n)-word space;
later Hon, Shah, and Vitter [41] reduced the space to linear. Now all these results
appear as a natural corollary of our optimal top-k retrieval solution. Our results also
subsume those on more recent variants of the problem [42], for example, when the
rank docrank (d) depends only on d (we just use w(P, d) = docrank (d)) or, where, in
addition, we exclude those d where P appears less than K times for a ﬁxed predeﬁned
K (we just use w(P, d) = docrank (d) if tf (P, d) ≥ K, or 0 otherwise).

Moreover, we can also answer queries for some relevance metrics not included in
Theorem 1. For instance, we might be interested in reporting all the documents d
with tf (P, d) × idf (P ) ≥ τ , where idf (P ) = log(N/df (P )) and df (P ) is the number
of documents where P appears [9]. Using the O(n)-bit structure of Sadakane [63],
we can compute idf (P ) in O(1) time from the suﬃx tree locus of P . To answer the
query, we use our data structure of Theorem 1 in online mode on measure tf : For
every reported document d we ﬁnd tf (P, d) and compute tf (P, d) × idf (P ); the procedure 
is terminated when a document dl with tf (P, dl) × idf (P ) < τ is encountered.
Thus we need O(p/ logσ n + occ) time to report all occ documents with tf × idf scores
above a threshold.

When log D = o(log n), it is not clear that our time is RAM-optimal. Instead, we
show that in this case the space of our data structures can be reduced from O(n log n)
bits to O(n(log σ + log D + log log n)). This is o(n log n) bits unless log σ = Θ(log n)
(in which case the linear-space data structure is already asymptotically optimal). For
the most important tf relevance measure, where we report documents in which P
occurs most frequently, we obtain a data structure that uses O(n(log σ + log D)) bits
of space. The price of the space reduction is an additive term O(logε
σ n) in the query
time, for any constant ε > 0.
We also consider the dynamic framework, where collection D admits insertions of
new documents and deletions of existing documents. Those updates are supported in
slightly superlogarithmic time per character, whereas the query times are only slightly
slowed down. We note that measure Cw is just O(1) for the typical relevance measures
tf and docrank , and O(log n) for mindist.

Theorem 2. Let D be a collection of documents of total length n over an integer 
alphabet [1, σ], and let w(S, d) be a function that assigns a numeric weight
to string S in document d, so that w(S, d) depends only on the set of starting positions 
of occurrences of S in d, and can be computed in O(Cw|d|) time for all
the nodes of the suﬃx tree of document d. Then there exists an O(n)-word space
data structure that, given a string P of length p and an integer k, reports k documents 
d containing P with highest w(P, d) values, in decreasing order of w(P, d), in
O(p(log log n)2/ logσ n + log n + k log log k) time, online in k. The structure can insert
new documents and delete existing documents in O(Cw + log1+ε n) time per inserted
character and O(log1+ε n) per deleted character, for any constant ε > 0.

We note that a direct dynamic implementation of the solution of Hon, Shah,
and Vitter [41] would require at least performing p + k dynamic RMQs, which cost
Ω(log n/ log log n) time [2]. Thus modeling the original problem as a geometric one
pays oﬀ in the dynamic scenario as well.

Furthermore, we can extend the top-k ranked retrieval problem by allowing a
further parameter par(P, d) to be associated with any pattern P and document d, so

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

83
that only documents with par(P, d) ∈ [τ1, τ2] are considered. Some applications are
selecting a range of creation dates, lengths, or PageRank values for the documents
(these do not depend on P ), bounding the allowed number of occurrences of P in d,
or the minimum distance between two occurrences of P in d, etc.

Theorem 3. Let D be a collection of documents of total length n over an integer
alphabet [1, σ], let w(S, d) be a function that assigns a numeric weight to string S in
document d, and let par(S, d) be another parameter, so that w and par depend only
on the set of starting positions of occurrences of S in d. Then there exists an O(n)-
word space data structure that, given a string P of length p, an integer k, and a range
[τ1, τ2], reports k documents d containing P and with par(P, d) ∈ [τ1, τ2], with highest
w(P, d) values, in decreasing order of w(P, d), in O(p/ logσ n + log1+ε n + k logε n)
time, online in k, for any constant ε > 0.

Our solutions map these document retrieval problems into range search problems
on multidimensional spaces, where points in the grids have associated weights. We
improve some of the existing solutions for those problems.

An early partial version of this article appeared in [53]. It included basically the
O(p + k)-time solution for the static case. This extended version includes, apart from
more precise explanations and ﬁxes, the improvement of the static result to achieve
RAM-optimality on the suﬃx tree traversal, and the new results on the dynamic scenario.
 The paper is organized as follows. In section 2 we review the top-k framework
of Hon, Shah, and Vitter [41] and reinterpret it as the combination of a suﬃx tree
search plus a geometric search problem. We introduce a RAM-optimal suﬃx tree
traversal technique that is of independent interest, and state our results on geometric
grids, each of which is related to the results we achieve on document retrieval. Those
can also be of independent interest. Sections 3 and 4 describe our basic static solution.
 Section 5 describes our dynamic solution. In section 6 we show how the static
solution can be modiﬁed to reduce its space requirements, and in section 7 we show
how it can be extended to support an additional restriction on the documents sought.
Finally, section 8 concludes and gives future work directions.

2. Top-k framework. In this section we overview the framework of Hon, Shah,
and Vitter [41]. Then, we describe a geometric interpretation of their structure and
show how top-k queries can be reduced to a special case of range reporting queries on
a grid.

Let T be the generalized suﬃx tree [71, 48, 69] for a collection of documents
d1, . . . , dD, each ending with the special terminator symbol “$.” T is a compact trie,
such that all suﬃxes of all documents are stored in the leaves of T . We denote by
path(v) the string obtained by concatenating the labels of all the edges on the path
from the root to v. The locus of a string P is the highest node v such that P is a
preﬁx of path(v). Every occurrence of P corresponds to a unique leaf that descends
from its locus. We refer the reader to classical books and surveys [7, 36, 20] for an
extensive description of this data structure.

We say that a leaf l is marked with document d if the suﬃx stored in l belongs
to d. An internal node v is marked with d if at least two children of v contain
leaves marked with d. While a leaf is marked with only one value d (equal suﬃxes of
distinct documents are distinguished by taking all the string terminators as diﬀerent
from each other and ordering them arbitrarily), an internal node can be marked with
many values d.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php84

GONZALO NAVARRO AND YAKOV NEKRICH

In every node v of T marked with d, we store a pointer ptr(v, d) to its lowest
ancestor u such that u is also marked with d. If no ancestor u of v is marked with d,
then ptr(v, d) points to a dummy node ν such that ν is the parent of the root of T .
We also assign a weight to every pointer ptr(v, d). This weight is the relevance score
of the document d with respect to the string path(v).

It is not hard to see that the nodes of T marked with d correspond precisely to
the suﬃx tree Td of document d, with the pointers ptr(v, d) playing the role of parent
pointers in Td. All the nodes of Td in T are lowest common ancestors of consecutive
leaves vi and vi+1 of leaves marked with d in T , lca(vi, vi+1). The following statements
hold; we prove them again for completeness.

Lemma 1 (see [41, Lemma 4]). The total number of pointers ptr(·,·) in T is

bounded by O(n).

Proof. The total number of pointers ptr(v, d) for all v ∈ T , does not exceed the
number of nodes marked with d. The total number of internal nodes marked with d is
smaller than the number of leaves marked with d. Since there are O(|d|) leaves marked
with d, the total number of pointers ptr(v, d) for a ﬁxed document d is bounded by
O(|d|), and those |d| add up to n.

Lemma 2 (see [41, Lemma 2]). Assume that document d contains a pattern P
and v is the locus of P . Then there exists a unique pointer ptr(u, d), such that u is in
the subtree of v (which includes v) and ptr(u, d) points to an ancestor of v.

Proof. If d contains P then there is at least one leaf u marked d below the locus
of P , with a pointer ptr(u, d). If there are two maximal (in the sense of ancestorship)
nodes u and u(cid:48) below v with pointers ptr(u, d) and ptr(u(cid:48), d), then their lowest common
ancestor v(cid:48) is also marked. Since v is an ancestor of u and u(cid:48), v is v(cid:48) or an ancestor of
v(cid:48) and then ptr(u, d) and ptr(u(cid:48), d) must point to v(cid:48), not to an ancestor of v. Therefore,
there is a unique maximal node u marked d below v (note that u might be v). Thus,
the pointer ptr(u, d) must point to an ancestor of v.

Moreover, in terms of Lemma 2, it turns out that path(u) occurs in d at the same
positions as path(v). Note that the starting positions of P and of path(v) in d are
the same, since v is the locus of P , and those are the same as the starting positions
of path(u) in d. Thus w(P, d) = w(path(u), d) for any measure w(·,·) considered in
Theorem 1.

RAM-optimal suﬃx tree traversal. To achieve time O(p) for the locus search in
the suﬃx tree while retaining linear space, one needs to organize the children of each
node in a perfect hash function (phf) [29]. In order to reduce this time to the RAMoptimal 
O(p/ logσ n) when P comes packed in p/ logσ n words, we proceed as follows.
Let l(u, v) be the concatenation of string labels from node u to its descendant v. We
collect in a phf H(u), for the suﬃx tree root u, all the highest descendants v such
that |l(u, v)| ≥ (cid:96) = logσ n. Those nodes v are indexed with a key built from the ﬁrst
(cid:96) symbols of l(u, v) interpreted as a number of lg n bits (lg stands for log2). We build
recursively phfs for all the identiﬁed descendants v. Since each suﬃx tree node is
included in at most one hash table, the total size is O(n) and the total deterministic
construction time is O(n log log n) [62].

Now P is searched for as follows. We take its ﬁrst chunk of (cid:96) characters, interpret
it as a number, and query the phf of the root. If no node v is found for that preﬁx of
P , then P is not in the collection. Otherwise, the string depth of v is ≥ (cid:96). We check
explicitly the extra |l(u, v)|−(cid:96) symbols in the text, by comparing chunks of (cid:96) symbols.
If there is a mismatch, then P does not appear in the collection. If the |l(u, v)| − (cid:96)

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

85

symbols are suﬃcient to match all the rest of P , then the locus is v. Otherwise, we
continue the search from v with the next (cid:96) unread symbols of P , and so on, until
there are less than (cid:96) symbols to match from a node v in the remaining suﬃx P (cid:48) of P .
At this point we switch to using a weak preﬁx search (wps) data structure [10]:
For each node u holding a phf, we also store this wps data structure with all the nodes
v that descend from u where |l(u, v)| < (cid:96), using l(u, v) as their key. We must also
include the children z of those nodes v, as well as the children z of u, with |l(u, z)| ≥ (cid:96),
using the ﬁrst (cid:96) − 1 symbols of l(u, z) as their key (note that these nodes z are also
stored in the phf structure of u). The wps data structure will return the lexicographic
range of the nodes x where P (cid:48) is a preﬁx of l(u, x). The ﬁrst in that range is the
locus of P . One detail is that, if there is no such node (i.e., P has no locus), the wps
structure returns an arbitrary value, but this can be easily checked in optimal time
in the text.
The wps structure requires, for our length |P (cid:48)| < (cid:96) and in the RAM model, O(1)
√
log n log log n)
query time. For the strings of length < (cid:96) we store, the structure uses O(
bits, or o(1) words, per stored node [10, Thm. 6]. Once again, each node is stored only
in one wps structure, so the overall extra space is linear. The wps construction takes
O(n logε n) randomized time. It can be made deterministic O(n polylog(n)) time by
using a phf inside the construction [1]. By replacing the wps structure by layered phfs
for (logσ n)/2i symbols, we would have an additive term O(log logσ n) in the query
time.
Geometric interpretation. We index the nodes of T in the following way: The
nodes are visited in preorder; we also initialize an index i ← 0. When a node v is
visited, if v is marked with documents dv1, . . . , dvj , we assign indexes i + 1, . . . , i + j
to v and set i ← i + j. We will denote by [lv, rv] the integer interval bounded by
the minimal and maximal indexes assigned to v or its descendants. Values lv and rv
are stored in node v of T . Furthermore, for every dvt, 1 ≤ t ≤ j, there is a pointer
ptr(v, dvt) that points to some ancestor ut of v. We encode ptr(v, dvt) as a point
(i + t, depth(ut)), where depth denotes the depth of a node; depth(ν) = 0. Thus every
pointer in T is encoded as a two-dimensional point on an integer O(n) × O(n) grid.
The weight of a point p is that of the pointer it encodes. We observe that all the
points have diﬀerent x-coordinates. Thus we obtain a set S of weighted points with
diﬀerent x-coordinates, and each point corresponds to a unique pointer.

For the ﬁnal answers we will need to convert the x-coordinates of points found
on this grid into document numbers. We store a global array of size O(n) to do this
mapping.

Answering queries. Assume that top-k documents containing a pattern P must
be reported. We ﬁnd the locus v of P in O(p/ logσ n) time. By Lemma 2, there is
a unique pointer ptr(u, d), such that u is a descendant of v (or v itself) and ptr(u, d)
points to an ancestor of v, for every document d that contains P . Moreover the weight
of that point is w(P, d). Hence, there is a unique point (x, y) with x ∈ [lv, rv] and
y ∈ [0, depth(v) − 1] for every document d that contains P . Therefore, reporting
top-k documents is equivalent to the following query: Among all the points in the
three-sided range [lv, rv] × [0, depth(v)), report k points with highest weights. We
In sections 3 and 4 we prove the
will call such queries three-sided top-k queries.
following result. Theorem 1 is an immediate corollary of it, as h = depth(v) − 1 and
depth(v) ≤ p, and we can choose c ≥ 1.

Theorem 4. A set of n weighted points on an n × n grid can be stored in a
data structure using O(n) words of space, built in O(n log n) time, so that for any

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpGONZALO NAVARRO AND YAKOV NEKRICH

86
1 ≤ k, h ≤ n, and 1 ≤ a ≤ b ≤ n, k most highly weighted points in the range
[a, b] × [0, h] can be reported in decreasing order of their weights in O(h/ logc n + k)
time for any constant c.

Top-k queries on dynamic collections. The static suﬃx tree is replaced by a dynamic 
one, with search time O(p(log log n)2/ logσ n + log n) and update time O(log n)
per symbol. We must also update the grid, for which we must carry out lowest common 
ancestor queries on the dynamic suﬃx tree and also insert/delete points (and
columns) in the grid. We split the grid of Theorem 4 into horizontal stripes of height
m = polylog n to obtain improved performance, and query the highest (cid:100)p/m(cid:101) of those
grids. In the most general case (i.e., the last grid) we carry out a three-sided top-k
query. We address this in section 5, where in particular we prove the following result
on dynamic grids. Theorem 2 is then obtained by combining those results.

Theorem 5. A set of n points, one per column with y-coordinates in [1, n], and
with weights in [1, O(n)], can be stored in O(n) words of space, so that for any
1 ≤ k ≤ n, 1 ≤ h ≤ n, and 1 ≤ a ≤ b ≤ n, k most highly weighted points
in the range [a, b] × [0, h] can be reported in decreasing order of their weights in
O(h/ logc n + log n + k log log k) time, online in k, for any constant c. Points (and
their columns) can be inserted and deleted in O(log1+ε n) time for any constant ε > 0.

Parameterized top-k queries. We use the same geometric interpretation as described 
above, but now each pointer ptr(v, d) is also associated with the parameter 
value par(path(v), d). We encode a pointer ptr(v, dvt) as a three-dimensional
point (i + t, depth(ut), par(path(v), dvt)), where i, t, and ut are deﬁned as in the
case of nonparameterized top-k queries. All the documents that contain a pattern
P (with locus v) and satisfy τ1 ≤ par(P, d) ≤ τ2 correspond to unique points in
the range [lv, rv] × [0, depth(v)) × [τ1, τ2]. Hence, reporting top-k documents with
par(P, d) ∈ [τ1, τ2] is equivalent to reporting top-k points in a three-dimensional
range. The following result is proved in section 7, and Theorem 3 is an immediate
corollary of it, choosing any c ≥ 1.

Theorem 6. A set of n weighted points on an n×n×n grid can be stored in O(n)
words of space, so that for any 1 ≤ k, h ≤ n, 1 ≤ a ≤ b ≤ n, and 1 ≤ τ1 ≤ τ2 ≤ n,
k most highly weighted points in the range [a, b] × [0, h] × [τ1, τ2] can be reported in
decreasing order of their weights in O(h/ logc n + log1+ε n + k logε n) time, for any
constants c and ε > 0.

3. An O(m + k) time data structure. In this section we give a ﬁrst data
structure for three-sided top-k queries [a, b] × [0, h] on a set S of n two-dimensional
weighted points. It does not yet achieve the desired O(h/ log n + k) time, but its time
depends on the width m of the grid. This will be used in section 4 to handle vertical
stripes of the global grid, in order to achieve the ﬁnal result.
We assume that a global array gives access to the points of S in constant time:
If we know the x-coordinate p.x of a point p ∈ S, we can obtain the y-coordinate p.y
of p in O(1) time. Both p.x and p.y are in [1, O(n)], thus the global array requires
O(n) words of space. We consider the question of how much additional space our
data structure uses if this global array is available.

The result of this section is summed up in the following lemma, where we consider
tall grids of m columns and n rows. The idea is to partition the points by weights,
where the weights are disregarded inside each partition. Those partitions are further
reﬁned, forming a multiary range tree. Then we solve the problem by traversing the
appropriate partitions and collecting all the points using classical range queries on

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

87

unweighted points. A tree of arity mΘ(1) yields constant height and thus constant
space per point.

Note, however, that this is not just a standard multiary range tree. Range trees
and similar geometric data structures can provide a solution for the threshold variant
of the problem, where we must report all points in a three-sided range with weight
exceeding a threshold. We can probably modify these methods and ﬁnd a solution for
the unsorted top-k problem, where k points with highest weights are reported in an
arbitrary order. However, in this case we consider the sorted top-k problem, where
points must be returned sorted by decreasing weight. It is not clear how this variant
can be solved in optimal time and linear space using standard techniques.

Lemma 3. Assume that m ≤ n and let 0 <  < 1 be a constant. There exists a
data structure that uses O(m log m) additional bits of space and construction time. It
answers three-sided top-k queries for a set of m points on an m× n grid in O(m + k)
time.

Proof. We partition S into classes S1, . . . , Sr, where r = m(cid:48)

for a constant 0 <
(cid:48) < . For any 1 ≤ i < j ≤ r, the weight of any point pi ∈ Si is larger than the
weight of any point pj ∈ Sj. For 1 ≤ i < r, Si contains m1−(cid:48)
points. Each class Si
that contains more than one element is recursively divided into min(|Si|, r) subclasses
in the same manner. This subdivision can be represented as a tree: If Si is divided
into subclasses Si1, . . . , Sik , we will say that Si is the parent of Si1 , . . . , Sik . This tree
has constant height O(1/(cid:48)).

For every class Sj we store data structures that support three-sided range counting 
queries and three-sided range reporting queries in O(log m) and O(log m + occ)
time, respectively. These structures will be described in section 3.1 and require
O(m1−(cid:48)
log m) construction time; note they do not involve weights. This adds up to
O((1/(cid:48))m log m) construction time.
We will report k most highly weighted points in a three-sided query range Q =
[a, b] × [0, h] using a two-stage procedure. During the ﬁrst stage we produce an unsorted 
list L of k most highly weighted points. During the second stage the list L is
sorted by weight.
Let Qk denote the set of k most highly weighted points in S ∩ Q. Then Qk can
be formed as the union of the result of the three-sided query over certain classes, at
most O(m(cid:48)
) clases per level over a constant number of levels. More precisely, there
) classes Sc, such that p ∈ Qk if and only if p ∈ Sc ∩ Q for some Sc. During
are O(m(cid:48)
the ﬁrst stage, we identify the classes Sc and report all the points in Sc ∩ Q using

the following procedure. Initially, we set our current tree node to (cid:101)S = S and its child
number to i = 1. We count the number of points inside Q in the ith child Si of (cid:101)S.
next child Si of (cid:101)S.
If ki > k, instead, we set (cid:101)S = Si, i = 1, and report k most
highly weighted points in the children of (cid:101)S using the same procedure. During the ﬁrst

If ki = |Si ∩ Q| ≤ k, we report all the points from Si ∩ Q and set k = k − ki. If
k = 0, the procedure is completed; otherwise we set i = i + 1 and proceed to the

log m + k) = O(m + k) time in

) classes Si and spend O(m(cid:48)

stage we examine O(m(cid:48)
total.
When the list L is completed, we can sort it in O(m + k) time. If L contains
points, L can be sorted in O(k log k) = O(m) time. If L contains k ≥ m(cid:48)
k < m(cid:48)
points, then we can sort it in O(k) time using radix sort: As the set S contains at
most m distinct weights, we store their ranks in an array ordered by x-coordinate,
and thus can sort the result using the ranks instead of the original values. By sorting
(cid:48) lg m bits per pass the radix sort runs in time O(k).

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php88

GONZALO NAVARRO AND YAKOV NEKRICH

As for the space, the structures in Lemmas 4 and 5 require O(log m) bits per
point. Each point of S belongs to O(1/(cid:48)) classes Si. Hence, the total number of
points in all classes is O(m), giving O(m log m) bits of total space. The local array
of weight ranks also uses O(m log m) bits.

3.1. Counting and reporting points. It remains to describe the data structures 
that answer three-sided counting and reporting queries, with no weights involved.
 These are variants of standard geometric data structures [49, 18] that we
adapt to the case of narrow grids, so as to use O(log m) bits per point instead of
O(log n). We exploit the fact that we can obtain p.y from p.x for any point p ∈ S,
and use compact data structures to reduce space.

Lemma 4. Let v ≤ m ≤ n. There exists a data structure that uses O(v log m)
additional bits and answers three-sided range counting queries for a set of v points on
an m × n grid in O(log v) time. It can be built in O(v log v) time.

Proof. We use the classic rank space technique [30] to reduce the problem of
counting on an m × n grid to the problem of counting on a v × n grid. We apply
ranking only on the x-coordinates, spending O(log v) additional query time and v lg m
bits of space to perform and to store the mapping, respectively.

We store the mapped points on a variant of the wavelet tree data structure [34, 18].
Each node of this tree W covers all the points within a range of y-coordinates. The
root covers all the nodes, and the two children of each internal node cover half of the
points covered by their parent. The leaves cover one point. The y-coordinate limits of
the nodes are not stored explicitly, to save space. Instead, we store the x-coordinate
of the point holding the maximum y-coordinate in the node. With the global array we
can recover the y-coordinate in constant time. Each internal node v covering r points
stores a bitmap Bv[1 . . . r], so that Bv[i] = 0 iﬀ the ith point, in x-coordinate order,
belongs to the left child (otherwise it belongs to the right child). Those bitmaps are
equipped with data structures answering operation rankb(Bv, i) in constant time and
r + o(r) bits of space [50], where rankb(Bv, i) is the number of occurrences of bit b in
Bv[1 . . . i]. Since W has O(v) nodes and height O(log v), its bitmaps require O(v log v)
bits and its pointers and x-coordinates need O(v log m) bits. The construction time
is O(v log v).
We can easily answer range counting queries [a, b] × [0, h] on W [46]. After
mapping [a, b] to [a(cid:48), b(cid:48)]
in rank space, the procedure starts at the root node
of W , with the range [a(cid:48), b(cid:48)] on its bitmap B. This range will become [al, bl] =
[rank0(B, a(cid:48) − 1) + 1, rank0(B, b(cid:48))] on the left child of the root, and [ar, br] =
[rank1(B, a(cid:48) − 1) + 1, rank1(B, b(cid:48))] on the right child. If the maximal y-coordinate
of the left child is smaller than or equal to h, we count the number of points p with
p.x ∈ [a, b] stored in the left child, which is simply bl − al + 1, and then visit the right
child. Otherwise, the maximal y-coordinate in the left child is larger than h, and we
just visit the left child. The time is O(1) per tree level.

Lemma 5. Let v ≤ m ≤ n. There exists a data structure that uses O(v log m)
additional bits and answers three-sided range reporting queries for a set S of v points
on an m × n grid in O(log v + occ) time, to report the occ results. It can be built in
O(v log v) time.

Proof. We again reduce the problem of reporting on an m× n grid to the problem
of reporting on a v × n grid, using the rank space technique [30]. The query time
is increased by O(log v), and the space usage increases by v lg m bits. To solve this
problem we sort the v points in x-coordinate order, build the sequence Y [1 . . . v] of

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

89

their y-coordinates, and build a range minimum query (RMQ) data structure on Y
[27]. This structure requires only O(v) bits of space, does not need to access Y
after construction (so we do not store Y ), and answers in constant time the query
r = rmq(x1, x2) = arg minx1≤x≤x2 Y [x] for any x1, x2. We then compute p.y for the
point p such that the rank-mapped value of p.x is r. If p.y > h we can stop since
there are no points to report. Otherwise we report p and continue recursively on the
intervals [a(cid:48), r − 1] and [r + 1, b(cid:48)]. It is well known that this procedure retrieves all
the occ points in the three-sided range [a(cid:48), b(cid:48)]× [0, h] in O(occ) time; see, for example,
Muthukrishnan [51]. Construction time is dominated by the sorting of the points.

4. An optimal time data structure. The data structure of Lemma 3 gives
us an O(m + k) time solution for top-k queries on the three-sided range [a, b] × [0, h]
for any constant , where m is the grid width. In this section we use it to obtain
O(h/ log n + k) time, where n is the number of points. The idea is to partition the
space into vertical stripes, for diﬀerent stripe widths, and index each stripe with
Lemma 3. Then the query is run on the partition of width m so that the O(m) time
complexity is dominated by O(h/ log n + k). The many partitions take total linear
space because the size per point in Lemma 3 is O(log m), and our widths decrease
doubly exponentially. As a query may span several stripes, a structure similar to
the one used in the classical RMQ solution [14] is used: We precompute answers
for sequences of doubling numbers of stripes, so that any query is covered by two
overlapped precomputed answers; the answers can then be merged. This doubling
scheme uses linear space for stripes of width up to Ω(log2 n). Smaller stripes are
solved with a smaller-scale replica of the main idea, and then using universal tables.
The hierarchical structure of stripes is described in section 4.1, and the way to query
it in section 4.2. Since the solution to smaller grids replicates the main idea at a
smaller scale, it is postponed to section 4.3.

In addition to the global array storing p.y for each p.x, we use another array
storing the weight corresponding to each p.x. As there are overall O(n) diﬀerent
weights, those can be mapped to the interval [1, O(n)] and still solve correctly any
top-k reporting problem. Thus the new global array also requires O(n) words of space.

4.1. Structure. Let gj = 1/2j for j = 0, 1, . . . , r. We choose r so that ngr =
O(1), thus r = O(log log n). The x-axis is split into intervals of size ∆j = ngj lg2 n
and j = 1, . . . , r. For convenience, we also deﬁne ∆0 = n and ∆(cid:48)
j = ∆j/ lg2 n = ngj .
For every 1 ≤ j < r and for every interval Ij,t = [(t − 1)∆j, t∆j − 1], we store all
the points p with p.x ∈ Ij,t in a data structure Ej,t implemented as described in
Lemma 3. Then Ej,t supports three-sided top-k queries in O((∆j) + k) time for any
constant 0 <  < 1/4. We also construct a data structure E0 that contains all the
points of S and supports three-sided top-k queries in O(n1/4 + k) time. To simplify
the description, we also assume that I−1 = I0 = [0, n − 1] and E−1 = E0.

The data structures Ej,t for a ﬁxed j contain O(n) points overall, hence, by
Lemma 3, all Ej,t use O(n log ∆j) = O(n log(ngj log2 n)) = (1/2j)O(n log n) +

O(n log log n) additional bits of space. Thus all Ej,t for 0 ≤ j < r use (cid:80)r−1

j=0
[(1/2j)O(n log n) + O(n log log n)] = O(n log n) bits, or O(n) words. They also require 
O(n log n) total construction time. Since  < 1/4, a data structure Ej,t supports
top-k queries in time O((∆j) + k) = O((ngj log2 n) + k) = O(ngj+2/ log n + k) =
O(∆(cid:48)
j+2/ log n+k) time. For each of the smallest intervals Ir,t we store data structures
Er,t that use o(log2 n) words of space (adding up to o(n)) and support three-sided
top-k queries in O(h/ log n + k) time. This structure will be described in section 4.3.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php90

GONZALO NAVARRO AND YAKOV NEKRICH

Note that our choice of writing (ngj lg2 n) = O(ngj+2/ log n) was arbitrary, because 
 is strictly less than 1/4. We could have written (ngj lg2 n) = O(ngj+2 / logc n)
for any constant c, and this would yield O(h/ logc n + k) query time. We have chosen 
to favor simplicity in the exposition, but will return to this point at the end of
section 4.3.
We also store structures to answer top-k queries on selected ranges of intervals.
For 1 ≤ j ≤ r, we consider the endpoints of intervals Ij,t. Let topj(a, b, c, k) denote the
list of top-k points in the range [a·∆j, b·∆j−1]×[0, c] in descending weight order. We
j+1) for any t ∈ [0, n/∆j], any 0 ≤ v ≤ lg(n/∆j),
store the values of topj(t, t + 2v, c, ∆(cid:48)
and any 0 ≤ c ≤ ∆(cid:48)
j+1)2 log n) =
O(n/ log n) words. Hence the total word space usage of all lists topj(·,·,·,·) for 2 ≤
j ≤ r is O(n log log n/ log n) = o(n). It can also be built in o(n) time using dynamic
programming.

j+1. All the lists topj(·,·,·,·) use space O((n/∆j)(∆(cid:48)

4.2. Queries. We can carry out the query using a range of intervals Ij,t of any
width ∆j. The key idea is to use a j value according to the height of the threesided 
query, so that the search time in Ij,t gives the desired O(h/ log n) time. More
precisely, assume we want to report top-k points in the range [a, b] × [0, h]. First, we
ﬁnd the index j such that ∆(cid:48)
j+2. The index j can be found in
O(log log(h + k)) time by linear search.1 If [a, b] is contained in some interval Ij,t,
then we can answer a query in O(∆(cid:48)
j+2/ log n + k) = O(h/ log n + k) time using Ej,t.
If [a, b] is contained in two adjacent intervals Ij,t and Ij,t+1, we generate the lists of
top-k points in ([a, b]∩ Ij,t)× [0, h] and ([a, b]∩ Ij,t+1)× [0, h] in O(h/ log n + k) time,
and merge them in O(k) time.

j+1 > max(h, k) ≥ ∆(cid:48)

m and L(cid:48)(cid:48)

m denote the lists of the ﬁrst k points in topj(a(cid:48), a(cid:48) + 2v, h, ∆(cid:48)

To deal with the case when [a, b] spans one or more intervals Ij,t, we use the
precomputed solutions for ranges of intervals. Assume that [a, b] spans intervals
[a, b] also intersects with intervals Ij,t1 and Ij,t2. Let a(cid:48)∆j
Ij,t1+1, . . . , Ij,t2−1;
and b(cid:48)∆j denote the left endpoints of Ij,t1+1 and Ij,t2, respectively. The list Lm
of top-k points in [a(cid:48)∆j, b(cid:48)∆j − 1] × [0, h] can be generated as follows.
Intervals
[a(cid:48)∆j, (a(cid:48) +2v)∆j−1] and [(b(cid:48)−2v)∆j, b(cid:48)∆j−1] for v = (cid:98)lg(b(cid:48)−a(cid:48))(cid:99) cover [a(cid:48)∆j, b(cid:48)∆j−
1]. Let L(cid:48)
j+1)
and topj(b(cid:48) − 2v, b(cid:48), h, ∆(cid:48)
j+1; similarly we have
the results for c = h because h < ∆(cid:48)
j+1). We merge both lists (possibly removing
duplicates) according to the weights of the points, and store in Lm the set of the ﬁrst
k points from the merged list. Let Lt1 and Lt2 denote the sets of top-k points in
[a, a(cid:48)∆j − 1]× [0, h] and [b(cid:48)∆j, b]× [0, h]. We can obtain Lt1 and Lt2 in O(h/ log n + k)
time using data structures Ej,t1 and Ej,t2 as explained above. Finally, we can merge
Lm, Lt1, and Lt2 in O(k) time; the ﬁrst k points in the resulting list are the top-k
points in [a, b] × [0, h].

j+1) (we have k results because k < ∆(cid:48)

4.3. A data structure for an O(log2 n) × n grid. The data structures Er,t
for an interval Ir,t use the same general approach as the data structures Ej,t, at a
smaller scale. Note that these structures will be consulted only when max(h, k) <
C = ∆(cid:48)

r+1 = O(1). Each interval Ir,t is subdivided into lg7/4 n intervals (cid:101)I1,(cid:101)I2, . . . of
width lg1/4 n. Let (cid:101)S denote the set that contains the endpoints of(cid:101)I1,(cid:101)I2, . . .. For every
x ∈ (cid:101)S, each 1 ≤ v ≤ 2 lg lg n, and each h ≤ C, we store the lists top(x, x + 2v, h, C).

All such lists use O((n/ log2 n)C 2 log7/4 n log log n) = o(n) space in total.

1This is deﬁnitely O(h/ log n + k) if max(h, k) = Ω(log n log log n); otherwise a small table can

be used to perform the search in constant time.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

91

A query on Ir,t is processed as follows. Suppose that [a, b] intersects with intervals
[0, h] in O(k) time using lists top(·,·,·,·), as before. We also ﬁnd top-k points from

(cid:101)Ig1, . . . ,(cid:101)Ig2 for some g1 ≤ g2. We ﬁnd the top-k points from ((cid:101)Ig1+1 ∪ ··· ∪(cid:101)Ig2−1) ×
((cid:101)Ig1 ∩ [a, b])× [0, h] and ((cid:101)Ig2 ∩ [a, b])× [0, h] in O(k) time using data structures for (cid:101)Ig1
and (cid:101)Ig2, respectively, to be described next. We thus obtain three lists of points sorted
Finally, we describe how to answer queries in O(k) time in the grids (cid:101)Ig, of width
on their weights. The resulting sequence Xg contains all mapped points in (cid:101)Ig and

lg1/4 n. We apply reduction to rank space [30] on the y-coordinates of points and

by their weights, and merge them in O(k) time as before.

consists of O(log1/4 n log log n) bits, so all the descriptions of all sequences Xg require 
O(n log log n) bits, or o(n) words. There are O(log1/2 n) queries that can be
asked (considering all the sensible values of [a, b], h, and k), and the answers require
O(k log(log1/4 n)) = O(log log n) bits. Thus we can store a universal look-up table of

table contains precomputed answers for all possible queries and all possible sequences
Xg. Hence, we can answer a top-k query on Xg in O(k) time.

size 2O(log3/4 n log log n)O(log log n) = o(n) words common to all subintervals (cid:101)Ig. This
A query on (cid:101)Ig can be transformed into a query on Xg by reduction to rank space
in the y coordinates. Consider a query range Q = [a, b] × [0, h] on (cid:101)Ig. We can ﬁnd
the rank h(cid:48) of h among the y-coordinates of points from (cid:101)Ig in O(h) = O(1) time by

linear search (remember that we store only the reordering of the local x-coordinates,
and the actual y-coordinates are found in the global array). Then, we can identify
the top-k points in Xg ∩ Q(cid:48), where Q(cid:48) = [a, b] × [0, h(cid:48)], using the look-up table and
report those points in O(k) time.

Thus our data structure uses O(n) words of space and answers queries in
O(h/ log n + k) time. It can be built in O(n log n) time. As mentioned at the end of
section 4.1, we can obtain any query time of the form O(h/ logc n+k), for any constant
c. This completes the proof of Theorem 4, which is given in this general form.

2ki−1, and si = (cid:80)i−1

4.4. Online queries. An interesting extension of the above result is that we can
deliver the top-k documents in online fashion. That is, after the O(p/ logσ n) time
initialization, we can deliver the highest weighted result, then the next highest one,
and so on. It is possible to interrupt the process at any point and spend overall time
O(p/ logσ n + k) after having delivered k results. That is, we obtain the same result
without the need of knowing k in advance. This is achieved via an online version
of Theorem 4, and is based on a known idea; see, e.g., [16, 41]. We describe it for
completeness.
Consider an arbitrary data structure that answers top-k queries in O(f (n)+kg(n))
time in the case when k must be speciﬁed in advance. Let k1 = (cid:100)f (n)/g(n)(cid:101), ki =
j=1 kj for i ≥ 2. Let S be the set of points stored in the data
structure and suppose that we must report top points from the range Q in the online
mode. At the beginning, we identify top-k1 points in O(f (n) + g(n)) time and store
them in a list L1. Reporting is divided into stages. During the ith stage, we report
points from a list Li. Li contains min(ki,|Q ∩ S| − si) top points that were not
reported during the previous stages. Simultaneously, we compute the list Li+1 that
contains min(2ki + si,|Q ∩ S|) < 4ki top points. We identify at most 2ki + si top
points in O(f (n) + 4ki · g(n)) = O(ki · g(n)) time. We also remove the ﬁrst si points
from Li+1 in O(ki) time. The resulting list Li+1 contains 2ki = ki+1 points that must
be reported during the next (i + 1)th stage. The task of creating and cutting the list

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php92

GONZALO NAVARRO AND YAKOV NEKRICH

Li+1 is executed in such a way that we spend O(1) time when each point of Li is
reported. Thus when all the points from Li are output, the list Li+1 that contains
the next ki+1 top points is ready and we can proceed with the (i + 1)th stage.

This reporting procedure outputs the ﬁrst k most highly weighted points in

O(f (n) + kg(n)) time, and can be interrupted at any time.

5. A dynamic structure. We consider now a scenario where insertions and
deletions of whole documents are interspersed with top-k queries. When a document
d is inserted, each of its d suﬃxes must be inserted at the appropriate positions in the
suﬃx tree. We must also maintain the pointers ptr(v, d) that describe the topology
of the suﬃx tree Td of d, and their connection with the grid, where weighted points
(and columns) are also inserted. All those structures must then support top-k queries.
Document deletions must revert those updates.

Section 5.1 describes our dynamic suﬃx trees. It diﬀers from the classical maintenance 
procedures in that we add to some selected nodes accelerator structures, similar
to the phfs we used in the static case to jump by logσ n characters of P . Those structures 
have to be maintained upon insertions and deletions of suﬃx tree nodes. We
deﬁne which nodes hold accelerator structures in a way that facilitates maintaining
them. The procedure to traverse the dynamic suﬃx tree to ﬁnd the locus of the pattern 
is analogous to the static case, taking O(p(log log n)2/ logσ n + log n) time. Each
document d is inserted or deleted in time O(|d| log n).

Section 5.2 describes how to maintain the relation between the suﬃx tree and
the grid. The y-coordinates, that used to be the tree depth of the target nodes
u = ptr(v, d), now become string depths, as these do not change upon updates in the
suﬃx tree. Maintaining the x-coordinates is more complicated, as we have to insert
and delete x-coordinates in the grid upon insertions and deletions of suﬃx tree nodes.
We replace the integers of the grid by abstract labels, and use existing techniques
to maintain order in a set of labels while we can insert and delete labels (this is the
order maintenance problem [23, 13]). Then we describe how those labels are created
or removed as we insert or delete each suﬃx of a document. For simplicity we consider
the relevance measure tf in this section; in section 5.5 we generalize to others. The
additional time needed to maintain this relation is within O(|d| log n).

We then face the problem of storing those points on a dynamic grid, which can be
eﬃciently queried. The most complex part is section 5.3, where we consider grids of
very small heights, O(logε n) for any constant 0 < ε < 1. We describe an extension of
B-trees where weighted points (using abstract labels as x-coordinates) can be inserted
and deleted. By storing the heaviest point with each y-coordinate below each B-tree
node, we carry out top-k queries in O(log n + k log log k) time. Insertion and deletion
of all the points induced by a document d takes time O(|d| log1+ε n), which dominates
the overall update time. The height limit of the grids is raised to any O(polylog n)
in section 5.4, by decomposing the grid into successively more reﬁned grids, each
of height O(logε n). This decomposition has constant height, and thus it multiplies
spaces and times by a constant only.
Section 5.5 wraps up, showing how a query for P starts on the suﬃx tree and
then is translated into a query of the form [a, b]× [0, p− 1], where a and b are abstract
labels. This query is split into bands of height O(polylog n), for each of which we
have stored a grid, and we obtain the k heaviest points from all the bands. The
total search time is O(p(log log n)2/ logσ n + log n + k log log k). We also show how to
accommodate other types of weighting schemes apart from tf , including those that
yield real numbers.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

93

5.1. Dynamic suﬃx trees. Compared to classical dynamic suﬃx tree data
structures [3, 4], we aim to improve the time to traverse the suﬃx tree at query time,
and also to support the operations that will maintain the connection with the grid.
We build on a dynamic suﬃx tree maintenance algorithm where leaves and unary
nodes can be inserted and deleted, and lowest common ancestors can be computed,
all in constant worst-case time [19]. The updates on leaves and unary nodes are the
operations we need to insert and delete all the suﬃxes of a document in the suﬃx tree,
in time proportional to the length of the document inserted or deleted, whereas the
lowest common ancestor queries are necessary to compute the new ptr(·,·) pointers
to insert in the grid.
In any node we will maintain the up to σ children using a
linear-space dynamic predecessor data structure that supports queries and updates in
worst-case time o((log log σ)2) [5].
Upon insertion of a new document d of length |d|, we follow McCreight’s procedure 
to insert a new string in a generalized suﬃx tree [48]. We describe it here for
completeness. First we search for the whole document string d in the suﬃx tree, until
we reach the point where it diﬀers from any other suﬃx in the tree. If this point is
a node v, we add a new leaf child z of v that represents the suﬃx d1...|d|. If, instead,
the point is in an edge linking v with its child u, we ﬁrst split the edge at the proper
point with a new node x, whose two children will be u and the new leaf z.
We must also maintain the suﬃx links of the tree, that is, the pointers from every
node v representing a string a · X to the node slink(v) representing X, where a is
a character and X is a string. To compute the value slink(z), we go to the node
v(cid:48) = slink(v), and descend from v(cid:48) with the characters of l(v, z) (although there are
no nodes between v and z, we may go through several nodes from v(cid:48)). We ﬁnally
reach a situation similar to the one where we created z: we create z(cid:48) and possibly
split an edge to create its parent x(cid:48). Then we set slink(z) = z(cid:48). If we had created a
node x, the path from v(cid:48) to z(cid:48) is followed in two stages, one with the string l(v, x),
and another with l(x, z). The path l(v, x) from v(cid:48) may lead to an existing node y, or
we might have to split an edge to create y. Then we set slink(x) = y (if we had to
create y, it will be that x(cid:48) = y is the parent of z(cid:48); we never create two internal nodes).
The leaf z(cid:48) represents the suﬃx d2...|d|. We continue taking suﬃx links from v(cid:48), x(cid:48) (if
we created it), and z(cid:48), until we insert all the |d| suﬃxes di...|d|. The whole process
is known to require O(|d|) operations on the suﬃx tree. Since we must update the
predecessor structures when creating children, our total time is O(|d|(log log σ)2).

The deletion of a document d is symmetric to insertion. We ﬁnd its corresponding
string, delete its leaf z and possibly its parent x if it becomes unary, follow the suﬃx
link z(cid:48) = slink(z), and repeat the process until removing all the leaves and possibly
their parents. This also takes O(|d|(log log σ)2) time.

Accelerating searches. On this dynamic suﬃx tree, ﬁnding the locus of P takes
O(p(log log σ)2) time. In order to search faster we will use a technique analogous to
the one used with the static suﬃx tree in section 2. We deﬁne (cid:96) = logσ n, and the level
of a node v as lev(v) = (cid:98)|l(root, v)|/(cid:96)(cid:99). Note that the level of a node depends on its
string depth, and thus it does not change upon updates. Each suﬃx tree node v with
parent u such that lev(v) > lev(u) will maintain a predecessor data structure called
an accelerator, storing all its highest descendant nodes z such that lev(z) > lev(v).
The key used for the predecessor data structure are the (cid:96) characters (lg n bits) formed
by l(root, z)[lev(v) · (cid:96) + 1, (lev(v) + 1) · (cid:96)]. Note these keys do not depend precisely on
v being the node holding the accelerator; any other ancestor of z of the same level of
v yields the same key. Note also that the nodes z stored in the accelerator of v are
owners of subsequent accelerators.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php94

GONZALO NAVARRO AND YAKOV NEKRICH

The predecessor structures hold O(n) nodes, and thus they require o((log log n)2)
time and linear space [5]. The total extra space is linear because each suﬃx tree node
belongs to at most one predecessor structure.

Upon searches, we start at the root and use the accelerators of successive nodes,
using consecutive chunks of (cid:96) symbols in P . In some cases we may arrive at nodes
whose string-depth diﬀerence with the previously visited node is more than (cid:96); in
those cases we check the missing symbols directly in the text, also in chunks of (cid:96)
characters. When, ﬁnally, there are less than (cid:96) remaining characters to compare in P ,
we switch to the character-based search. Thus the total search time is O(p(log log n)2/
logσ n + (logσ n)(log log σ)2) = O(p(log log n)2/ logσ n + log n).

Those accelerators must be updated upon insertions and deletions of suﬃx tree
nodes. Note that we always know l(root, v) when we insert or delete a node v. Upon
insertion of a leaf z as a child of a node x, it may turn out that the leaf must be
inserted into an accelerator (because lev(z) > lev(x)). We can simply ﬁnd the nearest
ancestor holding an accelerator via at most (cid:96) parent operations from z. We must also
initialize an empty accelerator for z. Symmetrically, when a leaf z is removed, we
may have to remove it from its ancestor’s accelerator. When an edge from v to u is
split with a new node x, it may be that lev(v) < lev(x) = lev(u). In this case, x takes
the role of u, “stealing” the accelerator from u (which needs no change, as explained).
We must also replace u by x in the accelerator stored at the proper ancestor of x.
Another case that requires care is when lev(v) < lev(x) < lev(u). In this case u is
replaced by x in the proper ancestor of x, but u retains its accelerator and x creates
a new accelerator holding only u. Other cases require no action. Upon deletions,
the obvious reverse actions are necessary. The total update time can be bounded by
O(|d| log n) for both insertions and deletions.

5.2. Relating the suﬃx tree and the grid. Since grid columns will appear
and disappear upon document insertions and deletions, we will not associate integers
with columns, but just abstract labels. The mapping between the suﬃx tree and the
grid columns will be carried out via a dynamic technique to maintain order in a list X
of such abstract labels [23, 13]. The data structure supports the operations of creating
a new label y as the immediate successor of a given label x ∈ X, deleting a label y ∈ X,
and determining which of two labels comes ﬁrst in X, all in constant time. In addition,
each suﬃx tree node v will hold a (classical) doubly linked list list(v) storing consecutive 
labels of X, each label corresponding to a grid column where this node induces
points, and will maintain pointers to the ﬁrst and the last node in list(v). Finally, v
will maintain special labels ﬁrst(v), last(v) ∈ X that do not represent any column, but
are the predecessor (resp., successor) in X of the ﬁrst (resp., last) label in its subtree.
Inserting suﬃxes. As we insert a new leaf z as the child of v, we must create a
successor of last(w) to assign to ﬁrst(z), where w is the previous sibling of z, and then
create a successor of ﬁrst(z) to assign to last(z). If z is the ﬁrst child of v, instead,
we create a successor of ﬁrst(v) to assign to ﬁrst(z). The same is done to compute
ﬁrst(z ) when we create a new node z that splits an edge from v to u, but this time
last(z) is obtained by creating a new successor of last(u). When a node z is removed,
its labels ﬁrst(z), last(z) are also removed from X.

As we insert a new document d, we must associate new grid columns with the
new and existing suﬃx tree nodes traversed. Each newly created pointer ptr(v, d) will
require creating a new label t(v, d) ∈ X as the successor of the last node in list(v)
(it will also be stored at the end of list(v)), or as the successor of ﬁrst(v) if list(v) is
empty. The pointer ptr(v, d) will be stored associated with the label t(v, d).

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

95

Computing the new weights. As we insert new leaves into the suﬃx tree, we
collect them in an array L[1,|d|]. We also create the ﬁrst label t(v, d) of such leaves
v. Now we sort L by the labels t(v, d), and as a result the new leaves become sorted
by their suﬃx tree preorder. All the internal suﬃx tree nodes that must be labeled
with d are obtained as u = lca(v, v(cid:48)) for consecutive leaves v = L[i] and v(cid:48) = L[i + 1].
We create pointers ptr(v, d) and ptr(v(cid:48), d) towards node u, associated with the labels
t(v, d) and t(v(cid:48), d), respectively, and with weights w(v, d) = w(v(cid:48), d) = 1 (as said, we
are considering term frequency weights for now). For each new internal suﬃx tree
node u = lca(v, v(cid:48)) obtained, we create a new label t(u, d) for the new grid column that
u will originate, and associate weight w(u, d) = 2 to it (at the end, w(u, d) will be the
number of leaves labeled d in the subtree of u). Each time u is obtained again (which
we know because the last element of list(u) is already t(u, d)), we increase w(u, d) by 1.
The previous procedure already visits all the internal nodes u of T that are labeled
with d, that is, all the nodes of the suﬃx tree Td of document d. Now we have to
propagate weights and pointers from those internal nodes to their nearest ancestors
labeled with d (i.e., the nodes that would be their parent in Td). For this sake, the
internal nodes u = lca(v, v(cid:48)) obtained are collected in a new array I, of size up to
|d| − 1, and I is sorted by the labels t(u, d), so that the nodes become sorted by
preorder. We traverse I left to right, simulating a recursive preorder traversal of the
suﬃx tree of document d, although the nodes are in the generalized suﬃx tree. Along
this simulated recursive traversal, each node identiﬁes its parent in Td, setting the
pointer ptr to it and increasing its weight. Let u = I[i] and v = I[j], initially, for
i = 1 and j = 2. If lca(u, v) = u, then u is the parent of v in Td. Thus we recursively
traverse the subtree that starts in v = I[j], which ﬁnishes at a node v(cid:48) = I[j(cid:48)] that is
not anymore a descendant of v. Now we check whether lca(u, v(cid:48)) = u (i.e., v(cid:48) is the
second child of u in Td), and so on. At some point, it will hold that I[j(cid:48)] does not
descend from u, and we have ﬁnished the traversal of the subtree of u. Then we set
i = j(cid:48), j = i+1, and restart the process. Along this recursive traversal we will identify
the nearest ancestor u labeled d of each node v labeled d, that is, the parent u of each
v in Td. For each such pair, and after having processed v and computed w(v, d), we
increase w(u, d) = w(u, d) + w(v, d) and generate the pointer ptr(v, d) pointing to u,
associated with label t(v, d) and weight w(v, d).

All the labels created when inserting a document d are additionally chained in a

(classical) list list(d), to facilitate deletion of the document.

Creating the grid points. Finally, we will create new columns and points in the
grid associated with all the pointers ptr(v, d) = u created. The label t(v, d) will be an
identiﬁer for the x-coordinate of the point (we remark that these are not integers, but
just labels that can be compared). The y-coordinate will be the string depth of the
target node, |l(root, u)|. This value is stored in the suﬃx tree node when the node
is created and, unlike the tree depth, does not change upon suﬃx tree updates. The
document associated with the new point is the new one, d, and the weight is the value
w(v, d) associated with the source node of the pointer.
The overall time of inserting d is O(|d| log |d|), dominated by the sorting via

comparisons of labels in X.

Deleting documents. Handling the deletion of a document d is simple. After
deleting all the corresponding suﬃx tree nodes, we follow the chain of labels t(v, d)
in list(d), delete them from X, and remove their nodes from the doubly linked list
list(v). This takes O(|d|) additional time. We also remove the columns in the grid
corresponding to the labels deleted, and the associated points. Both insertion and
deletion times are superseded by those of section 5.1.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php96

GONZALO NAVARRO AND YAKOV NEKRICH

5.3. Slim grids. To achieve faster searches, the grid will be divided into horizontal 
slices of small height r. For every slice, we maintain a structure that reports k
most highly weighted points from a horizontal range of labels [a, b) intersected with
a vertical range of integers [0, y). We describe here how those slices are updated and
queried for a sublogarithmic value of r, and in section 5.4 we extend the solution to
grids of polylogarithmic height.
Each slice is represented with a B-tree ordered by the labels (i.e., x-coordinates)
of the points of arity r to 2r − 1, for some r = lgε n and a constant 0 < ε < 1/2 (as
usual, the root can have arity as low as 2). Thus the B-tree has height O(logr n).
At each internal node u with a(u) children v1, . . . , va(u), we will store a(u) arrays
Wv1 [0 . . . r − 1], . . . , Wva(u)[0 . . . r − 1]. In these arrays Wv, Wv[y] is the point p with
maximum weight among all points (1) whose x-coordinates belong to the subtree
of v, (2) with y-coordinate equal to y, and (3) not stored in Wu[y] for ancestors u
of v (some Wv[y] cells can be empty, if no point with y-coordinate y exists below
v). We will also store a structure Wroot for the root node. Thus Wroot[y] contains
the point pr of maximum weight among all points with y-coordinate y; for a child
v of the root, Wv[y] contains the point pv of maximum weight among all points
p (cid:54)= pr in the subtree of v with y-coordinate y. In general, all points already stored
in ancestors are excluded from consideration. We store Wv[y] = (x, w, d), where
x is the x-coordinate, w is the weight, and d is the document of the point. Each
point is also stored in the corresponding leaf node of the B-tree. Those points in
Wv are not used to separate the x-coordinates of the points in the tree.
Instead,
new labels x(v1) . . . x(va(u)−1) ∈ X will be created and stored at node u, to split
the points between its a(u) consecutive children. That is, the x-coordinate of any
point stored below vi will be between x(vi−1) and x(vi). The size of the list X stays
O(n).
The leaves of the B-tree will store r to 2r − 1 points. Leaves store the actual
points, even if they are also mentioned in some previous Wv structure. The points
in leaves l are arranged in an array W (cid:48)
l , which is similar to the arrays Wv and lists
the points in increasing y-coordinate order, except that W (cid:48)
l has no empty cells and
some y-coordinates can be repeated in the points. Therefore the W (cid:48)
l cells store the
full point data, W (cid:48)
With each internal node u with children v1, . . . , va(u) we will also associate structures 
Yx u[0 . . . a(u)r − 1] and Yw u[0 . . . a(u)r − 1], where the child numbers and the
y-coordinates of the (up to) r points of the a(u) arrays Wvi are sorted by their xcoordinate 
label (in Yx u) and by their weight (in Yw u). That is, in Yx u and Yw u
we store the pair (i, y) for each entry Wvi[y], ordered by Wvi[y].x (in Yx u) or by
Wvi[y].w (in Yw u). Each value stored in Yx u and Yw u requires lg(2r2) bits, thus all
the values in these two structures add up to at most 4r2 lg(2r2) bits. Each time we
modify a value in a Wvi array, we rebuild from scratch the Yx u and Yw u structures
of the parent u of vi.
l on the (up to) 2r − 1 points of
leaves l, analogous to the Yx u and Yw u structures of internal nodes. Instead of the
pairs (i, y), structures Yx(cid:48)
l (those
positions would coincide with y-coordinates in internal nodes). Leaves will also store
an array Yl[0 . . . r−1] where Yl[y] = j if j is the last position where W (cid:48)
l [j] < y. Finally,
leaves will store bitmaps Ql marking in Ql[j] whether the point in W (cid:48)
l [j] also appears
in the Wv array of an ancestor v of l.
Since 4r2 lg(2r2) = o(log n), universal tables of 24r2 lg(2r2)· O(polylog (r2)) = o(n)
bits will be used to query and update the arrays Yx u and Yw u, in constant time. Siml 
will just store positions j of the array W (cid:48)

l [j] = (x, y, w, d).

We will also maintain structures Yx(cid:48)

l and Yw(cid:48)

l and Yw(cid:48)

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

97
ilarly, leaves will use even smaller universal tables of 24r lg(2r) · O(polylog (r)) = o(n)
bits.

The whole data structure requires linear space, because the leaves contain Θ(r)
points. The Wv arrays of internal nodes spend Θ(r) words and can be almost empty
(if all the descendants have the same y-coordinate, say), but there are only O(n/r)
internal nodes. If the whole grid contains less than r points, we just store the space
for them in a leaf.

5.3.1. Insertions. Consider the insertion of a new point (x, y, w, d), with label
x ∈ X, y-coordinate y ∈ [0, r), weight w, and document d. While following the normal
insertion procedure on the B-tree (where we compare the labels x(vi) of the nodes with
x to decide the insertion path), we look for the highest node v with Wv[y].w < w or
with Wv[y] empty. For the ﬁrst (i.e., highest) such v we ﬁnd, we set Wv[y] ← (x, w, d),
and then we continue the classical insertion procedure (not looking at Wv[y] entries
anymore) until adding the point (x, y, w, d) in a leaf l. In the leaf we mark in the
corresponding Ql entry whether we had updated an entry Wv[y] in some ancestor v.
If we updated some Wv[y], and it already had a previous value Wv[y] = (x(cid:48), w(cid:48), d(cid:48)),
we perform a process we call reinsertion of (x(cid:48), w(cid:48), d(cid:48)). We restart the process of
inserting the point (x(cid:48), y, w(cid:48), d(cid:48)) from node v (note that this point already exists in a
leaf; reinsertion will not alter the structure of the tree, but just rewrite some W and
Q values). In the reinsertion path, if we arrive at a node v(cid:48) where Wv(cid:48)[y].w < w(cid:48),
we set Wv(cid:48)[y] ← (x(cid:48), w(cid:48), d(cid:48)). If there was a previous value Wv(cid:48)[y] = (x(cid:48)(cid:48), w(cid:48)(cid:48), d(cid:48)(cid:48)), we
continue the reinsertion process for point (x(cid:48)(cid:48), w(cid:48)(cid:48), d(cid:48)(cid:48)) from node v(cid:48), and so on until
either we ﬁnd an empty space in some Wu[y] or we reach the leaf l where the point
being reinserted is actually stored. In this latter case, we clear the corresponding bit
in Ql, indicating that this point is not stored anymore in an ancestor structure.

Thus we traverse two paths, one for inserting the point, and another for reinserting
the point(s) possibly displaced from some Wv[y] structure. This part of the operation
requires, in the worst case, O(logr n) updates to the structures Yx u and Yw u of the
parents u of nodes v where Wv is modiﬁed, plus an insertion in a leaf.
Rebuilding structures Yx u and Yw u. Upon an assignment Wvi[y] ← (x, w, d), we
must rebuild the structures Yx u and Yw u of the parent u of vi. We binary search
Yx u for x, and binary search Yw u for w, both in O(log(r2)) = O(log r) time. In these
binary searches we obtain the actual label and weight of each element of Yx u and
Yw u, respectively, using its (i(cid:48), y(cid:48)) pair, as Wvi(cid:48) [y(cid:48)].x and Wvi(cid:48) [y(cid:48)].w. These binary
searches give the insertion positions 0 ≤ e < 2r2 and 0 ≤ g < 2r2, respectively, of the
pair (i, y) in Yx u and Yw u. Note that the new contents of Yx u and Yw u depend only
on their current contents, on the values e and g, and on the incoming pair (i, y) (the
existing occurrence of (i, y), if any, must be removed). Thus, the new content of Yx u
and Yw u for each (e, g, i, y) can be precomputed in a universal table of o(n) bits, as
explained, so that they are updated in constant time. Therefore the time to update
the structures is O(log(r2)) = O(log r), and the cost of a full reinsertion process is
O(logr n log r) = O(log n).

The process to update Yx u and Yw u upon removal of the value of a cell Wvi[y]
is analogous: We ﬁnd with binary search the positions e and g of the pair (i, y) to
remove, and then compute the new structures Yx u and Yw u in constant time with a
universal table.

When a new internal node of the B-tree is created, or when an internal node is
removed, we have to create a whole new Wv array, or remove a whole array Wv. We
can insert or remove all such cells one by one in Yx u and Yw u in time O(r log r). In

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php98

GONZALO NAVARRO AND YAKOV NEKRICH

l and also inserting the point data in Yl, Yx(cid:48)

those cases, we must rename all the labels i in the pairs (i, y) stored in those structures,
but those updates can also be precomputed in universal tables of sublinear size.
Insertion in leaves. In leaves l, we must actually insert the point, possibly disl,
 Yw(cid:48)
placing all the entries in W (cid:48)
l, and
Ql, all in O(r) time. When a leaf overﬂows to 2r points, we must split it into two
leaves l(cid:48) and l(cid:48)(cid:48) of r points each. We ﬁrst remove the array Wl from the parent u of
l, clearing the corresponding bits in Ql. Now we distribute the points of W (cid:48)
l into the
l(cid:48)(cid:48), and make l(cid:48) and l(cid:48)(cid:48) children of u, replacing the old l. We
new arrays W (cid:48)
create a new label x(l(cid:48)) ∈ X as the successor of the largest x-coordinate in l(cid:48), and
add it to u separating l(cid:48) and l(cid:48)(cid:48).
Next we build new arrays Wl(cid:48) and Wl(cid:48)(cid:48). Those arrays, as well as the Y , Yx(cid:48), Yw(cid:48),
and Q structures of l(cid:48) and l(cid:48)(cid:48), are built in O(r) time from W (cid:48)
l, and Ql. We
also set in Ql(cid:48) and Ql(cid:48)(cid:48) the points that have been included in Wl(cid:48) and Wl(cid:48)(cid:48) (we cannot
choose any point for Wl(cid:48) and Wl(cid:48)(cid:48) that is already marked in Ql). Finally, we update
the tables Yx u and Yw u according to the new tables Wl(cid:48) and Wl(cid:48)(cid:48) .

l(cid:48) and W (cid:48)

l , Yx(cid:48)

l, Yw(cid:48)

The overall time is O(r), but this is dominated by the O(r log r) time needed to
update the Yx u and Yw u arrays upon the O(r) changes induced by replacing Wl by
Wl(cid:48) and Wl(cid:48)(cid:48).

Overﬂows in internal nodes. The insertion of a new child in the parent u can
trigger an overﬂow in this internal node, if its arity reaches 2r. We must split u,
with children v1, . . . , v2r, into two nodes, u(cid:48) with children v1, . . . , vr and u(cid:48)(cid:48) with
children vr+1, . . . , v2r. The process is analogous to the case of leaves, but slightly
more complicated. We create a new x-coordinate x(u(cid:48)) ∈ X as a successor of x(vr),
to separate the points of u(cid:48) and u(cid:48)(cid:48). We create the two nodes u(cid:48) and u(cid:48)(cid:48) with their
corresponding arrays Wv1, . . . , Wvr and Wvr+1, . . . , Wv2r , and build the tables Yx and
Yw of u(cid:48) and u(cid:48)(cid:48), in O(r2) time from Yx u and Yw u.

Now we must create new arrays Wu(cid:48) and Wu(cid:48)(cid:48) to replace Wu in the parent of
u. First, we move each point in Wu[y] to Wu(cid:48)[y] or Wu(cid:48)(cid:48) [y], according to its xcoordinate.
 Now we can get rid of Wu, but we still have several empty cells in Wu(cid:48)[y]
and Wu(cid:48)(cid:48) [y]. Those are ﬁlled with a process we call uninsertion: To ﬁll some cell
Wu(cid:48)[y] (analogously for u(cid:48)(cid:48)), we take the maximum weight in cells Wv1[y], . . . , Wvr [y].
The maximum Wvi[y].w is found in constant time using a universal table on Yw u(cid:48) that
returns the ﬁrst pair with y-coordinate equal to y. Then we copy Wu(cid:48)[y] ← Wvi[y],
and continue the uninsertion process for Wvi[y]. When we ﬁnally arrive at uninserting
a point from a leaf l, all we have to do is to clear the corresponding entry in Ql. Note
that uninsertion does not alter the structure of the tree; it just rewrites some W and
Q values. The cost of one uninsertion is O(logr n log r) = O(log n), to rebuild the
aﬀected structures Yx and Yw . Thus the O(r) uninsertions in u(cid:48) and u(cid:48)(cid:48) add up to
O(r log n) time, which subsumes the O(r log r) cost to replace Wu by Wu(cid:48) and Wu(cid:48)(cid:48)
in the parent of u.

Note that the insertion of a single point could produce one split per level of the
B-tree, which would be too costly. To avoid this, we use a deamortization technique
by Fleischer [28]. This allows nodes to have from r/2 to 2r children. It maintains a
cursor per leaf, which all the time is navigating upwards to the root and then returns
to the leaf. Each update on the leaf also moves its cursor one step upwards. The node
where the cursor lies is split if it has r children or more (for leaves, r elements or more).
If the leaves are of size logr n (the tree height) or more, then one can ensure [28] that
all the nodes contain r/2 to 2r elements, and only one split per update is performed.
We can easily accommodate this wider freedom for the node arities. The problem is
that our leaves are of size r = lgε n, too small for the cursor to return to the leaf in

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

99

time for the next overﬂow. We then use a hybrid scheme: The lower nodes of the
tree, of height up to 1/ε (taking a leaf as height 1) are organized as weight-balanced
B-trees (WBB-trees) [8], which diﬀer from classical B-trees only in the policy to split
nodes. Our WBB-tree leaves contain r to 2r elements, whereas nodes of height h > 1
have arity r/4 to 4r and contain rh/2 to 2rh elements in their leaves. The nodes in
WBB-trees perform the splits as soon as they are needed, whereas the higher nodes
use Fleischer’s scheme. Then an update may trigger O(1/ε) splits at lower nodes,
each of which costs O((1/ε)r log n), for a total of O(r log n) time. The lowest nodes of
the higher levels act at the same time as the root of the WBB-trees and as the leaves
in Fleischer’s scheme. They contain at least (lg n)/2 elements in their subtree, and
therefore they can only overﬂow once every (lg n)/2 insertions due to the WBB-tree
splitting policies [8, Lem. 7]. Therefore Fleischer’s cursors associated with those leaves
have time to return to them and carry out the necessary splits.

5.3.2. Deletions. Deletion of a point (x, y) starts by searching the B-tree for
the x-coordinate x. The point will be found in its leaf, and also possibly in some cell
Wv[y] of some internal node v. The search takes O(log n) time because, for internal
nodes u, we do a binary search on the coordinates x(vi) stored in u for the correct
child v, in O(log r) time, and then only have to check if Wv[y].x = x. In leaves l, we
do a binary search for x in Yx(cid:48)

l in O(log r) time.

If the point has to be deleted from some Wv[y], we carry out the uninsertion
process already described, in O(logr n log(r2)) = O(log n) time. We also remove the
point (x, y) itself from leaf l. When a leaf l underﬂows, we merge it with a neighbor
leaf and, if necessary, split it again. The merging process is analogous to the splitting
and can be easily carried out in O(r) time, plus O(r log r) to update the structures
Yx and Yw in the parent.
If an internal node underﬂows, we also merge it with its neighbor and resplit
it if necessary. The merging of two sibling nodes v and v(cid:48) is carried out in O(r)
time, including the construction of the Yx and Yw structures for the merged node,
u. The diﬃcult part is, again, to get rid of the arrays Wv and Wv(cid:48) at the parent
node, replacing them by a new Wv∗ table for the merged node v∗. For this sake, we
choose the maximum weight between each Wv[y] and Wv(cid:48)[y] and assign it to Wv∗ [y].
The point that was not chosen among Wv[y] and Wv(cid:48)[y] must be reinserted, as before.
Finally, we must rebuild the Yx and Yw structures of the parent of v∗. The total
cost is O(r log n), just as for insertions.

Note that, upon leaf or internal node merges, a separating label x(v) becomes
unused, and it is removed from X. Like Fleischer [28], to avoid excessive merging
work, we delay these merges and use global deamortized rebuilding [59].

5.3.3. Queries.
Identifying the relevant nodes. To solve a top-k query with label restriction [a, b)
and y-coordinate restriction [0, y) on the slice, we ﬁrst identify the O(logr n) ranges
of siblings of the B-tree tree that exactly cover the interval of labels [a, b); plus up to
2 leaf nodes that partially overlap the interval. For each node u that is the parent of
a range of children vs, . . . , ve included in the cover, we ﬁnd the maximum weight in
Wvs [0, y − 1], . . . , Wve[0, y − 1] and insert the result in a max-priority queue Q sorted
by the weights of the points. Such a maximum across Wvi[0, y − 1] arrays is obtained
in constant time using universal tables on Yw u that ﬁnd the ﬁrst pair (i, y(cid:48)) with
s ≤ i ≤< e and y(cid:48) < y. For the leaves l partially or fully overlapping [a, b), the
points fall in the interval W (cid:48)
l [0, Yl[y]]. In addition, if the leaf partially overlaps [a, b),
we must binary search Yx(cid:48)
l for the range [xa, xb] corresponding to the interval [a, b).

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php100

GONZALO NAVARRO AND YAKOV NEKRICH

l [j], that the range of interest is W (cid:48)

l[xa, xb] and the range W (cid:48)
l, Yw(cid:48)

Furthermore, we can only return points whose Ql bit is not set, to avoid repeated
answers. Knowing the range in Yx(cid:48)
l [0, Yl[y]], the maximum
weight can be obtained from Yx(cid:48)
l, and Ql with a universal table, in constant
time. Identifying the cover nodes and ﬁnding their O(logr n) maxima takes O(log n)
time, and leaves add only O(log r) time.
Each element inserted in Q coming from a range of siblings will be a tuple
(u, s, e, i, z, k), where u is the parent node of the range of children vs, . . . , ve in the
cover, (i, z) means that the maximum was found at Wvi[z] (s ≤ i ≤ e), and k indicates
that the point Wvi[z] is the kth in the range of interest for u. All the nodes initially
inserted have k = 1.
The elements inserted in Q coming from leaves l are of the form [l, j, xa, xb, k],
meaning that the maximum was found in W (cid:48)
l [0, Yl[y]]
and Yx(cid:48)[xa, xb], and that the point is the kth in the range of interest. The ﬁrst insertions 
use k = 1.
We also insert in Q a third kind of tuples, namely, the maximum-weight point in
Wv[0, y − 1] with x-coordinate in [a, b), for each of the O(logr n) ancestors v of the
cover nodes, as they may also hold relevant points. To ﬁnd those maxima we consider
the parent u of v and binary search Yx u for a and b, to ﬁnd a mapped interval
Yx u[xa, xb], in O(log(r2)) = O(log r) time. Note that this area of Yx u corresponds
to nodes in Wv. Then we use universal tables on Yx u and Yw u to ﬁnd the maximum
weight of y-coordinate below y and in the range Yx u[xa, xb]. For these nodes we insert
tuples of the form (cid:104)u, v, z, xa, xb, k(cid:105) in Q, meaning that the maximum was obtained
from Wv[z], the range of interest is Yx u[xa, xb], and the point is the kth in its range
of interest. Since all these ancestors also amount to O(logρ n), the initial computation
on these nodes requires O(logr n log r) = O(log n) time. Recall that the root node of
the B-tree will also have a W structure computed (this is easily treated as a special
case).
We implement Q as a Thorup’s priority queue [67] on the universe of weights
[1, O(n)]. Note that we do not need to insert the whole initial set of O(logr n) tuples
in Q if this number exceeds k: If a tuple is not among the ﬁrst k, it cannot contribute
to the answer. Then we use linear-time selection to ﬁnd the kth largest weight in the
tuples and then insert only the ﬁrst k tuples in Q. This structure supports insertions
in constant time, thus the initialization of Q takes time O(logr n).
Extracting the top-k points. The ﬁrst answer to the top-k query is among the
O(k) tuples we have inserted in Q. Therefore, to obtain the ﬁrst result, we extract
the tuple with maximum weight from Q. If it is of the form [l, j, xa, xb, k], that is,
it comes from a leaf l, we report the point W (cid:48)
l [j], compute the (k + 1)th highestl 
[0, Yl[y]] and Yx(cid:48)
weight point W (cid:48)
l[xa, xb] using universal tables, and
reinsert tuple [l, j(cid:48), xa, xb, k + 1] in Q. (To these universal tables we give, in addition,
the latest point reported, and they ﬁnd the next one in decreasing weight order.)
If, instead, the maximum tuple extracted from Q is of the form (cid:104)u, v, z, xa, xb, k(cid:105),
that is, it becomes from an ancestor of a cover node, we report the point Wv[z],
compute the (k + 1)th highest-weight point Wv[z(cid:48)] with y-coordinate below y and
within Yx u[xa, xb] using universal tables, and reinsert tuple (cid:104)u, v, z(cid:48), xa, xb, k + 1(cid:105).
Finally, if the maximum tuple extracted from Q is of the form (u, s, e, i, z, k), we
report the point Wvi [z], where vi is the ith child of u, compute the (k + 1)th highestweight 
point Wvi(cid:48) [z(cid:48)] in Wvs[0, y − 1], . . . , Wve [0, y − 1] using universal tables, and
reinsert tuple (u, s, e, i(cid:48), z(cid:48), k + 1). If the extracted point had k = 1, however, it is
possible that the next highest-weight element comes from the child vi. Therefore, if vi
is an internal node, we compute the highest-weight point in Yw vi with y-coordinate

l [j(cid:48)] within W (cid:48)

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

l [j(cid:48)] in W (cid:48)

l [0, Yl[y]] using Yw(cid:48)

101
below y. Let it be the pair (i(cid:48)(cid:48), z(cid:48)(cid:48)), then we insert a new tuple (vi, 1, a(vi), i(cid:48)(cid:48), z(cid:48)(cid:48), 1) in
Q. If, instead, vi is a leaf l = vi with r(l) elements, then we ﬁnd the maximum-weight
l, and insert the tuple [l, j(cid:48), 1, r(l), 1] in Q. In all
point W (cid:48)
cases the cost to compute and insert the new tuples is constant.
If we carry out k extractions from Q, we will also carry out up to 2k insertions,
 thus the size of Q will be O(k) and minima extractions will cost O(log log k)
[67]. The cost of this part is then O(k log log k), and the total query time is
O(log n + log r + log n + logr n + k log log k). Recalling that r = lgε n, the query
time is O(log n + k log log k) and the update time is O(r log n) = O(log1+ε n). Note
that the process is not online: We must know k in advance so as to initially limit the
size of Q to k. We use the technique of section 4.4 to make the process online in k.
That is, k is not speciﬁed in advance and the process can be interrupted after having
produced any number k of results, and the total cost paid will be O(log n + log log k).

5.4. Multiresolution grids. We extend the result of section 5.3 to grids of
polylogarithmic height rc for some constant c. We will represent the grid at various
resolutions and split it into slim grids for each resolution. Consider a virtual perfect
tree of arity r and n leaves, so that the ith left-ro-right node of height j covers the
rows (i − 1) · rj + 1 to i · rj. The tree is of height c.

For each node v of this tree we store a slim grid of r rows, one per child. All the
points whose row belongs to the area covered by the ith child of v will be represented
as having y-coordinate i in the slim grid of v.

When a new point (x, y, w, d) is inserted into the grid, we insert it into the c slim
grids that cover it, giving it the appropriate row value in each slim grid, and similarly
when a point is deleted. The x-coordinate labels are shared among all the grids. This
arrangement multiplies space and insertion and deletion times by the constant c.

Now consider a 3-sided top-k query with the restriction [a, b) on the x-coordinates
and [0, y) on the y-coordinates. The range [0, y) is covered with the union of one range
in one slim grid per level of the tree. Let yc, . . . , y1 be the child numbers of the path
from the root to the yth row of the grid. Then we take the 3-sided query [a, b)× [0, yj)
at the node of height j in the path.
We stotart the searches in the c slim grids, and extract the ﬁrst result from each
grid. We insert those local maxima into a new global queue Q. Now we repeat k
times the process of extracting the next result from Q, reporting it, requesting the
next result from the grid where the result came from, and inserting it into Q. Note
that Q can be implemented naively because it contains at most c elements and c is a
constant.
Initializing the searches will then require O(c log n) time, and extracting k results
from the slim grids will require O(k log log k) time. Managing Q will require O(ck)
time even if done naively. Therefore the total time is still O(log n + k log log k). The
update time per element stays O(c log1+ε n). The process is also online. Then we
obtain the following lemma.

Lemma 6. A set of n points, one per column on an n× rc grid, for r = lgε n and
any constant 0 < ε < 1 and c ≥ 1, with weights in [1, O(n)], can be stored in O(n)
words of space, so that for any 1 ≤ k ≤ n, 1 ≤ h ≤ rc, and 1 ≤ a ≤ b ≤ n, k most
highly weighted points in the range [a, b] × [0, h] can be reported in decreasing order of
their weights in O(log n + k log log k) time, online in k. Points (and their columns)
can be inserted and deleted in O(log1+ε n) time.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php102

GONZALO NAVARRO AND YAKOV NEKRICH

5.5. The ﬁnal result. We ﬁnd the locus v of P in the suﬃx tree in time
O(p(log log n)2/ logσ n + log n). Then the x-coordinate range of labels to search for
in the grid is [a, b), where a is the ﬁrst label in list(v) and b = last(v). Since we store
string depths in the grid, the y-coordinate range of the query is [0, p).

Our dynamic grid is horizontally split into bands of rc rows, for a constant c, which
are handled as explained in section 5.4. Therefore, our 3-sided query is translated into
3-sided queries on the ﬁrst (cid:100)p/rc(cid:101) bands. All but the last will query for the whole row
interval [0, rc), whereas the latter will query for the row interval [0, (p − 1) mod rc].
We start the searches in all the bands, and extract the ﬁrst result from each. If
there are more than k bands, we use linear-time selection to keep only the k highest
weights. Then we insert the local maxima into a new global queue Q. Now we repeat
k times the process of extracting the ﬁrst result from Q, and if it came from the ith
band, then we request the next result from that band and insert it into Q (unless it
has no more results, in which case we continue with the remaining bands). Again, Q
will be implemented with Thorup’s priority queue [67].
Initializing the searches will then require O((cid:100)p/rc(cid:101) log n) time, and extracting k
(and inserting other k) results into Q will take time O(k log log k). We choose r = lgε n
for some 0 < ε < 1/2, as explained, and rename c as (c + 1)/ε. Therefore, we obtain
a query time of O(p/ logc n + log n + k log log k) for the grid. Once again, the scheme
can be made online with the technique of section 4.4. Updating grid points, including
extending the grid downwards, requires O(log1+ε n) time. This yields Theorem 5.

We developed our result for tf as the relevance measure. It is very easy to support
others like docrank , but if the weights are not integer numbers, then Thorup’s priority
queues [67] cannot be used. In this case we insert all the new weights that appear in a
data structure for monotonic list labeling, which assigns them integers in a polynomial
universe [1, nO(1)]. This adds at most O(log n) time per symbol inserted [22] (deletions
can be handled by deamortized periodic rebuildings [59]). In general we can support
any measure that can be computed in time O(|d|Cw) over the suﬃx tree Td of the
document d to insert: We explicitly build Td, compute the relevance measure for all
the nodes, and then use them to assign the weights as we insert the nodes into our
suﬃx tree. At the end we delete Td. This suﬃx tree can be built (and deleted) in
O(|d|) time on integer alphabets [24]. Therefore we simply charge O(Cw) time per
character inserted into our text collection. Note that Cw is O(1) for measures tf
and docrank . Hon, Shah, and Vitter [41] show how to compute mindist from Td in
O(|d| log |d|) time, so Cw = O(log n) in this case.

Our scheme works as long as lg n has a ﬁxed value (plus O(1)). We use standard
techniques to incrementally rebuild the structure for larger or smaller lg n values as
more insertions or deletions are processed [58].

6. A space-eﬃcient data structure. We now show how the space of our
static structure can be reduced to O(n(log σ + log D + log log n)) bits, where σ is
the alphabet size and D is the number of documents, and retain almost the same
query time. Our approach is to partition the tree into minitrees, which are connected
subtrees containing O(σ2D log n) nodes, so that their grids can be represented within
the given space. Pointers ptr that cross over minitrees can be safely replaced by
shorter ones going from some minitree leaf to a fake node above the minitree root,
without altering the answers to top-k queries. The minitrees are seen as nodes in a
so-called contracted tree T c, which requires only O(n) bits. Some queries are solved
locally within a minitree, while others are solved on T c. To ﬁnd the locus in the
right minitree or in T c, we use a compressed suﬃx tree data structure, which uses

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

103

O(n log σ) bits. This is responsible for the slight increase in query times compared
to the linear-space version of Theorem 1. In section 6.1 we show how to remove the
O(n log log n) term from the space when the relevance measure is the term frequency,
by exploiting particularities of this measure.
Partitioning the suﬃx tree. We deﬁne z = Θ(σD log n). We say that a suﬃx tree
node v ∈ T is heavy if the subtree rooted at v has at least z leaves, otherwise it is
light. A heavy node is fat if it has at least two heavy children, otherwise it is thin.

All the nonfat nodes of T are grouped into minitrees as follows. We traverse T
in depth-ﬁrst order. If a visited node v has two heavy children, we mark v as fat and
proceed. If v has no heavy children, we mark v as thin or light, and make v the root
of a minitree Tv that contains all the descendants of v (which need not be traversed).
Finally, if v has one heavy child v1, we mark v as thin and make it the root of a
minitree Tv. The extent of this minitree is computed as follows. If vi, i ≥ 1, is a thin
node with one heavy child vi+1, we visit nodes v1, v2, . . . , vj−1 and include vi and all
the descendants of its other children, until either vj−1 has no heavy children or is fat,
or Tv contains more than σz nodes after considering vj. Then we continue our tree
traversal from vj. Note that Tv contains at the very least the descendants of v by
children other than v1.

With the procedure for grouping nodes described above, the leaves of minitrees
can be parents of nodes not in the minitree. Those child nodes can be either fat nodes
or roots of other minitrees. However, at most one leaf of a minitree can have children
in T .

Note that the size of a minitree is at most O(σz). On the other hand, as two heavy
children have disjoint leaves, there are O(n/z) fat nodes in T . Finally, minitrees can
contain as little as one node (e.g., for leaves that are children of fat nodes). However,
note that a minitree root is either a child of a fat node (and thus there are O(σn/z)
minitrees of this kind), or a child of a leaf of another minitree such that the sum of
both minitree sizes exceeds σz (otherwise we would have included the root vj of the
child minitree as part of the parent minitree). Moreover, as said, at most one of the
leaves of a minitree can be the parent of another minitree, so these minitrees that are
“children” of others form chains where two consecutive minitrees cover at least σz
nodes of T . Thus there are O(n/(σz)) minitrees of this second kind. Adding up both
cases, there are O(σn/z) = O(n/(D log n)) minitrees in T .

Contracted tree and minitrees. The pointers in a tree T are deﬁned in the same
way as in section 2. Since we cannot store T without violating the desired space
bound, we store a contracted tree T c and the minitrees Tv.
The contracted tree T c contains all fat nodes of T , plus one node vc for each
minitree Tv. Each pointer ptr(u, d) = u(cid:48) of T is mapped to a pointer ptrc(uc, d) = (u(cid:48))c
of T c as follows. If u is a fat node, then uc = u. Otherwise, if u belongs to minitree Tv,
then uc = vc. Similarly, if u(cid:48) is a fat node then (u(cid:48))c = u(cid:48); otherwise, if u(cid:48) belongs to
minitree Tv(cid:48) then (u(cid:48))c = (v(cid:48))c. In other words, nodes of a minitree are mapped to the
single node that represents that minitree in T c and pointers are changed accordingly.
For each minitree Tv, we store one additional dummy node ν that is the parent
(cid:54)∈ Tv, we store an additional dummy
of v. If a leaf uh of Tv has a heavy child u(cid:48)
node ν(cid:48) ∈ Tv that is the only child of uh. Pointers of Tv are modiﬁed as follows.
Each pointer ptr(u, d), u ∈ Tv, that points to an ancestor of v is transformed into a
pointer ptr(u, d) that points to ν. Every pointer ptr(u(cid:48)(cid:48), d) that starts in a descendant
u(cid:48)(cid:48) of uh and points to a node u ∈ Tv, u (cid:54)= uh (respectively, to an ancestor of v), is
transformed into ptr(ν(cid:48), d) that starts in ν(cid:48) and points to u (respectively, to ν). By
Lemma 2, there are at most D such pointers ptr(u(cid:48)(cid:48), d). We observe that there is no

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php104

GONZALO NAVARRO AND YAKOV NEKRICH

need to store pointers to the node uh in the minitree Tv because such pointers are
only relevant for the descendants of uh that do not belong to Tv.

Compressed suﬃx trees. The contracted tree T c consists of O(n/(D log n)) nodes,
and thus it would require just O(n/D) bits. The minitrees contain O(σz) nodes, but
still an edge of a minitree can be labeled with a string of length Θ(n).
Instead
of representing the contracted tree and the minitrees separately, we use Sadakane’s
compressed suﬃx tree (CST) [63] to represent the topology of the whole T in O(n)
bits, and a compressed representation [35] of the global suﬃx array of the string collection,
 which takes O(n log σ) bits. This suﬃx array representation ﬁnds the suﬃx
array interval [l, r] of P in time O(p/ logσ n + logε
σ n) for any constant ε > 0, and a
lowest-common-ancestor query for the lth and rth leaves of T ﬁnds the locus u of P
in O(1) additional time. A bitmap M [1, n] marks which nodes are minitree roots, and
another bitmap C[1, n] marks which nodes are fat or minitree roots. Both are indexed
with preorder numbers of T , which are computed in constant time on the CST. With
a simple O(n)-bit structure for constant-time marked ancestor queries that is compatible 
with our CST representation [61, section 4.1], we can ﬁnd the lowest ancestor v of
u marked in M or in C. With bitmap M we can identify whether u belongs to a minitree 
rooted at v (with local preorder preorderTv (u) = preorderT (u) − preorderT (v)
and depth depthTv (u) = depthT (u) − depthT (v); depths are also computed in constant 
time). Similarly, with C and M we can identify whether u is a fat node, and
ﬁnd out its preorder in T c as preorderT c(u) = rank1(C, preorderT (u)) in constant
time. Its depth in T c can be stored in an array indexed by preorderT c in O(n/D)
bits.

Contracted grid. We deﬁne the grid of the contracted tree T c as in section 2,
considering all pointers ptrc. Those are either ptr pointers leaving from fat nodes, or
leaving from inside some minitree Tv and pointing above v. For every fat node and
for every minitree Tv, and for each document d, there is at most one such pointer by
Lemma 2. Thus each node of T c contributes at most D pointers ptrc. As there are
O(n/(D log n)) nodes, there are O(n/ log n) pointers ptrc in T c.

Therefore, the grid associated with T c is of width O(n/ log n) and height
O(n/(D log n)). As there are O(n/ log n) distinct weights among the ptrc pointers,
we only store their ranks. This change does not alter the result of any top-k query.
Therefore the data structure of Theorem 4 on T c occupies O(n/ log n) words, or O(n)
bits.

Local grids. The local grid for a minitree Tv collects the pointers ptr local to Tv.
It also includes at most D pointers towards its dummy root ν, and at most D pointers
coming from its node ν(cid:48), if it has one. Overall Tv contains O(σz) pointers and O(σz)
nodes, so its grid is of size O(σz) × O(σz). The weights are also replaced by their
ranks, so they are also in the range [1, O(σz)]. Using Theorem 4 the minitree requires
O(log(σz)) bits per node. Added over all the nodes of T that can be inside minitrees,
the total space is O(n log(σz)) = O(n(log σ + log D + log log n)). Note that the tree
topology is already stored in the CST, so information associated with nodes u ∈ Tv
such as the intervals [lu, ru] can be stored in arrays indexed by preorder numbers.

Queries. Given a query pattern P , we ﬁnd the locus u of P and determine whether
u is a fat node or if it belongs to a minitree in O(p/ logσ n+logε
σ n) time, as explained.
If u is fat, we solve the query on the contracted grid of T c. Note that this grid does
not distinguish among diﬀerent nodes in the same minitree. But since u is an ancestor
either of all nodes in a minitree or of none of them, such distinction is not necessary.
If u belongs to a minitree Tv, we answer the query using the corresponding local
grid. This grid does not distinguish where exactly the pointers pointing to ν lead, nor

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

105
where exactly the pointers that originate in ν(cid:48) come from. Once again, however, this
information is not important in the case where the locus u of P belongs to Tv.

Note that we still need to maintain the global array mapping x-coordinates to

document identiﬁers. This requires O(n log D) bits.

Theorem 7. Let D be a collection of D documents over an integer alphabet [1, σ]
with total length n, and let w(S, d) be a function that assigns a numeric weight to string
S in document d, that depends only on the set of starting positions of occurrences of
S in d. Then there exists an O(n(log D + log σ + log log n))-bit data structure that,
given a string P and an integer k, reports k documents d containing P with highest
w(P, d) values, in decreasing order of w(P, d), in O(p/ logσ n + logε
σ n + k) time, for
any constant ε > 0.

In case p < lg1+ε

σ n, we can use a diﬀerent compressed suﬃx array [11], which

gives O(p) search time, and the overall time becomes O(p + k).

6.1. A smaller structure when using term frequencies. In this section we
show that the space usage can be further improved if w(P, d) = tf , i.e., when the data
structure must report k documents in which P occurs most frequently.

Our improvement is based on applying the approach of Theorem 7 to each minitree.
 The nodes of a minitree are grouped into microtrees; if the structure for a
microtree still needs too much space, we store them in a compact form that will be
described below.
Let z(cid:48) = σD lg m, where m is the number of nodes in a minitree T . Using the
same method as in Theorem 7, we divide the nodes of T into O(m/z(cid:48)) minifat nodes
and O(m/(D log m)) microtrees, so that each microtree contains O(σz(cid:48)) nodes. We
construct the contracted minitree and the contracted grid for T as in Theorem 7.
Both the contracted minitree and the structure for the contracted grid use O(m) bits.
We can traverse a path in the microtree using the implementation of the global suﬃx
tree described in the previous section, as well as compute local preorders and depths,
and attach satellite information to microtree nodes.
For every microtree Tv, we deﬁne the dummy nodes ν and ν(cid:48). Pointers in Tv are
transformed as in the proof of Theorem 7 with regard to ν and ν(cid:48).
Let m(cid:48) denote the number of nodes in a microtree. If log m(cid:48) = O(log σ+log D), we
implement the local grid data structure described in Theorem 7 for a microtree. In this
case we can store a data structure for a microgrid in O(log(m(cid:48)+D)) = O(log σ+log D)
bits per node.
since log m(cid:48) = O(log(σz(cid:48))) =
O(log σ + log D + log log m), it follows that log m(cid:48) = O(log log m). Hence, the size of
the microtree is m(cid:48) = logO(1) m = (log σ + log D + log log n)O(1) = (log log n)O(1). The
total number of pointers in the microtree is also m(cid:48)(cid:48) = m(cid:48) + O(D) = (log log n)O(1)
(since log D = o(log m(cid:48))). Since all the grids in m(cid:48)(cid:48) × m(cid:48), with one point per xcoordinate,
 and weights in [1, m(cid:48)(cid:48)], can be expressed in m(cid:48)(cid:48)(lg m(cid:48) + lg m(cid:48)(cid:48)) = o(log n)
bits, we can store precomputed answers for all possible queries on all possible small
microtrees. The only technical diﬃculty is that weights of some pointers in a microtree 
can be arbitrarily large. However, as explained below, it is not necessary to
know the exact weights of pointers to answer a query on a small microtree.
All pointers ptr(ul, d), where ul is a leaf node and ul (cid:54)= ν(cid:48), have weight 1. The
weights of ptr(ν(cid:48), d) can be arbitrarily large. The weight of a pointer ptr(u, d) for
an internal node u equals the sum of weights of all pointers ptr(u(cid:48), d) for the same
document d that lead to u. Thus the weight of ptr(u, d) can also be large. We note

log m(cid:48) = ω(log σ + log D),

If,

instead,

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpGONZALO NAVARRO AND YAKOV NEKRICH

106
that there is at most one pointer ptr(ν(cid:48), d) for each d. Therefore the weight of each
pointer ptr(u, d) can be expressed as the sum w1(u)+w2(u), where w1(u) is the weight
of ptr(ν(cid:48), d) or 0 and w2(u) ≤ m(cid:48). In other words, the weight of ptr(u, d) diﬀers from
the weight of ptr(ν(cid:48), d) by at most m(cid:48).
Let the set N contain the weights of all pointers ptr(ul, d) and ptr(ν(cid:48), d). Let
N (cid:48) = {(cid:98)w/m(cid:48)(cid:99), (cid:98)w/m(cid:48)(cid:99) + 1| w ∈ N}. To compare the weights of any two pointers it
is suﬃcient to know (i) the tree topology (ii) for every leaf ul, the document d whose
suﬃx is stored in ul (iii) for every ptr(ν(cid:48), d), the pair (rank((cid:98)w/m(cid:48)(cid:99),N (cid:48)), w mod m(cid:48))
where w is the weight of ptr(ν(cid:48), d). There are o(n/ log n) possible combinations of tree
topologies and possible pairs (rank((cid:98)w/m(cid:48)(cid:99),N (cid:48)), w mod m(cid:48)). Hence, we can store
answers to all possible queries for all microtrees in a global look-up table of size o(n)
bits.
The topology of a microtree can be stored in O(m(cid:48)) bits. We can specify the
index of the document d stored in a leaf ul with lg D bits. We can specify each
pair (rank((cid:98)w/m(cid:48)(cid:99),N (cid:48)), w mod m(cid:48)) with O(log m(cid:48)) bits. Since D = O(m(cid:48)/ log m(cid:48)),
information from item (iii) can be stored in O(m(cid:48)) bits. Thus each microtree can
be stored in O(m(cid:48) log D) bits if log m(cid:48) = ω(log σ + log D). Summing up, our data
for a minitree uses O(m(log σ + log D)) bits. Therefore the total space usage is
O(n(log σ + log D)) bits.

A query for a pattern P is answered by locating the locus u of P . If u is a fat
node in T , the query is answered by a data structure for the contracted grid. If u
belongs to a minitree T and u is a minifat node, we answer the query by employing
the data structure for the contracted grid of T . If u belongs to a microtree Tv, the
query is answered either by a microgrid data structure or by a table lookup.

Theorem 8. Let D be a collection of strings over an integer alphabet [1, σ] with
total length n, and let tf (P, d) denote the number of occurrences of P in d. Then there
exists an O(n(log D + log σ))-bit data structure that, given a string P and an integer
k, reports k documents d containing P with highest tf (P, d) values, in decreasing order
of tf (P, d), in O(p/ logσ n + logε

σ n + k) time, for any constant ε > 0.

Again, we can obtain O(p + k) query time when p < lg1+ε

σ n.

7. Parameterized top-k queries. In this section we consider the extended
problem where a parameter par(P, d) is associated with the documents in relation to
the pattern P , and we want to recover only documents d where par(P, d) ∈ [τ1, τ2].
We include this extension in our framework by adding one more dimension to our slim
grids of section 5.3. Since the grids are slim, one of the dimensions is small, which we
exploit to obtain good query times.
We ﬁrst show that two-dimensional top-k queries can be solved in linear space
and O((k + log n) logε n) time, for any constant ε > 0, on n × n grids with weights
in [1, O(n)]. Then we extend the result (although we do not build on it) to threedimensional 
grids where one of the dimensions has an extension polylogarithmic in n,
obtaining the same space and time as in two dimensions. Finally, in section 7.3, we
show how this geometric structure is used to solve our parameterized top-k queries
by replacing our original two-dimensional grids.

7.1. Faster two-dimensional queries. In this section we improve a recent
data structure that supports two-dimensional top-k queries [54, section 5]. The structure 
is similar to our wavelet tree W described in the proof of Lemma 4. In addition,
for the points stored at any node of W , it stores an RMQ data structure that gives in
constant time the position of the point with maximum weight within any interval. As

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

107

explained, this structure [27] uses O(t) bits if the node of W handles t points, and thus
the total space of this extended wavelet tree W is O(n) words for an O(n)×O(n) grid.
In [54] they show how to support top-k queries in a general interval [a, b]×[c, d] by
ﬁrst identifying the O(log n) nodes v ∈ W that cover [c, d], mapping the interval [a, b]
to [av, bv] in all those nodes v, and setting up a priority queue with the maximumweight 
point of each such interval. Now, they repeat k times the following steps: (i)
extract the maximum weight from the queue and report it; (ii) replace the extracted
point, say x ∈ [av, bv], by two points corresponding to the maxima in the ranges
[av, x − 1] and [x + 1, bv], prioritized by those maximum weights.

Their total time is O((k + log n) log n) if using linear space. The O(log n) extra
factor is due to the need to traverse W in order to ﬁnd out the real weights, so as
to compare weights from diﬀerent nodes. However, those weights can be computed
in time O(logε n) and using O(n log n) extra bits [18, 57, 17]. The operations on the
priority queue can be carried out in O(log log n) time if the weights are integers in
[1, O(n)] [67]. Thus we have the following result.

Lemma 7. Given a grid of n×n points, there exists a data structure that uses O(n)
words of space and reports k most highly weighted points in a range Q = [a, b]×[c, d] in
O((k + log n) logε n) time, for any constant ε > 0. The structure is built in O(n log n)
time.

Note this technique automatically admits being used in online mode (i.e., without
knowing k in advance), since we have not made use of k to speed up the priority queue
as in previous sections. We can easily stop the computation at some k and resume it
later.

7.2. Limited three-dimensional queries. In this section we slightly extend
the scenario considered above. We assume that each point has an additional coordinate,
 denoted z, and that z ≤ lgα n for a constant α > 0. Top-k points in a
three-dimensional range [a, b]× [c, d]× [β, γ] must be reported sorted by their weights.
Such queries will be further called limited three-dimensional top-k queries. We can
obtain the same result as in Lemma 7 for these queries.
Instead of a binary wavelet tree, we use a multiary one [25], with node degree
lgε n and height O(log n/ log log n). Now each node v ∈ W has associated a vector Bv
so that Bv[i] contains the index of the child in which the ith point of v is stored. Each
element in Bv needs O(log(logε n)) = O(log log n) bits, adding up to O(n log log n)
per wavelet tree level and O(n log n) bits in total. Using Bv and some auxiliary data
structures, we can obtain the weight of any point at any node in O(logε n) time [57].
These structures also require O(n log n) bits.

We regard the t points of each node v as lying in a two-dimensional grid of xand 
z-coordinates. Instead of one-dimensional RMQs on the x-coordinates [av, bv],
we issue two-dimensional RMQs on [av, bv]× [β, γ]. The wavelet tree of the basic twodimensional 
RMQ data structure [54] (not our result of Lemma 7) handles n×m grids
in O(n log m) bits of space and answers RMQs in time O(log2 m). In our case m <
lgα n and thus the space is O(n log log n) bits and the query time is O((log log n)2).
Thus the space of the two-dimensional data structures is of the same order of that
used for vectors Bv, adding up to O(n log n) bits. As one-dimensional RMQs are built
in linear time, the total construction time is O(n log n).

Now we carry out a procedure similar to that of the two-dimensional version.
The range [a, b] is covered by O(log1+ε n/ log log n) nodes, since the wavelet tree has
O(log n/ log log n) levels and there can be O(logε n) covering nodes per level. We

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php108

GONZALO NAVARRO AND YAKOV NEKRICH

obtain all their (two-dimensional) range maxima, insert them in a priority queue, and
repeat k times the process of extracting the highest weight and replacing the extracted
point x ∈ [av, bv] by the next highest weighted point in [av, bv] (thus we are running
these range maxima queries in online mode).

The two-dimensional RMQ structures at nodes v cannot store the absolute weights
within overall linear space. Instead, when they obtain the x-coordinate of their local
grid, this coordinate xv is mapped to the global x-coordinate in O(logε n) time, using
the same technique as above. Then the global array of weights is used. Hence these
structures ﬁnd a two-dimensional maximum weight in time O(logε n log log n), not
O((log log n)2). This is repeated over O(log1+ε n/ log log n) nodes, and then iterated
k times. The overall time is O((k + log1+ε n/ log log n) logε n log log n), which is of the
form O((k + log n) logε n) by adjusting ε. The times to handle the priority queue are
negligible [67].

Lemma 8. Given a grid of n×n×lgα n points, for a constant α > 0, there exists a
data structure that uses O(n) words of space and reports k most highly weighted points
in a range Q = [a, b] × [c, d] × [β, γ] in O((k + log n) logε n) time, for any constant
ε > 0. It is built in O(n log n) time.

Again, this result holds verbatim in online mode.

7.3. The ﬁnal result. We divide the grid into horizontal stripes of height
r = (cid:100)lgc+1+ε n(cid:101) for any constant c, much as in section 5.5. We store a data structure 
for limited three-dimensional top-k queries for each slim grid, taking y as the
limited coordinate. A query [a, b] × [0, h] × [τ1, τ2] is processed just as in section 5.5,
with the only diﬀerence that the queries [a, b] × [τ1, τ2] × [0, y(cid:48)] to the local grids
now require O(log1+ε n) initialization time and then O(logε n) time per element retrieved,
 according to Lemma 8. Then, we initialize our global query Q in time
O((cid:100)h/r(cid:101) log1+ε n) = O(h/ logc n + log1+ε n), and then extract each new result in
time O(logε n). The time of the priority queue is blurred by adjusting ε. Hence, the
total query time is O(h/ logc n + (k + log n) logε n), and Theorem 6 is proved.

8. Conclusions. We have presented an optimal-time and linear-space solution
to top-k document retrieval, which can be used on a wide class of relevance measures
and subsumes in an elegant and uniform way various previous solutions to other ranked
retrieval problems. We have also presented dynamic variants, space-reduced indexes,
and structures that solve extensions of the basic problem. The solutions reduce the
problem to ranked retrieval on multidimensional grids, where we also present improved
results, some tailored to this particular application, some of more general interest.

After the publication of the conference version of this article [53], Shah et al. [65]
showed how to achieve the optimal O(k) time once the locus of P is known. This
is in contrast to our original result, where we used time O(p + k) after having spent
time O(p) to ﬁnd the locus. Their improvement allows one to use these techniques in
other scenarios where the locus is obtained in some other way, without the need to
search for it directly using P . They also extend the results to the important case of
external memory. The new results we obtain in this article about how to ﬁnd the locus
in RAM-optimal time O(p/ logσ n), and how to handle the dynamic scenario, nicely
complement those results and add up to a rather complete solution to the problem.
It is also worth mentioning that the journal version of the original paper of Hon,
Shah, and Vitter has recently appeared as well [40]. Here they show how to obtain
O(p + k) time if the top-k results are not to be returned sorted by relevance. Our
original [53] and present solutions do obtain the results in decreasing relevance order.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

109

There are several relevant research directions, on which we comment next.
RAM optimality. In our previous conference version we had achieved time
O(p + k), which was optimal only in the comparison model (although we used RAMbased 
techniques). Now we have improved this result to O(p/ logσ n + k), which is
optimal in general in the RAM model (considering the case log D = Θ(log n)), because 
it is the size in words of the input plus the output of the query. Achieving
O(p/ logσ n) time on the suﬃx tree, without any polylogarithmic additive penalty, is
an interesting result by itself, and we have obtained it without altering the topology
of the suﬃx tree (which is crucial for the invariants of Hon, Shah, and Vitter [41] to
work). However, we do not know if our solution is optimal when there are very few distinct 
documents, log D = o(log n). The question of whether O(p/ logσ n + k/ logD n)
time can be achieved is still open.

Construction time. Without considering the cost to compute weights w(path(u), d)
for all pointers ptr in the suﬃx tree, the construction time of Hon, Shah, and Vitter
[41] (which achieves suboptimal query time) is O(n). The time to build our grid
structure is O(n log n), to which we must add O(n logε n) randomized time to achieve
RAM-optimal search time in the suﬃx tree traversal (or O(n polylog n) deterministic
time). Is it possible to achieve linear, or at least O(n log n), deterministic construction
time for our data structures?

Dynamic optimality. In our dynamic variant, the static RAM-optimal search time
in the suﬃx tree becomes O(p(log log n)2/ logσ n + log n). There are schemes that do
better for large σ, for example, O(p + (log log σ)2) time [26]. Although they do not
support deletions yet, this seems to be possible. On the other hand, we obtained
O(log1+ε n) update time per symbol. A general question is, which is the best search
time we can obtain in the dynamic scenario?

Practical results. Our solutions are not complex to implement and do not make
use of impractical data structures. A common pitfall to practicality, however, is space
usage. Even achieving linear space (i.e., O(n log n) bits) can be insuﬃcient. We have
shown that our structure can use, instead, O(n(log σ + log D)) bits for the tf measure
(and slightly more for others), but the constants are still large. There is a whole
trend of reduced-space representations for general document retrieval problems with
the tf measure [64, 70, 41, 21, 32, 38, 12, 31, 68, 39, 56]. The current situation is
as follows [52]: One trend aims at the least-space usage. It has managed to use just
D lg(n/D)+O(D)+o(n) bits on top of a compressed suﬃx array of the collection, and
the best time complexity it has achieved is O(p + k log2 k log1+ε n) for any constant
ε > 0 [56]. Another trend adds to the space the so-called document array [51], which
uses n lg D + o(n log D) bits and enables faster solutions. Currently the fastest one
achieves time O(p + k log
k) [56]. This is very close to optimal, but not yet our
O(p/ logσ n + k) time.

∗

In practice, the most compact implementation in this trend [55] reaches about
1–2 times the text size (including a representation of the text) and retrieves each of
the top-k results within milliseconds. Implementations of the ideas we propose in this
article [44, 33] make use of the fact that, under very general probabilistic models, the
average height of the suﬃx tree (and hence of our grids) is O(log n) [66]. This enables
simple implementations of our grid-based index that use up to 2.5–3.0 times the text
size (including the text) and, although not reaching optimal query time, return each
answer within microseconds.

More complex queries. In the long term, the most interesting open questions
are related to extending the one-pattern results to the bag-of-words paradigm of
information retrieval. Our model easily handles single-word searches, and also phrases

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php110

GONZALO NAVARRO AND YAKOV NEKRICH

(which is quite complicated with inverted indexes [72, 9], particularly if their weights
have to be computed). Handling a set of words or phrases, whose weights within any
document d must be combined in some form (for example, using the tf × idf model)
√
is more challenging. Recent results [45] give Ω(
n)-time lower bounds for some basic
and natural queries that combine two patterns, unless there is a breakthrough on the
boolean matrix multiplication problem. Instead, one can aim at complexities related
to the results achieved with inverted lists on the simpler natural language model. It is
interesting to note that our online result allows simulating the left-to-right traversal,
in decreasing weight order, of the virtual list of occurrences of any string pattern
P . Therefore, for a bag-of-word queries, we can emulate any algorithm designed for
inverted indexes that stores those lists in explicit form [60, 6], therefore extending any
such technique to the general model of string documents.

Acknowledgments. We thank Djamal Belazzougui and Roberto Grossi for helpful 
pointers.

[1] N. Alon and M. Naor, Derandomization, witnesses for Boolean matrix multiplication and

REFERENCES

construction of perfect hash functions, Algorithmica, 16 (1996), pp. 434–449.

[2] S. Alstrup, T. Husfeldt, and T. Rauhe, Marked ancestor problems, in Proceedings of the
39th IEEE Annual Symposium on Foundations of Computer Science (FOCS), IEEE Computer 
Society, Los Alamitos, CA, 1998, pp. 534–544.

[3] A. Amir, M. Farach, Z. Galil, R. Giancarlo, and K. Park, Dynamic dictionary matching,

J. Comput. System Sci., 49 (1994), pp. 208–222.

[4] A. Amir, M. Farach, R. M. Idury, J. A. Lapoutre, and A. A. Schaffer, Improved dynamic

dictionary matching, Inform. and Comput., 119 (1995), pp. 258–282.

[5] A. Andersson and M. Thorup, Dynamic ordered sets with exponential search trees, J. ACM,

54 (2007), 13.

[6] V. Anh and A. Moffat, Pruned query evaluation using pre-computed impacts, in Proceedings
of the 29th Annual International ACM SIGIR Conference on Research and Development
in Information Retrieval (SIGIR), ACM, New York, 2006, pp. 372–379.

[7] A. Apostolico, The myriad virtues of subword trees, in Combinatorial Algorithms on Words,

NATO ISI Ser. Comput. Syst. Sci. 12, Springer, Berlin, 1985, pp. 85–96.

[8] L. Arge and J. S. Vitter, Optimal external memory interval management, SIAM J. Comput.,

32 (2003), pp. 1488–1508.

[9] R. Baeza-Yates and B. Ribeiro-Neto, Modern Information Retrieval, 2nd ed., AddisonWesley,
 New York, 2011.

[10] D. Belazzougui, P. Boldi, R. Pagh, and S. Vigna, Fast preﬁx search in little space, with applications,
 in Proceedings of the 18th Annual European Symposium on Algorithms (ESA),
Pt. 1, Lecture Notes in Comput. Sci. 6346, Springer, Berlin, 2010, pp. 427–438.

[11] D. Belazzougui and G. Navarro, Alphabet-independent compressed text indexing, ACM

Trans. Algorithms, 10 (2014), 23.

[12] D. Belazzougui, G. Navarro, and D. Valenzuela, Improved compressed indexes for full-text

document retrieval, J. Discrete Algorithms, 18 (2013), pp. 3–13.

[13] M. Bender, R. Cole, E. Demaine, M. Farach-Colton, and J. Zito, Two simpliﬁed algorithms 
for maintaining order in a list, in Proceedings of the 10th Annual European
Symposium on Algorithms (ESA), Lecture Notes in Comput. Sci. 2461, Springer, Berlin,
2002, pp. 152–164.

[14] M. Bender and M. Farach-Colton, The LCA problem revisited, in Proceedings of the 4th
Latin American Theoretical Informatics Symposium (LATIN), Lecture Notes in Comput.
Sci. 1776, Springer, Berlin, 2000, pp. 88–94.

[15] A. Blumer, J. Blumer, D. Haussler, R. McConnell, and A. Ehrenfeucht, Complete

inverted ﬁles for eﬃcient text retrieval and analysis, J. ACM, 34 (1987), pp. 578–595.

[16] G. Brodal, R. Fagerberg, M. Greve, and A. L´opez-Ortiz, Online sorted range reporting,
 in Proceedings of the 20th International Symposium on Algorithms and Computation
(ISAAC), Lecture Notes in Comput. Sci. 5878, Springer, Berlin, 2009, pp. 173–182.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

111

[17] T. Chan, K. G. Larsen, and M. Pˇatras¸cu, Orthogonal range searching on the RAM, revisited,
 in Proceedings of the 27th ACM Symposium on Computational Geometry (SoCG),
ACM, New York 2011, pp. 1–10.

[18] B. Chazelle, A functional approach to data structures and its use in multidimensional searching,
 SIAM J. Comput., 17 (1988), pp. 427–462.

[19] R. Cole and R. Hariharan, Dynamic LCA queries on trees, SIAM J. Comput., 34 (2005),

pp. 894–923.

[20] M. Crochemore and W. Rytter, Jewels of Stringology, World Scientiﬁc, Singapore, 2002.
[21] S. Culpepper, G. Navarro, S. Puglisi, and A. Turpin, Top-k ranked document search
in general text databases, in Proceedings of the 18th Annual European Symposium on
Algorithms (ESA), Lecture Notes in Comput. Sci. 6347, Springer, Berlin, 2010, pp. 194–
205.

[22] P. Dietz and R. Raman, Persistence, randomization and parallelization: On some combinatorial 
games and their applications (abstract), in Proceedings of the 3rd Workshop on
Algorithms and Data Structures (WADS), Lecture Notes in Comput. Sci. 709, Springer,
Berlin, 1993, pp. 289–301.

[23] P. Dietz and D. Sleator, Two algorithms for maintaining order in a list, in Proceedings of
the 19th Annual ACM Symposium on Theory of Computing (STOC), ACM, New York,
1987, pp. 365–372.

[24] M. Farach, Optimal suﬃx tree construction with large alphabets, in Proceedings of the 38th
Annual Symposium on Foundations of Computer Science (FOCS), IEEE Computer Society,
Los Alamitos, CA, 1997, pp. 137–143.

[25] P. Ferragina, G. Manzini, V. M¨akinen, and G. Navarro, Compressed representations of

sequences and full-text indexes, ACM Trans, Algorithms, 3 (2007), 20.

[26] J. Fischer and P. Gawrychowski, Alphabet-dependent string searching with wexponential
search trees, in Proceedings of the 26th Annual Symposium on Combinatorial Pattern
Matching (CPM), Lecture Notes in Comput. Sci. 9133, Springer, Cham, Switzerland, 2015,
pp. 160–171.

[27] J. Fischer and V. Heun, Space-eﬃcient preprocessing schemes for range minimum queries

on static arrays, SIAM J. Comput., 40 (2011), pp. 465–492.

[28] R. Fleischer, A simple balanced search tree with O(1) worst-case update time, Internat. J.

Found. Comput. Sci., 7 (1996), pp. 137–149.

[29] M. Fredman, J. Koml´os, and E. Szemer´edi, Storing a sparse table with O(1) worst case

access time, J. ACM, 31 (1984), pp. 538–544.

[30] H. N. Gabow, J. L. Bentley, and R. E. Tarjan, Scaling and related techniques for geometry
problems, in Proceedings of the 16th ACM Symposium on Theory of Computing (STOC),
ACM, New York, 1984, pp. 135–143.

[31] T. Gagie, J. K¨arkk¨ainen, G. Navarro, and S. J. Puglisi, Colored range queries and document 
retrieval, Theoret. Comput. Sci., 483 (2013), pp. 36–50.

[32] T. Gagie, G. Navarro, and S. J. Puglisi, New algorithms on wavelet trees and applications

to information retrieval, Theoret. Comput. Sci., 426–427 (2012), pp. 25–41.

[33] S. Gog and G. Navarro, Improved single-term top-k document retrieval, in Proceedings of the
17th Workshop on Algorithm Engineering and Experiments (ALENEX), SIAM, Philadelphia,
 2015, pp. 24–32.

[34] R. Grossi, A. Gupta, and J. Vitter, High-order entropy-compressed text indexes, in Proceedings 
of the 14th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), SIAM,
Philadelphia, 2003, pp. 841–850.

[35] R. Grossi and J. S. Vitter, Compressed suﬃx arrays and suﬃx trees with applications to

text indexing and string matching, SIAM J. Comput., 35 (2005), pp. 378–407.

[36] D. Gusfield, Algorithms on Strings, Trees and Sequences: Computer Science and Computational 
Biology, Cambridge University Press, Cambridge, 1997.

[37] W.-K. Hon, M. Patil, R. Shah, and S.-Bin Wu, Eﬃcient index for retrieving top-k most

frequent documents, J. Discrete Algorithms, 8 (2010), pp. 402–417.

[38] W.-K. Hon, R. Shah, and S. Thankachan, Towards an optimal space-and-query-time index
for top-k document retrieval, in Proceedings of the 23rd Annual Symposium on Combinatorial 
Pattern Matching (CPM), Lecture Notes in Comput. Sci. 7354, Springer, Berlin,
2012, pp. 173–184.

[39] W.-K. Hon, R. Shah, S. Thankachan, and J. Vitter, Faster compressed top-k document
retrieval, in Proceedings of the 23rd Data Compression Conference (DCC), IEEE, Piscataway,
 NJ, 2013, pp. 341–350.

[40] W.-K. Hon, R. Shah, S. V. Thankachan, and J. S. Vitter, Space-eﬃcient frameworks for

top-k string retrieval, J. ACM, 61 (2014), 9.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php112

GONZALO NAVARRO AND YAKOV NEKRICH

[41] W.-K. Hon, R. Shah, and J. Vitter, Space-eﬃcient framework for top-k string retrieval
problems, in Proceedings of the 50th IEEE Annual Symposium on Foundations of Computer
Science (FOCS), IEEE Computer Society, Los Alamitos, CA, 2009, pp. 713–722.

[42] M. Karpinski and Y. Nekrich, Top-k color queries for document retrieval, in Proceedings
of the 22nd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), SIAM,
Philadelphia, 2011, pp. 401–411.

[43] D. Knuth, The Art of Computer Programming, Vol. 3: Sorting and Searching, AddisonWesley,
 Reading, MA, 1973.

[44] R. Konow and G. Navarro, Faster compact top-k document retrieval, in Proceedings of the

23rd Data Compression Conference (DCC), IEEE, Piscataway, NJ, 2013, pp. 351–360.

[45] K. G. Larsen, J. I. Munro, J. S. Nielsen, and S. V. Thankachan, On hardness of several
string indexing problems, in Proceedings of the 25th Annual Symposium on Combinatorial
Pattern Matching (CPM), Lecture Notes in Comput. Sci. 8486, Springer, Cham, Switzerland,
 2014, pp. 242–251.

[46] V. M¨akinen and G. Navarro, Rank and select revisited and extended, Theoret. Comput. Sci.

387 (2007), pp. 332–347.

[47] Y. Matias, S. Muthukrishnan, S. C. Sahinalp, and J. Ziv, Augmenting suﬃx trees, with
applications, in Proceedings of the 6th European Symposium on Algorithms (ESA), Lecture
Notes in Comput. Sci. 1461, Springer, Berlin, 1998, pp. 67–78.

[48] E. McCreight, A space-economical suﬃx tree construction algorithm, J. ACM, 23 (1976),

pp. 262–272.

[49] E. M. McCreight, Priority search trees, SIAM J. Comput., 14 (1985), pp. 257–276.
[50] I. Munro, Tables, in Proceedings of the 16th Conference on Foundations of Software Technology 
and Theoretical Computer Science (FSTTCS), Lecture Notes in Comput. Sci. 1180,
Springer, Berlin, 1996, pp. 37–42.

[51] S. Muthukrishnan, Eﬃcient algorithms for document retrieval problems, in Proceedings of
the 13th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), ACM, New
York, 2002, pp. 657–666.

[52] G. Navarro, Spaces, trees and colors: The algorithmic landscape of document retrieval on

sequences, ACM Comput. Surv., 46 (2014), 52.

[53] G. Navarro and Y. Nekrich, Top-k document retrieval in optimal time and linear space, in
Proceedings of the 23rd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA),
ACM, New York, 2012, pp. 1066–1078.

[54] G. Navarro, Y. Nekrich, and L. Russo, Space-eﬃcient data-analysis queries on grids, Theoret.
 Comput. Sci., 482 (2013), pp. 60–72.

[55] G. Navarro, S. J. Puglisi, and D. Valenzuela, General document retrieval in compact space,

ACM J. Exp. Algorithmics, 19 (2014), 3.

[56] G. Navarro and S. V. Thankachan, New space/time tradeoﬀs for top-k document retrieval

on sequences, Theoret. Comput. Sci., 542 (2014), pp. 83–97.

[57] Y. Nekrich, A linear space data structure for orthogonal range reporting and emptiness

queries, Internat. J. Comput. Geom. Appl., 19 (2009), pp. 1–15.

[58] M. H. Overmars, The Design of Dynamic Data Structures, Lecture Notes in Comput. Sci.

156, Springer, Berlin, 1983.

[59] M. H. Overmars and J. van Leeuwen, Worst-case optimal insertion and deletion methods

for decomposable searching problems, Inform. Process. Lett., 12 (1981), pp. 168–173.

[60] M. Persin, J. Zobel, and R. Sacks-Davis, Filtered document retrieval with frequency-sorted

indexes, J. Amer. Soc. Inform. Sci., 47 (1996), pp. 749–764.

[61] L. Russo, G. Navarro, and A. Oliveira, Fully-compressed suﬃx trees, ACM Trans. Algorithms,
 7 (2011), 53.

[62] M. Ruˇzi´c, Constructing eﬃcient dictionaries in close to sorting time, in Proceedings of the 35th
International Colloquium on Automata, Languages and Programming (ICALP), Lecture
Notes in Comput. Sci. 5125, Springer, Berlin, 2008, pp. 84–95.

[63] K. Sadakane, Compressed suﬃx trees with full functionality, Theory Comput. Syst., 41 (2007),

pp. 589–607.

[64] K. Sadakane, Succinct data structures for ﬂexible text retrieval systems, J. Discrete Algorithms,
 5 (2007), pp. 12–22.

[65] R. Shah, C. Sheng, S. V. Thankachan, and J. Vitter, Top-k document retrieval in external
memory, in Proceedings of the 21st Annual European Symposium on Algorithms (ESA),
Lecture Notes in Comput. Sci. 8125, Springer, Berlin, 2013, pp. 803–814.

[66] W. Szpankowski, A generalized suﬃx tree and its (un)expected asymptotic behaviors, SIAM

J. Comput., 22 (1993), pp. 1176–1198.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.phpTIME-OPTIMAL TOP-k DOCUMENT RETRIEVAL

113

[67] M. Thorup, Integer priority queues with decrease key in constant time and the single source

shortest paths problem, J. Comput. System Sci., 69 (2004), pp. 330–353.

[68] D. Tsur, Top-k document retrieval in optimal space, Inform. Process. Lett., 113 (2013),

pp. 440–443.

[69] E. Ukkonen, On-line construction of suﬃx trees, Algorithmica, 14 (1995), pp. 249–260.
[70] N. V¨alim¨aki and V. M¨akinen, Space-eﬃcient algorithms for document retrieval, in Proceedings 
of the 18th Annual Symposium on Combinatorial Pattern Matching (CPM), Lecture
Notes in Comput. Sci. 4580, Springer, Berlin, 2007, pp. 205–215.

[71] P. Weiner, Linear pattern matching algorithm, in Proceedings of the 14th Annual IEEE Symposium 
on Switching and Automata Theory, IEEE Computer Society, Northridge, CA,
1973, pp. 1–11.

[72] J. Zobel and A. Moffat, Inverted ﬁles for text search engines, ACM Comput. Surv., 38

(2006), 6.

                                                                     Copyright © by SIAM. Unauthorized reproduction of this article is prohibited. Downloaded 07/22/18 to 200.9.97.193. Redistribution subject to SIAM license or copyright; see http://www.siam.org/journals/ojsa.php