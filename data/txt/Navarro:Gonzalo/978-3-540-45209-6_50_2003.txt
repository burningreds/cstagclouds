Suﬃx Arrays in Parallel(cid:1)

Mauricio Mar´ın1 and Gonzalo Navarro2

1 University of Magallanes, mmarin@ona.fi.umag.cl

2 University of Chile, Center for Web Research (www.cwr.cl)

gnavarro@dcc.uchile.cl.

Abstract. Suﬃx arrays are powerful data structures for text indexing.
In this paper we present parallel algorithms devised to increase throughput 
of suﬃx arrays on a multiple-query setting. Experimental results
show that eﬃcient performance is indeed feasible in this strongly sequential 
and very poor locality data structure.

1 Introduction

In the last decade, the design of eﬃcient data structures and algorithms for
textual databases and related applications has received a great deal of attention
due to the rapid growth of the Web [1]. To reduce the cost of searching a full large
text collection, specialized indexing structures are adopted. Suﬃx arrays or pat
arrays [1] are examples of such index structures. They are more suitable than
the popular inverted lists for searching phrases or complex queries composed of
regular expressions [1]. A fact to consider in parallel processing natural language
texts is that words are not uniformly distributed both in the text itself and the
queries provided by the users of the system. This produces load imbalance.

The eﬃcient construction in parallel of suﬃx arrays has been investigated in
[3,2]. In this paper we focus on query processing. We propose eﬃcient parallel
algorithms for (1) processing queries grouped in batches of Q queries, and (2)
load balancing properly this process when dealing with biased collections of
words such as in natural language.

2 Global Suﬃx Arrays in Parallel

The suﬃx array is a binary search based strategy. The array contains pointers
to the document terms, where pointers identify both documents and positions
of terms within them. The array is sorted in lexicographical order by terms. A
search is conducted by direct comparison of the terms pointed to by the array
elements. A typical query is ﬁnding all text positions where a given substring
appears in and it can be solved by performing two searches that locate the
delimiting positions of the array for the substring.

We assume a broker (server) operating upon a set of P machines running the
BSP model [4]. The broker services clients’ requests by distributing queries onto
(cid:1) Funded by Millenium Nucleus Center for Web Research, Grant P01-029-F, Mideplan,

Chile.

H. Kosch, L. B¨osz¨orm´enyi, H. Hellwagner (Eds.): Euro-Par 2003, LNCS 2790, pp. 338–341, 2003.
c(cid:1) Springer-Verlag Berlin Heidelberg 2003

Suﬃx Arrays in Parallel

339

the P machines implementing the BSP server. We assume that under a situation
of heavy traﬃc the server processes batches of Q = q P queries.

A suﬃx array can be distributed onto the processors using a global index
approach in which a single array of N elements is built from the whole text
collection and mapped evenly on the processors. In this case, each processor
stands for an interval or range of suﬃxes (lexicographic partition). The broker
machine mantains information of the values limiting the intervals in each machine 
and route queries to the processors accordingly. This fact can be the source
of load imbalance in the processors when queries tend to be dinamically biased
to particular intervals. We call this strategy G0.

In the local index strategy, on the other hand, a suﬃx array is constructed
in each processor by considering only the subset of text stored in its respective
processor. Unlike the global approach, no references to text postitions stored in
other processors are made. However, for every query it is necessary to search in all
of the processors in order to ﬁnd the pieces of local arrays that form the solution
for a given interval deﬁned by the query. It is also necessary to broadcast every
query to every processor. We have found both theoretically and experimentally
that the global index approach oﬀers the potential of better performance.

A drawback of the global index approach is related to the possibility of load
imbalance coming from large and sustained sequences of queries being routed
to the same processor. The best way to avoid particular preferences for a given
processor is to send queries uniformly at random among the processors. We
propose to achieve this eﬀect by multiplexing each interval deﬁned by the original
global array so that if the array element i is stored in processor p, then the
elements i+1, i+2, ... are stored stored in processors p+1, p+2, ... respectively
in a circular manner. We call this strategy G1.

In this case, any binary search can start at any processor. Once a search
has determined that the given term must be located between two consecutive
entries k and k + 1 of the array in a processor, the search is continued in the
next processor and so on, where at each processor it is only necessary to look
at entry k of the local arrays. In general, for large P , the inter-processors search
can be done in at most log P additional BSP supersteps by performing a binary
search accross processors.

The binary search on the global index approach can lead to a certain number
of accesses to remote memory. A very eﬀective way to reduce this is to associate
with every array entry the ﬁrst t characters of the terms respectively. The value
of t depends of the average length of terms. This reduced remote accesses to less
than 5% in [2], and less than 1% in our experiments, for relatively small t.

In G0 we keep in each processor an array of P strings of size (cid:1) marking
the delimiting points of each interval of G0. The broker machine routes queries
uniformly at random to the P real processors, and in every processor a log P
time binary search is performed to determine to which processor send a given
query (we do so to avoid the broker becoming a bottleneck). Once a query has
been sent to its target processor it cannot migrate to other processors as in the
case of G1. That is, this strategy avoids the inter-processors log P binary search.

