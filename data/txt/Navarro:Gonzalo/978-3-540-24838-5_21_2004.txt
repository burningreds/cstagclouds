Increased Bit-Parallelism for Approximate

String Matching

Heikki Hyyr¨o1,2(cid:1), Kimmo Fredriksson3(cid:1)(cid:1), and Gonzalo Navarro4(cid:1) (cid:1) (cid:1)

1 PRESTO, Japan Science and Technology Agency, Japan.

2 Department of Computer Sciences, University of Tampere, Finland.

3 Department of Computer Science, University of Joensuu, Finland.

Heikki.Hyyro@cs.uta.fi

4 Department of Computer Science, University of Chile, Chile.

Kimmo.Fredriksson@cs.joensuu.fi

gnavarro@dcc.uchile.cl

Abstract. Bit-parallelism permits executing several operations simultaneously 
over a set of bits or numbers stored in a single computer word.
This technique permits searching for the approximate occurrences of a
pattern of length m in a text of length n in time O((cid:1)m/w(cid:2)n), where w is
the number of bits in the computer word. Although this is asymptotically
the optimal speedup over the basic O(mn) time algorithm, it wastes bit-
parallelism’s power in the common case where m is much smaller than
w, since w − m bits in the computer words get unused.
In this paper we explore diﬀerent ways to increase the bit-parallelism
when the search pattern is short. First, we show how multiple patterns
can be packed in a single computer word so as to search for multiple
patterns simultaneously. Instead of paying O(rn) time to search for r
patterns of length m < w, we obtain O((cid:1)r/(cid:3)w/m(cid:4)(cid:2)n) time. Second, we
show how the mechanism permits boosting the search for a single pattern
of length m < w, which can be searched for in time O(n/(cid:3)w/m(cid:4)) instead
of O(n). Finally, we show how to extend these algorithms so that the time
bounds essentially depend on k instead of m, where k is the maximum
number of diﬀerences permitted.
Our experimental results show that that the algorithms work well in
practice, and are the fastest alternatives for a wide range of search parameters.


1 Introduction

Approximate string matching is an old problem, with applications for example in
spelling correction, bioinformatics and signal processing [7]. It refers in general
to searching for substrings of a text that are within a predeﬁned edit distance
(cid:1) Supported by the Academy of Finland and Tampere Graduate School in Information

Science and Engineering.

(cid:1)(cid:1) Supported by the Academy of Finland.

(cid:1) (cid:1) (cid:1) Supported in part by Fondecyt grant 1-020831.

C.C. Ribeiro and S.L. Martins (Eds.): WEA 2004, LNCS 3059, pp. 285–298, 2004.
c(cid:1) Springer-Verlag Berlin Heidelberg 2004

286

H. Hyyr, K. Fredriksson, and G. Navarro

threshold from a given pattern. Let T = T1...n be a text of length n and P =
P1...m a pattern of length m. Here Aa...b denotes the substring of A that begins
at its ath character and ends at its bth character, for a ≤ b. Let ed(A, B) denote
the edit distance between the strings A and B, and k be the maximum allowed
distance. Then the task of approximate string matching is to ﬁnd all text indices
j for which ed(P, Th...j) ≤ k for some h ≤ j.

The most common form of edit distance is Levenshtein distance [5]. It is
deﬁned as the minimum number of single-character insertions, deletions and
substitutions needed in order to make A and B equal. In this paper ed(A, B)
will denote Levenshtein distance. We also use w to denote the computer word
size in bits, σ to denote the size of the alphabet Σ and |A| to denote the length
of the string A.

Bit-parallelism is the technique of packing several values in a single computer 
word and updating them all in a single operation. This technique has
yielded the fastest approximate string matching algorithms if we exclude ﬁltration 
algorithms (which need anyway to be coupled with a non-ﬁltration one). In
particular, the O((cid:2)m/w(cid:3)kn) algorithm of Wu and Manber [13], the O((cid:2)km/w(cid:3)n)
algorithm of Baeza-Yates and Navarro [1], and the O((cid:2)m/w(cid:3)n) algorithm of Myers 
[6] dominate for almost every value of m, k and σ.

In complexity terms, Myers’ algorithm is superior to the others. In practice,
however, Wu & Manber’s algorithm is faster for k = 1 and Baeza-Yates and
Navarro’s is faster when (k + 2)(m − k) ≤ w or k/m is low. The reason is that,
despite that Myers’ algorithm packs better the state of the search (needing to
update less computer words), it needs slightly more operations than its competitors.
 Except when m and k are small, the need to update less computer words
makes Myers’ algorithm faster than the others. However, when m is much smaller
than w, Myers’ advantage disappears because all the three algorithms need to
update just one (or very few) computer words. In this case, Myers’ representation 
wastes many bits of the computer word and is unable to take advantage of
its more compact representation.

The case where m is much smaller than w is very common in several applications.
 Typically w is 32 or 64 in a modern computer, and for example the
Pentium 4 processor allows one to use even words of size 128. Myers’ representation 
uses m bits out of those w. In spelling, for example, it is usual to search for
words, whose average length is 6. In computational biology one can search for
short DNA or amino acid sequences, of length as small as 4. In signal processing
applications one can search for sequences composed of a few audio, MIDI or
video samples.

In this paper we concentrate on reducing the number of wasted bits in Myers’
algorithm, so as to take advantage of its better packing of the search state even
when m ≤ w. This has been attempted previously [2], where O(m(cid:2)n/w(cid:3)) time
was obtained. Our technique is diﬀerent. We ﬁrst show how to search for several
patterns simultaneously by packing them all in the same computer word. We can
search for r patterns of length m ≤ w in O((cid:2)r/(cid:4)m/w(cid:5)(cid:3)n+occ) rather than O(rn)
time, where occ ≤ rn is the total number of occurrences of all the patterns. We

