7
1
0
2

 

v
o
N
8

 

 
 
]
S
D
.
s
c
[
 
 

1
v
5
0
2
3
0

.

1
1
7
1
:
v
i
X
r
a

A Grammar Compression Algorithm based on Induced

Suﬃx Sorting

Daniel Saad Nogueira Nunes1,2, Felipe A. Louza3 ∗,

Simon Gog4, Mauricio Ayala-Rinc´on2 and Gonzalo Navarro5

1Federal Institute of Education, Science and Technology of Braslia

2Department of Computer Science, Brasilia University, Brazil

daniel.nunes@ifb.edu.br

3Department of Computing and Mathematics, University of S˜ao Paulo, Brazil

ayala@unb.br

4Institute of Theoretical Informatics, Karlsruhe Institute of Technology, Germany

louza@usp.br

5Department of Computer Science, University of Chile, Chile

gog@kit.edu

gnavarro@dcc.uchile.cl

Abstract

We introduce GCIS, a grammar compression algorithm based on the induced suﬃx sorting
algorithm SAIS, introduced by Nong et al.
in 2009. Our solution builds on the factorization 
performed by SAIS during suﬃx sorting. We construct a context-free grammar on
the input string which can be further reduced into a shorter string by substituting each
substring by its correspondent factor. The resulting grammar is encoded by exploring some
redundancies, such as common preﬁxes between suﬃx rules, which are sorted according to
SAIS framework. When compared to well-known compression tools such as Re-Pair and
7-zip, our algorithm is competitive and very eﬀective at handling repetitive string regarding
compression ratio, compression and decompression running time.

Introduction

Text compression consists in transforming an input string into another string whose
bit sequence representation is smaller. Given the suﬃx array [1, 2] of a string, one can
compute eﬃciently the Burrows-Wheeler transform (BWT) [3] and the Lempel-Ziv
factorization (LZ77) [4–7], which are at the heart of the popular data compression
tools 7-zip and GZIP [8].

In 2009, Nong et al. [9] introduced a remarkable algorithm called SAIS, which
runs in linear time and is fast in practice to construct the suﬃx array. Subsequently,
SAIS was adapted to compute directly the BWT [10], the Φ-array [7, 11], the LCP
array [12], and the suﬃx array for string collections [13].

In this article we introduce GCIS, a new grammar-based compression algorithm
that builds on SAIS. We construct a context-free grammar based on the string factorization 
performed by SAIS recursively. The rules are encoded according to the
∗ FAL was supported by the grant #2017/09105-0 from the S˜ao Paulo Research Foundation

(FAPESP).

1

length of longest common preﬁxes between consecutive rules, which are sorted lexicographically 
by SAIS.

Experiments have shown that, regarding repetitive strings, GCIS is competitive
with Re-Pair [14] and 7-zip [15], since GCIS presents the fastest compression time,
while maintaining a compression ratio close to Re-Pair, but being the slower to
decode. Hence, it is a practical alternative when considering all trade-oﬀ aspects.
Moreover GCIS utilizes a novel grammar compression framework in the sense that it
is the ﬁrst, as far as the authors are concerned, based on induced suﬃx sorting.

Background

Let T be a string of length |T| = n, T = T [1, n] = T [1] · T [2] . . . · T [n], over a ﬁxed
ordered alphabet Σ. A constant alphabet has size σ ∈ O(1) and an integer alphabet
has size σ ∈ nO(1). We denote the concatenation of strings or symbols by the dot
operator (·), which can be omitted. We use the symbol < for the lexicographic order
relation between strings.

For convenience, we assume that T always ends with a special symbol T [n] = $,
which is not present elsewhere in T and lexicographically precedes every symbol in
Σ. Let T [1, j] be the preﬁx of T that ends at position j, and T [i, n] be the suﬃx of
T that starts at position i also denoted as Ti by brevity. We denote the length of the
longest common preﬁx of two strings T1 and T2 in Σ∗ by lcp(T1, T2).

The suﬃx array (SA) [1, 2] of a string T [1, n] is an array of integers in the range
[1, n] that gives the lexicographic order of all suﬃxes of T , such that TSA[1] < TSA[2] <
. . . < TSA[n]. The suﬃxes starting with the same symbol c ∈ Σ form a c-bucket in the
suﬃx array. The head and the tail of a bucket refer to the ﬁrst and the last position
of the bucket in SA.

Let G = (Σ, Γ, P, XS) be a reduced context-free grammar (does not contain unreachable 
non-terminals). Σ is the terminal alphabet of G; Γ is the set of nonterminals 
symbols that is disjoint from Σ; P ⊆ Γ × (Σ ∪ Γ)∗ is the set of production
rules; and XS ∈ Γ is the start symbol. A production rule (Xi, αi) is also denoted by
Xi → αi. We say that αi is derived from Xi. For strings s, t ∈ (Σ ∪ Γ)∗, we say that
t derives from s if it is obtained by application of a production rule in P ; we say that
t is generated from s if t is obtained by a sequence of derivations from s. We deﬁne
|G| as the total length of the strings on the right side of all rules.

Given a string T , grammar compression is to ﬁnd a grammar G which generates
only T such that G can be represented in less space than the original T . Given that
G grammar-compresses T , for (Xi, αi) ∈ P , we deﬁne F(Xi) = s as the single string
s ∈ Σ∗ that is generated from αi. The language generated by G is L(G) = F(XS).

Related work

SAIS [9] builds on the induced suﬃx sorting technique introduced by previous algorithms 
[16, 17]. Induced suﬃx sorting consists in deducing the order of unsorted
suﬃxes from a set of already ordered suﬃxes.

The next deﬁnition classiﬁes suﬃxes and symbols of strings.

2

Deﬁnition 1 (L-type and S-type) For any string T , Tn = $ has type S. A suﬃx
Ti is an S-suﬃx if Ti < Ti+1, otherwise Ti is an L-suﬃx. T [i] has the type of Ti.

The suﬃxes can be classiﬁed in linear time by scanning T once from right to left.

The type of each suﬃx is stored in a bitmap of size n.

Note that, in a c-bucket, all L-suﬃxes precede to the S-suﬃxes.
Further, the classiﬁcation of suﬃxes is reﬁned as below:

Deﬁnition 2 (LMS-type) Let T be a string. Ti is an LMS-suﬃx if Ti is an S-suﬃx
and Ti−1 is an L-suﬃx.

Nong et al. [9] showed that the order of the LMS-suﬃxes is enough to induce the

order of all suﬃxes.

SAIS works as follows:

SAIS framework:

1. Sort the LMS-suﬃxes. This step is explained below.

2. Insert the LMS-suﬃxes into their c-buckets in SA, without changing their order.

3. Induce L-suﬃxes by scanning SA from left to right:

T [SA[i] − 1] is L-type, insert SA[i] − 1 into the head of its bucket.

for each suﬃx SA[i] if

4. Induce S-suﬃxes by scanning SA from right to left:

T [SA[i] − 1] is S-type, insert SA[i] − 1 into the tail of its bucket.

for each suﬃx SA[i] if

We say that whenever a value is inserted in the head (or tail) of a bucket,the head

(or tail) is increased (or decreased) by one.

In order to sort the LMS-suﬃxes in Step 1, T [1, n] is divided (factorized) into

LMS-substrings.

Deﬁnition 3 T [i, j] is an LMS-substring if both Ti and Tj are LMS-suﬃxes, but no
suﬃx between i and j has LMS-type. The last suﬃx Tn is an LMS-substring.

1, r1

Let r1

2, . . . , r1

n1 be the n1 LMS-substrings of T read from left-to-right. A modiﬁed 
version of SAIS is applied to sort the LMS-substrings. Starting from Step 2,
T [1, n] is scanned (right-to-left) and each unsorted LMS-suﬃx is inserted (bucket-
sorted) regarding its ﬁrst symbol at the tail of its c-bucket. Steps 3 and 4 work
exactly the same. At the end, all LMS-substrings are sorted and stored in their
corresponding c-buckets in SA.

Naming:

i < r1

i < v1

j if r1

i is assigned to each LMS-substring r1

A name v1
i according to its lexicographical rank
in [1, σ1], such that v1
j and σ1 is the number
of diﬀerent LMS-substrings in T . In order to compute the names, each consecutive
LMS-substrings in SA, say r1
i+1
or r1
i+1 is
named as v1
i + 1. This procedure may be sped up by comparing the LMS-substrings
ﬁrst by symbol and then by type, with L-type symbols being smaller than S-type
symbols in case of ties [18].

i+1, are compared to determine if either r1

i , whereas in the latter case v1

i+1. In the former case v1

i+1 is named as v1

i and r1

i = r1

i < r1

j , v1

i = v1

j if r1

i = r1

3

Recursive call:

1 · v1

1 ··· v1

n1 is created, whose length n1 is at most n/2,
A new (reduced) string T 1 = v1
and the alphabet size σ1 is integer. If every v1
j then all LMS-suﬃxes are already
sorted. Otherwise, SAIS is recursively applied to sort all the suﬃxes of T 1. Nong
et al. [9] showed that the relative order of the LMS-suﬃxes in T is the same as the
order of the respective suﬃxes in T 1. Therefore, the order of all LMS-suﬃxes can be
determined by the result of the recursive algorithm.

i (cid:54)= v1

Grammar Compression by Induced Suﬃx Sorting

In this section we introduce the grammar compression by induced sorting (GCIS),
which is based on SAIS.

First, we compute a context-free grammar G = (Σ, Γ, P, XS) that generates only

T [1, n]. To do this we modify SAIS as follows.

Grammar construction:

1, vj

i ) = vj

1, rj

2, . . . , rj

2, . . . , vj

nj and named into vj

i +(cid:80)j−1

Considering the j-th recursion level, in Step 1, after the input string T j[1, n] is divided
into the LMS-substrings rj
nj , we create a new
rule Xi → αi for each diﬀerent LMS-substring rj
i ) →
T j[a, b − 1], where r(vj
k=1 σk. Moreover, we create an additional rule
r(0j) → T j[1, j1−1] for the preﬁx of T j that is not included in the ﬁrst LMS-substring
rj
1.
2 ··· vj
nj
as input while σj < nj, that is, the LMS-substrings are not pairwise distinct. At the
end, when σj = nj, we create the start symbol of G as being XS, such the production
XS → r(0j) · r(vj

The algorithm is called recursively with the reduced string T j+1 = vj

i = T j[a, b] in the form r(vj

nj ) generates only the original string T [1, n].

1) · r(vj

2)··· r(vj

1 · vj

The algorithm stops after computing XS, since we are not interested in constructing 
the suﬃx array, we do not execute Steps 2, 3 and 4 of SAIS. The recursive calls
return to the top level and we have computed a grammar G that generates only
T [1, n].

Since for each LMS-substring a unique r(vj

i ) exists, there are no cycles in any

derivations, and L(G) = T , we have that G is a grammar that compresses T [19].

Grammar compression:

Consecutive entries in the set of productions P are likely to share a common preﬁx,
since the LMS-substrings are given lexicographically ordered by SAIS. Therefore,
each rule Xi → αi ∈ P is encoded using two values ((cid:96)i, s(αi)), such that (cid:96)i encodes
the length of longest common preﬁx (lcp) between αi−1 and αi, and the remaining
symbols of αi are given by s(αi) = αi[(cid:96)i + 1,|αi|]. This technique is known as Frontcoding 
[20].

The computation of ((cid:96)i, s(αi)) is performed with no additional cost with a slight
modiﬁcation in the naming procedure of SAIS. Each consecutive LMS-substring in
SA, say rj
i are compared ﬁrst by symbol and then by type to check if either
rj
i−1 = rj
i ) we compare them only by

i−1 < ri. In order to compute lcp(rj

i−1 and rj
i or rj

i−1, rj

4

Table 1: Simple8b possible arrangements [21].

Selector value
Item width
Group Size
Wasted bits

0
0
240
60

1
0
120
60

2
1
60
0

3
2
30
0

4
3
20
0

5
4
15
0

6
5
12
0

7
6
10
0

8
7
8
4

9
8
7
4

10
10
6
0

11
12
5
0

12
15
4
0

13
20
3
0

14
30
2
0

15
60
1
0

symbol until ﬁnding the ﬁrst mismatch. The resulting order is the same with a small
slowdown in the running time.

Computational cost:

GCIS runs in O(n) time, since each step of the modiﬁed SAIS is linear and the
length of the reduced string T j is at most |T j−1|/2.

Implementation details

In this section we discuss implementation details of the GCIS encoding and decoding
processes.

Encoding:

A rule Xi is derived into a pair αi = ((cid:96)i, s(αi)), where (cid:96) equals lcp(αi−1, αi) and s(αi)
corresponds to the remaining αi[(cid:96)i + 1,|αi|] symbols. The (cid:96) values tend to be small
and, considering the j-th recursion value, the sum of such values cannot be greater
than nj, since no two LMS-substrings overlap.

One can encode all (cid:96) values into a sequence of computer words L by using Simple8b
encoding [21]. This technique packs a number of small integers in a 64-bit word using
the number of bits required by the largest integer. Basically it identiﬁes a word with
a 4-bit tag called selector, which speciﬁes the number of integers encoded in a single
word and the width of such integers. Simple8b also has speciﬁc selectors for a run
consisting of zeroes. If a run of 240 or 120 zeros is encountered, it can be represented
with a single 64 bit word. Table 1 contain all possible selector values, which reﬂects
the possible arrangements of ﬁxed-width integers storage in a single 64-bit word under
this encoding scheme.
All s(αi) are encoded in a single ﬁxed-width integer array R, consisting of width
(cid:98)lg(αj)(cid:99) + 1 bits. The length of each s(αi) is also encoded using Simple8b into a
word array S. The same observation of the lcp sum can be done here: the sum of all
|s(αi)| is no larger than nj.

A greedy strategy was employed to stop the recursion when the dictionary size
of the (j + 1)-th level plus the size in bits of T j+1 is bigger than the size in bits of
T j. In this situation, the computation done on the j-th level is discarded and the
algorithm stops. When this condition is met, αj < nj, but this does not interfere on
the decoding algorithm.

5

Decoding:

The decoding process is done level-wise, starting from the last level, by decoding the
right side of each rule. In the j-th level, the values (x, y, z) from L, R and S are
decoded in a sequential way. In order to compute αk+1 from αk, the ﬁrst x symbols
of αk are copied to αk+1 and the z symbols from R, which correspond to the string
y, are copied to αk+1 as well. A bitmap D is built to contain the length of all αi by
using Rice-coding. With two select1 operations it is possible to query the starting
point of each αi in this array and the length |αi| in constant time using 2nj + o(nj)
bits, where j corresponds to the j-th recursive step of the grammar construction.
Once all rules are expanded into a ﬁxed-width integer array of (cid:98)lg(σj)(cid:99) + 1 bits,
T j−1 can be decoded from T j. First, the right side of r(0j) is copied into T j−1.
Then, T j is scanned in a left-to-right fashion and for each T j[i] the algorithm copies
a substring to T j−1 which equals the right side of r(T j[i]) and can be easily found
with the bitmap D support.

Experiments

We compared GCIS with Re-Pair1 and 7-zip2 regarding Pizza&Chili Repetitive
Corpus3 under the subjects of compression ratio, compression and decompression
running time. In particular, we used a space-eﬃcient implementation of Re-Pair
by Wan [22], wich encodes each rule with one integer plus few bits. GCIS was
implemented in C++11 using the Succinct Data Structure Library (SDSL) [23].

All experiments were conducted on machine with 2x Intel(R) Xeon(R) CPU
E5-2407 v2 @ 2.40GHz CPUs and 256GB of RAM memory. The operating system
used was based on the Debian GNU/Linux O.S. The input size of each experiment is
given in the second column of Tables 2, 3 and 4.

Experimental results show that our algorithm is very eﬀective at handling repetitive 
strings. GCIS presents a competitive compression ratio, compression and decompression 
time, being a real practical option when considering all those subjects
simultaneously.

Compression and decompression:

Table 2 comprises the compression Ratio (%), corresponding to the size of the compressed 
text over the original input size. 7-zip presents the best compression ratio,
except for coreutils, fib41, rs and tm29, where Re-Pair outperforms it. Note
that GCIS presents a competitive compression ratio compared to Re-Pair.

Table 3 shows the compression time of each algorithm. GCIS is the fastest algorithm,
 except for einstein.de, einstein.en and proteins, where 7-zip was the
fastest. GCIS outperforms Re-Pair and 7-zip by a large margin in most cases,
being up to 6.5 times faster than Re-Pair (tm29) and up to 6.9 times faster than
7-zip (cere).

1https://github.com/rwanwork/Re-Pair
2http://p7zip.sourceforge.net/
3http://pizzachili.dcc.uchile.cl/repcorpus.html

6

Table 2: Compression ratio regarding Pizzaz&Chili repetitive corpus.

Pizza&Chili Repetitive Corpus

Compression Ratio (%)
Input Size (MB) GCIS Re-Pair 7-zip
1.82
11.63
0.16
0.16
0.20
0.19
0.51
0.11
0.07
0.55
6.56
0.36
1.65
0.82
2.39
0.59
0.16
0.45
0.72
1.39

461.29
205.28
104.86
104.86
104.86
104.86
104.86
92.76
467.63
104.86
112.69
267.91
154.81
257.96
429.27
104.86
216.75
104.86
268.44
46.97

3.76
5.39
0.43
0.43
0.84
0.77
3.55
0.31
0.20
4.17
14.14
0.03
4.76
2.37
4.98
4.13
0.02
4.10
0.02
3.38

Experiment
cere
coreutils
dblp.xml.00001.1
dblp.xml.00001.2
dblp.xml.0001.1
dblp.xml.0001.2
dna.001.1
einstein.de.txt
einstein.en.txt
english.001.2
escherichiacoli
fib41
influenza
kernel
para
proteins.001.1
rs.13
sources.001.2
tm29
world leaders

1.86
2.54
0.19
0.18
0.46
0.39
2.43
0.16
0.10
2.41
9.60
0.00
3.26
1.10
2.74
2.64
0.00
2.34
0.00
1.79

Table 4 presents the decompression time of each algorithm. 7-zip outperforms
Re-Pair and GCIS, except for fib41, rs and tm29, where Re-Pair was the fastest.
GCIS is up to 20 times slower than Re-Pair and 7-zip (einstein.en), whereas
Re-Pair is up to 6.6 times slower than 7-zip (cere).

Peak memory

We evaluated the peak memory consumption of Re-Pair and GCIS in compression
and decompression procedures. 7-zip and was not evaluated since it require negligible
amount of space when compressing or decompressing.
Figure 1a shows that GCIS requires ﬁve times less the space needed by RePair 
during compression. Since GCIS is based on SAIS, it requires ≈ 5 × n bytes,
for inputs with n < 4GB, whereas Re-Pair requires ≈ 30 × n bytes, becoming
prohibitive when the input is large. In decompression, illustrated by 1b, Re-Pair
has a lower peak memory usage than GCIS, making the former more appealing when
memory is limited.

7

Table 3: Compression time regarding Pizzaz&Chili repetitive corpus.

Pizza&Chili Repetitive Corpus

Compression Time (s)

Experiment
cere
coreutils
dblp.xml.00001.1
dblp.xml.00001.2
dblp.xml.0001.1
dblp.xml.0001.2
dna.001.1
einstein.de.txt
einstein.en.txt
english.001.2
escherichiacoli
fib41
influenza
kernel
para
proteins.001.1
rs.13
sources.001.2
tm29
world leaders

Input Size (MB) GCIS Re-Pair
464.62
210.21
71.85
72.31
72.35
73.70
73.83
62.17
338.30
93.61
138.06
77.35
108.98
223.52
512.93
82.86
69.58
85.69
92.70
23.57

100.61
44.48
21.34
21.59
21.21
21.76
19.48
22.48
135.19
27.79
22.42
15.58
26.64
60.26
95.93
29.05
12.04
23.56
14.33
5.98

461.29
205.28
104.86
104.86
104.86
104.86
104.86
92.76
467.63
104.86
112.69
267.91
154.81
257.96
429.27
104.86
216.75
104.86
268.44
46.97

7-zip
693.10
85.19
25.63
25.60
25.79
27.16
63.56
16.26
85.02
41.36
143.05
29.36
46.14
120.18
583.92
21.27
22.88
31.16
39.11
9.26

Conclusions

In the article we introduced a new grammar-based compression algorithm, called
GCIS, which is based on the induced suﬃx sorting framework of SAIS [9]. Experiments 
showed that GCIS is competitive compared to Re-Pair and 7-zip, being very
eﬀective at handling repetitive strings.

Future works:

As a future work, one can think of a GCIS/Re-Pair hybrid approach The key idea
is to encode the ﬁrst recursive levels using GCIS and then shift to Re-Pair. While
making the compression a little slower, this approach can make decompression faster
while preserving a good compression ratio.

We remark that GCIS, as well as Re-Pair, can support extract random substrings 
T [l, r] without decompressing the complete string T [1, n], by storing additional
data structures [8], whereas such operation is not possible for LZ77 based compressors 
[24]. We intend to implement this operation aiming at reducing its memory
footprint. Also, an eﬃcient way to search for a pattern in the compressed text is
desirable.

8

Table 4: Decompression time regarding Pizzaz&Chili repetitive corpus.

Pizza&Chili Repetitive Corpus

Decompression Time (s)
Input Size (MB) GCIS Re-Pair 7-zip
2.01
2.37
0.34
0.34
0.34
0.34
0.37
0.29
1.43
0.37
0.87
1.09
0.67
0.94
2.16
0.38
0.71
0.36
1.16
0.20

461.29
205.28
104.86
104.86
104.86
104.86
104.86
92.76
467.63
104.86
112.69
267.91
154.81
257.96
429.27
104.86
216.75
104.86
268.44
46.97

18.88
13.53
5.61
5.62
5.58
5.65
6.31
5.57
29.40
7.48
7.49
11.55
9.16
16.50
19.18
7.69
9.19
6.93
10.26
1.66

Experiment
cere
coreutils
dblp.xml.00001.1
dblp.xml.00001.2
dblp.xml.0001.1
dblp.xml.0001.2
dna.001.1
einstein.de.txt
einstein.en.txt
english.001.2
escherichiacoli
fib41
influenza
kernel
para
proteins.001.1
rs.13
sources.001.2
tm29
world leaders

13.31
3.95
0.82
0.85
0.85
1.04
1.75
0.45
2.70
3.76
3.36
0.53
1.09
5.96
12.88
2.45
0.43
3.21
0.53
0.45

References

[1] U. Manber and E. W. Myers, “Suﬃx arrays: A new method for on-line string searches,”

SIAM J. Comput., vol. 22, no. 5, pp. 935–948, 1993.

[2] G. H. Gonnet, R. A. Baeza-Yates, and T. Snider, “New indices for text: Pat trees and
pat arrays,” in Information Retrieval. Upper Saddle River, NJ, USA: Prentice-Hall,
Inc., 1992, pp. 66–82.

[3] M. Burrows and D. J. Wheeler, “A block-sorting lossless data compression algorithm,”

Digital SRC Research Report, Tech. Rep., 1994.

[4] J. Ziv and A. Lempel, “A universal algorithm for sequential data compression,” IEEE

Transactions on Information Theory, vol. 23, no. 3, pp. 337–343, 1977.

[5] E. Ohlebusch and S. Gog, “Lempel-ziv factorization revisited,” in Proc. CPM, 2011,

pp. 15–26.

[6] J. K¨arkk¨ainen, D. Kempa, and S. J. Puglisi, “Linear time lempel-ziv factorization:

Simple, fast, small,” in Proc. CPM, 2013, pp. 189–200.

[7] K. Goto and H. Bannai, “Space eﬃcient linear time Lempel-Ziv factorization for small

alphabets,” in Proc. DCC, 2014, pp. 163–172.

[8] G. Navarro, Compact Data Structures – A practical approach. Cambridge University

Press, 2016.

[9] G. Nong, S. Zhang, and W. H. Chan, “Linear suﬃx array construction by almost pure

induced-sorting,” in Proc. DCC, 2009, pp. 193–202.

9

(a) Memory Peak (MB) during compression.


(b) Memory Peak (MB) during decompression.


Figure 1: Peak memory of GCIS and Re-Pair regarding compression and decompression.


[10] D. Okanohara and K. Sadakane, “A linear-time Burrows-Wheeler transform using induced 
sorting,” in Proc. SPIRE, 2009, pp. 90–101.

[11] J. K¨arkk¨ainen, G. Manzini, and S. J. Puglisi, “Permuted longest-common-preﬁx array,”

in Proc. CPM, 2009, pp. 181–192.

[12] J. Fischer, “Inducing the LCP-Array,” in Proc. WADS, 2011, pp. 374–385.
[13] F. A. Louza, S. Gog, and G. P. Telles, “Inducing enhanced suﬃx arrays for string

collections,” Theor. Comput. Sci., vol. 678, pp. 22–39, 2017.

[14] N. J. Larsson and A. Moﬀat, “Oﬄine dictionary-based compression,” in Proc. DCC,

1999, pp. 296–305.

[15] I. Pavlov, “The 7zip home page,” http://www.7-zip.org/, accessed: 10/2017.
[16] H. Itoh and H. Tanaka, “An eﬃcient method for in memory construction of suﬃx

arrays,” in Proc. SPIRE, 1999, pp. 81–88.

[17] P. Ko and S. Aluru, “Space eﬃcient linear time construction of suﬃx arrays,” in Proc.

CPM, 2003, pp. 200–210.

[18] G. Nong, S. Zhang, and W. H. Chan, “Two eﬃcient algorithms for linear time suﬃx

array construction,” IEEE Trans. Comput., vol. 60, no. 10, pp. 1471–1484, 2011.

[19] J. Arpe and R. Reischuk, “On the complexity of optimal grammar-based compression,”

in Proc. DCC, 2006, pp. 173–182.

[20] I. H. Witten, A. Moﬀat, and T. C. Bell, Managing Gigabytes: Compressing and Indexing 
Documents and Images, Second Edition. Morgan Kaufmann, 1999.

[21] V. N. Anh and A. Moﬀat, “Index compression using 64-bit words,” Softw., Pract.

Exper., vol. 40, no. 2, pp. 131–147, 2010.

[22] R. Wan, “Browsing and searching compressed documents,” Ph.D. dissertation, University 
of Melbourne, Australia, Dec. 2003.

[23] S. Gog, T. Beller, A. Moﬀat, and M. Petri, “From theory to practice: Plug and play

with succinct data structures,” in Proc. SEA, 2014, pp. 326–337.

[24] S. Kreft and G. Navarro, “Lz77-like compression with fast random access,” in Proc.

DCC, 2010, pp. 239–248.

10

