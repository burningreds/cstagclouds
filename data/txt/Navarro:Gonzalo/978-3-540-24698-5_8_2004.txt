Rotation and Lighting Invariant

Template Matching

Kimmo Fredriksson1, Veli M¨akinen2(cid:1), and Gonzalo Navarro3(cid:1)(cid:1)

1 Department of Computer Science, University of Joensuu.

2 Department of Computer Science, University of Helsinki.

kfredrik@cs.joensuu.fi

3 Center for Web Research, Department of Computer Science, University of Chile.

vmakinen@cs.helsinki.fi

gnavarro@dcc.uchile.cl

Abstract. We address the problem of searching for a two-dimensional
pattern in a two-dimensional text (or image), such that the pattern can
be found even if it appears rotated and brighter or darker than its occurrence.
 Furthermore, we consider approximate matching under several
tolerance models. We obtain algorithms that are almost worst-case optimal.
 The complexities we obtain are very close to the best current results
for the case where only rotations, but not lighting invariance, are supported.
 These are the ﬁrst results for this problem under a combinatorial
approach.

1 Introduction

We consider the problem of ﬁnding the occurrences of a two-dimensional pattern
of size m × m cells in a two-dimensional text of size n × n cells, when all possible 
rotations of the pattern are allowed and also pattern and text may have
diﬀerences in brightness. This stands for rotation and lighting invariant template
matching. Text and pattern are seen as images formed by cells, each of which
has a gray level value, also called a color.

Template matching has numerous important applications from science to
multimedia, for example in image processing, content based information retrieval
from image databases, geographic information systems, processing of aerial images,
 to name a few. In all these cases, we want to ﬁnd a small subimage (the
pattern) inside a large image (the text) permitting rotations (a small degree or
any). Furthermore, pattern and text may have been photographed under diﬀerent 
lighting conditions, so one may be brighter than the other.

The traditional approach to this problem [2] is to compute the cross correlation 
between each text location and each rotation of the pattern template. This

(cid:1) A part of the work was done while visiting University of Chile under a researcher

exchange grant from University of Helsinki.

(cid:1)(cid:1) Funded by Millennium Nucleus Center for Web Research, Grant P01-029-F, Mideplan,
 Chile.

M. Farach-Colton (Ed.): LATIN 2004, LNCS 2976, pp. 39–48, 2004.
c(cid:1) Springer-Verlag Berlin Heidelberg 2004

40

K. Fredriksson, V. M¨akinen, and G. Navarro

can be done reasonably eﬃciently using the Fast Fourier Transform (FFT), requiring 
time O(Kn2 log n) where K is the number of rotations sampled. Typically
K is O(m) in the two-dimensional (2D) case, and O(m3) in the 3D case, which
makes the FFT approach very slow in practice. In addition, lighting-invariant
features may be deﬁned in order to make the FFT insensitive to brightness. Also,
in many applications, “close enough” matches of the pattern are also accepted.
To this end, the user may specify, for example, a parameter κ such that matches
that have at most κ diﬀerences with the pattern should be accepted, or a parameter 
δ such that gray levels diﬀering by less than δ are considered equal. The
deﬁnition of the matching conditions is called the “matching model”.

Rotation invariant template matching was ﬁrst considered from a combinatorial 
point of view in [8,9]. Since then, several fast ﬁlters have been developed for
diverse matching models [10,7,6]. These represent large performance improvements 
over the FFT-based approach. The worst-case complexity of the problem
was also studied [1,7]. However, lighting invariance has not been considered in
this scenario.

On the other hand, transposition invariant string matching was considered
in music retrieval [3,11]. The aim is to search for (one-dimensional) patterns in
texts such that the pattern may match the text after all its characters (notes)
are shifted by some value. The reason is that such an occurrence will sound
like the pattern to a human, albeit in a diﬀerent scale. In this context, eﬃcient
algorithms for several approximate matching functions were developed in [12].
We note that transposition invariance becomes lighting invariance when we
replace musical notes by gray levels of cells in an image. Hence, the aim of
this paper is to enrich the existing algorithms for rotation invariant template
matching [7] with the techniques developed for transposition invariance [12] so
as to obtain rotation and lighting invariant template matching. It turns out that
lighting invariance can be added at very little extra cost. The key technique exploited 
is incremental distance computation; we show that several transposition
invariant distances can be computed incrementally taking the computation done
with the previous rotation into account in the next rotation angle.

Let us now determine which are the reasonable matching models. In [7],
some of the models considered were useful only for binary images, a case where
obviously we are not interested in this paper. We will address models that make
sense for gray level images. We deﬁne three transposition-invariant distances:
dt,δ
H , which counts how many pattern and text cells diﬀer by more than δ; dt,κ
MAD,
which is the maximum color diﬀerence between pattern and text cells when up to
κ outliers are permitted; and dt,κ
SAD, which is the sum of absolute color diﬀerences
between pattern and text cells permitting up to κ outliers. Table 1 shows our
complexities to compute these distances for every possible rotation of a pattern
centered at a ﬁxed text position. Variable σ is the number of diﬀerent gray levels
(assume σ = ∞ if the alphabet is not a ﬁnite discrete range). A lower bound to
this problem is O(m3), achieved in [7] without lighting invariance.

We also deﬁne two search problems, consisting in ﬁnding all the transpositioninvariant 
rotated occurrences of P in T such that: (1) there are at most κ cells
of P diﬀering by more than δ from their text cell (δ-matching); or (2) the sum

