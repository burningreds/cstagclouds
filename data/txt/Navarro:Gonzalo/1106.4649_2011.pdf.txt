2
1
0
2

 
r
a

 

M
1
3

 
 
]
S
D
.
s
c
[
 
 

2
v
9
4
6
4

.

6
0
1
1
:
v
i
X
r
a

Space-Eﬃcient Data-Analysis Queries on Grids

Gonzalo Navarroa,1, Yakov Nekricha,1, Lu´ıs M. S. Russob,c,2

aDept. of Computer Science, University of Chile.

bInstituto Superior T´ecnico - Universidade T´ecnica de Lisboa (IST/UTL).

cINESC-ID / KDBIO

Abstract

We consider various data-analysis queries on two-dimensional points. We give
new space/time tradeoﬀs over previous work on geometric queries such as dominance 
and rectangle visibility, and on semigroup and group queries such as sum,
average, variance, minimum and maximum. We also introduce new solutions
to queries less frequently considered in the literature such as two-dimensional
quantiles, majorities, successor/predecessor, mode, and various top-k queries,
considering static and dynamic scenarios.

range queries, databases, succinct data structures, dynamic data

Keywords:
structures, statistical database queries, orthogonal range queries, point
dominance, rectangle visibility, wavelet tree, range minimum queries, alpha
majority, quantile, top-k, mode
2010 MSC: 11Y16, 68Q25, 03C13, 62-04

1. Introduction

Multidimensional grids arise as natural representations to support conjunctive 
queries in databases [BCKO08]. Typical queries such as “ﬁnd all the employees 
with age between x0 and x1 and salary between y0 and y1” translate
into a two-dimensional range reporting query on coordinates age and salary.
More generally, such a grid representation of the data is useful to carry out a
number of data analysis queries over large repositories. Both space and time
eﬃciency are important when analyzing the performance of data structures on
massive data. However, in cases of very large data volumes the space usage can
be even more important than the time needed to answer a query. More or less

Email addresses: gnavarro@dcc.uchile.cl (Gonzalo Navarro),

yakov.nekrich@googlemail.com (Yakov Nekrich), luis.russo@ist.utl.pt (Lu´ıs M. S.
Russo)

1Author supported in part by Millennium Institute for Cell Dynamics and Biotechnology

(ICDB), Grant ICM P05-001-F, Mideplan, Chile.

2Author supported by FCT through projects TAGS PTDC/EIA-EIA/112283/2009, HELIX 
PTDC/EEA-ELC/113999/2009 and the PIDDAC Program funds (INESC-ID multiannual 
funding).

Preprint submitted to Elsevier

June 6, 2018

space usage can make the diﬀerence between maintaining all the data in main
memory or having to resort to disk, which is orders of magnitude slower.

In this paper we study various problems on two-dimensional grids that are
relevant for data analysis, focusing on achieving good time performance (usually 
polylogarithmic) within the least possible space (even succinct for some
problems).

Counting the points in a two-dimensional range Q = [x0, x1] × [y0, y1], i.e.,
computing Count(Q), is arguably the most primitive operation in data analysis.
 Given n points on an n × n grid, one can compute Count in time
O(log n/ log log n) using “linear” space, O(n) integers [Nek09]. This time is
optimal within space O(n polylog(n)) [P˘07], and it has been matched using
asymptotically minimum (i.e., succinct) space, n + o(n) integers, by Bose et
al. [BHMM09].

The k points in the range can be reported in time O(log log n + k) using
O(n logǫ n) integers, for any constant ǫ > 0 [ABR00]. This time is optimal
within space O(n polylog(n)), by reduction from the colored predecessor problem 
[PT06]. With O(n) integers, the time becomes O((k + 1) logǫ n) [CLP11].
Within n + o(n) integers space, one can achieve time O(k log n
log log n ) [BHMM09].
We start with two geometric problems, dominance and rectangular visibility.
 These enable data analysis queries such as “ﬁnd the employees with worst
productivity-salary combination within productivity range [x0, x1] and salary
range [y0, y1]”, that is, such that no less productive employee earns more.

The best current result for the 4-sided variant of these problems (i.e., where
the points are limited by a general rectangle Q) is a dynamic structure by Brodal
and Tsakalidis [BT11]. It requires O(n log n)-integers space and reports the d
dominant/visible points in time O(log2 n + d). Updates take O(log2 n) time.
They achieve better complexities for simpler variants of the problem, such as
some 3-sided variants.

Our results build on the wavelet tree [GGV03], a succinct-space variant of a
classical structure by Chazelle [Cha88]. The wavelet tree has been used to handle
various geometric problems, e.g., [MN07, GPT09, BHMM09, BLNS10, BCN10,
GNP11]. We show in Section 3 how to use wavelet trees to solve dominance and
visibility problems using n + o(n) integers space and O((d + 1) log n) time. The
dynamic version also uses succinct space and requires O((d + 1) log2 n/ log log n)
time, carrying out updates in time O(log2 n/ log log n). Compared to the best
current result [BT11], our structure requires succinct space instead of O(n log n)
integers, oﬀers better update time, and has a comparable query time (being
faster for small d = O(log log n)).

The paper then considers a wide range of queries we call “statistical”: The
points have an associated value in [0, W ) = [0, W − 1] and, given a rectangle Q,
we consider the following queries:

Sum/Avg/Var: The sum/average/variance of the values in Q (Section 4).

Min/Max: The minimum/maximum value in Q (Section 5).

Quantile: The k-th smallest value in Q (Section 7).

2

Majority(α): The values appearing with relative frequency > α in Q (Sections 
6 and 8).

Succ/Pred: The successor/predecessor of a value w in Q (Section 9).

These operations enable data-analysis queries such as “the average salary
of employees whose annual production is between x0 and x1 and whose age is
between y0 and y1”. The minimum operation can be used to determine “the
employee with the lowest salary”, in the previous conditions. The α-majority operation 
can be used to compute “which are frequent (≥ 20%) salaries”. Quantile
queries enable us to determine “which are the 10% highest salaries”. Successor 
queries can be used to ﬁnd the smallest salary over $100,000 among those
employees.

Other applications for such queries are frequently found in Geographic Information 
Systems (GIS), where the points have a geometric interpretation and
the values can be city sizes, industrial production, topographic heights, and so
on. Yet another application comes from Bioinformatics, where two-dimensional
points with intensities are obtained from DNA microarrays, and various kinds
of data-analysis activities are carried out on them. See Rahul et al. [RGJR11]
for an ample discussion on some of these applications and several others.

A popular set of statistical queries includes range sums, averages, and max-
ima/minima. Willard [Wil85] solved two-dimensional range-sum queries on ﬁnite 
groups within O(n log n)-integers space and O(log n) time. This includes
Sum and is easily extended to Avg and Var. Alstrup et al. [ABR00] obtained
the same complexities for the semigroup model, which includes Min/Max. The
latter can also be solved in constant time using O(n2)-integers space [AFL07,
BDR11]. Chazelle [Cha88] showed how to reduce the space to O(n/ǫ) integers
and achieve time O(log2+ǫ n) on semigroups, and O(log1+ǫ n) for the particular
case of Min/Max.

On this set of queries our contribution is to achieve good time complexities
within linear and even succinct space. This is relevant to handle large datasets
in main memory. While the times we achieve are not competitive when using
O(n) integers or more, we manage to achieve polylogarithmic times within just
n log n+o(n log n) bits on top of the bare coordinates and values, which we show
is close to the information-theoretic minimum space necessary to represent n
points.

As explained, we use wavelet trees. These store bit vectors at the nodes of
a tree that decomposes the y-space of the grid. The vectors track down the
points, sorted on top by x-coordinate and on the bottom by y-coordinate. We
enrich wavelet trees with extra data aligned to the bit vectors, which speeds up
the computation of the statistical queries. Space is then reduced by sparsifying
these extra data.

We also focus on more sophisticated queries, for which fewer results exist,

such as quantile, majority, and predecessor/successor queries.

In one dimension, the best result we know of for quantiles queries is a linearspace 
structure by Brodal and Jørgensen [BJ09], which ﬁnds the k-th element of
any range in an array of length n in time O(log n/ log log n), which is optimal.

3

Space per point (bits)

Operation
Sum, Avg, Var
Min, Max
log n(2 + 1/t) + log m
Majority(α), ﬁxed
log n logℓ m + O(log m)
Quantile
Majority(α), variable log n logℓ m + O(log m)
Succ, Pred
log n logℓ m + O(log m)

log n(1 + 1/t)
log n(1 + 1/t)

Time

O(min(t log W, log n)t log W log n)

O(min(t log m, log n)t log n)

O(t log m log2 n)
O(ℓ log n logℓ m)
O( 1
α ℓ log n logℓ m)
O(ℓ log n logℓ m)

O(log3 n)
O(log2 n)
O(log3 n)

Time in linear space Source
Thm. 6
Thm. 8
Thm. 10
Thm. 11
Thm. 12
Thm. 13

O(nǫ)
O(nǫ)
O(nǫ)

Table 1: Our static results on statistical queries, for n two-dimensional points with associated
values in [0, W ); m = min(n, W ); 2 ≤ ℓ ≤ u and t ≥ 1 are parameters. The space omits the
mapping of the real (x, y) coordinates to the space [0, n), as well as the storage of the point
values. The 5th column gives simpliﬁed time assuming log n = Θ(log W ), any constant ǫ, and
use of O(n log n) bits.

An α-majority of a range Q is a value that occurs more than α · Count(Q)
times inside Q, for some α ∈ [0, 1]. The α-majority problem was previously
considered in one and two dimensions [KN08, DHM+11, GHMN11]. Durocher
et al. [DHM+11] solve one-dimensional α-range majority queries in time O(1/α)
using O(n(1 + log(1/α))) integers. Here α must be chosen when creating the
data structure. A more recent result, given by Gagie et al. [GHMN11], obtains
a structure of O(n2(H + 1) log(1/α)) bits for a dense n × n matrix (i.e., every
position contains an element), where H is the entropy of the distribution of
elements. In this case α is also chosen at indexing time, and the structure can
answer queries for any β ≥ α. The resulting elements are not guaranteed to
be β-majorities, as the list may contain false positives, but there are no false
negatives.

Other related queries have been studied in two dimensions. Rahul et al. [RGJR11]

considered a variant of Quantile where one reports the top-k smallest/largest
values in a range. They obtain O(n log2 n)-integers space and O(log n+k log log n)
time. Navarro and Nekrich [NN12] reduced the space to O(n/ǫ) integers, with
time O(log1+ǫ n + k logǫ n). Durocher and Morrison [DM11] consider the mode
(most repeated value) in a two-dimensional range. Their times are sublinear
but super-polylogarithmic by far.

Our contribution in this case is a data structure of O(n log n) integers able
to solve the three basic queries in time O(log2 n). The space can be stretched up
to linear, but at this point the times grow to the form O(nǫ). Our solution for
range majorities lets α to be speciﬁed at query time. For the case of α known
at indexing time, we introduce a new linear-space data structure that answers
queries in time O(log3 n), and up to O(log2 n) when using O(n log n) integers
space.

In this case we build a wavelet tree on the universe of the point values. A
sub-grid at each node stores the points whose values are within a range. With
this structure we can also solve mode and top-k most-frequent queries.

Table 1 shows the time and space results we obtain in this article for statistical 
queries. Several of our data structures can be made dynamic at the price
of a sublogarithmic penalty factor in the time complexities, as summarized in
Table 2.

4

Operation
Sum, Avg, Var
Min, Max
Quantile
Majority(α), var.
Succ, Pred

Query time

Space per point (bits)
log U (1 + o(1) + 1/t) O(log U log n(1 + min(t log W,log U)t log W
log U (1 + o(1) + 1/t) O(log U log n(1 + min(t log W,log U)t log W
log U logℓ W (1 + o(1))
log U logℓ W (1 + o(1))
log U logℓ W (1 + o(1))

O(ℓ log U log n logℓ W/ log log n)
O( 1
α ℓ log U log n logℓ W/ log log n)
O(ℓ log U log n logℓ W/ log log n)

log log n

log log n

))
))

Update time
O(log U log n)

O(log U (log n + t log W ))

O(log U log n logℓ W/ log log n)
O(log U log n logℓ W/ log log n)
O(log U log n logℓ W/ log log n)

Table 2: Our dynamic results on statistical queries, for n two-dimensional points on an U × U
grid with associated values in [0, W ); 2 ≤ ℓ ≤ W , t ≥ 1 and 0 < ǫ < 1 are parameters. The
space omits the mapping of the real x coordinates to [0, n), as well as the point values. The
ﬁrst line is proved in Thm. 7, the second in Thm 9, and the rest in Thm. 14.

2. Wavelet Trees

Wavelet trees [GGV03] are deﬁned on top of the basic Rank and Select
functions. Let B denote a bitmap, i.e., a sequence of 0’s and 1’s. Rank(B, b, i)
counts the number of times bit b ∈ {0, 1} appears in B[0, i], assuming Rank(B, b,−1) =
0. The dual operation, Select(B, b, i), returns the position of the i-th occurrence 
of b, assuming Select(B, b, 0) = −1.
The wavelet tree represents a sequence S[0, n) over alphabet Σ = [0, σ), and
supports access to any S[i], as well as Rank and Select on S, by reducing
them to bitmaps. It is a complete binary tree where each node v may have a
left child labeled 0 (called the 0-child of v) and a right child labeled 1 (called
the 1-child). The sequence of labels obtained when traversing the tree from the
Root down to a node v is the binary label of v and is denoted L(v). Likewise
we denote V (L) the node that is obtained by following the sequence of bits L,
thus V (L(v)) = v. The binary labels of the leaves correspond to the binary
representation of the symbols of Σ. Given c ∈ Σ we denote by V (c) the leaf
that corresponds to symbol c. By c{..d} we denote the sequence of the ﬁrst d
bits in c. Therefore, for increasing values of d, the V (c{..d}) nodes represent
the path to V (c).
Each node v represents (but does not store) the subsequence S(v) of S
formed by the symbols whose binary code starts with L(v). At each node v we
only store a (possibly empty) bitmap, denoted B(v), of length |S(v)|, so that
B(v)[i] = 0 iﬀ S(v)[i]{..d} = L(v)· 0, where d = |L(v)| + 1, that is, if S(v)[i] also
belongs to the 0-child. A bit position i in B(v) can be mapped to a position in
each of its child nodes: we map i to position R(v, b, i) = Rank(B(v), b, i)− 1 of
the b-child. We refer to this procedure as the reduction of i, and use the same
notation to represent a sequence of steps, where b is replaced by a sequence of
bits. Thus R(Root, c, i), for a symbol c ∈ Σ, represents the reduction of i from
the Root using the bits in the binary representation of c. With this notation we
describe the way in which the wavelet tree computes Rank, which is summarized
by the equation Rank(S, c, i) = R(Root, c, i) + 1. We use a similar notation
R(v, v′, i), to represent descending from node v towards a given node v′, instead
of explicitly describing the sequence of bits b such that L(v′) = L(v) · b and
writing R(v, b, i).
An important path in the tree is obtained by choosing R(v, B(v)[i], i) at each

5

node, i.e., at each node we decide to go left of right depending on the bit we are
currently tracking. The resulting leaf is V (S[i]), therefore this process provides
a way to obtain the elements of S. The resulting position is R(Root, S[i], i) =
Rank(S, S[i], i) − 1.
It is also possible to move upwards on the tree, reverting the process computed 
by R. Let node v be the b-child of v′. Then, if i is a bit position in B(v),
we deﬁne the position Z(v, v′, i), in B(v′), as Select(B(v′), b, i + 1). In general,
when v′ is an ancestor of v, the notation Z(v, v′, i) represents the iteration of
this process. For a general sequence, Select can be computed by this process,
as summarized by the equation Select(S, c, i) = Z(V (c), Root, i − 1).
Lemma 1 ([GGV03, MN07, GGG+07]). The wavelet tree for a sequence S[0, n)
over alphabet Σ = [0, σ) requires at most n log σ + o(n) bits of space.3 It solves
Rank, Select, and access to any S[i] in time O(log σ).

Proof. Grossi et al. [GGV03] proposed a representation using n log σ +O( n log σ log log n
log n
+O(σ log n) bits. M¨akinen and Navarro showed how to use only one pointer
per level, reducing the last term to O(log σ log n) = O(log2 n) = o(n). Finally,
 Golynski et al. [GGG+07] showed how to support binary Rank and
Select in constant time, while reducing the redundancy of the bitmaps to
O(n log log n/ log2 n), which added over the n log σ bits gives o(n) as well.

)

2.1. Representation of Grids

Consider a set P of n distinct two-dimensional points (x, y) from a universe
[0, U ) × [0, U ). We map coordinates to rank space using a standard method
[Cha88, ABR00]: We store two sorted arrays X and Y with all the (possibly
repeated) x and y coordinates, respectively. Then we convert any point (x, y)
into rank space [0, n)× [0, n) in time O(log n) using two binary searches. Range
queries are also mapped to rank space via binary searches (in an inclusive manner 
in case of repeated values). This mapping time will be dominated by other
query times.

Therefore we store the points of P on a [0, n) × [0, n) grid, with exactly one
point per row and one per column. We regard this set as a sequence S[0, n) and
the grid is formed by the points (i, S[i]). Then we represent S using a wavelet
tree.

The space of X and Y corresponds to the bare point data and will not be
further mentioned; we will only count the space to store the points in rank space,
as usual in the literature. In Appendix A we show how we can represent this
mapping into rank space so that, together with a wavelet tree representation,
the total space is only O(n) bits over the minimum given by information theory.
The information relative to a point p0 = (x0, y0) is usually tracked from
the Root and denoted R(Root, y0{..d}, x0). A pair of points p0 = (x0, y0)
and p1 = (x1, y1), where x0 ≤ x1 and y0 ≤ y1, deﬁnes a rectangle; this is

3From now on the space will be measured in bits and log will be to the base 2.

6

the typical query range we consider in this paper. Rectangles have an implicit
representation in wavelet trees, spanning O(log n) nodes [MN07]. The binary
representation of y0 and y1 share a (possibly empty) common preﬁx. Therefore 
the paths V (y0{..d}) and V (y1{..d}) have a common initial path and then
split at some node of depth k, i.e., V (y0{..d}) = V (y1{..d}) for d ≤ k and
V (y0{..d′}) 6= V (y1{..d′}) for d′ > k. Geometrically, V (y0{..k}) = V (y1{..k})
corresponds to the smallest horizontal band of the form [j · n/2k, (j + 1) · n/2k)
that contains the query rectangle Q, for an integer j. For d′ > k the nodes
V (y0{..d′}) and V (y1{..d′}) correspond respectively to successively thinner, nonoverlapping 
bands that contain the coordinates y0 and y1.
Given a rectangle Q = [x0, x1] × [y0, y1] we consider the nodes V (y0{..d} · 1)
such that y0{..d} · 1 6= y0{..d + 1}, and the nodes V (y1{..d} · 0) such that
y1{..d} · 0 6= y1{..d + 1}. These nodes, together with V (y0) and V (y1), form
the implict representation of [y0, y1], denoted imp(y0, y1). The size of this set is
O(log n). Let us recall a well-known application of this decomposition.

Lemma 2. Given n two-dimensional points, the number of points inside a query
rectangle Q = [x0, x1] × [y0, y1], Count(Q), can be computed in time O(log n)
with a structure that requires n log n + o(n) bits.

Proof. The result is Pv∈imp(y0,y1) R(Root, v, x1) − R(Root, v, x0 − 1). Notice
that all the values R(Root, y0{..d}, x) and R(Root, y1{..d}, x) can be computed 
sequentially, in total time O(log n), for x = x1 and x = x0 − 1. For a
node v ∈ imp(y0, y1) the desired diﬀerence can be computed from one of these
values in time O(1). Then the lemma follows.

This is not the best possible result for this problem (a better result by Bose
et al. [BHMM09] exists), but it is useful to illustrate how wavelet trees solve
range search problems.

3. Geometric Queries

In this section we use wavelet trees to solve, within succinct space, two

geometric problems of relevance for data analysis.

3.1. Dominating Points

Given points p0 = (x0, y0) and p1 = (x1, y1), we say that p0 dominates p1
if x0 ≥ x1 and y0 ≥ y1. Note that one point can dominate the other even if
they coincide in one coordinate. Therefore, for technical convenience, in the
reduction described in Section 2.1, points with the same y coordinates must be
ranked in Y by increasing x value, and points with the same x coordinates must
be ranked in X by increasing y value. A point is dominant inside a range if
there is no other point in that range that dominates it. In Fig. 1 we deﬁne the
cardinal points N, S, E, W, SW, etc. We ﬁrst use wavelet trees to determine
dominant points within rectangles.

7

Theorem 3. Given n two-dimensional points, the d dominating points inside
a rectangle Q = [x0, x1] × [y0, y1] can be obtained (in NW to SE order) in time
O((d + 1) log n), with a data structure using n log n + o(n) bits.

Proof. Let v ∈ imp(y0, y1) be nodes in the implicit representation of [y0, y1].
We perform depth-ﬁrst searches (DFS) rooted at each v ∈ imp(y0, y1), starting
from V (y1) and continuing sequentially to the left until V (y0). Each such DFS
is computed by ﬁrst visiting the 1-child and then the 0-child. As a result, we
will ﬁnd the points in N to S order.

We ﬁrst describe a DFS that reports all the nodes, and then restrict it to
the dominant ones. Each visited node v′ tracks the interval (R(Root, v′, x0 −
1), R(Root, v′, x1)]. If the interval is empty we skip the subtree below v′. As
the grid contains only one point per row, for leaves v′ = v(i) the intervals
(R(Root, v(i), x0−1), R(Root, v(i), x1)] contain at most one value, corresponding 
to a point p(i) ∈ P ∩ Q. Then x(i) = Z(v(i), Root, R(Root, v(i), x1)) and
p(i) = (x(i), S[x(i)]). Reporting k points in this way takes O((k + 1) log n) time.
By restricting the intervals associated with the nodes we obtain only dominant 
points. In general, let v′ be the current node, that is either in imp(y0, y1)
or it is a descendant of a node in imp(y0, y1), and let (x(i), S[x(i)]) be the last
point that was reported. Instead of considering the interval (R(Root, v, x0 −
1), R(Root, v, x1)], consider the interval (R(Root, v, x(i)), R(Root, v, x1)]. This
is correct as it eliminates points (x, y) with x < x(i), and also y < S[x(i)], given
the N to S order in which we deliver the points.

As explained, a node with an empty interval is skipped. On the other hand,
if the interval is non-empty, it must produce at least one dominant point. Hence
the cost of reporting the d dominant points amortizes to O((d + 1) log n).

y1
S[x(i)]

y0

y

NW

NE

1

0

x

SW

SE

x0

x1

x(i) = X(v(i), Root, R(Root, v(i), x1))

q

Figure 1: Dominance on wavelet tree coordinates.
 The grayed points dominate all the
others in the rectangle. We also show the 4
directions.

Figure 2: Rectangle visibility. For SW visibility 
the problem is the same as dominance.
We grayed the points that are visible in the
other 3 directions.

8

3.2. Rectangle Visibility

Rectangle visibility is another, closely related, geometric problem. A point
p ∈ P is visible from a point q = (x0, y0), not necessarily in P, if the rectangle
deﬁned by p and q as diagonally opposite corners does not contain any point of
P. Depending on the direction from q to p the visibility is called SW, SE, NW
or NE (see Fig. 2). Next we solve visibility as variant of dominance.

Theorem 4. The structure of Thm. 3 can compute the d points that are visible
from a query point q = (x0, y0), in order, in time O((d + 1) log n).

Proof. Note that SW visibility corresponds precisely to determining the dominant 
points of the region [0, x0]× [0, y0]. Hence we use the procedure in Thm. 3.
We now adapt it to the three remaining directions without replicating the structure.


For NE or SE visibility, we change the deﬁnition of operation R to R(v, b, i) =
Rank(B(v), b, i − 1) + 1, thus Rank(S, c, i) = R(Root, c, i) + 1 if S[i] = c and
In this case we track the intervals
Rank(S, c, i) = R(Root, c, i) otherwise.
[R(Root, v′, x0), R(Root, v′, x1 + 1)). This R(Root, v′, x1 + 1) is replaced by
R(Root, v′, x(i)) when restricting the search with the last dominant point.

For NE or NW visibility, the DFS searches ﬁrst visit the 0-child and then use
the resulting points to restrict the search on the visit to the 1-child, moreover
they ﬁrst visit the node V (y0) and move to the right.

Finally, for NW or SE visibility our point ordering in presence of ties in X
or Y may report points with the same x or y coordinate. To avoid this we
detect ties in X or Y at the time of reporting, right after determining the pair
p(i) = (x, y) = (x(i), S[x(i)]). In the NW (SE) case, we binary search for the last
(ﬁrst) positions x′ such that X[x′] = X[x] and y′ such that Y [y′] = Y [y]. Then
we correct p(i) to (x′, y) (to (x, y′)). The subsequent searches are then limited
by x′ instead of x = x(i). We also limit subsequent searches in a new way: we
skip traversing subsequent subtrees of imp(y0, y1) until the y values are larger
(NW) or smaller (SE) than y′. Still the cost per reported point is O(log n).

3.3. Dynamism

We can support point insertions and deletions on a ﬁxed U×U grid. Dynamic
variants of the bitmaps stored at each wavelet tree node raise the extra space to
o(log U ) per point and multiply the times by O(log n/ log log n) [HM10, NS10].

Lemma 5. Given n points on a U × U grid, there is a structure using n log U +
o(n log U ) bits, answering queries in time O(t(log U ) log n/ log log n), where t(h)
is the time complexity of the query using static wavelet trees of height h. It
handles insertions and deletions in time O(log U log n/ log log n).

Proof. We use the same data structure and query algorithms of the static
wavelet trees described in Section 2.1, yet representing their bitmaps with the
dynamic variants [HM10, NS10]. We also maintain vector X, but not Y ; we use
the y-coordinates directly instead since the wavelet tree handles repetitions in

9

y. Having a wavelet tree of depth log U makes the time t(log U ), whereas using
dynamic bitmaps multiplies this time by O(log n/ log log n),

Instead of an array, we use for X a B-tree tree with arity Θ(log U ). Nodes are
handled with a standard technique for managing cells of diﬀerent sizes [Mun86],
which wastes just O(log2 U ) bits in total. As a result, the time for accessing a
position of X or for ﬁnding the range of elements corresponding to a range of
coordinates is O(log U ), which is subsumed by other complexities. The extra
space on top of that of the bare coordinates is O(n + log2 U ) bits. This is
o(n log U ) unless n = o(log U ), in which case we can just store the points in
plain form and solve all queries sequentially. It is also easy to store diﬀerentially
encoded coordinates in this B-tree to reduce the space of mapping the universe
of X coordinates to the same achieved in Section 2.1.

When inserting a new point (x, y), apart from inserting x into X, we track
the point downwards in the wavelet tree, doing the insertion at each of the log U
bitmaps. Deletion is analogous.

As a direct application, dominance and visibility queries can be solved in
the dynamic setting in time O((d + 1) log U log n/ log log n), while supporting
point insertions and deletions in time O(log U log n/ log log n). The only issue
is that we now may have several points with the same y-coordinate, which is
noted when the interval is of size more than one upon reaching a leaf. In this
case, as these points are sorted by increasing x-coordinate, we only report the
ﬁrst one (E) or the last one (W). Ties in the x-coordinate, instead, are handled
as in the static case.

4. Range Sum, Average, and Variance

We now consider points with an associated value given by an integer function 
w : P → [0, W ). We deﬁne the sequence of values W (v) associated to
each wavelet tree node v as follows: If S(v) = p0, p1, . . . , p|S(v)|, then W (v) =
w(p0), w(p1), . . . , w(p|S(v)|). We start with a solution to several range sum problems 
on groups. In our results we will omit the bare n⌈log W⌉ bits needed to
store the values of the points.

Theorem 6. Given n two-dimensional points with associated values in [0, W ),
the sum of the point values inside a query rectangle Q = [x0, x1] × [y0, y1],
Sum(Q), can be computed in time O(min(t log W, log n)t log W log n), with a
structure that requires n log n(1 + 1/t) bits, for any t ≥ 1. It can also compute
the average and variance of the values, Avg(Q) and Var(Q) respectively.

Proof. We enrich the bitmaps of the wavelet tree for P. For each node v we
represent its vector W (v) = w(p0), w(p1), . . . , w(p|S(v)|) as a bitmap A(v), where
we concatenate the unary representation of the w(pi)’s, i.e., w(pi) 0’s followed
by a 1. These bitmaps A(v) are represented in a compressed format [OS07]
that requires at most |S(v)| log W + O(|S(v)|) bits. With this structure we can
determine the sum w(p0)+w(p1)+. . .+w(pi), i.e., the partial sums, in constant

10

time by means of Select(A(v), 1, i) queries4, Wsum(v, i) = Select(A(v), 1, i+
1)−i is the sum of the ﬁrst i + 1 values. In order to compute Sum(Q) we use a
formula similar to the one of Lemma 2:

X

v∈imp(y0,y1)

Wsum(v, R(Root, v, x1)) − Wsum(v, R(Root, v, x0 − 1)).

(1)

To obtain the tradeoﬀ related to t, we call τ = t log W and store only every
τ -th entry in A, that is, we store partial sums only at the end of blocks of
τ entries of W (v). We lose our ability to compute Wsum(v, i) exactly, but
can only compute it for i values that are at the end of blocks, Wsum(v, τ · i) =
Select(A(v), 1, i+1)−i. To compute each of the terms in the sum of Eq. (1) we
can use Wsum(v, τ ·⌊R(Root, v, x1)/τ⌋)− Wsum(v, τ ·⌈R(Root, v, x0− 1)/τ⌉)
to ﬁnd the sum of the part of the range that covers whole blocks. Then we must
ﬁnd out the remaining (at most) 2τ − 2 values w(pi) that lie at both extremes
of the range, to complete the sum.
In order to ﬁnd out those values, we store the vectors W (v) explicitly at all
the tree nodes v whose height h(v) is a multiple of τ , including the leaves. If a
node v ∈ imp(y0, y1) does not have stored its vector W (v), it can still compute
any w(pi) value by tracking it down for at most τ levels.
As a result, the time to compute a Sum(Q) query is O(τ 2 log n), yet it is
limited to O(τ log2 n) if τ > log n, as at worst we have W (v) represented at the
leaves. The space for the A(v) vectors is at most (|S(v)|/τ )(log W + O(1)) bits,
which adds up to n log n(log W + O(1))/τ bits. On the other hand, the W (v)
vectors add up to n log n(log W )/τ = n(log n)/t bits. This holds for any t even
when we store always the W (v) vectors at the leaves: The space of those W (v)
is not counted because we take for free the space needed to represent all the
values once, as explained.

The average inside Q is computed as Avg(Q) = Sum(Q)/Count(Q), where
the latter is computed with the same structure by just adding up the interval
lengths in imp(y0, y1). To compute variance we use, conceptually, an additional
instance of the same data structure, with values w′(p) = w2(p). Then Var(Q) =
Sum′(Q)/Count(Q) − (Sum(Q)/Count(Q))2, where Sum′ uses the values w′.
Note that in fact we only need to store additional (sampled) bitmaps A′(v)
corresponding to the partial sums of vectors W ′(v) (these bitmaps may need
twice the space of the A(v) bitmaps as they handle values that ﬁt in 2 log W
bits). Explicitly stored vectors W ′(v) are not necessary as they can be emulated
with W (v), and we can also share the same wavelet tree structures and bitmaps.
This extra space ﬁts within the same O(n(log n)/t) bits.

Appendix B shows how to further reduce the constant hidden in the O
notation. This is important because this constant is also associated with the
⌈log W⌉ bits of the weights, that are being omitted from the analysis: In the
case of w′ we have 2⌈log W⌉ bits per point.

4Using constant-time Select structures on their internal bitmap H [OS07].

11

Finite groups. The solution applies to ﬁnite groups (G,⊕,−1 , 0). We store
Wsum(v, i) = w(p0) ⊕ w(p1) ⊕ . . . w(pi), directly using ⌈log |G|⌉ bits per entry.
The terms Wsum(v, i)− Wsum(v, j) of Eq. (1) are replaced by Wsum(v, j)−1⊕
Wsum(v, i).

4.1. Dynamism

A dynamic variant is obtained by using the dynamic wavelet trees of Lemma 5,
a dynamic partial sums data structure instead of A(v), and a dynamic array for
vectors W (v).

Theorem 7. Given n points on a U × U grid, with associated values in [0, W ),
there is a structure that uses n log U (1 + o(1) + 1/t) bits, for any t ≥ 1, that answers 
the queries in Theorem 6 in time O(log U log n(1+min(t log W, log U )t log W
/ log log n)), and supports point insertions/deletions, and value updates, in time
O(log U log n).

Proof. The algorithms on the wavelet tree bitmaps are carried out verbatim,
now on the dynamic data structures of Lemma 5, which add o(n log U ) bits
of space overhead and multiply the times by O(log U/ log log n). This adds
O(min(t log W, log U )t log W log U log n/ log log n) to the query times.

Dynamic arrays to hold the explicit W (v) vectors can be implemented within
|S(v)| log W (1+o(1)) bits, and provide access and indels in time O(log n/ log log n)
[NS10, Lemma 1]. This adds O(t log W log n/ log log n) to the query times, which
is negligible.

For insertions we must insert the new bits at all the levels as in Lemma 5,
which costs O(log U log n/ log log n) time, and also insert the new values in W (v)
at 1+(log U )/(t log W ) levels, which in turn costs time O((1+(log U )/(t log W ))
log n/ log log n) (this is negligible compared to the cost of updating the bitmaps).
Deletions are analogous. To update a value we just delete and reinsert the point.
A structure for dynamic searchable partial sums [MN08] takes n log W +
o(n log W ) bits to store an array of n values, and supports partial sums, as well
as insertions and deletions of values, in time O(log n). Note that we carry out
O(log U ) partial sum operations per query. We also perform O(log U ) updates
when points are inserted/deleted. This adds O(log U log n) time to both query
and update complexities.

Maintaining the sampled partial sums A(v) is the most complicated part.
Upon insertions and deletions we cannot maintain a ﬁxed block size τ . Rather,
we use a technique [GN08] that ensures that the blocks are of length at most
2τ and two consecutive blocks add up to at least τ . This is suﬃcient to ensure
that our space and time complexities hold. The technique does not split or
merge blocks, but it just creates/removes empty blocks, and moves one value to
a neighboring block. All those operations are easily carried out with a constant
number of operations in the dynamic partial sums data structure.

Finally, we need to mark the positions where the blocks start. We can maintain 
the sequence of O(|S(v)|/τ ) block lengths using again a partial sums data
structure [MN08], which takes O((|S(v)|/τ ) log τ ) bits. The starting position

12

of any block is obtained as a partial sum, in time O(log n), and the updates
required when blocks are created or change size are also carried out in time
O(log n). These are all within the same complexities of the partial sum structure 
for A(v).

Finite groups and semigroups. The solution applies to ﬁnite groups (G,⊕,−1 ,
0). The dynamic structure for partial sums [MN08] can be easily converted into
one that stores the local “sum” w(pi)⊕ w(pi+1)⊕ . . . w(pj ) of each subtree containing 
leaves pi, pi+1, . . . pj. The only obstacle in applying it to semigroups is
that we cannot move an element from one block to another in constant time, because 
we have to recalculate the “sum” of a block without the element removed.
This takes time O(τ ), so the update time becomes O(log U (log n + t log W )).

5. Range Minima and Maxima

For the one-dimensional problem there exists a data structure using just
2n + o(n) bits, which answers queries in constant time without accessing the
values [Fis10]. This structure allows for a better space/time tradeoﬀ compared
to range sums.

For the queries that follow we do not need the exact w(p) values, but just
their relative order. So we set up a bitmap V [1, W ] where the values occurring 
in the set are marked. This bitmap can be stored within at most
m log(W/m)+O(m) bits [OS07], where m ≤ min(n, W ) is the number of unique
values. This representation converts between actual value and relative order in
time O(log m), which will be negligible. This way, many complexities will be
expressed in terms of m.

Theorem 8. Given n two-dimensional points with associated values in [0, W ),
the minimum of the point values inside a query rectangle Q = [x0, x1] × [y0, y1],
Min(Q), can be found in time O(min(t log m, log n)t log n), with a structure using 
n log n(1 + 1/t) bits, for any t ≥ 1 and m = min(n, W ). The maximum of
the point values inside a query rectangle Q can be found within the same time
and space bounds.

Proof. We associate to each node v the one-dimensional data structure [Fis10]
corresponding to W (v), which takes 2|W (v)| + o(|W (v)|) bits. This adds up to
2n log n + o(n log n) bits overall. We call Wmin(v, i, j) = arg mini≤s≤j W (v)[s]
the one-dimensional operation. Then we can ﬁnd in constant time the position
of the minimum value inside each v ∈ imp(y0, y1) (without the need to store the
values in the node), and the range minimum is

min

v∈imp(y0,y1)

W (v)[Wmin(v, R(Root, v, x0), R(v, Root, v, x1 + 1) − 1)].

To complete the comparison we need to compute the O(log n) values W (v)[s]
of diﬀerent nodes v. By storing the W (v) vectors of Theorem 6 (in the range
[1, m]) every τ = t log m levels, the time is just O(min(τ, log n) log n) because

13

we have to track down just one point for each v ∈ imp(y0, y1). The space is
3n log n + (n log n log m)/τ = 3n log n + (n log n)/t bits. The second term holds
for any t even when we always store n log m bits at the leaves, because adding
these to the m log(W/m) + O(m) bits used for V , we have the n⌈log W⌉ bits
corresponding to storing the bare values and that are not accounted for in our
space complexities.

To reduce the space further, we split W (v) into blocks of length r and create
a sequence W ′(v), of length |S(v)|/r, where we take the minimum of each block,
W ′(v)[i] = min{W (v)[(i − 1)· r + 1], . . . , W (v)[i · r]}. The one-dimensional data
structures are built over W ′(v), not W (v), and thus the overall space for these
is O((n/r) log n) bits. In exchange, to complete the query we need to ﬁnd the
r values covered by the block where the minimum was found, plus up to 2r − 2
values in the extremes of the range that are not covered by full blocks. The
time is thus O(r min(τ, log n) log n). By setting r = t we obtain the result.

For Max(Q) we use analogous data structures.

Top-k queries in succinct space. We can now solve the top-k query of
Rahul et al. [RGJR11] by iterating over Theorem 8. Let us set r = 1. Once we
identify that the overall minimum is some W (v)[s] from the range W (v)[i, j], we
can ﬁnd the second minimum among the other candidate ranges plus the ranges
W (v)[i, s − 1] and W (v)[s + 1, j]. As this is repeated k times, we pay time
O(τ (k + log n)) to ﬁnd all the minima. A priority queue handling the ranges
will perform k minimum extractions and O(k + log n) insertions, and its size
will be limited to k. So the overall time is O(τ log n + k(τ + log k)) by using a
priority queue with constant insertion time [CMP88]. Using τ = t log m for any
t = ω(1) we obtain time O(t log m log n + kt log m log k) and n log n + o(n log n)
bits of space. The best current linear-space solution [NN12] achieves better time
and linear space, but the constant multiplying the linear space is far from 1.

5.1. Dynamism

We can directly apply the result on semigroups given in Section 4.1. Note
that, while in the static scenario we achieve a better result than for sums, in
the dynamic case the result is slightly worse.

Theorem 9. Given n points on an U × U grid, with associated values in [0, W ),
there is a structure using n log U (1 + o(1) + 1/t) bits, for any t ≥ 1, that answers
the queries in Theorem 8 in time O(log U log n(1+min(t log W, log U )t log W/ log log n)),
and supports point insertions/deletions, and value updates, in time O(log U (log n+
t log W )).

6. Range Majority for Fixed α

In this section we describe a data structure that answers α-majority queries
for the case where α is ﬁxed at construction time. Again, we enrich the wavelet
tree with additional information that is sparsiﬁed. We obtain the following
result.

14

Theorem 10. Given n two-dimensional points with associated values in [0, W )
and a ﬁxed value 0 < α < 1, all the α-majorities inside a query rectangle Q =
[x0, x1]×[y0, y1], Majority(α, Q), can be found in time O(t log m log2 n), with a
structure using n((2 + 1/t) log n+ log m) bits, for any t ≥ 1 and m = min(n, W ).

Proof. We say that a set of values C is a set of α-candidates for S′ ⊂ S if each
α-majority value w of S′ belongs to C. In every wavelet tree node v we store
an auxiliary data structure A(v) that corresponds to elements of W (v). The
data structure A(v) enables us to ﬁnd the set of α-candidates for any range
[r1 · s, r2 · s] in W (v), for a parameter s = t log m. We implement A(v) as a
balanced binary range tree T (v) on W (v). Every leaf of T (v) corresponds to
an interval of W (v) of size s/α. The range of an internal node w of T is the
union of ranges associated with its children. In every such node w, we store
all α-majority values for the range of w (these are at most 1/α values). The
space required by T (v) is (2|W (v)|/(s/α))(1/α) log m = O(|W (v)|/t) bits, which
added over all the wavelet tree nodes v sums to (n log n)/t bits.
Given an interval [r1 · t, r2 · t], we can represent it as a union of O(log n)
ranges for nodes wi ∈ T (v). If a value is an α-majority value for [r1 · t, r2 · t],
then it is an α-majority value for at least one wi. Hence, a candidate set for
[r1 · t, r2 · t] is the union of values stored in wi. The candidate set contains
O((1/α) log n) values and can be found in O((1/α) log n) time.
Moreover, for every value c, we store the grid G(c) of Lemma 2, which
enables us to ﬁnd the total number of elements with value w in any range Q =
[x0, x1]× [y0, x1]. Each G(c), however, needs to have the coordinates mapped to
the rows and columns that contain elements with value c. We store sequences Xc
and Yc giving the value identiﬁers of the points sorted by xand 
y-coordinates,
respectively. By representing them as wavelet trees, they take 2n log m + o(n)
bits of space and map in constant time any range [x0, x1] or [y0, y1] using rank
operations on the sequences, in O(log m) time using the wavelet trees. Then the
local grids, which overall occupy other Pc∈[1,m] nc log nc +o(nc) ≤ n log(n/m)+
o(n) bits, complete the range counting query in time O(log n). So the total space
of these range counting structures is n log n + n log m + o(n).

To solve an α-majority query in a range Q = [x1, x2] × [y1, y2], we visit
each node v ∈ imp(y0, y1). We identify the longest interval [r1 · s, r2 · s] ⊆
[R(Root, v, x0), R(Root, v, x1)]. Using A(v) the candidate values in [r1·s, r2·s]
can be found in time O((1/α) log n). Then we obtain the values of the elements 
in [R(Root, v, x0), r1 · s) and (r2 · s, R(Root, v, x1)], in time O(s log n)
by traversing the wavelet tree. Added over all the v ∈ imp(y0, y1), the cost to
ﬁnd the (1/α + s) log n candidates is O((1/α + s log n) log n). Then their frequencies 
in Q are counted using the grids G(c) in time O((1/α + s) log2 n), and
the α-majorities are ﬁnally identiﬁed.

Thus the overall time is O(t log m log2 n). The space is n(2 log n + log m +
(log n)/t), higher than for the previous problems but less than the structures to
come.

15

A slightly better (but messier) time complexity can be obtained by using
the counting structure of Bose et al. [BHMM09] instead of that of Lemma 2,
storing value identiﬁers every s tree levels, O(t log m log n(min(t log m, log n) +
log n/ log log n)). The space increases by o(n log(n/m)). On the other hand,
by using s = t = 1 we increase the space to O(n log n) integers and reduce the
query time to O(log2 n).

7. Range Median and Quantiles

We compute the median element, or more generally, the k-th smallest value

w(p) in an area Q = [x0, x1]×[y0, y1] (the median corresponds to k = Count(Q)/2).
From now on we use a diﬀerent wavelet tree decomposition, on the universe
[0, m) of w(·) values rather than on y coordinates. This can be seen as a wavelet
tree on grids rather than on sequences: the node v of height h(v) stores a grid
G(v) with the points p ∈ P such that ⌊w(p)/2h(v)⌋ = L(v{..⌈log m⌉ − h(v)}).
Note that each leaf c stores the points p with value w(p) = c.

Theorem 11. Given n two-dimensional points with associated values in [0, W ),
the k-th smallest value of points within a query rectangle Q = [x0, x1] × [y0, y1],
Quantile(k, Q), can be found in time O(ℓ log n logℓ m), with a structure using
n log n logℓ m + O(n log m) bits, for any ℓ ∈ [2, m] and m = min(n, W ).
Proof. We use the wavelet tree on grids just described, representing each grid
G(v) with the structure of Lemma 2. To solve this query we start at root of
the wavelet tree of grids and consider its left child, v. If t = Count(Q) ≥ k
on grid G(v), we continue the search on v. Otherwise we continue the search
on the right child of the root, with parameter k − t. When we arrive at a leaf
corresponding to value c, then c is the k-th smallest value in P ∩ Q.
Notice that we need to reduce the query rectangle to each of the grids G(v)
found in the way. We store the X and Y arrays only for the root grid, which
contains the whole P. For this and each other grid G(v), we store a bitmap
X(v) so that X(v)[i] = b iﬀ the i-th point in x-order is stored at the b-child of v.
Similarly, we store a bitmap Y (v) with the same bits in y-order. Therefore, when
we descend to the b-child of v, for b ∈ {0, 1}, we remap x0 to Rank(X(v), b, x0)
and x1 to Rank(X(v), b, x1 + 1) − 1, and analogously for y0 and y1 with Y (v).
The bitmaps X(v) and Y (v) add up to O(n log m) bits of space. For the
grids, consider that each point in each grid contributes at most log n + o(1)
bits, and each p ∈ P appears in ⌈log m⌉ − 1 grids (as the root grid is not really
necessary).
To reduce space, we store the grids G(v) only every ⌈log ℓ⌉ levels (the bitmaps
X(v) and Y (v) are still stored for all the levels). This gives the promised space.
For the time, the ﬁrst decision on the root requires computing up to ℓ operations
Count(Q), but this gives suﬃcient information to directly descend log ℓ levels.
Thus total time adds up to O(ℓ log n logℓ m).

Again, by replacing our structure of Lemma 2 by Bose et al.’s counting
structure [BHMM09], the time drops to O(ℓ log n logℓ m/ log log n) when using
n log n logℓ m(1 + o(1)) + O(n log m) bits of space.

16

The basic wavelet tree structure allows us to count the number of points p ∈
Q whose values w(p) fall in a given range [w0, w1], within time O(ℓ log n logℓ m)
or O(ℓ log n logℓ m/ log log n). This is another useful operation for data analysis,
and can be obtained with the formula Pv∈imp(w0,w1) Count(Q).
As a curiosity, we have tried, just as done in Sections 4 and 5, to build
a wavelet tree on the y-coordinates and use a one-dimensional data structure.
We used the optimal linear-space structure of Brodal and Jørgensen [BJ09].
However, the result is not competitive with the one we have achieved by building
a wavelet tree on the domain of point values.

8. Range Majority for Variable α

We can solve this problem, where α is speciﬁed at query time, with the same

structure used for Theorem 11.

Theorem 12. The structures of Theorem 11 can compute all the α-majorities
of the point values inside Q, Majority(α, Q), in time O( 1
α ℓ log n logℓ m), where
α can be chosen at query time.
Proof. For α ≥ 1
2 we ﬁnd the median c of Q and then use the leaf c to count
its frequency in Q. If this is more than α · Count(Q), then c is the answer,
else there is no α-majority. For α < 1
2 , we solve the query by probing all the
(i · α)Count(Q)-th elements in Q.

Once again, we attempted to build a wavelet tree on y-coordinates, using
the one-dimensional structure of Durocher et al. [DHM+11] at each level, but
we obtain inferior results.

Culpepper et al. [CNPT10] show how to ﬁnd the mode, and in general the
k most repeated values inside Q, using successively more reﬁned Quantile
queries. Let the k-th most repeated value occur α· Count(Q) times in Q, then
we require at most 4/α quantile queries [CNPT10]. The same result can be
obtained by probing successive values α = 1/2i with Majority(α) queries.

9. Range Successor and Predecessor

The successor (predecessor) of a value w in a rectangle Q = [x0, x1]× [y0, y1]
is the smallest (largest) value larger (smaller) than, or equal to, w in Q. We
also have an eﬃcient solution using our wavelet trees on grids.

Theorem 13. The structures of Theorem 11 can compute the successor and
predecessor of a value w within the values of the points inside Q, Succ(w, Q)
and Pred(w, Q), in time O(ℓ log n logℓ m).

Proof. We consider the nodes v ∈ imp(w, +∞) from left to right, tracking
rectangle Q in the process. The condition for continuing the search below a
node v that is in imp(w, +∞), or is a descendant of one such node, is that
Count(Q) > 0 on G(v). Succ(w, Q) is the value associated with the ﬁrst

17

leaf found by this process. Likewise, Pred(w, Q) is computed by searching
imp(−∞, w) from right to left. To reduce space we store the grids only every 
⌈log ℓ⌉ levels, and thus determining whether a child has a point in Q may
cost up to O(ℓ log n). Yet, as for Theorem 11, the total time amortizes to
O(ℓ log n logℓ m).

Once again, storing one-dimensional data structures [CIK+08, MNU05] on

a y-coordinate-based wavelet tree does not yield competitive results.

10. Dynamism

Our dynamic wavelet tree of Lemma 5 supports range counting and point
insertions/deletions on a ﬁxed grid in time O(log U log n/ log log n) (other tradeoﬀs 
exist [Nek09]). If we likewise assume that our grid is ﬁxed in Theorems 11,
12 and 13, we can also support point insertions and deletions (and thus changing
the value of a point).

Theorem 14. Given n points on a U ×U grid, with associated values in [0, W ),
there is a structure using n log U logℓ W (1 + o(1)) bits, for any ℓ ∈ [2, W ], that
answers the queries Quantile, Succ and Pred in time O(ℓ log U log n logℓ W/
log log n), and the Majority(α) operations in time O( 1
α ℓ log U log n logℓ W/
log log n). It supports point insertions and deletions, and value updates, in time
O(log U log n logℓ W/ log log n).

Proof. We use the data structure of Theorems 11, 12 and 13, modiﬁed as follows.
We build the wavelet tree on the universe [0, W ) and thus do not map the
universe values to rank space. The grids G(v) use the dynamic structure of
Lemma 5, on global y-coordinates [0, U ). We maintain the global array X of
Lemma 5 plus the vectors X(v) of Theorem 11, the latter using dynamic bitmaps
[HM10, NS10]. The time for the queries follows immediately. For updates
we track down the point to insert/delete across the wavelet tree, inserting or
deleting it in each grid G(v) found in the way, and also in the corresponding
vector X(v).

11. Conclusions

We have demonstrated how wavelet trees [GGV03] can be used for solving a
wide range of two-dimensional queries that are useful for various data analysis
activities. Wavelet trees have the virtue of using little space. By enriching them
with further sparsiﬁed data, we support various complex queries in polylogarithmic 
time and linear space, sometimes even succinct. Other more complicated
queries require slightly superlinear space.

We believe this work just opens the door to the possible applications to data
analysis, and that many other queries may be of interest. A prominent one
lacking good solutions is to ﬁnd the mode, that is, the most frequent value, in
a rectangle, and its generalization to the top-k most frequent values. There has

18

been some recent progress on the one-dimensional version [GNP10] and even in
two dimensions [DM11], but the results are far from satisfactory.

Another interesting open problem is how to support dynamism while retaining 
time complexities logarithmic in the number of points and not in the
grid size. This is related to the problem of dynamic wavelet trees, in particular 
supporting insertion and deletion of y-coordinates (on which they build
the partition). Dynamic wavelet trees would also solve many problems in other
areas.

Finally, a natural question is which are the lower bounds that relate the
achievable space and time complexities for the data analysis queries we have
considered. These are well known for the more typical counting and reporting
queries, but not for these less understood ones.

References

References

[ABR00] S. Alstrup, G. Brodal, and T. Rauhe. New data structures for
orthogonal range searching. In Proc. 41st Annual Symposium on
Foundations of Computer Science (FOCS), pages 198–207, 2000.

[AFL07] Amihood Amir, Johannes Fischer, and Moshe Lewenstein. Twodimensional 
range minimum queries. In Proc. 18th Annual Symposium 
on Combinatorial Pattern Matching (CPM), LNCS 4580,
pages 286–294, 2007.

[BCKO08] Mark Berg, Otfried Cheong, Marc Kreveld, and Mark Overmars.
In ComputaOrthogonal 
range searching: Querying a database.
tional Geometry, pages 95–120. Springer, 2008.

[BCN10] J. Barbay, F. Claude, and G. Navarro. Compact rich-functional binary 
relation representations. In Proc. 9th Latin American Symposium 
on Theoretical Informatics (LATIN), LNCS 6034, pages 170–
183, 2010.

[BDR11] Gerth Brodal, Pooya Davoodi, and S. Rao. On space eﬃcient two
dimensional range minimum data structures. Algorithmica, 2011.
DOI 10.1007/s00453-011-9499-0.

[BHMM09] Prosenjit Bose, Meng He, Anil Maheshwari, and Pat Morin. Succinct 
orthogonal range search structures on a grid with applications
to text indexing. In Proc. 11th International Symposium on Algorithms 
and Data Structures (WADS), LNCS 5664, pages 98–109,
2009.

[BJ09] Gerth Brodal and Allan Jørgensen. Data structures for range median 
queries. In Proc. 20th International Symposium on Algorithms
and Computation (ISAAC), LNCS 5878, pages 822–831, 2009.

19

[BLNS10] N. Brisaboa, M. Luaces, G. Navarro, and D. Seco. A fun application
of compact data structures to indexing geographic data. In Proc.
5th International Conference on Fun with Algorithms (FUN), LNCS
6099, pages 77–88, 2010.

[BT11] G. Brodal and K. Tsakalidis. Dynamic planar range maxima
queries. In Proc. 38th International Colloquium on Automata, Languages 
and Programming (ICALP), pages 256–267, 2011.

[CGL79] T. Chan, G. Golub, and R. LeVeque. Updating formulae and a pairwise 
algorithm for computing sample variances. Technical Report
STAN-CS-79-773, Dept. of CS, Stanford Univ., 1979.

[Cha88] B. Chazelle. A functional approach to data structures and its
use in multidimensional searching. SIAM Journal on Computing,
17(3):427–462, 1988.

[CIK+08] M. Crochemore, C. S. Iliopoulos, M. Kubica, M. Rahman, and
T. Walen. Improved algorithms for the range next value problem
and applications. In Proc. 25th Symposium on Theoretical Aspects
of Computer Science (STACS), pages 205–216, 2008.

[CLP11] T. M. Chan, K. Larsen, and M. Pˇatra¸scu. Orthogonal range searching 
on the RAM, revisited. In Proc. 27th Annual Symposium on
Computational Geometry (SoCG), pages 1–10, 2011.

[CMP88] S. Carlsson, J. I. Munro, and P. V. Poblete. An implicit binomial 
queue with constant insertion time. In Proc. 1st Scandinavian
Workshop on Algorithmic Theory (SWAT), pages 1–13, 1988.

[CNPT10] S. Culpepper, G. Navarro, S. Puglisi, and A. Turpin. Top-k ranked
document search in general text databases. In Proc. 18th Annual
European Symposium on Algorithms (ESA), LNCS 6347, pages 194–
205 (part II), 2010.

[DHM+11] Stephane Durocher, Meng He, Ian Munro, Patrick Nicholson, and
Matthew Skala. Range majority in constant time and linear space.
In Proc. 38th International Colloquium on Automata, Languages
and Programming (ICALP), pages 244–255, 2011.

[DM11] Stephane Durocher and Jason Morrison. Linear-space data structures 
for range mode query in arrays. CoRR, 1101.4068, 2011.

[Fis10] J. Fischer. Optimal succinctness for range minimum queries.

In
Proc. 9th Latin American Symposium on Theoretical Informatics
(LATIN), LNCS 6034, pages 158–169, 2010.

[GGG+07] A. Golynski, R. Grossi, A. Gupta, R. Raman, and S. Srinivasa
Rao. On the size of succinct indices. In Proc. 15th Annual European
Symposium on Algorithms (ESA), LNCS 4698, pages 371–382, 2007.

20

[GGV03] R. Grossi, A. Gupta, and J. Vitter. High-order entropy-compressed
text indexes. In 14th Annual ACM-SIAM Symposium on Discrete
Algorithms (SODA), pages 841–850, 2003.

[GHMN11] Travis Gagie, Meng He, J. Munro, and Patrick Nicholson. Finding
frequent elements in compressed 2d arrays and strings.
In Proc.
18th International Symposium on String Processing and Information 
Retrieval (SPIRE), LNCS 7024, pages 295–300, 2011.

[GN08] R. Gonz´alez and G. Navarro. Rank/select on dynamic compressed 
sequences and applications. Theoretical Computer Science,
410:4414–4422, 2008.

[GNP10] T. Gagie, G. Navarro, and S. Puglisi. Colored range queries and document 
retrieval. In Proc. 17th International Symposium on String
Processing and Information Retrieval (SPIRE), pages 67–81, 2010.

[GNP11] T. Gagie, G. Navarro, and S.J. Puglisi. New algorithms on wavelet
trees and applications to information retrieval. Theoretical Computer 
Science, 2011. To appear.

[GPT09] T. Gagie, S.J. Puglisi, and A. Turpin. Range quantile queries: another 
virtue of wavelet trees. In Proc. 16th International Symposium
on String Processing and Information Retrieval (SPIRE), pages 1–
6, 2009.

[HM10] M. He and I. Munro. Succinct representations of dynamic strings.
In Proc. 17th International Symposium on String Processing and
Information Retrieval (SPIRE), pages 334–346, 2010.

[KN08] Marek Karpinski and Yakov Nekrich. Searching for frequent colors
in rectangles. In Proc. 20th Canadian Conference on Computational
Geometry (CCCG), 2008.

[MN07] V. M¨akinen and G. Navarro. Rank and select revisited and extended.
 Theoretical Computer Science, 387(3):332–347, 2007.

[MN08] V. M¨akinen and G. Navarro. Dynamic entropy-compressed sequences 
and full-text indexes. ACM Transactions on Algorithms,
4(3):art. 32, 2008.

[MNU05] V. M¨akinen, G. Navarro, and E. Ukkonen. Transposition invariant

string matching. J. Alg., 56(2):124–153, 2005.

[Mun86] J. I. Munro. An implicit data structure supporting insertion, deletion,
 and search in O(log n) time. Journal of Computer Sysstems
Science, 33(1):66–74, 1986.

[Nek09] Y. Nekrich. Orthogonal range searching in linear and almostlinear 
space. Computational Geometry Theory and Applications,
42(4):342–351, 2009.

21

[NN12] G. Navarro and Y. Nekrich. Top-k document retrieval in optimal
time and linear space. In Proc. 23rd Annual ACM-SIAM Symposium 
on Discrete Algorithms (SODA), 2012. To appear.

[NS10] G. Navarro and K. Sadakane. Fully-functional static and dynamic

succinct trees. CoRR, 0905.0768v5, 2010.

[OS07] D. Okanohara and K. Sadakane. Practical entropy-compressed
rank/select dictionary. In Proc. Workshop on Algorithm Engineering 
and Experiments (ALENEX), 2007.

[PT06] M. Patrascu and M. Thorup. Time-space trade-oﬀs for predecessor
search. In Proc. 38th ACM Symposium on Theory of Computing
(STOC), pages 232–240, 2006.

[P˘07] M. P˘atra¸scu. Lower bounds for 2-dimensional range counting.
In Proc. 39th Annual ACM Symposium on Theory of Computing
(STOC), pages 40–46, 2007.

[RGJR11] Saladi Rahul, Prosenjit Gupta, Ravi Janardan, and K. Rajan. Efﬁcient 
top-k queries for orthogonal ranges.
In Proc. 5th International 
Workshop on Algorithms and Computation (WALCOM),
LNCS 6552, pages 110–121, 2011.

[Wel62] B. P. Welford. Note on a method for calculating corrected sums of

squares and products. Technometrics, 4(3):pp. 419–420, 1962.

[Wil85] D.E. Willard. New data structures for orthogonal range queries.

SIAM Journal on Computing, 14(232-253), 1985.

Appendix A. Optimal-Space Representation of Grids

We analyze the representation described in Section 2.1, showing how it can
be made near-optimal in the information-theoretic sense. Recall that our representation 
of a set of points of [0, U )2 consists in storing two sorted arrays X
and Y , which reduce the [0, U ) values to [0, n). The points in the [0, n) × [0, n)
grid have exactly one point per row and one per column.
An optimal-space representation of the above data uses the data structure of
Okanohara and Sadakane [OS07] for mapping the sorted X coordinates (where
point X(i) is represented as a bit set at position i + X(i) in a bitmap of length
n + U ), a similar structure for the Y coordinates, and a wavelet tree for the grid
of mapped points. The former occupues n log n+U
n (cid:1) + O(n)
bits of space, gives constant-time access to the real coordinate of any point
X(i) = select1(i) − i, and takes O(log U+n
n ) time to map any value x to rank
space at query time; and similarly for Y . The wavelet tree requires n log n +
o(n) = log n! + O(n) bits. Overall, if we ignore the O(n)-bit redundancies, the

n + O(n) = log(cid:0)U+n

total space is log(cid:16)n!(cid:0)U+n
n (cid:1)

2(cid:17) bits.

22

2

Hence our representation can be in any of n!(cid:0)U+n
n (cid:1)

conﬁgurations. Note
that we can represent repeated points, which is useful in some cases, especially 
when they can have associated values. We show now that our number
of conﬁgurations is not much more than the number of possible conﬁgurations
of P even if repeated points are forbidden, i.e., n distinct points from [0, U )2
can be in (cid:0)U 2
n! conﬁgurations. The diﬀerence is not so large because 
(cid:0)U+n
n (cid:1)
In terms of bits this means that
n (cid:1) + log n! ≤ log(cid:0)U 2
2 log(cid:0)U+n
n (cid:1) + n log c and therefore our representation is at
most O(n) bits larger than an optimal representation, aside from the O(n) bits
we are already wasting with respect to log(cid:16)n!(cid:0)U+n

n (cid:1)2
n (cid:1) ≤ (cid:0)U+n
n! ≤ (cid:0)U 2
n (cid:1)cn, for any c ≥ 4.

n (cid:1)2(cid:17).

2

2

n (cid:1)cn.

To see this, notice that (cid:0)U+n
n! = ((U +n)!/(n!U !))2n! = ((U +n)!/U !)2/n! =
n (cid:1)
i=0 (U + n− i)2)/n!. For suﬃciently large c, this is ≤ (Qn−1
(Qn−1
i=0 c(U 2 − i))/n! =
cnU 2!/((U 2 − n)!n!) = (cid:0)U 2
We need c ≥ (U + n − i)2/(U 2 − i) for any 0 ≤ i < n. We next show that,
if n ≤ U , then (U + n)2/U 2 ≥ (U + n − i)2/(U 2 − i), and thus it is enough to
choose c ≥ (U + n)2/U 2. Simple algebra shows that the condition is equivalent
to i ≤ 2(U + n) − (1 + (n/U ))2. Since we assume for now that n/U ≤ 1, the
inequality is satisﬁed if i ≤ 2(U + n) − 4. Since i < n, the inequality always
holds (as U, n ≥ 1). Thus it is suﬃcient that c ≥ (U + n)2/U 2, which is no
larger than 4 if n ≤ U .
Let us now consider the case n > U . Our analysis still holds, up large enough
n. Since i ≤ n − 1, it is suﬃcient that n − 1 ≤ 2(U + n) − (1 + (n/U ))2. Simple
algebra shows this is equivalent to the cubic inequality 2U 3+nU 2−2nU−n2 ≥ 0.
As a function of U this function has three roots, the only positive one at U = √n.
Therefore it is positive for U ≥ √n, i.e., n ≤ U 2, which covers all the possible

values of n.

Appendix B. Reducing Space for Variance

We now discuss how to bring the 2⌈log W⌉ space factor associated to storing
weights w′(p) = w(p)2 closer to ⌈log V ⌉, where V is the overall variance.
Instead of storing w′(p), we can store w′′(p) = (w(p) − ⌈T /n⌉)2, where T /n
is the average of all the points. To obtain Var(Q) from the sum of the w′′ in
Q notice that (w(p) − (TQ/q))2 = (w(p) − ⌈T /n⌉)2 − 2(w(p) − ⌈T /n⌉)(⌈T /n⌉ −
(TQ/q)) + ((T /n) − (TQ/q))2, where TQ = Sum(Q) and q = Count(Q). This
formula makes use of the stored w′′(p) values, as well as queries Sum(Q) and
Count(Q). Note that rounding is used to keep the values as integers, hence
limiting the number of bits necessary in its representation.

To avoid numeric instability and wasted space, it is better that T /n is close
to Tq/q. This simultaneously yields smaller (w(p)−⌈T /n⌉)2 values and reduces
the (⌈T /n⌉−(TQ/q)) factor in the subtraction. To ensure this we may (logically)
partition the space and use the local average, instead of the global one. Each
level of the wavelet tree partitions the space into horizontal non-overlapping

23

bands, of the form [j · n/2k, (j + 1) · n/2k), for some k. At every level we
use the average of the band in question. This allows us to compute variances
for rectangles whose y coordinates are aligned with the bands, while the x
coordinates are not restricted. For a general rectangle Q we decompose it into
band-aligned rectangles, just as with any other query on the wavelet tree (recall
Equation (1)). Alternatively, we can use a variance update formula [CGL79,
Wel62] that is stable and further reduces the instability of the ﬁrst calculation.
We rewrite the update formula of Chan et al. [CGL79] in terms of sets, since
originally it was formulated in one dimension.

Lemma 15 ([CGL79, Eq. 2.1]). Given two disjoint sets A and B, which have
values w(p) associated with element p, where TA = Sum(A), TB = Sum(B),
m = Count(A), n = Count(B), SA = Pp∈A(w(p) − TA/m)2 and SB =
Pp∈B(w(p) − TB/n)2, the following equalities hold:

TA S B = TA + TB

SA S B = SA + SB +

m

n(m + n)

(

n
m

TA − TB)2

(B.1)

(B.2)

Notice that Var(A) = SA.

24

