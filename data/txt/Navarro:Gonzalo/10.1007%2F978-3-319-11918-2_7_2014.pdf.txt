Eﬃcient Indexing and Representation of Web

Access Logs(cid:2)

Francisco Claude1, Roberto Konow1,2, and Gonzalo Navarro2

1 Escuela de Inform´atica y Telecomunicaciones, Universidad Diego Portales

fclaude@recoded.cl

2 Department of Computer Science, University of Chile

{rkonow,gnavarro}@dcc.uchile.cl

Abstract. We present a space-eﬃcient data structure, based on the
Burrows-Wheeler Transform, especially designed to handle web sequence
logs, which are needed by web usage mining processes. Our index is
able to process a set of operations eﬃciently, while at the same time
maintains the original information in compressed form. Results show
that web access logs can be represented using 0.85 to 1.03 times their
original (plain) size, while executing most of the operations within a few
tens of microseconds.

1

Introduction

Web Usage Mining (WUM) [14] is the process of extracting useful information
from web server access logs, which allows web site administrators, designers and
engineers to understand the users’ interaction with their web site. This process
is used to improve the layout of the web site to better suit their users, or to
analyze the performance of their systems in order to apply smart prefetching
techniques for faster response, among other applications.

One particular WUM task is to predict the path of web pages that the user
is going to traverse within a website. Accurately predicting the web user access
behavior can minimize the user perception of latency, which is an important
measure of the website quality of service [5,6,28]. This is achieved by fetching the
web page before the user requests it. Another application is as a recommendation
technique [19, 29]: the prediction can be displayed to the user, giving an insight
of what the user might be looking for, therefore improving the user’s experience.
Other relevant mining operations include determining how frequently the path
has been followed, which users have followed the path, and so on.

The prediction problem can be formalized as follows. Access logs obtained
from web servers are used to extract the user’s web site visit path as an ordered

sequence of web pages Su = (cid:2)v1, v2, v3, . . . , vm(cid:3) (several sessions of the same

user u might be concatenated into Su). Therefore the system records the set

(cid:2) This work was partially supported by the Conicyt PhD Scholarship, by Fondecyt Ini-
ciaci´on Grant 11130104, and by Millennium Nucleus Information and Coordination
in Networks ICM/FIC P10-024F.

E. Moura and M. Crochemore (Eds.): SPIRE 2014, LNCS 8799, pp. 65–76, 2014.
c(cid:2) Springer International Publishing Switzerland 2014

66

F. Claude, R. Konow, and G. Navarro

S = {S1, S2, . . . , Sn} of the accesses of each user. Given a new visit sequence

(or path) P that is currently being performed by a user, the predicting task has
to predict which page will be visited next. One n¨aive approach to this problem
is to ﬁrst return the k web pages that have been visited most commonly by
users after following the same path P , that is, we consider each time P appears
as a substring of some Su, and pick the most common symbols following those
occurrences of P . After this process is done, more complex recommendation
or machine learning algorithms [16] can be employed to accurately predict the
next web page that is going to be visited. One particular challenge is that this
operation needs to be done in an on-line manner, that is, we have to eﬃciently
update our results as new requests are appended at the end of P . The system
to the corresponding Su sequences in S,
will eventually add those requests S
via periodic updates. At query time, the set S can be taken as static. The other
mining operations are deﬁned analogously.

(cid:3)

Another interesting operation coming from WUM and general data mining is
to retrieve the top-k most frequent sequences [12, 22] of a certain length. These
are commonly used in retailing, add-on sales, customer satisfaction and in many
other ﬁelds.

A typical WUM system faces two challenges: On the one hand, it has to
manage huge amounts of data, that comes directly from the web access logs that
store the records of all the interactions between the web server and the users.
With the increasing amount of users and content on the Internet, handling this
amount of data is a non-trivial task. On the other hand it has to provide accurate
results. This is usually performed via a two stage process [16]: The ﬁrst stage is
a fast and simple ﬁltration procedure that returns few hundreds or thousands of
candidates from possibly millions of alternatives. During the second stage, more
complex data mining techniques are performed to reduce the preliminary results
to just a few high-quality results. In this paper we focus on improving the space
consumption and time to perform queries on the web access sequences obtained
from the web server logs used during the ﬁrst step, thus freeing resources for the
second stage and therefore increasing the performance of the process.

We present a space-eﬃcient data structure in the Word-RAM model for representing 
web access logs, based on the Burrows-Wheeler Transform (BWT) [2].
Our index is able to eﬃciently process various queries of interest, while representing 
the data in compressed form. In this paper we focus on the following key
operations; others are described in the Conclusions.

– Access(u, i) : Access the i-th web page visited by user u.
– UserPath(u) : Return the complete path done by user u.
– Count (P ) : Count how many times path P has been performed in the collection.


– MostCommonNextPage(P, k) : Return the k most common web pages visited

after path P .

– ListUsers(P, k) : Return k distinct users that have followed path P .
– MostFrequentPath(k, q) : Return the k most frequent paths of length q done

by the users.

Eﬃcient Indexing and Representation of Web Access Logs

67

Our experimental results show that our index is able to represent the web access 
logs using 0.85–1.03 of their plain representations, thereby replacing them
by a representation that uses about the same space but eﬃciently answers various 
queries, within microseconds in most cases. Our index can be easily deployed
in other types of applications that handle ordered sequences, such as GPS trajectories,
 stock price series, customer buying history, and so on.

To our knowledge, this is the ﬁrst compressed representation of logs that

answers queries speciﬁc of WUM applications.

2 Basic Concepts

2.1 Rank and Select

Two basic operations used as building blocks for space-eﬃcient data structures
are rank and select. Given a bitmap B of length n, rankb(i) computes the
number of bits b up to position i. The operation selectb(j) retrieves the position
where the j-th bit b appears. Munro [17] and Clark [3] obtained constant-time
solutions for both operations while using o(n) bits of space on top of B. Raman
et al. [23] managed to compress the space to nH0(B) + o(n) bits1 while still
supporting both operations in constant time.

The wavelet tree [11] of a sequence S of length n over an alphabet of size σ
extends the results for rank and select to general sequences, by decomposing
the sequence hierarchically alphabet-wise in the form of a balanced tree. Internal
nodes Tv store a binary string Bv. The root contains n bits, one per symbol in
the sequence, and they are set to 0 or 1, depending on whether the corresponding
symbol of S belongs to the lower or higher half of the alphabet. The left/right
subtree is built for the subsequence of elements that have a 0/1 on the root.
This decomposition continues, halving the alphabet, until the leaves, which correspond 
to a single symbol. All bitvectors are processed to handle binary rank
and select queries in O(1) time. This data structure accesses any S[x] and solves
rankb(S, x) and selectb(S, x) in O(lg σ) time, using n lg σ(1 + o(1)) bits (which
is close to the space a plain representation of S would require).

2.2 Range Minimum Queries

A range minimum query asks for the position of the minimum element in a
given range (i, j) of an integer array A of length n, that is, RM QA(i, j) =
argmini≤k≤jA[k]. This query can be solved in constant time [8], after building
a Cartesian tree over the array, convert it into a general tree using the usual
bijection, and representing the general tree with a compact tree representation
[27] that answers lowest common ancestor (lca) and other queries in constant
time. This data structure requires 2n + o(n) bits.
The Cartesian tree of array A[1, n] is a binary tree whose root corresponds to
the minimum position i in A, its left child is the Cartesian tree of A[1, i − 1],
and its right child is the Cartesian tree of A[i + 1, n].

1 H0(B) is the zero-order entropy of the bitmap B.

68

F. Claude, R. Konow, and G. Navarro

2.3 Burrows-Wheeler Transform and the SSA Index

The Succinct Suﬃx Array (SSA) [20] is a compressed index that builds on the
Burrows-Wheeler transform (BWT) of a text [2]. The main idea is to represent
the BWT of a text T in compressed space and support pattern matching.

Given a text T of length N , ending with a unique symbol $ smaller than
the rest, the BWT corresponds to a permutation of the symbols in T that is
reversible. A simple way to describe the transformation is to imagine the N × N
matrix of the N cyclic rotations of the text T , sort the rows lexicographically,
and then keep the last column of the matrix, L[1, N ] = BW T (T ). The ﬁrst
column, formed by all the characters of T in order, is called F [1, N ]. Note that
any F [i] is preceded by L[i] in T .

It has been shown [15] that local compressors tend to handle the BWT of
a text much better than the text itself, since the transformation tends to cluster 
together occurrences of the same symbol. This is not surprising, since the
symbols are actually arranged according to their context (symbols appearing
after it). An interesting operation that allows to support the ones we are interested 
in is known as the LF -mapping. LF (i) tells where does L[i] appear in
F [i], this way allowing us to retrieve the text that precedes it in T in backward 
form: L[i], L[L[i]], and so on. The LF operation can be computed as
LF (i) = rankc(BW T (T ), i) + occ[c], where occ[c] corresponds to the number of
symbols lexicographically smaller than c in T . By representing BW T (T ) with
a wavelet tree [11], the LF operation takes O(lg σ) time, the same as accessing
any position in BW T (T ).

The backward search operation [7] returns in O(m lg σ) time the range L[sp, ep]
from where all the occurrences of a given pattern P of length m can be located. It
is called backward search since its procedure seeks the pattern in reverse order.
Backward search is suﬃcient to compute the number of occurrences of P , as
ep − sp + 1; this procedure is called count.

A Succinct Suﬃx Array (SSA) enhances the BWT representation with a sampling 
of some suﬃx array entries. This sampling is used to locate the actual
positions where P occurs in T from the range L[sp, ep]. Given a sampling factor 
sa, which requires O((N/sa) lg N ) further bits of space, the SSA locates the
position in T of any of the ep − sp + 1 occurrences of P in O(sa lg σ) time.
With a similar sampling, the SSA can also extract any desired substring T [l, r]
in O((sa + r − l) lg σ) time. By choosing any sa = ω(lgσ N ), the SSA index can
be represented using N Hk(T ) + o(N lg σ) bits of space, where N Hk(T ) is the
k-th order entropy of the text T .

3

Indexing Web Access Sequences

3.1 Construction

We start by concatenating all ordered web access sequences S = {S1, S2, . . . , Sn}
from all users into a sequence T (S) of size N =
|Si| over an alphabet of
size σ, where σ is the amount of distinct web pages visited by any user in the

(cid:2)n

i=1

Eﬃcient Indexing and Representation of Web Access Logs

69

log ﬁle. Instead of building the BW T to index T (S), we construct the index
over T (S)R , that is, T (S) has each Si reversed. This simple trick allows us to
maintain a range of elements that match the sequence of requests so far, while
performing backward search, and thus allowing us to add new arriving requests
by just performing one more step. Having the BWT of T (S)R is not enough to
reconstruct the information from the log. We also need to store the user identiﬁer
associated with each position in the sequence. To do so without spending N lg n
bits to associate a user id to each position in the BWT of T (S)R, we construct
a bitmap B of length N and mark with a 1 the positions where each Si ends
in T (S)R. We later index B to solve rank and select queries in constant time
using compressed space [23]. This is enough to obtain the user associated to a
location in the BWT of the sequence, by locating its original position p in the
sequence and then performing rank1(B, p).

For listing the distinct users (strings) where path P occurs, we implement
Muthukrishnan’s document listing algorithm [18], as compressed by Sadakane

[26]. We construct a temporary array U [i] = rank1(B, i), for 1 ≤ i ≤ N , that
stores the user ids and then permute the values so that the ids are aligned to
the BW T (T (S)R) sequence. Another integer array C is constructed by setting
C[i] = selectU[i](U, rankU[i](U, i)− 1)2 for all 0 ≤ i ≤ N , and then build a RMQ

data structure on C. We keep this structure and discard C and U .

The RMQ data structure requires 2N + o(N ) bits. The SSA index requires
N Hk(T (S)) + o(N lg σ) bits. The representation of bitmap B takes H0(B) +
o(N ) ≤ N + o(N ) bits. Note that we do not store the users, nor the frequencies
in an explicit way.

3.2 Queries

Access(u, i). To obtain the i-th web page visited by user u within the sequence,
we need to locate the position in the original sequence T (S)R where the user’s
session begins. We can do this by computing p = select1(B, u + 1) − 1 − i and
then applying extract T (S)R[p, p] on the SSA index, in O(sa lg σ) time.

UserPath(u). To obtain the path done by user u, we compute p1 = select1(B, u)
and p2 = select1(B, u + 1) − 1 and then extract T (S)R[p1, p2] using the SSA index.
 This takes O(((cid:4) + sa) lg σ) time, where (cid:4) = p2 − p1 is the length of the

extracted path.

Count(P ). Given a path P of length m we can count its occurrences, by just
performing Count(P ) on the SSA index in O(m lg σ) time.

MostCommonNextPage(P, k). We describe this operation incrementally.
Assume we have already processed the sequence of requests P = r1, r2, . . . , rm−1.
Our invariant is that we know the interval [sp, ep] corresponding to path P , and
2 To avoid corner cases, we deﬁne selectU [i](U, 0) = −1.

70

F. Claude, R. Konow, and G. Navarro

a
0

a
0

b
0

c
0

a
0

d
0

$
0

a
1

b
0

c
0

d
0

a
0

$
0

a
1

a
0

a
0

b
0

c
0

d
0

a
0

$
0

a
1

a
0

a
0

$
0

0
1

a
4
0

a
3
-2

a
2
-3

d
1
-4

a
4
1

d
3
2

d
2
3

a
4
5

$
3
6

0

$
2
7

a
1
4

a
3
9

a
1
12

a
3
13

$
1
14

c
1
16

a
1
17

a
3
15

a
2
11

b
1
18

b
3
19

b
2
20

a
1
21

c
3
22

c
2
23

T (S)R
B

BWT

U
C

a
1

$
4
-1

RMQ

Fig. 1. Layout of our index organization using example sequences: S1 = dacbaaa, S2 =
adcba, S3 = adcbaaa and S4 = aaa. The dollar ($) symbol is used to represent the end
of each sequence and the zero symbol is used to mark the end of the concatenation of
the sequences T (S)R. At the bottom we show the topology of the Cartesian tree built
over the C array representing the RMQ data structure. Recall that arrays U and C
are not represented and are only shown for guidance.

this is suﬃcient to answer query MostCommonNextPage(P, k). Now a new request 
rm arrives at the end of P . Then we proceed as follows:
1. Update the range [sp, ep] in BW T (T (S)) using rm, in O(lg σ) time [7].
2. Retrieve the k most frequent symbols in BW T [sp, ep], which are precisely
those preceding the occurrences of P R in T (S)R, or following P in T (S).
The second step is done with the heuristic proposed by Culpepper et al. [4] to
retrieve the k most frequent symbols in a range of a sequence represented with
a wavelet tree. It is a greedy algorithm that starts at the wavelet tree root and
maps the range (in constant time, using rank on the bitmap of the wavelet tree
node) to its children, until reaching the leaves. The traversal is prioritized by
visiting the longest ranges ﬁrst, and reporting the symbols corresponding to the
ﬁrst k leaves found in the process. The worst-case performance of this algorithm
is bounded by the number of diﬀerent symbols present in the string range. This
is smaller than both σ and the size of the range. By using more sophisticated
data structures (that nevertheless do not add much space) [13, 21], a worst case
of O(k + polylog n) time can be guaranteed. Note that, if we want to list all
the request that have followed P , we can use an optimal algorithm based on
depth-ﬁrst traversal of the wavelet tree [9].

ListUsers(P, k). To list k (or all) distinct users that have followed path P we
ﬁrst locate the starting and ending points [sp, ep] for the given path, using the

Eﬃcient Indexing and Representation of Web Access Logs

71

SSA index in O(m lg σ) time (we can also proceed incrementally as in operation
MostCommonNextPage). Then we apply the optimal document listing algorihtm
[18, 26]. Each value C[p] < sp, for sp ≤ p ≤ ep, signals a distinct value of U [p]
in U [sp, ep]. Recall that we do not have C or U anymore, but the procedure for
extracting the list of users can be emulated with the RMQ data structure over
array C and the bitmap B. The procedure for extracting the list of all users
works as shown in Algorithm 1. Function locate takes a position in the BWT
and maps it to the corresponding position in the original T (S)R, in O(sa lg σ)
time. Listing k distinct users for path P takes O((k · sa + p) lg σ) time.

Fig. 1 shows an example of listing users. The framed region represents the
range sp, ep. Red nodes in the RMQ tree represent the position of the retrieved
users, while the blue node represents the last visited node before returning.
Algorithm 1. – UserListing(sp, ep, users = ∅)
p ← RM QC(sp, ep)
if ep < sp then
return users

end if
u ← rank1(B, locate(p))
if u (cid:3)∈ users then

users ← users ∪ u
UserListing (sp, p − 1, users)
UserListing (p + 1, ep, users)

end if

MostFrequentPath(k, q). We want to retrieve the k most frequent paths of
a certain length q done by the users in the system. We start by pushing into a
priority queue all ranges obtained by performing a backward-search of paths of
length 1 for each possible symbol (σ at most). Now, we extract the biggest range
from the priority queue as well as the path that created that range. We execute
the same procedure again, creating new paths by appending to the extracted
path one further symbol (trying the σ possible ones in the worst case) and we
push the ranges obtained by performing the backward search on these new paths
into the priority queue. When we extract a path of length q, we report it and
remove it from the priority queue. The procedure ends when k paths are reported
or when the priority queue is empty. In the worst case, this operation can take
O(σq).

This method may perform poorly when the alphabet σ is large. An optimization 
is to avoid trying out all the σ characters to extend the current path, but
just those symbols that do appear in the current range. Those are found by
traversing the wavelet tree from the root towards all the leaves that contain
some symbol in the current range [9].

4 Experiments and Results

Setup and Implementations. We used dedicated server with 16 processors
Intel Xeon E5-2609 at 2.4GHz, with 256 GB of RAM and 10 MB of cache.

72

F. Claude, R. Konow, and G. Navarro

Table 1. Space usage, in bytes, of the data structures used in our index. Plain corresponds 
to the sum of the space usage of plain representations of the sequence and users.
Ratio corresponds to the total index size divided by the plain representation size.

Data Structure Msnbc Kosarak
SSA
3,175,504 12,500,964
1,770,690 2,807,570
RMQ
608,044
Users Bitmap
5,554,246 16,086,346 124,618,994
Total
Plain
5,782,495 18,884,286 120,613,202
0,96
Ratio

Spanish
75,667,016
39,538,238
9,413,732

777,804

0,85

1,03

The operating system is Linux with kernel 3.11.0-15 64 bits. We used g++
compiler version 4.8.1 with full optimizations (-O3) ﬂags.

We implemented the SSA index using the public available wavelet tree implementation 
obtained from libcds (http://www.github.com/fclaude/libcds)
and developed the heuristic proposed by Culpepper et al. [4] on top of that
implementation. The wavelet tree needed for the SSA index uses a RRR [23]
compressed bitmap representation. The bitmap B needed to retrieve the users
is used in plain form [10]. We implemented the RMQ data structure based on
compact tree representations [1], which in practice requires 2.38n bits. Our implementation 
is available at https://gitlab.com/fclaude/wum-index/.

Experimental Data. We used web access sequences from the public available
Msnbc, Kosarak, and Spanish datasets. The Msnbc dataset comes from Internet
Information Services log ﬁles of msnbc.com for a complete day of September, 28
of 1999. It contains web access sequences from 989, 818 users with an average
of 5.7 web page categories visits per sequence, the alphabet size of this dataset
is σ = 17. The Kosarak dataset contains the click-stream data obtained from a
Hungarian on-line news portal. It contains sequences of 990, 000 users with an
average of 8.1 web page visits per sequence and an alphabet size σ = 41, 270.
Finally, the Spanish dataset contains the visitors’ click-stream obtained from
a Spanish on-line news portal during September 2012. This dataset consists of
9, 606, 228 sequences of news-categories that were visited, with an average of 12.3
categories visited per sequence and an alphabet size of σ = 42.

Space Usage. Table 1 shows the space usage of each data structure for each
dataset. Row “Plain” shows the space required to represent the original sequence
T (S)R using an array of N lg σ bits plus an array to represent the users using
n lg N bits. The table shows that our index is able to compress the sequence
by up to 15%, on the Kosarak dataset, while requiring only 3% extra space at
most, on the Spanish dataset. Within this space, we are able to support the
aforementioned operations, while at the same time can reconstruct the original
sequence and the users information.

Eﬃcient Indexing and Representation of Web Access Logs

73

s
d
n
o
c
e
s
o
r
c
i

M

 
.

g
v
A

 140
 120
 100
 80
 60
 40
 20
 0

Access User Sequence

Msnbc
Kosarak
Spanish

 10  20  30  40  50  60  70  80  90  100

Sequence length

 

l
o
b
m
y
S
d
e
t
c
a
r
t
x
E
 
r
e
p
 
s
d
n
o
c
e
s
o
r
c
i

M

 
.

g
v
A

 35

 30

 25

 20

 15

 10

 5

 0

Extract User Path

Msnbc
Kosarak
Spanish

 10  20  30  40  50  60  70  80  90  100

Sequence length

Fig. 2. On the left, average microseconds to perform Access (u, i); on the right, average
microseconds per extracted symbol for the operation UserPath (u)

We evaluated alternatives to the SSA, such as the Compressed Suﬃx Array
(CSA) [24] and the Compressed Suﬃx Tree (CST) [25], using the ones provided
by the sdsl-lite library (https://github.com/simongog/sdsl-lite). Table 2
compares their space usage to our SSA at representing the sequence. The SSA is
a better choice in this case, using up to 33% less space than the others. The CST
could be used to compute some of the operations, since it is naturally a faster
alternative. In fact, we evaluated this alternative for counting the occurrences
of a sequence, and it is in practice four to twenty times faster than the SSA.
We discarded it since the space requirement makes it unpractical for massive
datasets. In fact, the CST needs to be augmented in order to support all the
operations presented in this paper, which would increase its memory usage.

Time Performance. To evaluate the main operations using our proposed data
structure, we generate query paths by choosing uniformly at random a position
in the original sequences, and then extracting a path of the desired length.

Fig. 2 (left) shows the time to access positions chosen uniformly at random
from users whose traversal log has length 1 to 100. The time does not depend
on the length, but directly on sa lg σ. Fig. 2 (right) shows the time per symbol
extracted, when we access the whole sequence associated with a user. We can see
that for users with short interactions the SSA sampling has a greater eﬀect, and
this is amortized when accessing longer sequences, that is, the term O(sa lg σ)
is spread among more extracted symbols and the time converges to lg σ.

Table 2. Comparison of the space consumption of the SSA, CSA, and CST for representing 
sequence T (S)R. We show the ratio of each index space over the plain representation 
of the sequence without the user’s information by using N lg σ bits.

Data Structure Msnbc Kosarak Spanish
SSA
CSA
CST

1,08
1,61
3,82

0,77
0,87
1,43

0,85
1,13
2,96

74

F. Claude, R. Konow, and G. Navarro

Count Path Occurrences

Most Common Next Visit, varying k, p=5

s
d
n
o
c
e
s
o
r
c
i

M

 
.

g
v
A

 250

 200

 150

 100

 50

 0

Msnbc
Kosarak
Spanish

 4

 8  12  16  20  24  28  32  36  40

Sequence length

s
d
n
o
c
e
s
o
r
c
i

M

 
.

g
v
A

 1000

 100

 10

 1

Msnbc
Kosarak
Spanish

 1

 2

 4

 8  16  32  64  128 256 512 1024

k

Fig. 3. On the left, average microseconds to perform Count (P ); on the right, average
microseconds for the MostFrequentPath operation with varying k using patterns of ﬁxed
length p = 5

s
d
n
o
c
e
s
o
r
c
i

M

 
.

g
v
A

 1000

 800

 600

 400

 200

 0

List Distinct Users

Top-10 Most Common Path of Length q

Msnbc
Kosarak
Spanish

 4

 8  12  16  20  24  28  32  36  40

Sequence length

y
r
e
u
Q

 
r
e
p
 
s
d
n
o
c
e
s
i
l
l
i

M

 1e+06

 100000

 10000

 1000

 100

 10

 1

Msnbc
Kosarak
Spanish

 4

 8  12  16  20  24  28  32  36  40

q

Fig. 4. On the left, average microseconds to list distinct users that traversed paths
with varying lengths. On the right, the time required to perform top-10 most common
path operation for varying pattern lengths.

We then measured the time to count the number of times a certain path
appears in the access sequence. Fig. 3 (left) shows the time per query. As expected,
 it grows linearly with the length of the path being counted, and the lg σ
term determines the slope of the line. On Fig. 3 (right) we show the results for
the MostCommonNextPage operation. The x-axis and y-axis are in log scale.
For datasets containing small alphabets such as Msnbc (σ = 17) and Spanish
(σ = 42) this operation is performed in under 30 microseconds for all possible 
values of k (note it is impossible to obtain more than σ distinct symbols),
and shows a logarithmic behavior. We also note that the slope of the logarithm
depends on the value of σ, as shown in the Kosarak dataset. The operation,
however, is still reasonably fast, taking less than 1 millisecond for k = 1024.

Fig. 4 (left) shows the time for retrieving the set of users that followed a given
access pattern in the system. For shorter sequences, the index has to retrieve a
bigger set of users, as these sequences are more likely to appear. As the sequences
grow in length, the time decreases, since the resulting set is also smaller. The
behavior for Kosarak, which after a certain point starts increasing in time per
query, can be explained by the fact that determining the range [sp, ep] grows

Eﬃcient Indexing and Representation of Web Access Logs

75

linearly with the length of the pattern, and at some point it dominates the
query time. This is also expected, at a later point, for Msnbc and Spanish.

query

time

for

4

shows

the

(right)

Finally, Fig.

operation
MostFrequentPath(k, q). Our ﬁrst implementation tried following all symbols at
every step of the algorithm. This worked quite well for small alphabets but had
a very bad performance on the Kosarak dataset. This plot shows the implementation 
traversing the wavelet tree at each step to only follow symbols that do
appear in the range. This gives a slightly worse performance for small alphabets,
but a considerable speedup (1–2 orders of magnitude) for larger ones.

5 Discussion and Future Work

We introduced a new data structure for handling web access sequences in compressed 
form that fully replaces the original dataset and also supports useful
operations for typical WUM processes. Our experiments show that our index
uses about the same size of the plain representation of the data, and within this
space supports various relevant operations within tens of microseconds. This is
competitive; consider that in most common scenarios the systems have to reply
over a network, which have considerable latency and transfer time. Ours is the
ﬁrst compressed representation tailored for this scenario.

We have not yet fully explored other possible operations of interest in log
mining that can be supported with our arrangements. For example, we can count
the number of users that followed some path in constant time using 2n + o(n)
bits using document counting [26], compute the k users that have followed a
path most frequently using top-k document retrieval [13], and others.

Our index can be easily adapted to custom scenarios by adding satellite information,
 such as duration of the visit, actions (buy, login/logout, comment, etc.),
browser information, location, and others, to each event in the log and include
the information by mapping it to the BW T transform for later processing. This
enables our index to be applied in other scenarios involving ordered sequences,
such as GPS trajectories, stock price series, customer buying history, and so on.

References

1. Arroyuelo, D., C´anovas, R., Navarro, G., Sadakane, K.: Succinct trees in practice.

In: Proc. 11th ALENEX, pp. 84–97 (2010)

2. Burrows, M., Wheeler, D.J.: A block-sorting lossless data compression algorithm.

Tech. rep., Digital Equipment Corporation (1994)

3. Clark, D.: Compact Pat Trees. Ph.D. thesis, Univ. of Waterloo, Canada (1996)
4. Culpepper, J.S., Navarro, G., Puglisi, S.J., Turpin, A.: Top-k ranked document
search in general text databases. In: de Berg, M., Meyer, U. (eds.) ESA 2010, Part
II. LNCS, vol. 6347, pp. 194–205. Springer, Heidelberg (2010)

5. Dom`enech, J., Gil, J.A., Sahuquillo, J., Pont, A.: Web prefetching performance

metrics: A survey. Perform. Eval. 63(9), 988–1004 (2006)

6. Dongshan, X., Junyi, S.: A new markov model for web access prediction. Computing 
in Science and Eng. 4(6), 34–39 (2002)

76

F. Claude, R. Konow, and G. Navarro

7. Ferragina, P., Manzini, G.: Indexing compressed texts. J. ACM 52(4), 552–581

(2005)

8. Fischer, J., Heun, V.: Space-eﬃcient preprocessing schemes for range minimum

queries on static arrays. SIAM J. Comp. 40(2), 465–492 (2011)

9. Gagie, T., Navarro, G., Puglisi, S.: New algorithms on wavelet trees and applications 
to information retrieval. Theor. Comp. Sci. 426-427, 25–41 (2012)

10. Gonz´alez, R., Grabowski, S., M¨akinen, V., Navarro, G.: Practical implementation

of rank and select queries. In: Proc. Posters 4th WEA, pp. 27–38 (2005)

11. Grossi, R., Gupta, A., Vitter, J.S.: High-order entropy-compressed text indexes.

In: Proc. 14th SODA, pp. 841–850 (2003)

12. Han, J., Cheng, H., Xin, D., Yan, X.: Frequent pattern mining: current status and

future directions. Data Mining Knowl. Disc. 15(1), 55–86 (2007)

13. Hon, W.K., Shah, R., Vitter, J.: Space-eﬃcient framework for top-k string retrieval

problems. In: Proc. 50th FOCS, pp. 713–722 (2009)

14. Hussain, T., Asghar, S., Masood, N.: Web usage mining: A survey on preprocessing

of web log ﬁle. In: Proc. ICIET, pp. 1–6 (2010)

15. Manzini, G.: An analysis of the Burrows-Wheeler transform. J. ACM 48(3),

407–430 (2001)

16. Mobasher, B.: Data mining for web personalization. In: Brusilovsky, P., Kobsa,
A., Nejdl, W. (eds.) Adaptive Web 2007. LNCS, vol. 4321, pp. 90–135. Springer,
Heidelberg (2007)

17. Munro, J.I.: Tables. In: Chandru, V., Vinay, V. (eds.) FSTTCS 1996. LNCS,

vol. 1180, pp. 37–42. Springer, Heidelberg (1996)

18. Muthukrishnan, S.: Eﬃcient algorithms for document retrieval problems. In: Proc.

13th SODA, pp. 657–666 (2002)

19. Nadi, S., Saraee, M., Davarpanah-Jazi, M.: A fuzzy recommender system for dynamic 
prediction of user’s behavior. In: Proc. ICITST, pp. 1–5 (2010)

20. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Comp. Surv. 39(1)

(2007)

21. Navarro, G., Valenzuela, D.: Space-eﬃcient top-k document retrieval. In: Klasing,

R. (ed.) SEA 2012. LNCS, vol. 7276, pp. 307–319. Springer, Heidelberg (2012)

22. Pei, J., Han, J., Mortazavi-Asl, B., Zhu, H.: Mining access patterns eﬃciently
from web logs. In: Terano, T., Liu, H., Chen, A.L.P. (eds.) PAKDD 2000. LNCS,
vol. 1805, pp. 396–407. Springer, Heidelberg (2000)

23. Raman, R., Raman, V., Rao, S.: Succinct indexable dictionaries with applications
to encoding k-ary trees, preﬁx sums and multisets. ACM Trans. Alg. 3(4), art. 43
(2007)

24. Sadakane, K.: New text indexing functionalities of the compressed suﬃx arrays. J.

Alg. 48(2), 294–313 (2003)

25. Sadakane, K.: Compressed suﬃx trees with full

functionality. Theor. Comp.

Sys. 41(4), 589–607 (2007)

26. Sadakane, K.: Succinct data structures for ﬂexible text retrieval systems. J. Discr.

Alg. 5(1), 12–22 (2007)

27. Sadakane, K., Navarro, G.: Fully-functional succinct trees. In: Proc. 21st SODA,

pp. 134–149 (2010)

28. Su, Z., Yang, Q., Lu, Y., Zhang, H.: Whatnext: A prediction system for web requests 
using n-gram sequence models. In: Proc. 1st WISE, pp. 214–224 (2000)

29. Sumathi, C., Valli, R.P., Santhanam, T.: Automatic recommendation of web pages

in web usage mining. Intl. J. Comp. Sci. Eng. 2, 3046–3052 (2010)

