A Lempel-Ziv Compressed Structure

for Document Listing(cid:4)

H´ector Ferrada and Gonzalo Navarro

Department of Computer Science, University of Chile

{hferrada,gnavarro}@dcc.uchile.cl

Abstract. Document listing is the problem of preprocessing a set of
sequences, called documents, so that later, given a short string called the
pattern, we retrieve the documents where the pattern appears. While
optimal-time and linear-space solutions exist, the current emphasis is
in reducing the space requirements. Current document listing solutions
build on compressed suﬃx arrays. This paper is the ﬁrst attempt to solve
the problem using a Lempel-Ziv compressed index of the text collections.
We show that the resulting solution is very fast to output most of the
resulting documents, taking more time for the ﬁnal ones. This makes
this index particularly useful for interactive scenarios or when listing
some documents is suﬃcient. Yet, it also oﬀers a competitive space/time
tradeoﬀ when returning the full answers.

1

Introduction

The classical Information Retrieval (IR) problems aimed at natural language
text collections can be naturally generalized to general sequence collections. Such
general document retrieval problems are of interest in various areas like bioinformatics,
 multimedia databases, software repositories, and so on [17]. Moreover, IR
on Oriental languages like Chinese and Korean also regards the texts as general
sequences, since inverted indexes do not handle well those languages.

In this paper we focus on the simplest document retrieval problem, called document 
listing. Given D documents, which are strings d1 . . . dD over an alphabet
of size σ, each terminated with a special symbol $, we preprocess them to build
an index. Later, given a pattern p[1, m] over the same alphabet, we must list the
ndoc documents where p appears.

(cid:4) |di| is the total length of the

Muthukrishnan [15] solved this problem in optimal time O(m + ndoc), using

an index of O(n) words of space, where n =
documents. This space usage, albeit linear, is very large in practice. Much subsequent 
research focused on reducing the space requirements. One research line
[23,8,7,19] achieved about O(m + ndoc lg D) time and |CSA| + n lg D + O(n) bits
of space, where CSA is a compressed suﬃx array [18] of T . The CSA has a space
close to that of the compressed text and can replace it. They achieve in practice
fast document listing, but the extra space n lg D is still considerable. A second

The original version of this chapter was 
corrected. The Erratum to this chapter is available at DOI:
(cid:2) Partially funded by Fondecyt grant 1-110066, Chile.
O. Kurland, M. Lewenstein, and E. Porat (Eds.): SPIRE 2013, LNCS 8214, pp. 116–128, 2013.
c(cid:2) Springer-Verlag Berlin Heidelberg 2013

10.1007/978-3-319-02432-5 33

 The copyright line was incorrect. This has been

re iv eds

:

A Lempel-Ziv Compressed Structure for Document Listing

117

research line [22,11] reduced the space to |CSA| + o(n) bits, but with the higher
listing time O(m + ndoc lg1+ε n).

In this paper we propose a novel alternative, which obtains low time and low
extra space. We build on the idea of the LZ-index [16,1] so as to produce a
document listing index that is small thanks to LZ78 compression, whereas it
can list the documents fast. While the theoretical upper bounds we can prove,
5|LZ78| + O(n lg2 σ/ lg n) bits (where |LZ78| ≈ |CSA| is the size of the LZ78compressed 
text) and O(m2 lg n + ndoc m lg2 n) time, are not too good, they are
overly pessimistic. Indeed, a good part of the occurrences are listed in O(1) time
each. We show that the index is very fast to list those ﬁrst occurrences (which
usually form most of the output), becoming slower to output the ﬁnal ones. This
makes it ideal for interactive scenarios, where one wishes to show some results
to the user as fast as possible, and there is much more time to produce further
results while the user browses the ﬁrst ones. Another scenario is when only a
partial or approximate answer is suﬃcient, that is, when one simply wants to ﬁnd
several documents where the pattern appears. However, the index also oﬀers a
very competitive space/time combination when returning the full set of answers.

2 Related Work

Muthukrishnan [15] solved the document listing problem in optimal time O(m +
ndoc), using an index of O(n) words of space. Let T [1, n] be the concatenation
of the D documents. Let A[1, n] be the suﬃx array [13] of T . Muthukrishnan
deﬁned the so-called document array E[1, n], where E[i] is the identiﬁer of the
document containing the suﬃx A[i]. A new array C[1, n] is deﬁned over E as
C[i] = max{1 ≤ k < i, E[k] = E[i]} ∪ {0}, that is, the position of the previous 
occurrence of E[i] in E, or 0 if there is no previous occurrence. Array C is
then preprocessed for range minimum queries (RMQs), which are of the form
rmqC(i, j) = argmini≤k≤j C[k], that is, it gives the position of the minimum
value in C[i, j]. RMQs can be solved in constant time after a linear-time preprocessing 
(see, e.g., [6]). Once the interval A[sp, ep] of the suﬃxes starting with
p is determined, the problem becomes that of listing the distinct values in the
interval E[sp, ep]. The interval is found in time O(m) using a suﬃx tree [24]. The
ndoc distinct values are listed in time O(ndoc) using the observation that the
ﬁrst occurrence E[k] of each distinct value in E[sp, ep] satisﬁes C[k] < sp. Then
the process recursively ﬁnds the smallest values of C[sp, ep]: It ﬁrst computes
k = rmqC (sp, ep) and reports E[k], then it continues recursively with C[sp, k−1]
and C[k + 1, ep]. The recursion stops at any branch where C[k] ≥ sp.

While this solution is time-optimal, it requires much space, O(n lg n) bits.
Subsequent work has focused on reducing the space, giving away the optimality.
V¨alim¨aki and M¨akinen [23] proposed a low-space implementation of Muthukr-
ishnan’s structure. They used a 2n+o(n) bit, constant time RMQ succinct index
[6] that still required access to C. They showed that access to C can be implemented 
by rank and select queries on E, where rankc(E, i) is the number of
occurrences of symbol c in E[1, i] and selectc(E, j) is the position in E of the

118

H. Ferrada and G. Navarro

jth occurrence of c. Then it holds C[i] = selectE[i](E, rankE[i](E, i − 1)) if we
assume that selectc(E, 0) = 0. By representing E with a multiary wavelet tree
[5,9], the space is n lg D + o(n) bits and the operations are carried out in time
O(1 + lg D/ lg lg n). Finally, the suﬃx tree is replaced by a compressed suﬃx
array (CSA), of which there are many choices [18]. A recent one [3] requires

|CSA| = nHk(T ) + o(nHk(T )) + O(n) bits of space and ﬁnds the interval [sp, ep]
in time ttsearch(m) = O(m). A slightly smaller one [2] reaches |CSA| = nHk(T ) +
o(nHk(T )) + o(n) bits and ttsearch = O(m lg lg σ). Here Hk(T ) is the empirical
kth order entropy of T [12]. Overall, their solution requires |CSA| + n lg D + O(n)
bits and solves the problem in time O(ttsearch(m) + ndoc(1 + lg D/ lg lg n)).

Gagie et al. [8,7] showed that a wavelet tree [10] can be used for document
listing without any need of RMQs, but just a DFS traversal. Their index can
use |CSA| + n lg D + o(n) bits and their document listing time is O(ttsearch(m) +
ndoc lg(D/ndoc)). Navarro et al. [19] achieved nearly 50% compression of the
wavelet tree in practice, at the price of nearly doubling the time required (these
wavelet-tree based indices also solve more complex queries).

Sadakane [22] initiated another line based on the idea of Muthukrishnan, but
avoiding the large n lg D-bit term in the space. He replaced the RMQ solution
by a constant-time one that does not need access to C. His structure needed
4n + o(n) bits, but more recent ones [6] require 2n + o(n) bits. The other use for
C is to determine where to stop the recursion. Sadakane used instead a bitmap
V [1, D] where the already reported documents are marked. Once a branch of the
recursion attempts to report a marked document, it is pruned. Finally, array E
is only needed to list the document identiﬁers. This is done with a bit vector
B[1, n] that marks the positions in T where the documents start; then it holds
E[k] = rank1(B, A[k]). Value A[k] is computed by the CSA, for example in
time O(lg1+ε n) for any constant ε > 0 [2,3]. Bitmap B can be represented in
D lg(n/D) + O(D) + o(n) bits with rank queries supported in constant time [20].
Overall, the data structure requires only |CSA|+2n+D lg(n/D)+O(D)+o(n) =
|CSA| + O(n) bits and O(ttsearch(m) + ndoc lg1+ε n) time. Hon et al. [11] achieved
a further reduction to |CSA| + D lg(n/D) + O(D) + o(n) bits, within the same
asymptotic time, by running the RMQs over blocks of lgε n cells (see Navarro
[17] for comments on the correctness of this solution).

As it can be seen, all the approaches build on the suﬃx array. Our new
approach uses instead the LZ-index, a compressed text index not based on suﬃx
arrays but on the LZ78 compression [25] of the text.

3 The LZ-Index

The algorithm LZ78 builds a dictionary of phrases (text substrings), with the
aim of replacing strings by pointers to their previous occurrences in the text.
(cid:3)
The dictionary grows as the text is processed, and the result is a sequence of n
(cid:3) ≤ n/ lgσ n). The phrases are formed by scanning the text
distinct phrases (n
left to right. In each step, the method ﬁnds the longest preﬁx of the remaining
text that is a phrase of the dictionary. It then creates a new phrase formed by

A Lempel-Ziv Compressed Structure for Document Listing

119

the phrase found plus the symbol following it in the remaining text. This is
represented by a pointer to the dictionary and the extra character. The number
of bits output by the compressor is |LZ78| = n
(lg n + lg σ) ≤ n Hk(T ) + o(n lg σ)
for k = o(lgσ n) [12]. The LZ-index [16] is a compressed text index built on the
LZ78 parsing of the text, and it supports locating the occurrences of a pattern
p[1, m] in T . The index is formed by the following components.

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

+ne ≤ 2n

1. LZTrie: a trie composed of all the phrases produced by the LZ78 parsing.
Note that the set of phrases is preﬁx-closed (the preﬁx of a phrase is also a
phrase), so LZTrie has n
nodes. It stores the phrase identiﬁers of each node.
2. RevTrie: a trie storing the reversed phrases. It is not preﬁx-closed, so there
are empty nodes not associated to phrases. We collapse unary paths of empty
nodes. The trie has nrev = n
nodes, where ne empty nodes remain
after collapsing. The phrase numbers of the n
nonempty nodes are stored.
3. Node: an array mapping from phrase numbers to their preorder in LZTrie.
4. Range: an n
grid where the rows represent the phrases and the columns
the reverse phrases, both in lexicographic order. If the (k + 1)th text phrase
is at row i and the kth at column j, then there is a point at (i, j) in the grid.
Thus the LZ-index uses 4|LZ78|(1 + o(1)) bits of space. To search for the occurrences 
of pattern p[1, m] we divide them into three classes: (1) those completely
inside a phrase, (2) those spanning two phrases, (3) those spanning 3 phrases or
more. Those are found separately.

(cid:3)×n

(cid:3)

(cid:3)

– Type 1. Search for pr (the reversed pattern) in RevTrie, arriving at node vr.
Each node ur descending from vr (including vr) corresponds to an occurrence
of type 1 where p appears at the end of the phrase. The other occurrences of
that descend from u in LZTrie, where u corresponds
type 1 are the nodes u
to ur. Thus, for each node ur that is nonempty, we read the phrase id fu of
ur, compute u = Node(fu), and report all the phrase ids in the subtree of u.
This takes O(m + occ1) time, reporting the occ1 occurrences of type 1. See
Fig. 1, ignoring for now Doclz, Docrev, and LDocrev.
– Type 2. Partition p = pstart · pend in the m−1 possible ways, searching for
pr
start in RevTrie and for pend in LZTrie. The subtrees found deﬁne column
and row ranges in the grid Range, and each point in the range is a type 2
occurrence. The phrase identiﬁers are obtained from those stored in LZTrie
using the rows of the reported points. Using a linear-space geometric data
structure, the total time is O(m2) for the m searches in LZTrie and RevTrie,
O(m lg n) for the m range searches, and O(occ2 lg n) for reporting the occ2
points found.

– Type 3. Since phrases are unique, each p[i, j] equal to a phrase leads to
at most one occurrence of type 3. We search LZTrie incrementally for the
O(m2) pattern substrings p[i, j] and ﬁnd their phrase ids, if any. Then we
ﬁnd concatenations of consecutive phrases that together form a maximal
substring p[i, j] = bk . . . bl. Finally, we check if the phrases bk−1 and bl+1
are equal to the strings p[1, i−1] and p[j+1, m], respectively. For the second
we check that the subtree of phrase p[j+1, m] in LZTrie contains Node(l+1).

120

H. Ferrada and G. Navarro

For the ﬁrst we check if the column range of the node for p[1, i−1]r in
RevTrie has a point at row Node(k), corresponding to LZTrie (the m searches
in RevTrie are computed once). Thus these occurrences require O(m2 lg n)
time [1].

The total search time for the occ occurrences is O(m2 lg n + occ lg n).

Wavelet Trees. The geometric data structure we use in practice is a wavelet
tree [10]. It is a pefect binary tree where the points are sorted in row order at
the root and in column order in the bottom. The coordinates are not explicitly
stored. At the root, a bitmap marks with a 0 or a 1 whether each point belongs
to the left or right half of the grid, respectively. Those on the left/right side of
the grid are then recursively subdivided at the left/right child of the root node.
The wavelet tree uses in total n

bits.

lg n

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

] × [j, j

the new interval [rank0/1(B, i − 1) + 1, rank0/1(B, i

To support range searches, the bitmaps are enhanced with rank/select data
structures. Both can be computed in constant time and o(n
) extra bits [14]. To
] (rows × columns), we start with B[i, i
(cid:3)
ﬁnd the points in a range [i, i
]
in the root bitmap, and project the interval to the left/right children, towards
)]. We continue splitting
the interval, stopping when it becomes empty, or the wavelet tree node has no
intersection with the columns [j, j
]. In the last
case, all the values in the current bitmap interval are points in the range. They
can be counted directly, or reported one by one by tracking them to the leaves, to
(cid:3)
know their column values, for example. As any range is decomposed into O(lg n
)
wavelet tree nodes that have in total O(lg n
) ancestors, counting the points in
the range takes O(lg n
) time.

) time and reporting each of them requires O(lg n

], or it is fully included in [j, j

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

4 A Novel LZ-Index Based Document Listing Structure

We now adapt the LZ-index to carry out document listing instead of reporting
all the occurrences of a pattern p. The general search strategy will be as follows.
For occurrences of type 1, we store the RMQ of the expansion of RevTrie with
the subtree of LZTrie that corresponds to each node. This requires O(n) bits
and allows us to apply Muthukrishnan’s algorithm [22] directly. For type 2, we
enhance the bitmaps of the wavelet tree of Range with RMQ data structures for
their documents. We can then apply Muthukrishnan’s algorithm on any of the
O(lg n
) nodes into which the range is decomposed. For occurrences of type 3 we
ﬁnd their documents one by one. The total time will be O(m2 lg n+ndoc m lg2 n).

(cid:3)

Structure. We modify the LZ78 parsing so that no phrase crosses a document
boundary. Now consider the LZTrie and RevTrie structures of the original LZindex 
resulting from this parsing. We store the following structures.

– RevTrie. We represent only the topology and the letters of RevTrie and
LZTrie, just in order to be able to navigate RevTrie and to search it for
lg σ +
patterns in constant time per symbol [1]. The structure requires 3n
O(n
) bits. (In the implementation we do not represent LZTrie, but all the
nodes of RevTrie, which in the worst case can be n but in practice are not.)

(cid:3)

(cid:3)

A Lempel-Ziv Compressed Structure for Document Listing

121

Fig. 1. Our structures for occurrences of type 1

(cid:3)

– Doc. Let us deﬁne Doclz, the sequence of n

document identiﬁers of the
(cid:3)(cid:7)lg D(cid:8) bits.
LZTrie phrases in preorder. We save Doclz explicitly with n
This is equivalent to the document array [15], but restricted to phrases.
Now we deﬁne Docrev, a sequence of n document identiﬁers built as follows.
We traverse RevTrie in preorder, and for each phrase node vr, let v be the
corresponding LZTrie node. Let Doclz[lv, rv] be the range in Doclz of all the
descendants of v (included). We append Doclz[lv, rv] to Docrev. Docrev will
not be stored, but just its RMQ structure, so as to run Muthukrishnan’s
algorithm [15] over Docrev. This RMQ structure answers queries in O(1)
time without accessing Docrev and uses 2n + o(n) bits [6].1 Finally we store
a bitmap LDocrev[1, n], which marks the Docrev positions where the intervals
(cid:3)(cid:7)lg D(cid:8)+3n+o(n) bits. Fig. 1 illustrates.
Doclz[lv, rv] start. In total we store n
– Node. Now this is a mapping from RevTrie to LZTrie. If the node vr in
RevTrie with nonempty preorder i corresponds to the node v in LZTrie with
preorder j, then Node[i] = j. Array Node uses n

(cid:3)(cid:8) bits.

(cid:3)(cid:7)lg n

– Range. An enhanced binary wavelet tree. Each wavelet tree node implicitly
represents a sequence of points. Now consider the array of their corresponding 
documents. We store, in addition to the bitmap, the RMQ structure
corresponding to Muthukrishnan’s algorithm [15] on its (virtual) array of
documents. The total space of Range is then 3n
(cid:3)

(cid:3)
lg n
)+3n+o(n) ≤
(cid:3)
5nHk(T ) + 3n + o(n lg σ) bits (and ≤ 4nHk(T ) + 3n + o(n lg σ) if lg D = o(lg n)).

Overall, our structure requires 4n

lg σ+o(n

lg D+3n

) bits.

lg n

+n

lg n

+ o(n

(cid:3)

lg n

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

This is close to the original LZ-index size [16]. We describe the document listing
procedure now.
Type 1 Occurrences. We search for p[1, m]r in RevTrie, arriving at node v
with preorder jv. We ﬁnd the interval I = Docrev[sv, ev] containing all the occurrences 
of type 1, where sv = select1(LDocrev, jv) and ev = select1(LDocrev, jv +
subtree-size(jv)) − 1. Next, we report all the distinct documents in I with
1 The length is n because n is the internal path length (sum of all node depths) in
LZTrie. Each LZTrie node is appended to Docrev once per ancestor it has in LZTrie.

122

H. Ferrada and G. Navarro

Muthukrishnan’s algorithm using RMQs. For each new position Docrev[pos] reported 
by an RMQ, we determine the nonempty preorder j = rank1(LDocrev,
pos) of the RevTrie node holding that position, and the preorder of this node in
LZTrie, i = Node[j]. The diﬀerence d = pos − select1(LDocrev, j) provides the

]. To ﬁnd the LZTrie interval we do as follows. We search RevTrie for pr

oﬀset of this position within the leaf interval of the LZTrie node with preorder
i. Thus, the document is Doclz[i + d]. The time is O(m + ndoc1), where ndoc1 is
the number of distinct documents containing at least one occurrence of type 1.
Type 2 Occurrences. We consider all the m−1 partitions p = pstart·pend. For
start, arriving at node vr with preorder interval
each one, we search RevTrie for pr
[j, j
end. If
it does not exist, or it leads to an empty node, then pend is not a phrase and there
are no phrases starting with pend (as phrases are built incrementally letter by
letter). If instead we reach node ur, with nonempty preorder t, then i = Node[t] is
the LZTrie preorder of the corresponding node u, which represents pend. It is also
the left end of the preorder interval of the descendants of u. We compute the size
of the interval using LDocrev: (cid:4) = select1(LDocrev, t + 1) − select1(LDocrev, t),

= i + (cid:4) − 1 and the row interval for the search in Range is [i, i
(cid:3)

) wavelet tree nodes that cover the interval 
[j, j
] is projected on their bitmaps. Each
of these O(lg n
) intervals represent documents with occurrences of type 2, and
we list the documents in each by running Muthukrishnan’s algorithm over the
RMQ structures that enhance the bitmaps. For each document, which is found
in O(1) time, we need O(lg n
) time to reach the corresponding leaf and ﬁnd its
identiﬁer in Doclz. Although unlikely, in the worst case we can output the same
) intervals for each of the m−1 partitions, which
document in each of the O(lg n
gives O(m2) time for the RevTrie searches plus a (very pessimistic) worst-case
bound of O(ndoc2 m lg2 n

) time for the ndoc2 occurrences of type 2.

Now we identify in Range the O(lg n

], and the ranges where interval [i, i

(cid:3)

then i

(cid:3)

(cid:3)

(cid:3)

].

(cid:3)

(cid:3)

(cid:3)

(cid:3)

(cid:3)

Type 3 Occurrences. We wish to apply the same algorithm of the original
LZindex and then output the documents, yet we have fewer data structures now.
First, all the searches for all the substrings p[i, j] are carried out in RevTrie, in
time O(m2), and we record the RevTrie and LZTrie preorder values of each
(the latter using Node from the RevTrie node). For each i, we store in array Ai
the information for the substrings of the form p[i, j], sorted by LZTrie preorder
value. Now note that we have not stored phrase numbers, yet we can still use
Range to determine the LZTrie preorder t of the phrase following that of p[i, j],
which has RevTrie preorder tr. If we traverse the wavelet tree of Range starting
at position tr in the root bitmap and track it to the leaves, the ﬁnal position is
) time. Now we can binary search Aj+1
precisely t. This operation takes O(lg n
(cid:3)
for LZTrie preorder t, and if we ﬁnd it corresponding to a phrase p[j + 1, j
],
we can concatenate p[i, j] to get p[i, j
]. Therefore we can carry out the same
process for ﬁnding maximal concatenations [16], in total time O(m2 lg n).
Finally, we have to check if p[1..i− 1] precedes the maximal concatenation and
if p[j + 1, m] follows it. The ﬁrst question is equivalent to computing whether the
preorder interval for p[1..i−1]r in RevTrie is connected with the LZTrie preorder
value t of the ﬁrst phrase in the maximal concatenation. The second question

(cid:3)

(cid:3)

A Lempel-Ziv Compressed Structure for Document Listing

123

corresponds to computing the LZTrie preorder interval of p[j + 1, m] (which can
be done using RevTrie, as before) and then asking if the RevTrie preorder value
tr of the last phrase in the maximal concatenation is connected with some point
in the LZTrie interval. These tests add up O(m lg n) time.

This adds up to the promised total time of O(m2 lg n + ndoc m lg2 n). Note,
however, that the occurrences of type 1 are reported very early, in time O(m +
ndoc1). If the text is generated by an ergodic source, the occurrences of any
pattern p appear regularly, every d positions on average (e.g., d = σm if the
symbols are generated uniformly and independently). On the other hand, since
(cid:3) ≤ n/ lgσ n, only O((n/d)m/ lgσ n) of those occurrences hit a phrase boundary
n
on average. This means that that a fraction of 1− O(m/ lgσ n) of the occurrences
are of type 1, and also ndoc2 = O(ndoc m/ lgσ n) = o(ndoc) if m = o(lgσ n). Thus
we report almost all of the occurrences in O(1) time each. If we just lose those
o(ndoc) occurrences not of type 1, our time is the optimal O(m+ndoc)! We show
in the next section that, indeed, our index is particularly competitive to show
the ﬁrst occurrences (those of type 1), which are the most for short patterns.

5 Experimental Results

We consider the following document collections, following previous work [19].

– ClueChin: A 2.3 MB sample of ClueWeb09 (boston.lti.cs.cmu.edu/Data/

clueweb09), formed by 23 Web pages in Chinese.

– ClueWiki: A 141 MB sample of ClueWeb09, formed by 3,334 Web pages

from the English Wikipedia (same source as the previous).

– KGS: A 75 MB collection of 18,838 sgf-formatted Go game records from year

2009 (www.u-go.net/gamerecords).

– Proteins: A 60 MB collection formed by 143,244 sequences of Human and

Mouse proteins (www.ebi.ac.uk/swissprot).

Our machine is an Intel Xeon with 8 processors of 2.4GHz and 12MB cache,
with 96GB RAM. It runs Linux 2.6.32-46-server, and we use gcc with full optimization.
 We choose 40,000 patterns of lengths m = 3 and m = 8 extracted
randomly from the collection.

Table 1 gives the space obtained by our LZ-Index structure on those collections.
 ClueWiki and KGS are the most compressible ones, reaching 11–12 bpc,
whereas ClueChin and Proteins are the least compressible ones. All are, as
roughly expected from the space analysis, 4.3–5.3×|LZ78|. We show how |LZ78|
, and how it roughly coincides with the output size of Compress,
relates to n/n
a classical LZW Unix compressor.

(cid:3)

In the more compressible collections, RevTrie uses less than 20% of the space,
Doc uses slightly more than 30%, Node slightly more than 10%, and Range uses
almost 40%. The distribution varies a bit on the less compressible collections,
where the fraction of Node and Range increases, reaching 50%. Note that component 
Range can be omitted if we only want to list the occurrences of type 1,
in which case the index size is reduced by 40%–50%.

124

H. Ferrada and G. Navarro

Table 1. Space breakdown of the main components of our LZ-Index based structure.
The numbers are in bpc. Main components are in bold and their space is the sum
of the second-level components (bpc in italics). The percentages are w.r.t. the total
LZ-Index size, whose line indicates its ratio over |LZ78|. The |LZ78| line, in turn, gives
(cid:2)
also (n/n

). The last line gives the bpc of a real LZ78-like compression program.

(15%)

(22%)

ClueChin
2.429
0.396
1.793
0.240
3.594
0.638
2.331
0.625
2.424
7.938

(16%)

(33%)

ClueWiki
1.725
0.182
1.396
0.147
3.529
0.696
2.336
0.497
1.335
4.279

(9%)

(25%)

KGS
2.091
0.247
1.613
0.231
3.864
1.002
2.360
0.502
1.403
4.423

(18%)

Proteins
2.154
0.461
1.530
0.163
5.777
2.788
2.348
0.641
(12%)
3.717
(37%) 11.748

(33%)

Component
RevTrie

Doc

topology
labels
empty nodes

Doclz
Docrev RMQ
LDocrev

Node
(16%)
Range
(50%)
Total LZ-Index (/|LZ78|) 16.386 (4.27×) 10.870 (5.21×) 11.831 (5.35×) 23.550 (4.90×)
|LZ78| (avg. phrase length)
(6.45)
Compress

(15%)
(48%)

(12%)
(39%)

2.211 (14.93)
1.851

4.805
4.610

3.840
2.927

(7.81)

2.088 (17.24)
2.733

m=3

m=8

 20

 15

 10

 5

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

 0

 8

ClueChin
ClueWiki
KGS
Proteins

 10

 12

 14

 16

 18

 20

 22

 24

space (bpc)

 60

 50

 40

 30

 20

 10

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

 0

 8

ClueChin
ClueWiki
KGS
Proteins

 10

 12

 14

 16

 18

 20

 22

 24

space (bpc)

Fig. 2. Space versus listing time per document output. The tradeoﬀ is obtained by not
representing RMQ information on the last levels of the wavelet tree of Range.

A way to reduce the space without sacriﬁcing functionality is to remove the
RMQ structures at the last levels of the wavelet tree of Range. In those levels
we simply obtain all the documents one by one. The query covers at most two
ranges per level, those at the last levels are the smallest, and they are closest to
the bottom, so obtaining the document identiﬁers is faster. Thus, removing those
structures should not impact much the time. Fig. 2 conﬁrms that the time is
practically unaﬀected when the ﬁrst levels are removed, while the space improves
noticeably. From now on we will remove the RMQ structures on the last 6 levels
of ClueChin, 12 levels of ClueWiki and KGS, and all the levels in Proteins.

Table 2 shows the number of documents listed by the queries. In these relatively 
small collections we list a good percentage of the documents, with the
exception of Proteins, which has many more documents and then a document
listing query is selective enough. From the listed documents, many are obtained
as type 1 occurrences (75%–100% for m = 3 and 50%–95% for m = 8). This
shows that we could obtain a signiﬁcant part of the result using just the fastest
listing and without representing Range.

A Lempel-Ziv Compressed Structure for Document Listing

125

Table 2. Number of occurrences of each type, for pattern lengths m = 3 and m = 8.
Global percentages are w.r.t. the total number of documents, whereas local percentages
(in italics) are w.r.t. the total number of occurrences found.

Occurrences
m = 3

m = 8

Type 1
Type 2
Type 3

Type 1
Type 2
Type 3

0.208

ClueWiki
2,732.41 (82%)

KGS
ClueChin
15,799.10 (84%)
14.20 (62%)
13.60 (96%) 2,727.93 (99%) 15,132.60 (96%)
(4%)
0.598
(0%)
0.002
4,285.02 (23%)
2,943.00 (69%)
1,338.74 (31%)
(0%)

(1%)
(4%)
(0%)
(0%)
6.52 (28%)
1,742.52 (52%)
5.02 (77%) 1,646.97 (95%)
1.28 (20%)
(5%)
(0%)
(3%)

25.06
0.001

94.79
0.724

667.40
0.022

3.29

Proteins
(8%)
12,106.90
9,185.01 (76%)
2,921.90 (24%)
(0%)
0.015
89.45
(0%)
46.27 (52%)
42.49 (48%)
(0%)
0.981

Fig. 3 compares our LZ-Index structures in three modes: the full mode where
it returns all the occurrences, a mode where it can return all the occurrences but
we take the time needed to return only the occurrences of type 1, and use the
minimum space for Range (called “up to type 1”), and a mode where it can only
return the occurrences of type 1 as it does not store Range at all (called “only
type 1”). We also compare Sadakane’s document listing [22] we implemented on
top of Sadakane’s CSA [21] obtained from PizzaChili2, and showing three points
using suﬃx array sampling steps 32, 64, and 128. Finally, we include the variant
using document arrays as plain wavelet trees [23], as RePair-compressed wavelet
trees, and an intermediate between both called “alpha”, as implemented by their
authors [19] and using Sadakane’s CSA with no sampling to minimize space (the
sampling is not needed here).

It can be seen that Sadakane’s technique uses less space than our smallest LZIndex 
variant, but it is orders of magnitude slower (except on ClueChin), even
on this CSA that is the fastest [4] to compute A[i]. The wavelet trees dominate
our LZ-Index variants on ClueChin, because it has very few documents and thus
the wavelet trees are small and fast. On the other collections, instead, wavelet
trees use much more space than our LZ-Index variants. Indeed, in all but the
toy collection ClueChin, even the LZ-Index in full mode is a relevant alternative,
whereas the approximate ones oﬀer even better space/time performance.

6 Final Remarks

We have introduced the ﬁrst document listing data structure based on LempelZiv 
compression. Apart from oﬀering a competitive space/time tradeoﬀ in general,
 an interesting feature of the index is its ability to retrieve a large number
of documents very fast. This makes it an ideal choice in interactive scenarios,
where one must show some answers immediately and others can be calculated
in the background, and in cases where only some answers are suﬃcient.

We plan to extend our ideas to top-k document retrieval. Since the bulk of
the occurrences are type 1, considering only those for computing top-k would
yield very fast an answer that will usually be very accurate.

2 From site pizzachili.di.unipi.it or pizzachili.dcc.uchile.cl

126

H. Ferrada and G. Navarro

ClueChin, m=3

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 5

 6

 7

 8

 10  11  12  13  14  15

 9
space (bpc)

ClueWiki, m=3

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 4

 6

 8

 10

 12

 14

 16

 18

 20

 22

space (bpc)

KGS, m=3

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 1000

 100

 10

 1

 0.1

 1000

 100

 10

 1

 0.1

 100

 10

 1

)
c
e
s
o
r
c
m

i

(
 
t
n
e
m
u
c
o
d
 
r
e
p
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

 1000

 100

 10

 1

 1000

 100

 10

 1

 0.1

 100

 10

 1

)
c
e
s
o
r
c
m

i

(
 
t
n
e
m
u
c
o
d
 
r
e
p
 
e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

ClueChin, m=8

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 5

 6

 7

 8

 10  11  12  13  14  15

 9
space (bpc)

ClueWiki, m=8

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 4

 6

 8

 10

 12

 14

 16

 18

 20

 22

space (bpc)

KGS, m=8

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 25

 30

 0.1

 5

 10

 15
 20
space (bpc)

 25

 30

 0.1

 5

 10

 15
 20
space (bpc)

Proteins, m=3

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

 100

 10

 1

 0.1

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Alpha

 5

 10

 15

 25
 20
space (bpc)

 30

 35

 40

)
c
e
s
o
r
c
m

i

(
 
t

n
e
m
u
c
o
d

 
r
e
p

 

e
m

i
t

 1000

 100

 10

 1

 0.1

Proteins, m=8

LZ-Index
LZ-Index, up to type 1
LZ-Index, only type 1
Sadakane
WT Plain
WT RePair
WT Proteins

 5

 10

 15

 25
 20
space (bpc)

 30

 35

 40

Fig. 3. Space versus listing time (logscale) per document output, for various indexes

A Lempel-Ziv Compressed Structure for Document Listing

127

References

1. Arroyuelo, D., Navarro, G., Sadakane, K.: Stronger Lempel-Ziv based compressed

text indexing. Algorithmica 62(1), 54–101 (2012)

2. Barbay, J., Gagie, T., Navarro, G., Nekrich, Y.: Alphabet partitioning for compressed 
rank/select and applications. In: Cheong, O., Chwa, K.-Y., Park, K. (eds.)
ISAAC 2010, Part II. LNCS, vol. 6507, pp. 315–326. Springer, Heidelberg (2010)
3. Belazzougui, D., Navarro, G.: Alphabet-independent compressed text indexing. In:
Demetrescu, C., Halld´orsson, M.M. (eds.) ESA 2011. LNCS, vol. 6942, pp. 748–759.
Springer, Heidelberg (2011)

4. Ferragina, P., Gonz´alez, R., Navarro, G., Venturini, R.: Compressed text indexes:

From theory to practice. ACM J. Exp. Alg. 13, art. 12 (2009)

5. Ferragina, P., Manzini, G., M¨akinen, V., Navarro, G.: Compressed representations

of sequences and full-text indexes. ACM Trans. Alg. 3(2), article 20 (2007)

6. Fischer, J., Heun, V.: Space-eﬃcient preprocessing schemes for range minimum

queries on static arrays. SIAM J. Comp. 40(2), 465–492 (2011)

7. Gagie, T., Navarro, G., Puglisi, S.J.: New algorithms on wavelet trees and applications 
to information retrieval. Theor. Comp. Sci. 426-427, 25–41 (2012)

8. Gagie, T., Puglisi, S.J., Turpin, A.: Range quantile queries: Another virtue of
wavelet trees. In: Karlgren, J., Tarhio, J., Hyyr¨o, H. (eds.) SPIRE 2009. LNCS,
vol. 5721, pp. 1–6. Springer, Heidelberg (2009)

9. Golynski, A., Grossi, R., Gupta, A., Raman, R., Rao, S.S.: On the size of succinct
indices. In: Arge, L., Hoﬀmann, M., Welzl, E. (eds.) ESA 2007. LNCS, vol. 4698,
pp. 371–382. Springer, Heidelberg (2007)

10. Grossi, R., Gupta, A., Vitter, J.S.: High-order entropy-compressed text indexes.

In: Proc. 14th SODA, pp. 636–645 (2003)

11. Hon, W.-K., Shah, R., Vitter, J.: Space-eﬃcient framework for top-k string retrieval

problems. In: Proc. 50th FOCS, pp. 713–722 (2009)

12. Kosaraju, S., Manzini, G.: Compression of low entropy strings with Lempel-Ziv

algorithms. SIAM J. Comp. 29(3), 893–911 (2000)

13. Manber, U., Myers, G.: Suﬃx arrays: a new method for on-line string searches.

SIAM J. Comp. 22(5), 935–948 (1993)

14. Munro, I.: Tables. In: Chandru, V., Vinay, V. (eds.) FSTTCS 1996. LNCS,

vol. 1180, pp. 37–42. Springer, Heidelberg (1996)

15. Muthukrishnan, S.: Eﬃcient algorithms for document retrieval problems. In: Proc.

13th SODA, pp. 657–666 (2002)

16. Navarro, G.: Indexing text using the ziv-lempel trie. J. Disc. Alg. 2(1), 87–114

(2004)

17. Navarro, G.: Spaces, trees and colors: The algorithmic landscape of document retrieval 
on sequences. CoRR, arXiv:1304.6023v1 (2013)

18. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Comp. Surv. 39(1),

art. 2 (2007)

19. Navarro, G., Puglisi, S.J., Valenzuela, D.: Practical compressed document retrieval.
In: Pardalos, P.M., Rebennack, S. (eds.) SEA 2011. LNCS, vol. 6630, pp. 193–205.
Springer, Heidelberg (2011)

20. Raman, R., Raman, V., Rao, S.S.: Succinct indexable dictionaries with applications
to encoding k-ary trees, preﬁx sums and multisets. ACM Trans. Alg. 3(4), art. 43
(2007)

128

H. Ferrada and G. Navarro

21. Sadakane, K.: New text indexing functionalities of the compressed suﬃx arrays. J.

Alg. 48(2), 294–313 (2003)

22. Sadakane, K.: Succinct data structures for ﬂexible text retrieval systems. J. Disc.

Alg. 5(1), 12–22 (2007)

23. V¨alim¨aki, N., M¨akinen, V.: Space-eﬃcient algorithms for document retrieval. In:
Ma, B., Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 205–215. Springer,
Heidelberg (2007)

24. Weiner, P.: Linear pattern matching algorithm. In: Proc. 14th IEEE Symposium

on Switching and Automata Theory, pp. 1–11 (1973)

25. Ziv, J., Lempel, A.: Compression of individual sequences via variable-rate coding.

IEEE Trans. Inf. Theor. 24(5), 530–536 (1978)

