Compressed Text Indexes with Fast Locate

Rodrigo Gonz´alez(cid:2) and Gonzalo Navarro(cid:2)(cid:2)

Dept. of Computer Science, University of Chile

{rgonzale,gnavarro}@dcc.uchile.cl

Abstract. Compressed text (self-)indexes have matured up to a point
where they can replace a text by a data structure that requires less
space and, in addition to giving access to arbitrary text passages, support
indexed text searches. At this point those indexes are competitive with
traditional text indexes (which are very large) for counting the number
of occurrences of a pattern in the text. Yet, they are still hundreds to
thousands of times slower when it comes to locating those occurrences in
the text. In this paper we introduce a new compression scheme for suﬃx
arrays which permits locating the occurrences extremely fast, while still
being much smaller than classical indexes. In addition, our index permits
a very eﬃcient secondary memory implementation, where compression
permits reducing the amount of I/O needed to answer queries.

1 Introduction and Related Work

Compressed text indexing has become a popular alternative to cope with the
problem of giving indexed access to large text collections without using up too
much space. Reducing space is important because it gives one the chance of maintaining 
the whole collection in main memory. The current trend in compressed
indexing is full-text compressed self-indexes [13,1,4,14,12,2]. Such a self-index (for
short) replaces the text by providing fast access to arbitrary text substrings, and
in addition gives indexed access to the text by supporting fast search for the occurrences 
of arbitrary patterns. These indexes take little space, usually from
30% to 150% of the text size (note that this includes the text). This is to be
compared with classical indexes such as suﬃx trees [15] and suﬃx arrays [10],
which require at the very least 10 and 4 times, respectively, the space of the
text, plus the text itself. In theoretical terms, to index a text T = t1 . . . tn over
an alphabet of size σ, the best self-indexes require nHk + o(n log σ) bits for any
k ≤ α logσ n and any constant 0 < α < 1, where Hk ≤ log σ is the k-th order
empirical entropy of T [11,13]1. Just the uncompressed text alone would need
n log σ bits, and classical indexes require O(n log n) bits on top of it.

The search functionality is given via two operations. The ﬁrst is, given a
pattern P = p1 . . . pm, count the number of times P occurs in T . The second

(cid:2) Work supported by Mecesup Grant UCH 0109, Chile.
(cid:2)(cid:2) This work was funded by a grant from Yahoo! Research Latin America.
1 In this paper log stands for log2.

B. Ma and K. Zhang (Eds.): CPM 2007, LNCS 4580, pp. 216–227, 2007.
c(cid:2) Springer-Verlag Berlin Heidelberg 2007

Compressed Text Indexes with Fast Locate

217

log log n)) and even O(1+ m

is to locate the occurrences, that is, to list their positions in T . Current selfindexes 
achieve a counting performance that is comparable in practice with that
of classical indexes. In theoretical terms, for the best self-indexes the complexity
is O(m(1+ log σ
logσ n), compared to O(m log σ) of suﬃx trees
and O(m log n) or O(m+log n) of suﬃx arrays. Locating, on the other hand, is far
behind, hundreds to thousands of times slower than their classical counterparts.
While classical indexes pay O(occ) time to locate the occ occurrences, self-indexes
pay O(occ logε n), where ε can in theory be any number larger than zero but is
in practice larger than 1. Worse than that, the memory access patterns of selfindexes 
are highly non-local, which makes their potential secondary-memory
versions rather unpromising. Extraction of arbitrary text portions is also quite
slow and non-local compared to having the text directly available as in classical
indexes. The only implemented self-index which has more local accesses and
faster locate is the LZ-index [12], yet its counting time is not competitive.

In this paper we propose a suﬃx array compression technique that builds on
well-known regularity properties that show up in suﬃx arrays when the text they
index is compressible [13]. This regularity has been exploited in several ways in
the past [7,14,8], but we present a completely novel technique to take advantage
of it. We represent the suﬃx array using diﬀerential encoding, which converts the
regularities into true repetitions. Those repetitions are then factored out using
Re-Pair [6], a compression technique that builds a dictionary of phrases and
permits fast local decompression using only the dictionary (whose size one can
control at will, at the expense of losing some compression). We then introduce
some novel techniques to further compress the Re-Pair dictionary, which can be
of independent interest. We also use speciﬁc properties of suﬃx arrays to obtain
a much faster compression losing only 1%–14% of compression.

As a result, for several text types, we reduce the suﬃx array to 20–70% of
its original size, depending on its compressibility. This reduced index can still
extract any portion of the suﬃx array very fast by adding a small set of sampled
absolute values. We prove that the size of the result is O(Hk log(1/Hk)n log n)
bits for any k ≤ α logσ n and any constant 0 < α < 1. Note that this reduced
suﬃx array is not yet a self-index as it cannot reproduce the text.
This structure can be used in two ways. One way is to attach it to a selfindex 
able of counting, which in this process identiﬁes as well the segment of
the (virtual) suﬃx array where the occurrences lie. We can then locate the
occurrences by decompressing that segment using our structure. The result is a
self-index that needs 1–3 times the text size (that is, considerably larger than
current self-indexes but also much smaller than classical indexes) and whose
counting and locating times are competitive with those of classical indexes, far
better for locating than current self-indexes. In theoretical terms, assuming for
example the use of an alphabet-friendly FM-index [2] for counting, our index
needs O(Hk log(1/Hk)n log n+n) bits of space, counts in time O(m(1+ log σ
log log n))
and locates the occ occurrences of P in time O(occ + log n).

A second and simpler way to use the structure is, together with the plain text,
as a replacement of the classical suﬃx array. In this case we must not only use

218

R. Gonz´alez and G. Navarro

it for locating the occurrences but also for binary searching. The binary search
can be done over the samples ﬁrst and then decompress the area between two
consecutive samples to ﬁnish the search. This yields a very practical alternative
requiring 0.8–2.4 times the text size (as opposed to 4) plus the text.

On the ther hand, if the text is very large, even a compressed index must
reside on disk. Performing well on secondary memory with a compressed index
has proved extremely diﬃcult, because of their non-local access pattern. Thanks
to its local decompression properties, our reduced suﬃx array performs very well
(cid:4) disk accesses for locating the
on secondary memory. It needs the optimal (cid:3) occ
occ occurrences, being B the disk block size measured in integers. On average,
if the compression ratio (compressed divided by uncompressed suﬃx array size)
(cid:4) accesses. That is, our index actually performs
is 0 ≤ c ≤ 1, we perform (cid:3) c·occ
better, not worse (as it seems to be the norm), thanks to compression. We show
how to upgrade this structure to an eﬃcient secondary-memory self-index.

We experimentally explore the compression performance we achieve, the time
for locating, and the simpliﬁed suﬃx array implementation, comparing against
previous work. Our structure stands out as an excellent practical alternative.

B

B

2 Compressing the Suﬃx Array

Given a text T = t1 . . . tn over alphabet Σ of size σ, where for technical reasons
we assume tn = $ is smaller than any other character in Σ and appears nowhere
else in T , a suﬃx array A[1, n] is a permutation of [1, n] such that TA[i],n ≺
TA[i+1],n for all 1 ≤ i < n, being “≺” the lexicographical order. By Tj,n we
denote the suﬃx of T that starts at position j. Since all the occurrences of a
pattern P = p1 . . . pm in T are preﬁxes of some suﬃx, a couple of binary searches
in A suﬃce to identify the segment in A of all the suﬃxes that start with P ,
that is, the segment pointing to all the occurrences of P . Thus the suﬃx array
permits counting the occurrences of P in O(m log n) time and reporting the occ
occurrences in O(occ) time. With an additional array of integers, the counting
time can be reduced to O(m + log n) [10].

Suﬃx arrays turn out to be compressible whenever T is. The k-th order empirical 
entropy of T , Hk [11], shows up in A in the form of large segments A[i, i + (cid:6)]
that appear elsewhere in A[j, j + (cid:6)] with all the values shifted by one position,
A[j + s] = A[i + s] + 1 for 0 ≤ s ≤ (cid:6). Actually, one can partition A into runs
of maximal segments that appear repeated (shifted by 1) elsewhere, and the
number of such runs is at most nHk + σk for any k [8,13].

This property has been used several times in the past to compress A. M¨aki-
nen’s Compact Suﬃx Array (CSA) [7] replaces runs with pointers to their deﬁnition 
elsewhere in A, so that the run can be recovered by (recursively) expanding 
the deﬁnition and shifting the values. M¨akinen and Navarro [8] use
the connection with FM-indexes (runs in A are related to equal-letter runs in
the Burrows-Wheeler transform of T , basic building block of FM-indexes) and
run-length compression. Yet, the most successful technique to take advantage of
−1[A[i] + 1] (or
those regularities has been the deﬁnition of function Ψ(i) = A

219
−1[1] if A[i] = n). It can be seen that Ψ(i) = Ψ(i − 1) + 1 within runs of A,
A
and therefore a diﬀerential encoding of Ψ is highly compressible [14].

Compressed Text Indexes with Fast Locate

We present a completely diﬀerent method to compress A. We ﬁrst represent
(cid:3)[i] = A[i] − A[i − 1] if i > 1. Take now
A in diﬀerential form: A
a run of A of the form A[j + s] = A[i + s] + 1 for 0 ≤ s ≤ (cid:6). It is easy to see that
(cid:3)[i + s] for 1 ≤ s ≤ (cid:6). We have converted the runs of A into true
(cid:3)[j + s] = A
A
(cid:3).
repetitions in A

(cid:3)[1] = A[1] and A

(cid:3)[i]A

(cid:3)[i+1] in A

The next step is to take advantage of those repetitions in a way that permits
(cid:3). We resort to Re-Pair [6], a dictionary-based comfast 
local decompression of A
pression method based on the following algorithm: (1) identify the most frequent
(cid:3), let ab be such pair; (2) create a new integer symbol s ≥ n
pair A
(cid:3) and add rule s → ab to a dictionary; (3)
larger than all existing symbols in A
replace every occurrence of ab in A by s2; (4) iterate until every pair has frequency 
1. The result of the compression is the table of rules (call it R) plus the
(cid:3) has been compressed (call
sequence of (original and new) symbols into which A
it C). Note that R can be easily stored as a vector of pairs, so that rule s → ab
is represented by R[s − n + 1] = a : b.

Any portion of C can be easily decompressed in optimal time and fast in
practice. To decompress C[i], we ﬁrst check if C[i] < n. If it is, then it is an
(cid:3) and we are done. Otherwise, we obtain both symbols from
original symbol of A
R[C[i] − n + 1], and expand them recursively (they can in turn be original or
(cid:3) in O(u) time, and the
created symbols, and so on). We reproduce u cells of A
accesses pattern is local if R is small.

Since R grows by 2 integers (a, b) for every new pair, we can stop creating
pairs when the most frequent one appears only twice. R can be further reduced
by preempting this process, which trades its size for overall compression ratio.
A few more structures are necessary to recover the values of A: (1) a sampling
of absolute values of A at regular intervals l; (2) a bitmap L[1, n] marking the
(cid:3))
positions where each symbol of C (which could represent several symbols of A
(cid:3); (3) o(n) further bits to answer rank queries on L in constant time
starts in A
[5,13]: rank(L, i) is the number of 1’s in L[1, i]. Thus, to retrieve A[i, j] we: (1)
see if there is a multiple of l in [i, j], extending i to the left or j to the right
to include such a multiple if necessary; (2) make sure we expand an integral
number of symbols in C, extending i to the left and j to the right until L[i] = 1
(cid:3)[i, j] by
and L[j + 1] = 1; (3) use the mechanism described above to obtain A
expanding C[rank(L, i), rank(L, j)]; (4) use any absolute sample of A included
(cid:3)[i, j], the values A[i, j]; (5) return
in [i, j] to obtain, using the diﬀerences in A
the values in the original interval [i, j] requested.

The overall time complexity of this decompression is the output size plus what
we have expanded the interval to include a multiple of l (i.e., O(l)) and to ensure
an integral number of symbols in C. The latter can be controlled by limiting the
length of the uncompressed version of the symbols we create.

2 If a = b it might be impossible to replace all occurrences, e.g. aa in aaa, but in such

case one can at least replace each other occurrence in a row.

220

R. Gonz´alez and G. Navarro

2.1 Faster Compression

(cid:3)[j + s] = A

A weak point in our scheme is compression speed. Re-Pair can be implemented
in O(n) time, but needs too much space [6]. We have used instead an O(n log n)
time algorithm that requires less memory. We omit the details for lack of space.
We note that Ψ (which is easily built in O(n) time from A) can be used to
obtain a much faster compression algorithm, which in practice compresses only
slightly less than the original Re-Pair. Recall that Ψ(i) tells where in A is the
value A[i]+1. The idea is that, if A[i, i+(cid:6)] is a run such that A[j+s] = A[i+s]+1
(cid:3)[i + s] for 1 ≤ s ≤ (cid:6)), then Ψ(i + s) = j + s
for 0 ≤ s ≤ (cid:6) (and thus A
for 0 ≤ s ≤ (cid:6). Thus, by following permutation Ψ we have a good chance of ﬁnding
(cid:3) (although, as explained, Re-Pair does a slightly better job).
repeated pairs in A
−1[1]. We start at i = i1 and
(cid:3)[Ψ(i)]A
(cid:3)[Ψ(i) + 1]. If this does not hold, we move on to
see if A
i ← Ψ(i) and iterate. If the equality holds, we start a chain of replacements: We
(cid:3)[i + 1] to R, make the replacements at i and Ψ(i) and
add a new pair A
move on with i ← Ψ(i), replacing until the pair changes. When the pair changes,
(cid:3)[Ψ(i)+ 1], we restart the process with i ← Ψ(i),
(cid:3)[Ψ(i)]A
that is A
(cid:3) without
looking again for a new pair to create. When we traverse the whole A
ﬁnding any pair to replace, we are done. With some care (omitted for lack of
space) this algorithm runs in O(n) time.

(cid:3)[i + 1] = A
(cid:3)[i]A
(cid:3)[i + 1] (cid:9)= A

The algorithm is thus as follows. Let i1 = A

(cid:3)[i]A

(cid:3)[i]A

2.2 Analysis

(cid:3)[i]A

(cid:3)[i]A

4N .

(cid:3)[i] = A

(cid:3), and thus the most frequent pair appears at least n

We analyze the compression ratio of our data structure. Let N be the number of
runs in Ψ. As shown in [8,13], N ≤ Hkn + σk for any k ≥ 0. Except for the ﬁrst
(cid:3)[Ψ(i)] within the run. Thus, we cut oﬀ
cell of each run, we have that A
(cid:3)[i + 1]
the ﬁrst cell of each run, to obtain up to 2N runs now. Every pair A
(cid:3)[Ψ(i)]A
(cid:3)[Ψ(i) + 1], thus the only pairs
contained in such runs must be equal to A
(cid:3)[i + 1] that are not equal to the “next” pair are those where i
of cells A
is the last cell of its run. This shows that there are at most 2N diﬀerent pairs
2N times. Because of
in A
overlaps, it could be that only each other occurrence can be replaced, thus the
total number of replacements in the ﬁrst iteration is at least βn, for β = 1
After we choose and replace the most frequent pair, we end up with at most
n− βn integers in A
(cid:3). The number of runs has not varied, because a replacement
cannot split a run. Thus, the same argument shows that the second time we
remove at least β(n − βn) = βn(1 − β) cells. The third replacement removes at
least β(n − βn − βn(1 − β)) = βn(1 − β)2 cells. It is easy to see by induction
that the i-th iteration removes βn(1 − β)i−1 cells.
i=1 βn(1− β)i−1 = n− n(1− β)M cells,
and hence the length of C is n(1− β)M and the length of R is 2M. The total size
, where it is 2(ln n+ln ln 1
1−β
is optimized for M
. Since
ln 1
1−β
ln 1
4N + O(N) integers.

∗ = ln n+ln ln 1
1−β
ln 1
1−β
4N (1 + O( 1
N )), the total size is 8N ln n

After M iterations we have removed

1−β = ln 4N

4N−1 = 1

−ln 2+1)

(cid:2)

M

−ln 2

Compressed Text Indexes with Fast Locate

221
Since N ≤ Hkn + σk, if we stick to k ≤ α logσ n for any constant 0 < α < 1,
it holds σk = O(nα) and the total space is O(Hk log 1
n log n) + o(n) bits, as
Hk
even after the M

∗ replacements the numbers need O(log n) bits.

(cid:3) using R and C needs O(Hk log 1

Theorem 1. Our structure representing A
n log n) + o(n) bits, for any k ≤ α logσ n and any constant 0 < α < 1.
As a comparison, M¨akinen’s CSA [7] needs O(Hkn log n) bits [13], which is always
better as a function of Hk. Yet, both tend to the same space as Hk goes to zero.
Other self-indexes are usually smaller.

Hk

We can also show that the simpliﬁed replacement method of Section 2.1
reaches the same asymptotic space complexity (proof omitted for lack of space).

2.3 Compressing the Dictionary

We now develop some techniques to reduce the dictionary of rules R without
aﬀecting C. Those can be of independent interest to improve Re-Pair in general.
A ﬁrst observation is that, if we have a rule s → ab and s is only mentioned
(cid:3) → sc, then we could perfectly remove rule s → ab and rewrite
in another rule s
(cid:3) → abc. This gives a net gain of one integer, but now we have rules of varying
s
length. This is easy to manage, but we prefer to go further. We develop a technique 
that permits eliminating every rule deﬁnition that is used within R, once
or more, and gain one integer for each rule eliminated. The key idea is to write
down explicitly the binary tree formed by expanding the deﬁnitions (by doing a
preorder traversal and writing 1 for internal nodes and 0 for leaves), so that not
only the largest symbol (tree root) can be referenced later, but also any subtree.
For example, assume the rules R = {s → ab, t → sc, u → ts}, and C = tub.
We could ﬁrst represent the rules by the bitmap RB = 100100100 (where s
corresponds to position 1, t to 4, and u to 7) and the sequence RS = ab1c41
(cid:3), and the bitmap positions as
(we are using letters for the original symbols of A
the identiﬁers of created symbols3). We express C as 47b. To expand, say, 4, we
go to position 4 in RB and compute rank0(RB, 4) = 2 (number of zeros up to
position 4, rank0(i) = i− rank(i)). Thus the corresponding symbols in RS start
at position 3. We extract one new symbol from RS for each new zero we traverse
in RB, and stop when the number of zeros traversed exceeds the number of ones
(this means we have completed the subtree traversal). This way we obtain the
deﬁnition 1c for symbol 4.

Let us now reduce the dictionary by expanding the deﬁnition of s within t
(even when s is used elsewhere). The new bitmap is RB = 11000100 (where
t = 1, s = 2, and u = 6), the sequence is RS = abc12, and C = 16b. We can
now remove the deﬁnition of t by expanding it within u. This produces the new
bitmap RB = 1110000 (where u = 1, t = 2, s = 3), the sequence RS = abc3 and
C = 21b. Further reduction is not possible because u’s deﬁnition is only used
3 In practice letters are numbers up to n−1 and the bitmap positions are distinguished
by adding them n − 1.

R. Gonz´alez and G. Navarro

222
from C4. At the cost of storing at most 2|R| bits, we can reduce R by one integer
for each deﬁnition that is used at least once within R.

The reduction can be easily implemented in linear time, avoiding the successive 
renamings of the example. We ﬁrst count how many times each rule is
used within R. Then we traverse R and only write down (the bits of RB and
the sequence RS for) the entries with zero count. We recursively expand those
entries, appending the resulting tree structure to RB and leaf identiﬁers to RS.
Whenever we ﬁnd a created symbol that does not yet have an identiﬁer, we give
it as identiﬁer the current position in RB and recursively expand it. Otherwise
the expansion ﬁnishes and we write down a leaf (a "0") in RB and the identiﬁer
in RS. Then we rewrite C using the renamed identiﬁers.

3 Towards a Text Index

As explained in the Introduction, the reduced suﬃx array is not by itself a text
index. We explore now diﬀerent alternatives to upgrade it to full-text index.

3.1 A Main Memory Self-index

One possible choice is to add one of the many self-indexes able of counting the
occurrences of P in little space [1,2,14,4]. Those indexes actually ﬁnd out the
area [i, j] where the occurrences of P lie in A. Then locating the occurrences
boils down to decompressing A[i, j] from our structure.
To ﬁx ideas, consider the alphabet-friendly FM-index [2]. It takes nHk +
o(n log σ) bits of space for any k ≤ α logσ n and constant 0 < α < 1, and can
count in time O(m(1 + log σ
log log n)). Our additional structure dominates the space
complexity, requiring O(Hk log(1/Hk)n log n) + o(n) bits for the representation
(cid:3). To this we must add O((n/l) log n) bits for the absolute samples, and the
of A
extra cost to limit the formation of symbols that represent very long sequences.
If we limit such lengths to l as well, we have an overhead of O((n/l) log n) bits,
(cid:3)
as this can be regarded as inserting a spurious symbol every l positions in A
to prevent the formation of longer symbols. By choosing l = log n we have
O(Hk log(1/Hk)n log n + n) bits of space, and time O(occ + log n) for locating
the occurrences. Other tradeoﬀs are possible, for example having n log1−ε n bits
of extra space and O(occ + logε n) time, for any 0 < ε < 1.
Extracting substrings can be done with the same FM-index, but the time
to display (cid:6) text characters is, using n log1−ε n additional bits of space, O(((cid:6) +
logε n)(1+ log σ
log log n)). By using the structure proposed in [3] we have other nHk +
o(n log σ) bits of space for k = o(logσ n) (this space is asymptotically negligible)
and can extract the characters in optimal time O(1 + (cid:7)

logσ n).

Theorem 2. There exists a self-index for text T of length n over an alphabet
of size σ and k-th order entropy Hk, which requires O(Hk log(1/Hk)n log n +
4 It is tempting to replace u in C, as it appears only once, but our example is artiﬁcial:

A symbol that is not mentioned in R must appear at least twice in C.

Compressed Text Indexes with Fast Locate

223
n log1−ε n) + o(n log σ) bits of space, for any 0 ≤ ε ≤ 1. It can count the occurrences 
of a pattern of length m in time O(m(1 + log σ
log log n)) and locate its occ
occurrences in time O(occ + logε n). For k = o(logσ n) it can display any text
logσ n). For larger k ≤ α logσ n, for any
substring of length (cid:6) in time O(1 + (cid:7)
constant 0 < α < 1, this time becomes O(((cid:6) + logε n)(1 + log σ

log log n)).

3.2 A Smaller Classical Index

A simple and practical alternative is to use our reduced suﬃx array just like the
classical suﬃx array, that is, not only for locating but also for searching, keeping
the text in uncompressed form as well. This is not anymore a compressed index,
but a practical alternative to a classical index.

The binary search of the interval that corresponds to P will start over the
absolute samples of our data structure. Only when we have identiﬁed the interval
between consecutive samples of A where the binary search must continue, we
decompress the whole interval and ﬁnish the binary search. If the two binary
searches ﬁnish in diﬀerent intervals, we will also need to decompress the intervals
in between for locating all the occurrences. For displaying, the text is at hand.
The cost of this search is O(m log n) plus the time needed to decompress the
portion of A between two absolute samples. We can easily force the compressor to
make sure that no symbol in C spans the limit between two such intervals, so that
the complexity of this decompression can be controlled with the sampling rate
l. For example, l = O(log n) guarantees a total search time of O(m log n + occ),
just as the suﬃx array version that requires 4 times the text size (plus text).

Theorem 3. There exists a full-text index for text T of length n over an alphabet
of size σ and k-th order entropy Hk, which requires O(Hk log(1/Hk)n log n + n)
bits of space in addition to T , for any k ≤ α logσ n and any constant 0 < α < 1.
It can count the occurrences of a pattern of length m in time O(m log n) and
locate its occ occurrences in time O(occ + log n).

3.3 A Secondary Memory Index

In [9], an index of size nH0 + O(n log log σ) bits is described, which can identify
the area of A containing the occurrences of a pattern of length m (and thus
count its occurrences) using at most 2m(1 + (cid:3)logB n(cid:4)) accesses to disk, where
B log n is the number of bits in a disk block. However, this index is extremely
slow to locate the occurrences: each locate needs O(logε n) random accesses to
disk, where in practice ε = 1. This is achieved by storing the inverse of Ψ [14].
If, instead, we keep only the data structures for counting, and use our reduced
(cid:4) accesses to report the occ occurrences, which
suﬃx array, we can obtain (cid:3) occ
is worst-case optimal. Assume table R is small enough to ﬁt in main memory
(recall we can always force so, losing some compression). Then, we read the
corresponding area of C from disk, and uncompress each cell in memory without
any further disk access (the area of C to read can be obtained from an in-memory

B

224

R. Gonz´alez and G. Navarro

binary search over an array storing the absolute position of the ﬁrst C cell of
each disk block). On average, if we achieved compression ratio c ≤ 1, we will
need to read c·occ cells from C, at a cost of (cid:3) c·occ
(cid:4). Therefore, we achieve for the
ﬁrst time a locating complexity that is better thanks to compression, not worse.
Note that M¨akinen’s CSA would not perform well at all under this scenario, as
the decompression process is highly non-local.

B

To extract text passages of length (cid:6) we could use compressed sequence mechanisms 
like [3], which easily adapt to disk and have local decompression.

4 Experimental Results

We present three series of experiments in this section. The ﬁrst one regards
compression performance, the second the use of our technique as a plug-in for
boosting the locating performance of a self-index, and the third the use of our
technique as a classical index using reduced space. We use text collections obtained 
from the PizzaChili site, http://pizzachili.dcc.uchile.cl.

Compression performance. In Section 2.1 we mentioned that compression time
of our scheme would be an issue and gave an approximate method based on Ψ
which should be faster. Table 1 compares the performance of the exact Re-Pair
compression algorithm (RP) and that of the Ψ-based approximation (RPΨ). We
take absolute samples each 32 positions.

Table 1. Index size and build time using Re-Pair (RP) and its Ψ-based approximation
(RPΨ). For the xml case, we also include a Re-Pair version (RPC) with rules up to
length 256. Compression ratio compares with the 4n bytes needed by a suﬃx array.

Collection, size Method Index Size Compr. Re-Pai Expected Dict. Main Compr. with
Ratio Time (s) decompr. compr. memory 5% in RAM
(MB), H3/H0
xml, 100,
23.51% 25986
34.29%
81.85%
25.69%
260
26.28%
35.86%
24.96% 25129
95.52%
83.55% 11150
101.4%
84.86%
546
87.98%
55.33% 93421
60.33%
485
99.33%
67.54%
57.77% 15371
85.36%
180
62.16%
79.58%
3143
71.67%
91.83%
73.78%
641
64.03%
37.95% 106173
44.04%
377
95.67%

dna, 100,
97.02%
english, 100,
53.05%
pitches, 50,
61.37%
proteins, 100, RP
97.21%
sources, 100,
40.74%

(MB)
94.04
102.76
99.82
333.96
339.45
221.31
241.33
115.54
124.32
286.66
295.15
151.81
176.15

6939.99
7570.49
134.99
5.01
4.73
238.31
202.79
33.71
26.78
58.97
52.52
2046.80
1778.79

57%
57%
58%
79%
78%
59%
60%
70%
67%
80%
75%
58%
58%

RP
RPΨ
RPC
RP
RPΨ
RP
RPΨ
RP
RPΨ

RPΨ
RP
RPΨ

49%
51%
47%
19%
20%
43%
44%
21%
25%
10%
13%
48%
50%

The approximation runs 5 to 280 times faster and just loses 1%–14% in compression 
ratio. RP runs at 3 to 100 sec/MB, whereas RPΨ needs 0.26 to 0.65
sec/MB. Most of the indexing time is spent this compression; the rest adds up
around 120 sec overall in all cases.

Compression ratio varies widely. On XML data we achieve 23.5% compression 
(the reduced suﬃx array is smaller than the text!), whereas compression

Compressed Text Indexes with Fast Locate

225

is extremely poor on DNA. In many text types of interest we slash the suﬃx
array to around half of its size. Below the name of each collection we wrote the
percentage H3/H0, which gives an idea of the compressibility of the collection
independent of its alphabet size (e.g. it is very easy to compress DNA to 25%
because there are mainly 4 symbols but one chooses to spend a byte for each in
the uncompressed text, otherwise DNA is almost incompressible).

Other statistics are available. In column 6 we measure the average length of
a cell of C if we choose uniformly in A (longer cells are in addition more likely
to be chosen for decompression). Those numbers explain the times obtained for
the next series of experiments. Note that they are related to compressibility, but
not as much as one could expect. Rather, the numbers obey to a more detailed
structure of the suﬃx array: they are higher when the compression is not uniform
across the array. In those cases, we can limit the maximum length of a C cell. To
show how this impacts compression ratio and decompression speed, we include
a so-called RPC method for xml (which has the largest C lengths). RPC forbids
a rule to cross a 256-cell boundary. We can see that compression ratio is almost
the same, worsening by 6.17% on xml (and less on others, not shown).

In column 7 we show the compression ratio achieved with the technique of
Section 2.3, charging it the bitmap introduced as well. It can be seen that the
technique is rather eﬀective. Column 8 shows the percentage of the compressed
structure (i.e., the compressed version of R) that should stay in RAM in order
to be able to access C and the samples in secondary memory, as advocated in
Section 3.3. Note that the percentage is not negligible when compression is good,
and that 100 minus the percentage almost gives the percentage taken by C. The
last column shows how much compression we would achieve if the structures
that must reside on RAM were limited to 5% of the original suﬃx array size
(this is measured before dictionary compression, so it would be around 3% after
compression). We still obtain attractive compression performance on texts like
XML, sources and pitches (recall that on secondary memory the compression
ratio translates almost directly to decompression performance). As expected,
RPΨ does a much poorer job here, as it does not choose the best pairs early.

A plugin for self-indexes. Section 3.1 considers using our reduced suﬃx array
as a plugin to provide fast locate on existing self-indexes. In this experiment we
plug our structure to the counting structures of the alphabet-friendly FM-index
(AFI [2]), and compare the result against the original AFI, the Sadakane’s CSA
[14] and the SSA [2,8], all from PizzaChili. We increased the sampling rate of
the locating structures of AFI, CSA and SSA, to match the size of our index
(RPT). To save space we exclude DNA and pitches.

Fig. 1 shows the results. The experiment consists in choosing random ranges
of the suﬃx array and obtaining the values. This simulates a locating query
where we can control the amount of occurrences to locate. Our reduced suﬃx
array has a constant time overhead (which is related to column 6 in Table 1 and
the sample rate of absolute values) and from then on the cost per cell located is
very low. As a consequence, it crosses sooner or later all the other indexes. For
example, it becomes the fastest on XML after locating 4,000 occurrences, but it

226

R. Gonz´alez and G. Navarro

Extract over dblp.xml.100MB

Extract over sources.100MB

RPT
SSA
AFI
CSA
RPC

 0

 1000

 2000
 3000
Extracted Size

 4000

 5000

Extract over english.100MB

RPT
SSA
AFI
CSA

 400

 350

 300

 250

 200

 150

 100

 50

 0

 1.6

 1.4

 1.2

 1

 0.8

 0.6

 0.4

 0.2

)
s
n
o
i
t
c
a
r
t
x
e
 

4

0
1
 
r
e
p
 
c
e
s
(
e
m

i
t

)
s
n
o

i
t
c
a
r
t
x
e

 

4

0
1
 
r
e
p
 
c
e
s
(
e
m

i
t

 12

 10

RPT
SSA
AFI
CSA

 8

 6

 4

 2

 0

 0

 50

 100

 150

 200

 250

 300

Extracted Size

Extract over proteins.100MB

RPT
SSA
AFI
CSA

 0.7

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

)
s
n
o
i
t
c
a
r
t
x
e
 

4

0
1
 
r
e
p
 
c
e
s
(
e
m

i
t

)
s
n
o

i
t
c
a
r
t
x
e

 

4

0
1
 
r
e
p
 
c
e
s
(
e
m

i
t

 0

 0

 5

 10

 20

 15
 25
Extracted Size

 30

 35

 40

 0

 0

 5

 10

 15

 20

Extracted Size

Fig. 1. Time to locate occurrences, as a function of the number of occurrences to locate.
On xml, RPC becomes the fastest when extracting more than 2 results.

Locate xml.100MB

Locate english.100MB

RPT m=05
MakCSA m=05
SA m=05
RPT m=10
MakCSA m=10
SA m=10
RPT m=15
MakCSA m=15
SA m=15

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

)
c
o

l
 

6

0
1

 
r
e
p

 
c
e
s
(
e
m
T

i

RPT m=05
MakCSA m=05
SA m=05
RPT m=10
MakCSA m=10
SA m=10
RPT m=15
MakCSA m=15
SA m=15
RPT m=20
MakCSA m=20
SA m=20

 1.5

 2

 3
IndexSize/TextSize-1

 2.5

 3.5

 4

 0

 1.5

 2

 2.5

 3

 3.5

 4

Locate proteins.100MB

RPT m=05
MakCSA m=05
SA m=05
RPT m=10
MakCSA m=10
SA m=10
RPT m=20
MakCSA m=20
SA m=20
RPT m=40
MakCSA m=40
SA m=40

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

)
c
o
l
 

6

0
1
 
r
e
p
 
c
e
s
(
e
m
T

i

IndexSize/TextSize-1

Locate sources.100MB

RPT m=05
MakCSA m=05
SA m=05
RPT m=10
MakCSA m=10
SA m=10
RPT m=20
MakCSA m=20
SA m=20
RPT m=40
MakCSA m=40
SA m=40

)
c
o

l
 

6

0
1

 
r
e
p

 
c
e
s
(
e
m
T

i

)
c
o
l
 

6

0
1
 
r
e
p
 
c
e
s
(
e
m
T

i

 0.4

 0.35

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

 0

 0.5

 1

 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0

 2.6

 2.8

 3

 3.2

 3.4

 3.6

 3.8

 4

IndexSize/TextSize-1

 0

 1

 1.5

 2.5

 2
 3
IndexSize/TextSize-1

 3.5

 4

Fig. 2. Simulating a classical suﬃx array to binary search and locate the occurrences

Compressed Text Indexes with Fast Locate

227

needs just 6 occurrences to become the fastest on proteins. However, the RPC
version shows an impressive (more than 500-fold) improvement on the cost per
cell, standing as an excellent alternative when compression is so good.

A classical reduced index. Finally, we test our reduced suﬃx array as a replacement 
of the suﬃx array, that is, adding it the text and using it for binary
searching, as explained in Section 3.2. We compare it with a plain suﬃx array
(SA) and M¨akinen’s CSA (MakCSA [7]), as the latter operates similarly.

Fig. 2 shows the result. The CSA oﬀers space-time tradeoﬀs, whereas those of
our index (sample rate for absolute values) did not signiﬁcantly aﬀect the time.
Our structure stands out as a relevant space/time tradeoﬀs, especially when
locating many occurrences (i.e. on short patterns).

References

1. Ferragina, P., Manzini, G.: Indexing compressed texts. J. of the ACM 52(4), 552–

581 (2005)

2. Ferragina, P., Manzini, G., M¨akinen, V., Navarro, G.: Compressed representation
of sequences and full-text indexes. ACM Transactions on Algorithms, 2006. TR
2004-05, Technische Fakult¨at, Univ. Bielefeld, Germany (to appear)

3. Gonz´alez, R., Navarro, G.: Statistical encoding of succinct data structures. In:
Lewenstein, M., Valiente, G. (eds.) CPM 2006. LNCS, vol. 4009, pp. 295–306.
Springer, Heidelberg (2006)

4. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed text indexes. In:

Proc. 14th SODA, pp. 841–850 (2003)

5. Jacobson, G.: Space-eﬃcient static trees and graphs. In: Proc. 30th FOCS, pp.

549–554 (1989)

1722–1732 (2000)

6. Larsson, J., Moﬀat, A.: Oﬀ-line dictionary-based compression. Proc. IEEE 88(11),

7. M¨akinen, V.: Compact suﬃx array — a space-eﬃcient full-text index. Fundamenta

Informaticae 56(1–2), 191–210 (2003)

8. M¨akinen, V., Navarro, G.: Succinct suﬃx arrays based on run-length encoding.

Nordic J. of Computing 12(1), 40–66 (2005)

9. M¨akinen, V., Navarro, G., Sadakane, K.: Advantages of backward searching —
eﬃcient secondary memory and distributed implementation of compressed suﬃx
arrays. In: Fleischer, R., Trippen, G. (eds.) ISAAC 2004. LNCS, vol. 3341, pp.
681–692. Springer, Heidelberg (2004)

10. Manber, U., Myers, G.: Suﬃx arrays: a new method for on-line string searches.

SIAM J. Computing 22(5), 935–948 (1993)

11. Manzini, G.: An analysis of the Burrows-Wheeler transform. J. of the ACM 48(3),

12. Navarro, G.: Indexing text using the Ziv-Lempel trie. J. of Discrete Algo13.
 Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Computing Surveys

407–430 (2001)

rithms 2(1), 87–114 (2004)

(to appear)

14. Sadakane, K.: New text indexing functionalities of the compressed suﬃx arrays. J.

of Algorithms 48(2), 294–313 (2003)

15. Weiner, P.: Linear pattern matching algorithm. In: Proc. 14th IEEE Symp. on

Switching and Automata Theory, pp. 1–11 (1973)

