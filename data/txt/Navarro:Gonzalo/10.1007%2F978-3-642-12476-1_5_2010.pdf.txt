Extended Compact Web Graph Representations

Francisco Claude1,(cid:2) and Gonzalo Navarro2,(cid:2)(cid:2)

1 David R. Cheriton School of Computer Science, University of Waterloo

2 Department of Computer Science, University of Chile

fclaude@cs.uwaterloo.ca

gnavarro@dcc.uchile.cl

Abstract. Many relevant Web mining tasks translate into classical algorithms 
on the Web graph. Compact Web graph representations allow
running these tasks on larger graphs within main memory. These representations 
at least provide fast navigation (to the neighbors of a node),
yet more sophisticated operations are desirable for several Web analyses.
We present a compact Web graph representation that, in addition,
supports reverse navigation (to the nodes pointing to the given one).
The standard approach to achieve this is to represent the graph and
its transpose, which basically doubles the space requirement. Our structure,
 instead, represents the adjacency list using a compact sequence
representation that allows ﬁnding the positions where a given node v is
mentioned, and answers reverse navigation using that primitive. This is
combined with a previous proposal based on grammar compression of the
adjacency list. The combination yields interesting algorithmic problems.
As a result, we achieve the smallest graph representation reported in the
literature that supports direct and reverse navigation, and also obtain
other variants that occupy relevant niches in the space/time tradeoﬀ.

1 Introduction and Related Work

The Web can be modeled as a directed graph: every page corresponds to a node
and every link between two pages is represented as a directed edge between the
corresponding nodes. This so-called “Web graph” contains an enormous amount
of useful information, which is used for a wealth of purposes, from technical (such
as improving search engines) to economic (such as detecting potential customers)
to scientiﬁc (such as carrying out sociological studies).

Methods to discover Web communities, Web spam, Web structure, hubs and
authorities, and many others, rely on classical graph algorithms. Donato et
al. [16] show how several common Web mining techniques used to discover the
structure and evolution of the Web graph build on classical graph algorithms
such as depthand 
breadth-ﬁrst-search, reachability, and weakly and strongly
connected components. Saito et al. [28] presents a technique for Web spam detection 
that boils down to algorithms for ﬁnding strongly connected components,
(cid:2) Funded by NSERC of Canada and Go-Bell Scholarships Program.
(cid:2)(cid:2) Funded in part by Fondecyt Grant 1-080019, and by Millennium Institute for Cell

Dynamics and Biotechnology, Grant ICM P05-001-F, Mideplan, Chile.

T. Elomaa et al. (Eds.): Ukkonen Festschrift, LNCS 6060, pp. 77–91, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010

78

F. Claude and G. Navarro

for clique enumeration, and for minimum cuts. A simple representation that allows 
direct navigation (to the nodes pointed from the current one) suﬃces for
these purposes. Yet, there are other important applications where eﬃcient reverse 
navigation (to the nodes pointing to the current one) is also necessary. The
HITS algorithm [23] to ﬁnd hubs and authorities on the Web starts by selecting 
random pages and ﬁnding the induced subgraphs, which are the pages that
point to or are pointed from the selected pages [22]. Uniform sampling methods 
[27] also require direct and reverse navigation, and are usually replaced by
suboptimal alternatives due to the diﬃculty of implementing the latter.

An important limitation when processing this kind of graphs is their size.
Many of the graph algorithms we mentioned are not disk-friendly, and thus the
sizes of the graphs that can be analyzed by the Web mining applications, and
consequently the quality of their results, is limited by the main memory size.
Much eﬀort has been spent in representing Web graphs in compressed form, so
that the direct neighbors of a node can be eﬃciently retrieved [10,1,30,8,13].
Boldi and Vigna [8] achieve currently the least space combined with eﬃcient
navigation. In later work [13,14] we introduced the use of grammar compression
of the adjacency lists (more precisely, Re-Pair [24]). This required more space
than the best achievable by Boldi and Vigna, but when both methods used the
same space, ours was faster. Other techniques [4], instead, achieve even less space
than Boldi and Vigna, yet with much higher access times.

By essentially doubling the space of these solutions, one can represent the
graph and its transpose, thus providing reverse navigation as well. Needless to
say, adding such an amount of redundancy is against the goal of providing a
compact representation. The only approach we know of where direct and reverse
navigation is supported [9], the k2-tree, is based on representing the adjacency
matrix in a way that takes advantage of its sparseness. They achieve similar
times for direct and reverse queries.
In this work we introduce an alternative way of supporting direct and reverse
navigation. Let G = (V, E) be our graph, where n = |V | and m = |E|. We resort
to previous work by regarding G as a binary relation on V × V , and then use the
techniques of Barbay et al. [5], where forward and reverse traversal operations
can be solved in time O(log log n) per node delivered. A more recent followup
[6] retains those times and reduces the space to the worst-case entropy of the
binary relation, that is, log

(our logarithms are in base 2).

This worst-case compression, however, is poor for Web graphs, as these are
far from random in the Erd˜os-R´enyi sense [17]. To illustrate this, we downloaded
four Web crawls from the WebGraph project1, which will be used for the experiments 
along the article. Table 1 shows their main characteristics. The third
column shows the size (in bits per edge, bpe) required by a plain adjacency
list representation using 4-byte integers. The fourth column shows the space
required for a plain representation of the graph plus its transpose. The ﬁfth column 
shows the lower bound given by the worst-case entropy, and the last column

(cid:3)

(cid:2)
2
n
m

1

http://law.dsi.unimi.it

Extended Compact Web Graph Representations

79

Table 1. Some characteristics of the four crawls used in our experiments, as well as
expected space usage (in bpe) with some known methods

Edges

Nodes
Crawl
862,664 19,235,140
EU
7,414,866 194,109,311
Indochina
UK (2002) 18,520,486 298,113,762
22,744,080 639,999,458
Arabic

Plain 2×Plain Bin.Rel. Re-Pair
7.65
20.81
4.54
23.73
7.50
25.89
25.51
5.53

41.62
47.46
51.78
51.02

15.25
17.95
20.13
19.66

the space actually achieved by the best method based on Re-Pair compression
[13] for the direct plus the transposed graph. This shows that the worst-case
entropy measure is a poor estimation of the compression that can be achieved.
In this article we combine our previous technique based on Re-Pair [13], which
has been successful to compress Web graphs while supporting direct navigation,
with the binary relation idea [5]. The latter boils down to representing the adjacency 
lists using a sequence representation that allows ﬁnding the occurrences
of a symbol (that is, the places where a given node v is mentioned in some list),
and then ﬁnd the reverse neighbors using this primitive. The combination with
grammar compression poses some interesting algorithmic problems, however, because 
the compressed text is a sequence of terminals and nonterminals and thus
the technique cannot be directly applied. The result achieves forward and reverse
navigation within competitive times, and signiﬁcantly less space, than representing 
the direct plus the transposed graph using previous techniques. Depending on
the compact data structure we use to represent the sequence, we obtain, on one
hand, the smallest reported space for a structure that supports bidirectional navigation 
(indeed, within O(log n) time per delivered neighbor); and on the other, a
faster (O(log log n) time) and larger data structure that occupies a relevant niche
in the space/time tradeoﬀ of the current state of the art.

2 Basic Concepts

2.1 Compact Data Structures for Sequences

A compact data structure aims at representing the same data as its classical
counterpart in little space, while still supporting interesting queries without expanding 
the whole data structure. Sometimes compact data structures require
more time per query in theory, but since they use less space, they can ﬁt in
smaller and faster memories. This important advantage allows them to outperform 
their classical counterparts, especially if we consider the scenario where the
classical version of the data structure has to resort to disk, while the compact
data structure ﬁts in main memory.

A basic tool used in many compact data structures is the bitmap with rank
and select capabilities [25]. Consider a binary string B[1, n] We support the
following queries:

80

F. Claude and G. Navarro

– rank B(b, i): counts how many times the bit b appears in the preﬁx B[1, i].
– select B(b, j): returns the position of the j-th occurrence of bit b in B.
– access B(i): retrieves B[i].

Clark [12] proposed a solution that achieves constant time for the queries and
requires n + o(n) bits. This was later improved by Raman, Raman and Rao
(RRR) [26]. They achieved constant time for the queries while using nH0(B) +
o(n) bits, where H0 represents the zero-order entropy. The zero-order (empirical)
entropy of a sequence S, drawn from an alphabet Σ of size σ, is deﬁned as
H0(S) = − (cid:4)
c∈Σ pc log pc ≤ log σ, where pc = nc/n and nc is the number of
occurrences of character c in S.
Rank/select/access queries naturally extend to sequences, where b ∈ Σ. A
sequence representation supporting these primitives is the wavelet tree [20,25],
which achieves O(log σ) time per query and requires n log σ+o(n) log σ bits. The
wavelet tree stores a number of bitmaps, which can be compressed using RRR,
in which case the space requirement drops to nH0(S) + o(n) log σ bits.

Golynski, Munro, and Rao (GMR) [18] presented another representation that
achieves time O(log log σ) for rank and access, and O(1) for select. Alternatively,
 they can achieve O(1) time for access, O(log log σ) for select, and O
(log log σ log log log σ) for rank. The structure requires n log σ + n o(log σ) bits.
Note both structures replace the sequence. Claude and Navarro [15] carried
out a practical evaluation of rank/select/access capable bitmap and sequence
representations. They included a simpliﬁed version of GMR for the case n ≈ σ,
which we call chunk. The chunk proved to be very fast for large alphabets, while
requiring little extra space on top of n log σ. Wavelet trees, on the other hand,
not only supported the three queries, but also were shown to be an interesting
alternative for compressing sequences over large alphabets, where classical methods 
like Huﬀman fail due to the alphabet representation overhead. The paper
also showed how to omit the pointers of the wavelet tree while preserving its
time performance, which saves much space overhead on large alphabets.

2.2 Re-Pair Compression of Web Graphs

Re-Pair [24] is a grammar-based compression algorithm consisting of repeatedly
ﬁnding the most frequent pair of symbols in a sequence of integers and replacing
it with a new symbol, until no more replacements are convenient. Re-Pair works
as follows over a sequence L: (1) It identiﬁes the most frequent pair ab in L. (2)
It adds the rule s → ab to a dictionary R, where s is a new symbol not appearing
in L. (3) It replaces every occurrence of ab in L by s. (4) It iterates until the
replacements do not compensate for the increase of R.

We call C the sequence resulting from L after compression. Every symbol in
C represents a phrase (a substring of L), which is of length 1 if it is an original
symbol (called a terminal) or longer if it is an introduced one (a nonterminal).
Any phrase can be recursively expanded in optimal time (that is, proportional
to its length), even if C is stored on secondary memory (as long as the dictionary
of rules R is kept in RAM).

Extended Compact Web Graph Representations

81

T(G)

Rule f −> cd 

Rule g −> af 

Pointers

a

a

a

g

a

a

a

g

g

b

c

f

b

d

c

d

b

g

e

d

b

a

c

f

e

a

f

d

e

d

e

e

c

c

e

d

d

d

c

e

f

d

d

e

e

f

e

d

e

c

e

Fig. 1. A small example graph, its T (G) representation, the Re-Pair compression of it,
and the ﬁnal replacement of the ¯vis by pointers

Re-Pair can be implemented in linear time [24]. However, this requires several 
data structures to track the pairs that must be replaced. This is problematic 
when applying it to large sequences. We developed an approximate version
[13,14] that requires little space on top of the sequence.

In our proposal [13] to represent a Web graph G, each node v has a special
identiﬁer ¯v to mark the beginning of its adjacency list. The representation of the
graph, T (G), is the concatenation of the representations of all the adjacency lists,
deﬁned as T (vi) = ¯vivk1 vk2 . . . vkr where vkj , 1 ≤ j ≤ r, are the nodes pointed
from vi. Now T (G) is compressed using Re-Pair. Since symbols ¯vi are unique,
they stay as terminals in C. Therefore adjacency lists correspond to substrings in
C, and thus can be decompressed in optimal time. The values ¯vi are afterwards
removed from the sequence, and instead n pointers to the beginning in C of the
list of each node is stored (in about the same space gained with the removal of the
¯vis). This allows direct navigation in optimal time, but not reverse navigation.
Later [14], we proposed several variations achieving better space/time. Figure 1
illustrates the process for a small graph.

2.3 Representing the Re-Pair Rules

The dictionary R can be represented as an array of pairs of integers, or in
some compact form. We use a representation [19] that reduces it to about 50%
while retaining eﬃcient access to R. The set of rules can be seen as a directed
acyclic graph of outdegree 2 where internal nodes are nonterminals and leaves
are terminals. This is converted into a forest of binary trees, where nonterminal
leaves signal shared subtrees. The forest is represented as a sequence RS of leaf
values and a bitmap RB that deﬁnes the tree shape. Nonterminals are identiﬁed
with the starting position of the (sub)tree that deﬁnes them in RB. In RB, the
trees are described by a preorder traversal where a 1 represents an internal node
(with 2 children) and a 0 represents a leaf. The (terminal or nonterminal) leaf
value corresponding to RB[i] = 0 can be found at RS[rank RB(0, i)].
For example, the set of rules c → ab, d → cb, e → ac, f → ed and g → ae,
over terminals {a, b}, can be represented as shown in Figure 2. We have RB =
110011000100 and RS = a6abba2, where the ‘6’ represents the nonterminal ‘c’,
whose tree is at position 6 in RB; similarly ‘2’ represents ‘e’.

82

F. Claude and G. Navarro

g

f

f

g

a

e

d

e

a

c

b

a

c

c

a

b

a

a

e

d

b

b

Position

RB
RS

1
= 1
=

2
1

3
0
a

4
0
6

5
1

6
1

7
0
a

8
0
b

9
0
b

10
1

11
0
a

12
0
2

Fig. 2. Example of our representation of Re-Pair rules. Top left: the initial DAG. Top
right: the forest representation. Bottom: Encoding with RB and RS.

To expand a given nonterminal at position i in RB, we scan RB[i . . .] until we
have seen more 0s than 1s, and then collect all the consecutive leaf values. Leaf
values corresponding to nonterminals must be recursively expanded.

3 A Simple Representation Based on Binary Relations

We note that sequence T (G) (without Re-Pair compression), armed with symbol
rank and select operations, is already able of handling an extended set of queries
that includes reverse navigation, using an approach similar to Barbay et al.’s [5].
Assume we store a bitmap B marking the positions of T (G) where each adjacency
list starts, more precisely, of the positions of the ¯vis: start(vi) = select T (G)(¯vi, 1).
We will also use operation pred(i) = select B(1, rank B(1, i)) that ﬁnds the last 1
up to position i in B. We can support the following queries. Note |T (G)| = n+m.
– outdegree of vi: it is start(vi+1) − start(vi) − 1.
– the k-th direct neighbor of vi: it is T [start(vi) + k].
– indegree of vi: it is rank T (G)(vi, m + n), the number of times vi is mentioned

in some adjacency list.

identiﬁer ¯v of the k-th reverse neighbor.

– the k-th reverse neighbor: T [pred(select T (G)(vi, k))] gives the corresponding
– edge (vi, vj) exists: if rank T (G)(vj , start(vi+1))−rank T (G)(vj, start(vi)) = 1.
In practice we remove the ¯vis from T (G) and set n pointers S[vi] to the beginning 
of each list, so that start(vi) = S[vi] and the k-th reverse neighbor
becomes rank B(select T (G)(vi, k)),2 and the slow-in-practice [15] select B operation 
is totally avoided. Array S requires n log m bits of space. Bitmap B requires
2 Nodes with zero outdegree must be handled somehow so that they do not interfere
with rank B, for example by marking them in another bitmap, or renumbering them
after all the other nodes.

Extended Compact Web Graph Representations

83

Table 2. Size required by our simple representation, using wavelet trees without pointers 
and RRR for the bitmaps [15], measured in bpe. The last column adds up the
Re-Pair representations for the original and transposed graph.

Crawl
EU
Indochina
UK
Arabic

Wavelet Tree

13.67
14.16
15.05
15.30

Plain
20.81
23.73
25.89
25.51

Bin.Rel. Re-Pair
15.25
17.95
20.13
19.66

7.65
4.54
7.50
5.53

at most mH0(B) + o(m) = n log m
n + O(n) + o(m) bits using RRR (Section 2.1).
The remaining T (G) can be represented using GMR (Section 2.1), requiring
m log n+m o(log n) bits. The total space used is m log n+O(n log m)+o(m log n)
bits. This is basically the space of a plain adjacency list representation, yet we
have the extended functionality. On the other hand, the upper bound is higher
m + O(m) worst-case entropy of the graph. Operathan 
the log
tions outdegree, indegree, and reverse neighbors are carried out in constant time
per delivered datum3, whereas checking existance of edges and retrieving direct
neighbors cost O(log log n).

= m log n

(cid:2)
2
n
m

(cid:3)

2

(cid:4)

ni log m

With a wavelet tree representation, instead, every delivered direct or reverse
neighbor (and checking edge existance) takes O(log n) time, but T (G) can be
compressed to mH0(T (G)) + o(m) log n bits. Let ni be the indegree of node vi,
thus vi appears ni times in T (G). Then mH0(T (G)) =
ni . Web graphs
are known to have varying indegrees: a Zipf-distribution with parameter θ = 2.1
has been observed [2,10]. Under this distribution we obtain mH0(T (G)) = c ·
−θ)−1 ≈ 0.58. On the other hand,
m log n + O(m), with c = ((θ − 1)
=
m/n is around 15–30 on Web graphs, so the worst-case entropy is log
m log n − O(m). Table 2 shows that this representation takes less space than a
plain adjacency list (which does not answer reverse queries) on our four Web
crawls, by a factor remarkably close to 0.58 (except on the smaller EU, where
it is 0.65). It also takes less space than the worst-case graph entropy. Still, the
last column reminds us that it is still far from the state of the art. In the next
section we will combine this idea with Re-Pair compression.

(cid:2)
2
n
m

i≥1 i

(cid:4)

(cid:3)

4 Combining Re-Pair with Binary Relations

The result of the previous section makes it clear that we cannot go too far with
zero-order compression of T (G) or the graph binary relation. Re-Pair is much
more successful. In fact, Re-Pair compression on graphs can be regarded as (and
attribute its success to) the decomposition of the graph binary relation into two:
– Nodes are related to the Re-Pair symbols that conform their (compressed)

adjacency list.

– Re-Pair symbols are related to the graph nodes they expand to.

3 For indegree one needs to use other n log m bits, otherwise it costs O(log log n).

84

F. Claude and G. Navarro

The regularities exposed by this factorization go well beyond those captured by
the worst-case entropy of the original binary relation or zero-order entropy of
its sequence representation. In very broad terms, we attempt at representing the
graph as the composition of these two binary relations. Using the technique of
Barbay et al. [5], each direct neighbor would be retrieved in time O(log log n),
by ﬁnding all the Re-Pair symbols that conform its adjacency list (ﬁrst relation)
and then the graph nodes each such symbol expands to (second relation).

Finding the reverse neighbors of node v, on the other hand, is harder. We
should ﬁrst ﬁnd all the Re-Pair symbols (nonterminals) that expand to v (second
relation), and then, for each such symbol, all the nodes in which adjacency list
the symbol participates (ﬁrst relation). The problem is that many nonterminals
exist in the dictionary for the sake of structuring the grammar but do not appear
in C, and thus we can carry out much work that does not lead to any result.
A further challenge is that representing the second binary relation as such,
with the rules in fully expanded form, could require space ω(|R|). Thus we must
use the representation of Section 2.3 for the second binary relation, and this
complicates the operations we must carry out on it. We describe now our solution.

4.1 Representation

We apply our simple sequence representation of Section 3 on top of the RePair 
compressed T (G), instead of on the plain sequence. We compress T (G)
and represent sequences C and RS not in plain form, but instead using a
rank/select/access capable representation (see Section 2.1). This can be either:

– The GMR representation. It does not compress C or RS any further, but it
provides access and symbol rank in time O(log log n) (yet typically constant),
and symbol select in constant time.

– A wavelet tree. The operations are carried out in O(log n) time, but the
representation compresses further T (G) up to its zero-order entropy. Albeit
signiﬁcantly slower, this achieves unprecedented space results, as we see later.

Extraction of the direct neighbors is done exactly as in previous work [13], using
access on the sequences C and RS to expand the list of the desired node.

4.2 Extracting Reverse Neighbors

As explained, to ﬁnd reverse neighbors of v we must consider that v may appear
not only explicitly in C, but also implicitly, in the form of a nonterminal that
expands to v. Given our representation of the rules R, we must look for v in RS
and, for each occurrence, collect all of its ancestors in RB, and look for each of
them in C. Because each such ancestor might appear in RS again (due to the
conversion of the DAG into a forest) and have further ancestors, the process has
to be repeated recursively for every ancestor found.

The occurrences of vi (or, recursively, any other nonterminal) in RS are obtained 
using select RS (vi, k). In order to extract the ancestors, we can use an alternative 
representation for RB called LOUDS [21]. LOUDS represents each leaf

Extended Compact Web Graph Representations

85

For k ← 1 to rankC (v, |C|) Do

occ ← selectC(v, k)
report rankB(1, occ)

rev-adj(v)
1.
2.
3.
4.
5.
6.
7.

For k ← 1 to rankRS (v, |RS|) Do

occ ← selectRS (v, k)
For each s ancestor of RS[occ] in RS Do

rev-adj(s)

Fig. 3. Obtaining the reverse adjacency list

with a 0 and has been shown to be very eﬀective when only parent/child traversals 
are required [3], which makes it ideal for our purpose. We adapt LOUDS to
binary forests as follows. Let f be the number of trees in the dictionary forest.
The forest is traversed level-wise and left-to-right within each level, and for each
node found we write a 1 if the node has (two) children and a 0 if not. In Figure 2,
f = 2 and RB = 111100001000. Each node is identiﬁed with its corresponding
bit position i ≥ 1. Now, LOUDS formulas become as follows:
– childlef t/right(i) = f − 1 + 2 · rank RB(i, 1) + 0/1,
– parent(i) = select RB((cid:7)(i − f + 1)/2(cid:8))
We call this solution GMR LOUDS*. Although constant-time in theory, this solution
resorts to select on bitmaps, which is not that fast in practice [15]. An alternative,
less sophisticated, solution is to mark the beginning of the top-level trees of RB
in another bitmap. Then we unroll the whole tree containing the occurrence in
RS and spot the ancestors. We call this second solution GMR.

(i is a root if i ≤ f).

Figure 3 shows the algorithm for retrieving the reverse neighbors. We use the
bitmap B that marks the beginning of each adjacency list in C. This bitmap is
included in the original structure [14], so it does not add any more space and
allows us to determine to which list a position in C belongs.

No reverse neighbor is reported twice: Even if we ﬁnd several times the same

position of C along the process, it will be for diﬀerent occurrences within C.

On the other hand, we are not providing any time guarantee for the process,
because as explained we might do sterile work for ancestors in RB which do not
appear in C. For the others we obtain at least one occurrence per access to the
sequences. We address this problem next.

5 Guaranteeing Reverse Neighbor Retrieval Time

A way to alleviate the problem in practice is to include a bitmap, parallel to
RB, which indicates, for each internal node, whether or not it appears in C or in
RS. This can be combined either with the LOUDS or the basic representation of
RB. Each time we ﬁnd an ancestor, the parallel bitmap indicates immediately
whether it is worth paying the eﬀort of looking for it in C and RS. Indeed, given
the negligible cost of such a bitmap, we opt for storing two of them: one referring

86

F. Claude and G. Navarro

to C and the other to RS. This helps us limiting further unnecessary searches,
although we still pay a constant-time cost to process useless nodes. We will test
these bitmaps in combination with binary-tree LOUDS (GMR LOUDS* M), with
general LOUDS (GMR LOUDS M, just to test it loses to the previous one), and
with the basic representation (GMR M).

An alternative to achieve a logarithmic-time guarantee per retrieved neighbor
is to use balanced Re-Pair [29], which enforces logarithmic rule heights. Since
the roots of the DAG must appear in C, in the worst case we pay O(1) time to
discard (using the bitmaps introduced above) each element of an upward path
(of length now limited to O(log m)), except the root. As the root yields at least
one neighbor, we can charge this O(log m) time to that result.

A solution that guarantees a constant number of operations on the sequences
per reverse neighbor delivered is to eﬀectively remove from the forest those nodes
that do not appear in C nor in RS. The children of the removed node become
children of their former grandparent. This can be done precisely because those
nodes will not be accessed from elsewhere. The result is not anymore binary, but
a general tree that is represented with the original LOUDS format [21,3]. Now
we can prove our result.

Lemma 1. Using the reduced tree, we pay O(1) operations on the sequences per
reverse neighbor delivered.

Proof. Consider the original DAG with the useless nodes removed. Then each
node either (a) is a root, (b) appears in C, or (c) has at least two parents (i.e.,
appears again in RS). The algorithm in Figure 3 is equivalent to starting from
some arbitrary node and traversing the DAG upwards, so that a constant number
of operations on RS, RB and C are carried out (i) per DAG node considered
and (ii) per result retrieved. We focus on (i). Nodes of type (a) and (b) yield at
least one result, so their cost can be absorbed by (ii). For nodes of type (c), they
have at least two parents, and thus each unit of work invested on them increases
(cid:9)(cid:10)
at least by 1 the number of results to report.

Therefore, combined with GMR representation, we recover the constant time per
reverse neighbor we had in Section 3. This representation is called GMR LOUDS in
the experiments.

6 Experimental Results

The experiments were run on a 2GHz Intel Xeon (8 cores) with 16 GB RAM,
running Ubuntu GNU/Linux with kernel 2.6.22-14 SMP (64 bits). The code was
compiled with g++ using the -O9 directive.

From the several Re-Pair based versions studied in previous work [14], we
chose “Reord CDict NoPtrs”. For the wavelet trees we used the version without
pointers [15]. For the GMR structure we used the simpler and faster chunk
variant [15], as the grown alphabet after running Re-Pair on T (G) (originally n)
and the reduced length (originally m) become suﬃciently similar.

Extended Compact Web Graph Representations

87

Table 3. Space consumption (in bpe) of the Re-Pair based compressed representations
of the adjacency lists, and previous work

Crawl

Re-Pair

EU
Indochina
UK
Arabic

WT
3.93
2.30
3.98
2.72

Re-Pair
GMR
5.86
3.65
6.22
4.15

Re-Pair
(dir+rev)

k2-tree WebGraph
(dir+rev)

7.65
4.54
7.50
5.53

5.20
2.82
4.20

7.20
2.94
4.34
3.25

Asano
×2
5.56

We ﬁrst focus on achieving minimum space usage, while still retrieving direct
and reverse neighbors within reasonable time, that is, much faster than decompressing 
the whole graph. Later we focus on the faster alternatives. The space
we report does not include special bitmaps for computing in/outdegrees.

Table 3 shows the space required for the four crawls. The ﬁrst two columns
are our contributions. In column Re-Pair WT we represent C and RS using
a compressed wavelet tree with sample value 64 [15] (space decreases by about
0.20 bpe more with larger sample values, but retrieval times degrade). In column
Re-Pair GMR we show the representation that combines Re-Pair with a GMR
chunk. Next columns are previous alternatives. Column Re-Pair shows the space
needed by Re-Pair compression (variant “Diﬀs CDict NoPtrs”) of the graph plus
its transpose (so as to support direct and reverse queries) [13]. Column k2-tree
gives the smallest space achieved by that technique [9] (the space for the largest
graph, Arabic, is not reported in there, and we could not build it either).

Column WebGraph gives the space achieved by the WebGraph technique [7],
version 2.4.2, using variant strictHostByHostGray, which gave the best results.
We add up the space for the direct and the transposed graph. We account only
the space the structure requires on disk, even if the process requires much more
memory to run. On the other hand, we account for their “oﬀset” structure,
which is the one providing direct access to the neighbors (without the oﬀsets,
the structure degenerates into a pure compression scheme). For this experiment
we set the parameters so as to largely favor compression over speed (window size
10, maximum reference unlimited). With this compression they retrieve direct
neighbors in about 100 microseconds.
Finally, column Asano×2 shows the space achieved by Asano et al. [4] on
the EU graph (which is the largest graph they report). We double the space to
account for the transposed graph. The time they report is over 1 millisecond per
neighbor retrieved, whereas typical times (as shown next) are a few microseconds.
Doubling the space is a bit pessimistic, as the transposed graph compresses
slightly better, but still the diﬀerence with Re-Pair WT is signiﬁcant, and this
was the only reasonable way we found to try including them in the comparison.
We observe that our techniques require less space than adding up direct and
reverse Re-Pair compressed graphs, while achieving good performance, as we
see soon. By combining with a wavelet tree, on the other hand, we achieve
the smallest space reported in the literature while supporting direct and reverse
neighbors in reasonable time: around 35 microseconds/edge for direct and 55 for

88

F. Claude and G. Navarro

EU

UK

)
e
g
d
e
/
c
e
s
o
r
c
i
m
(
 
e
m
i
t

 5

 4

 3

 2

 1

 0

GMR
GMR Rev
GMR M
GMR M Rev
GMR LOUDS*
GMR LOUDS* Rev
GMR LOUDS* M
GMR LOUDS* M Rev
GMR LOUDS M
GMR LOUDS M Rev
GMR GLOUDS
GMR GLOUDS Rev

 12

 10

 8

 6

 4

 2

)
e
g
d
e
/
c
e
s
o
r
c
i
m
(
 
e
m
i
t

GMR
GMR Rev
GMR M
GMR M Rev
GMR LOUDS*
GMR LOUDS* Rev
GMR LOUDS* M
GMR LOUDS* M Rev
GMR LOUDS M
GMR LOUDS M Rev
GMR GLOUDS
GMR GLOUDS Rev

 5.6

 5.8

 6

 6.2

 6.4

 6.6

 6.8

 7

 0

 6.1

 6.2

 6.3

 6.4

 6.5

 6.6

 6.7

 6.8

space (bits/edge)

space (bits/edge)

Fig. 4. Space/time tradeoﬀs of the diﬀerent dictionary representations

reverse neighbors. The next experiments show that, using more space, one can
reduce these times by an order of magnitude. However, no alternative scheme
can operate within tens of microseconds and achieve the space of Re-Pair WT.
Figure 4 shows direct and reverse neighbor retrieval times on two crawls, for
the diﬀerent alternatives studied in Sections 4.2 and 5. Reverse retrieval times
are marked Rev. As it can be seen, the general LOUDS versions (without modiﬁer
“*”) lose to the simpler ones, and also the idea of marking nodes (suﬃx “M”)
does not pay oﬀ. The space/time map is dominated by GMR and GMR LOUDS*.
We use GMR for the rest of the experiments.

Figure 5 shows retrieval times obtained for the four crawls, for both forward
and reverse neighbors. We include only the techniques that are most competitive
in time: WebGraph (storing both direct and reverse graphs), Re-Pair (storing
both direct and reverse graphs), Re-Pair GMR (ours), and k2-trees (variants
called Hybrid5 and Hybrid37, which give the best space/time tradeoﬀs [9]). We
also include a variant of Re-Pair GMR labeled “(2)”, where we use the variant
of GMR that solves access in O(1) time and select in time O(log log n). Thus,
while Re-Pair GMR is faster for reverse neighbors (using constant-time select),
Re-Pair GMR (2) is faster on direct neighbors (using constant-time access)4.
When times are not constant, an internal sampling used to compute an inverse
permutation produces the observed space/time tradeoﬀ.

Re-Pair GMR is not as fast as Re-Pair (at best, 3 times slower), but it requires
signiﬁcantly less space (about 25%). The k2-tree (with variant Hybrid5) can
achieve about 13% less space than the second point of Re-Pair GMR (recall that
k2-tree used much more space than Re-Pair WT, but it is much faster than it).
Yet, when using that space, it is either 4–7 times slower for direct neighbors and
1.0–1.5 times faster for reverse neighbors (if using our variant (2)), or about 3–5
times slower for reverse neighbors and similar for direct neighbors (if using our

4 Alternatively, we could have used the original structure and index the transposed
graph, but this turned out not to be a good idea: compression of the reverse graph
generates many more dictionary symbols and deeper dictionary trees, and thus both
queries are slower than on Re-Pair GMR (2).

Extended Compact Web Graph Representations

89

EU

Re-Pair Direct
Re-Pair Reverse
Re-Pair GMR Direct
Re-Pair GMR Reverse
Re-Pair GMR Direct (2)
Re-Pair GMR Reverse (2)
Hybrid5 Direct
Hybrid5 Reverse
Hybrid37 Direct
Hybrid37 Reverse
WebGraph
WebGraph Reverse

 6

 5

 4

 3

 2

 1

)
e
g
d
e
/
c
e
s
o
r
c
i
m
(
 
e
m
i
t

Indochina

Re-Pair Direct
Re-Pair Reverse
Re-Pair GMR Direct
Re-Pair GMR Reverse
Re-Pair GMR Direct (2)
Re-Pair GMR Reverse (2)
Hybrid5 Direct
Hybrid5 Reverse
Hybrid37 Direct
Hybrid37 Reverse
WebGraph
WebGraph Reverse

 5

 6

 7

 8

 9

 10

 11

 12

 13

 0

 3

 3.5

 4

 4.5

 5

space (bits/edge)

UK

Re-Pair Direct
Re-Pair Reverse
Re-Pair GMR Direct
Re-Pair GMR Reverse
Re-Pair GMR Direct (2)
Re-Pair GMR Reverse (2)
Hybrid5 Direct
Hybrid5 Reverse
Hybrid37 Direct
Hybrid37 Reverse
WebGraph
WebGraph Reverse

 7

 6

 5

 4

 3

 2

 1

)
e
g
d
e
/
c
e
s
o
r
c
i
m
(
 
e
m
i
t

space (bits/edge)

Arabic

Re-Pair Direct
Re-Pair Reverse
Re-Pair GMR Direct
Re-Pair GMR Reverse
Re-Pair GMR Direct (2)
Re-Pair GMR Reverse (2)
WebGraph
WebGraph Reverse

 5

 4

 3

 2

 1

)
e
g
d
e
/
c
e
s
o
r
c
i
m
(
 
e
m
i
t

 0

 4

 20

 15

 10

 5

)
e
g
d
e
/
c
e
s
o
r
c
i
m
(
 
e
m
i
t

 0

 4

 4.5

 5

 5.5
 6.5
space (bits/edge)

 6

 7

 7.5

 8

 0

 3

 4

 5

 6

 7

 8

space (bits/edge)

Fig. 5. Space/time tradeoﬀs of the most competitive variants

ﬁrst variant). A nice point in k2-tree is that it is symmetric (in technique and
time) to obtain forward or reverse neighbors. A nice point in our structure is
that, if one is interested mainly in direct or reverse neighbors, one can choose one
of the two alternatives and be much faster on those queries, while still supporting
the others in reasonable time. Adding up both times, we see that our alternative
would be very close to Hybrid37, in space and time, if both direct and reverse
neighbors had to be obtained. (An exception is graph UK, where k2-tree is 35%
smaller than Re-Pair GMR, but siginiﬁcantly slower in all aspects.)

For WebGraph we show the curves reaching as much as possible to the left;
using less space yields a sudden increase in time. The comparison with our
technique is mixed. On EU and Arabic, WebGraph cannot approach the space we
use (while maintaining reasonable retrieval performance). On Indochina, both
achieve comparable results. On UK, instead, WebGraph dominates.

7 Conclusions

We introduced a technique to represent Web graphs in compressed form so that
not only fast access to the (direct) neighbors is supported, but also to the reverse 
neighbors (that is, nodes pointing to a given one). This has many applications 
to several Web analysis and mining tasks, where the memory limitations
pose serious obstacles to analyzing massive graphs. Our representation combines 
grammar-based compression with compact data structures for sequences

90

F. Claude and G. Navarro

that represent the compressed adjacency lists relations, and for trees that represent 
the grammar DAG. We provide several solutions, which support direct and
reverse neighbor retrieval within a time that ranges from constant to logarithmic.
We achieve several relevant space/time tradeoﬀs. On one hand, we achieve
the most compact functional Web graph representation reported up to date. On
a sample of Web crawls, it required 2.3–4.0 bits per edge (bpe) while supporting
direct and reverse navigation within a few tens of microseconds per neighbor.
The best alternatives require 2.8–5.2 bpe for the same functionality. Compared
to a 2 × 32-bit plain representation of the graph plus its transpose, we allow
handling graphs 15–30 times larger within the same main memory.

If slightly more space is available, our faster representation requiring 3.6–6.5
bpe is of interest. It supports direct and reverse navigation within 1–3 microseconds 
per neighbor, occupying a relevant niche among alternative representations.
It would be of interest to extend this research to the compression of other
types of networks with similar characteristics. For example, compression of social
networks is starting to receive attention [11]. These share some characteristics
with Web graphs, yet they have other unique ones such as reciprocity in links
and presence of relatively large cliques or bicliques. In particular, many social
networks are undirected. With current techniques, the representation of an undirected 
graph forces either to duplicate each edge {u, v} as (u, v) and (v, u), or
to choose arbitrarily from both, but then the (undirected) neighbors of v will
be the union of its direct and reverse neighbors under this representation. Data
structures like ours ours are ideal for this scenario.

References

1. Adler, M., Mitzenmacher, M.: Towards compressing Web graphs. In: Proc. 11th

DCC, pp. 203–212 (2001)

2. Aiello, W., Chung, F., Lu, L.: A random graph model for massive graphs. In: Proc.

32th STOC, pp. 171–180 (2000)

3. Arroyuelo, D., C´anovas, R., Navarro, G., Sadakane, K.: Succinct trees in practice.

In: Proc. 11th ALENEX, pp. 84–97 (2010)

4. Asano, Y., Miyawaki, Y., Nishizeki, T.: Eﬃcient compression of Web graphs. In:
Hu, X., Wang, J. (eds.) COCOON 2008. LNCS, vol. 5092, pp. 1–11. Springer,
Heidelberg (2008)

5. Barbay, J., Golynski, A., Munro, I., Rao, S.S.: Adaptive searching in succinctly
encoded binary relations and tree-structured documents. In: Proc. 17th CPM, pp.
24–35 (2006)

6. Barbay, J., He, M., Munro, I., Rao, S.S.: Succinct indexes for strings, binary relations 
and multi-labeled trees. In: Proc. 18th SODA, pp. 680–689 (2007)

7. Boldi, P., Santini, M., Vigna, S.: Permuting web graphs. In: Avrachenkov, K.E.,
Donato, D., Litvak, N. (eds.) WAW 2009. LNCS, vol. 5427, pp. 116–126. Springer,
Heidelberg (2009)

8. Boldi, P., Vigna, S.: The WebGraph framework I: compression techniques. In: Proc.

13th WWW, pp. 595–602 (2004)

9. Brisaboa, N.R., Ladra, S., Navarro, G.: k2-trees for compact web graph representation.
 In: Hyyro, H. (ed.) SPIRE 2009. LNCS, vol. 5721, pp. 18–30. Springer,
Heidelberg (2009)

Extended Compact Web Graph Representations

91

10. Broder, A., Kumar, R., Maghoul, F., Raghavan, P., Rajagopalan, S., Stata, R.,
Tomkins, A., Wiener, J.: Graph structure in the Web. Journal of Computer Networks 
33(1-6), 309–320 (2000)

11. Chierichetti, F., Kumar, R., Lattanzi, S., Mitzenmacher, M., Panconesi, A., Raghavan,
 P.: On compressing social networks. In: Proc. 15th KDD, pp. 219–228 (2009)

12. Clark, D.: Compact Pat Trees. Ph.D. thesis, University of Waterloo (1996)
13. Claude, F., Navarro, G.: A fast and compact Web graph representation. In: Ziviani,
N., Baeza-Yates, R. (eds.) SPIRE 2007. LNCS, vol. 4726, pp. 105–116. Springer,
Heidelberg (2007)

14. Claude, F., Navarro, G.: Fast and compact Web graph representations. Tech. Rep.

TR/DCC-2008-3, Dept. of Comp. Sci., Univ. of Chile (2008)

15. Claude, F., Navarro, G.: Practical rank/select queries over arbitrary sequences. In:
Amir, A., Turpin, A., Moﬀat, A. (eds.) SPIRE 2008. LNCS, vol. 5280, pp. 176–187.
Springer, Heidelberg (2008)

16. Donato, D., Laura, L., Leonardi, S., Meyer, U., Millozzi, S., Sibeyn, J.: Algorithms
and experiments for the Web graph. Journal of Graph Algorithms and Applications 
10(2), 219–236 (2006)

17. Erd˜os, P., R´enyi, A.: On random graphs I. Publicationes Mathematicae 6, 290–297

(1959)

18. Golynski, A., Munro, I., Rao, S.: Rank/select operations on large alphabets: a tool

for text indexing. In: Proc. 17th SODA, pp. 368–373 (2006)

19. Gonz´alez, R., Navarro, G.: Compressed text indexes with fast locate. In: Ma, B.,
Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 216–227. Springer, Heidelberg
(2007)

20. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed text indexes. In:

Proc. 14th SODA, pp. 841–850 (2003)

21. Jacobson, G.: Succinct Static Data Structures. Ph.D. thesis, Carnegie Mellon University 
(1989)

22. Kleinberg, J., Kumar, R., Raghavan, P., Rajagopalan, S., Tomkins, A.: The Web
as a graph: Measurements, models, and methods. In: Asano, T., Imai, H., Lee,
D.T., Nakano, S.-i., Tokuyama, T. (eds.) COCOON 1999. LNCS, vol. 1627, pp.
1–17. Springer, Heidelberg (1999)

23. Kleinberg, J.M.: Authoritative sources in a hyperlinked environment. Journal of

the ACM 46(5), 604–632 (1999)

24. Larsson, J., Moﬀat, A.: Oﬀ-line dictionary-based compression. Proc. IEEE 88(11),

1722–1732 (2000)

25. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Computing Surveys 
39(1), article 2 (2007)

26. Raman, R., Raman, V., Rao, S.: Succinct indexable dictionaries with applications
to encoding k-ary trees and multisets. In: Proc. 13th SODA, pp. 233–242 (2002)
27. Rusmevichientong, P., Pennock, D., Lawrence, S., Giles, C.L.: Methods for sampling 
pages uniformly from the World Wide Web. In: Proc. AAAI Fall Symposium
on Using Uncertainty Within Computation, pp. 121–128 (2001)

28. Saito, H., Toyoda, M., Kitsuregawa, M., Aihara, K.: A large-scale study of link

spam detection by graph algorithms. In: Proc. 3rd AIRWeb (2007)

29. Sakamoto, H.: A fully linear-time approximation algorithm for grammar-based

compression. Journal of Discrete Algorithms 3(2-4), 416–430 (2005)

30. Suel, T., Yuan, J.: Compressing the graph structure of the Web. In: Proc. 11th

DCC, pp. 213–222 (2001)

