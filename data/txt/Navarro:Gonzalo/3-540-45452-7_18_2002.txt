Faster Bit-Parallel Approximate String Matching

Heikki Hyyr¨o1(cid:1) and Gonzalo Navarro2(cid:1)(cid:1)

1 Dept. of Computer and Information Sciences, University of Tampere, Finland

2 Dept. of Computer Science, University of Chile

Abstract. We present a new bit-parallel technique for approximate
string matching. We build on two previous techniques. The ﬁrst one
[Myers, J. of the ACM, 1999], searches for a pattern of length m in a
text of length n permitting k diﬀerences in O(mn/w) time, where w is
the width of the computer word. The second one [Navarro and Raﬃnot,
ACM JEA, 2000], extends a sublinear-time exact algorithm to approximate 
searching. The latter technique makes use of an O(kmn/w) time
algorithm [Wu and Manber, Comm. ACM, 1992] for its internal workings.
This algorithm is slow but ﬂexible enough to support all the required operations.
 In this paper we show that the faster algorithm of Myers can
be adapted to support all those operations. This involves extending it
to compute edit distance, to search for any pattern suﬃx, and to detect
in advance the impossibility of a later match. The result is an algorithm
that performs better than the original version of Navarro and Raﬃnot
and that is the fastest for several combinations of m, k and alphabet
sizes that are useful, for example, in natural language searching and
computational biology.

1 Introduction

Approximate string matching is one of the main problems in classical string
algorithms, with applications to text searching, computational biology, pattern
recognition, etc. Given a text of length n, a pattern of length m, and a maximal 
number of diﬀerences permitted, k, we want to ﬁnd all the text positions
where the pattern matches the text up to k diﬀerences. The diﬀerences can be
substituting, deleting or inserting a character. We call α = k/m the diﬀerence
ratio, and σ the size of the alphabet Σ. All the average case ﬁgures in this paper
assume random text and uniformly distributed alphabet.

In this paper we consider online searching, that is, the pattern can be preprocessed 
but the text cannot. The classical solution to the problem is based on
ﬁlling a dynamic programming matrix and needs O(mn) time [16]. Since then,
many improvements have been proposed (see [11] for a complete survey). These
can be divided into four types.

(cid:1) Supported by the Academy of Finland and Tampere Graduate School in Information 
Science and Engineering.

(cid:1)(cid:1) Partially supported by Fondecyt Project 1-020831.

A. Apostolico and M. Takeda (Eds.): CPM 2002, LNCS 2373, pp. 203–224, 2002.
c(cid:1) Springer-Verlag Berlin Heidelberg 2002

204

Heikki Hyyr¨o and Gonzalo Navarro

The ﬁrst type is based on dynamic programming and has achieved O(kn)
worst case time [7,9]. These algorithms are not really practical, but there exist 
also practical solutions that achieve, on the average, O(kn) [20] and even
O(kn/

√
σ) time [4].

The second type reduces the problem to an automaton search, since approximate 
searching can be expressed in that way. A deterministic ﬁnite automaton
(DFA) is used in [20] so as to obtain O(n) search time, which is worst-case optimal.
 The problem is that the preprocessing time and the space is O(3m), which
makes the approach practical only for very small patterns. In [22] they trade
time for space using a Four Russians approach, achieving O(kn/ log s) time on
average and O(mn/ log s) in the worst case, assuming that O(s) space is available
for the DFAs.

The third approach ﬁlters the text to quickly discard large text areas, using
a necessary condition for an approximate occurrence that is easier to check than
the full condition. The areas that cannot be discarded are veriﬁed with a classical 
algorithm [18,17,5,12,14]. These algorithms achieve “sublinear” expected
time in many cases for low diﬀerence ratios, that is, not all text characters are
inspected. However, the ﬁltration is not eﬀective for higher ratios. The typical
√
average complexity is O(kn logσ m/m) for α = O(1/ logσ m). The optimal average 
complexity is O((k+logσ m)n/m) for α < 1−O(1/
σ) [5], which is achieved
in the same paper. The algorithm, however, is not practical.

Finally, the fourth approach is bit-parallelism [1,21], which consists in packing
several values in the bits of the same computer word and managing to update
all them in a single operation. The idea is to simulate another algorithm using
bit-parallelism. The ﬁrst bit-parallel algorithm for approximate searching [21]
parallelized an automaton-based algorithm: a nondeterministic ﬁnite automaton
(NFA) was simulated in O(k(cid:3)m/w(cid:4)n) time, where w is the number of bits in
the computer word. We call this algorithm BPA (for Bit-Parallel Automaton)
in this paper. BPA was improved to O((cid:3)km/w(cid:4)n) [3] and ﬁnally to O((cid:3)m/w(cid:4)n)
time [10]. The latter simulates the classical dynamic programming algorithm
using bit-parallelism, and we call it BPM (for Bit-Parallel Matrix) in this paper.
Currently the most successful approaches are ﬁltering and bit-parallelism. A
promising approach combining both [14] will be called ABNDM in this paper
(for Approximate BNDM). The original ABNDM was built on BPA because the
latter is the most ﬂexible for the particular operations needed. The faster BPM
was not used at that time yet because of the diﬃculty in modifying it to be
suitable for ABNDM.

In this paper we extend BPM in several ways so as to permit it to be used
in the framework of ABNDM. The result is a competitive approximate string
matching algorithm. In particular, the algorithm turns out to be the fastest for
a range of m and k that includes interesting cases of natural language searching
and computational biology applications.

