CCCG 2012, Charlottetown, P.E.I., August 8–10, 2012

Adaptive Techniques to ﬁnd Optimal Planar Boxes

J. Barbay ∗

G. Navarro †

P. P´erez-Lantero ‡

Abstract

Given a set P of n planar points, two axes and a realvalued 
score function f () on subsets of P , the Optimal
Planar Box problem consists in ﬁnding a box (i.e. an
axis-aligned rectangle) H maximizing f (H ∩ P ). We
consider the case where f () is monotone decomposable,
i.e. there exists a composition function g() monotone
in its two arguments such that f (A) = g(f (A1), f (A2))
for every subset A ⊆ P and every partition {A1, A2} of
A. In this context we propose a solution for the Optimal 
Planar Box problem which performs in the worst
case O(n2 lg n) score compositions and coordinate comparisons,
 and much less on other classes of instances
deﬁned by various measures of diﬃculty. A side result
of its own interest is a fully dynamic MCS Splay tree
data structure supporting insertions and deletions with
the dynamic ﬁnger property, improving upon previous
results [Cort´es et al., J.Alg. 2009].

1 Introduction

Consider a set P of n planar points, and two axes
x and y forming a base of the plane, such that the
points are in general position (i.e. no pair of points
share the same x or y coordinate). We say that a
real-valued function f () on subsets of P is decomposable 
[2, 7] if there exists a composition function g() such
that f (A) = g(f (A1), f (A2)) for every subset A ⊆ P
and every partition {A1, A2} of A. Without loss of generality,
 we extend f () to P such that f (p) = f ({p}). A
decomposable function is monotone if the corresponding
composition function g() is monotone in its two arguments.
 A box is a rectangle aligned to the axes, and
given a monotone decomposable function f (), such a
box is f ()-optimal if it optimizes f (H ∩ P ). Without
loss of generality, we assume that we want to maximize
f () and that its composition function g() is monotone
∗Department of Computer Science, University of Chile,
Chile, jeremy.barbay@dcc.uchile.cl. Partially funded by grant
FONDECYT 1-120054, Chile.
†Department of Computer Science, University of Chile, Chile,
gnavarro@dcc.uchile.cl. Partially funded by Millennium Nucleus 
Information and Coordination in Networks ICM/FIC P10024F,
 Mideplan, Chile.
‡Escuela de Ingenier´ıa Civil en Inform´atica, Universidad
de Valpara´ıso, Chile, pablo.perez@uv.cl. Partially supported
by grant FONDECYT 11110069 (Chile) and project MEC
MTM2009-08652 (Spain).

increasing in its two arguments. Given a monotone decomposable 
function f () well deﬁned for the empty set
∅, a point p of P is positive if f (p) > f (∅). Otherwise,
this point p is negative. Observe that if p is positive then
f (A ∪ {p}) = g(f (A), f (p)) > g(f (A), f (∅)) = f (A) by
monotonicity of g(): hence a point p is positive if and
only if f (A ∪ {p}) > f (A) for every subset A ⊂ P not
containing p. A stripe is an area delimited by two lines
parallel to the same axis. A positive stripe (resp. negative 
stripe) is one which contains only positive (resp.
negative) points. A monochromatic stripe is a stripe in
which all points have the same sign.

Given a set of planar points, a simple example of such
monotone decomposable functions is counting the number 
of points the box contains. Other examples include
counting the number of blue points; returning the diﬀerence 
between the number of blue points and the number
of red points contained; returning the number of blue
points in the box or −∞ if it contains some red points;
summing the weights of the points contained; taking the
maximum of the weights of contained points; etc.

Given a set P of n planar points and a real-valued
function f () on subsets of P , the Optimal Planar
Box problem consists in ﬁnding an f ()-optimal box.
Depending on f (), this problem has various practical
applications, from identifying rectangular areas of interest 
in astronomical pictures to the design of optimal
rectangular forest cuts or the analysis of medical radiographies.
 We present various adaptive techniques for
the Optimal Planar Box problem:

• In the worst case over instances composed of n
points, our algorithm properly generalizes Cort´es et
al.’s solution [5] for the Maximum Weight Box
problem, within the same complexity of O(n2 lg n)
score compositions.

• For any δ ∈ [1..n] and n1, . . . , nδ ∈ [1..n] summing
to n, in the worst case over instances composed
of δ monochromatic stripes of alternating signs
when the points are sorted by their y-coordinates,
such that the i-th stripe contains ni points, our
algorithm executes O(δn(1 + H(n1, . . . , nδ))) ⊂
O(δn lg(δ + 1)) score compositions (Theorem 4),
i=1(ni/n) lg(n/ni) is the

where H(n1, . . . , nδ) =(cid:80)δ

usual entropy function.

• Assuming the same y-coordinate order,

for any
λ ∈ [0..n2], in the worst case over instances where

24th Canadian Conference on Computational Geometry, 2012

λ is the sum of the distances between the insertion 
positions of the consecutive points according to
their x-coordinate, our algorithm makes O(n2(1 +
lg(1 + λ/n)) score compositions (Lemma 5). Measure 
λ relates to the local insertion sort complexity 
[11] of the sequence of x-coordinates. It holds
λ ∈ O(n + Inv), where Inv is the number of inversions 
in the sequence. When the points are grouped
into δ monochromatic stripes, the complexity drops
to O(nδ(1 + lg(1 + Inv/n)) (Theorem 7).

• Assuming the same y-coordinate order, for a minimal 
cover of the same sequence of x-coordinates
into ρ ≤ n runs (i.e. contiguous increasing sub-
sequences) of lengths r1, . . . , rρ, our algorithm executes 
O(n2(1 + H(r1, . . . , rρ))) ⊂ O(n2 lg(ρ + 1))
score compositions (Lemma 6). When the points
can be grouped into δ monochromatic stripes, this
complexity decreases to O(nδ(1+H(r1, . . . , rρ))) ⊂
O(nδ lg(ρ + 1)) (Theorem 7 again).

• Using an approach orthogonal to the one of Cort´es
et al. [5], we partition (via a clever strategy considering 
axis-parallel lines) the point set P into subsets 
called diagonal blocks, so that a new adaptive 
algorithm is obtained (Theorem 14). The algorithm 
solves the Optimal Planar Box problem
in each block and combine the solutions. Extending 
this algorithm, we obtain another adaptive algorithm 
running in O(n lg n + σn) comparisons and
O(σn lg n) score compositions, where σ ∈ [1..n] is a
measure of diﬃculty of the instance that depends
on the partition in diagonal blocks (Theorem 18).

Due to the lack of space, several proofs are omitted.
 A longer version of this paper is available at
http://arxiv.org/abs/1204.2034.

2 Optimal Boxes and Related Problems

Given a set P of n weighted planar points, in which the
weight of a point can be either positive or negative, the
Maximum Weight Box problem [5] consists in ﬁnding
a box R maximizing the sum of the weights of the points
in R ∩ P . Cort´es et al. [5] gave an algorithm solving
this problem in time O(n2 lg n) using O(n) space, based
on MCS trees, a data structure supporting in O(lg n)
time the dynamic computation of the Maximum-Sum
Consecutive Subsequence problem [3] (hence the
name “MCS”).

The Maximum Weight Box problem [5] and, by
successive reductions, the Maximum Subarray problem 
[14], the Maximum Box problem [5, 8, 10], and the
Maximum Discrepancy Box problem [5, 6] can all be
reduced to a ﬁnite number of instances of the Optimal
Planar Box problem by choosing adequate deﬁnitions
for the score functions f () to optimize.

Cort´es et al.’s algorithm [5] ﬁrst sorts the points by
their y-coordinate in O(n lg n) time and then traverses
the resulting sequence of points p1, p2, . . . pn as follows.
For each pi, it sets an MCS tree (described in more
details in Section 3) with points pi, . . . pn, where the key
is their x-coordinate xi, and all have value f (∅). It then
successively activates points pj for j ∈ [i..n], setting
its weight to value f (pj), updating in time O(lg n) the
MCS tree so that to compute the optimal box contained
between the y-coordinate of pi to that of pj. The whole
algorithm executes in time O(n2 lg n).

3 Fully Dynamic MCS Trees

maximizing(cid:80)

The MCS tree [5] is an index for a ﬁxed sequence S =
(xi)i∈[1..n] of n elements, where each element xk of S has
a weight w(xk) ∈ R, so that whenever a weight w(xk)
is updated, a consecutive subsequence (xi)i∈[l..r] of S
i∈[l..r] w(xi) is obtained (or recomputed)
in O(lg n) time. This behavior is dynamic in the sense
that it allows modiﬁcation of element weights, yet it
is only partially dynamic in the sense that it admits
neither addition nor deletion of elements.

Existing dynamic data structures can be easily
adapted into a truly dynamic data structure with the
same functionalities as MCS trees. We start by generalizing 
MCS trees [5] from mere additive weights to
monotone decomposable score functions in Lemma 1.
We further generalize this solution to use an AVL tree [1]
in Lemma 2 and a Splay tree [13] in Lemma 3, whose
“ﬁnger search” property will play an essential role in
the results of Sections 4 and 5.

Lemma 1 Let S be a static sequence of n elements, and
f () be a monotone decomposable score function receiving 
as argument any subsequence of S, deﬁned through
the activation and deactivation of each element of S.
There exists a semi-dynamic data structure for maintaining 
S using linear space that supports the search for
an element in O(lg n) comparisons; the activation or deactivation 
of an element in O(lg n) score compositions;
and f ()-optimal sub range queries in O(lg n) comparisons 
and score compositions.

The MCS tree data structure can be converted into a
truly dynamic data structure supporting both insertions
and deletions of elements. This data structure can be
used to index a dynamic sequence S = (xi)i∈[1..n] of
n elements so that whenever an element is inserted or
removed, a consecutive subsequence S(cid:48) = (xi)i∈[l..r] of S
optimizing f (S(cid:48)) can be (re)computed in O(lg n) score
compositions and comparisons. The following lemma
establishes the property of this data structure, which
we call MCS AVL tree.

Lemma 2 Let S be a dynamic sequence of n elements,
and f () be a monotone decomposable score function receiving 
as argument any consecutive subsequence of S.
There exists a fully dynamic data structure for maintaining 
S using linear space that supports the search for
an element in O(lg n) comparisons; the update of the
score of an element in O(lg n) score compositions, the
insertion or deletion of an element in O(lg n) comparisons 
and score compositions; and f ()-optimal subrange
queries in O(lg n) comparisons and score compositions.

trary n-node Splay tree costs O(m+n+(cid:80)m

The Splay tree is a self-adjusting binary search tree
created by Sleator and Tarjan [13]. It supports the basic
operations search, insert and delete, all of them called
accesses, in O(lg n) amortized time. For many sequences
of accesses, splay trees perform better than other search
trees, even when the speciﬁc pattern of the sequences are
unknown. Among other properties of Splay trees, we are
particularly interested in the Dynamic Finger Property,
conjectured by Sleator and Tarjan [13] and proved by
Cole et al. [4]: every sequence of m accesses on an arbi-
j=1 lg(dj +1))
rotations where, for j = 1..m, the j-th and (j − 1)-th
accesses are performed on elements whose ranks among
the elements stored in the Splay tree diﬀer by dj. For
j = 0, the j-th element is the element stored at the
root. It is easy to see that in the MCS AVL tree we can
replace the underlying AVL tree by a Splay tree, and
obtain then the next lemma, which describes the MCS
Splay tree data structure.

Lemma 3 Let S be a dynamic sequence of n elements
and f () be a monotone decomposable function receiving
as argument any consecutive subsequence of S. There
exists a data structure for maintaining S that uses linear 
space and supports the search in O(lg n) amortized
comparisons, the update of the score of an element in
O(lg n) amortized score compositions, and the insertion 
and deletion of elements in O(lg n) amortized comparisons 
and score compositions. Joint with the insertion 
or deletion of any element, the consecutive subsequence 
S(cid:48) of S maximizing f (S(cid:48)) is recomputed. The
Dynamic Finger Property is also satisﬁed for each operation 
(search, insertion and deletion), both for the number 
of comparisons and for the number of score compositions 
performed.

4 Taking Advantage of Monochromatic Stripes

Consider an instance where positive and negative points
can be clustered into δ positive and negative stripes
along one given axis, of cardinalities n1, . . . , nδ. Such
stripes can be easily identiﬁed in O(n lg n) comparisons
and O(n) score accesses. On such instances one does
not need to consider boxes whose borders are in the
middle of some stripes: all optimal boxes will start at

CCCG 2012, Charlottetown, P.E.I., August 8–10, 2012

the edge of a stripe; speciﬁcally, the top (resp. bottom)
of an optimal box will align with a positive point at the
top (resp. bottom) of a positive stripe.

tree of ﬁnal size n amortizes to O(n +(cid:80)δ
by convexity the cost O(n +(cid:80)n
per bounded by O(n +(cid:80)δ
O(n +(cid:80)δ

This very simple observation not only limits the number 
of boxes for which we need to compute a score,
but also it makes it easier to compute the score of
each box: adding the ni points of the i-th stripe in
increasing order of their coordinates in a MCS Splay
i=1 ni lg(n/ni))
coordinate comparisons and score compositions. The
reason is that the ni distances dj + 1 of Lemma 3
telescope to at most n + ni within stripe i, and thus
j=1 lg(dj + 1)) is up-
i=1 ni lg(1 + n/ni)) which is
i=1 ni lg(n/ni)) = O(n(1 + H(n1, . . . , nδ))) ⊂
O(n lg(δ + 1)). Combining this with the fact that the
top of an optimal box is aligned with a positive point at
the top of a positive stripe yields the following result.
Theorem 4 For any δ ∈ [1..n] and n1, . . . , nδ ∈ [1..n]
summing to n, in the worst case over instances composed 
of δ stripes of alternating signs over an axis such
that the i-th stripe contains ni points, there exists an
algorithm that ﬁnds an f ()-optimal box in O(δn(1 +
H(n1, . . . , nδ))) ⊂ O(δn lg(δ + 1)) score compositions
and O(δn(1 + H(n1, . . . , nδ)) + n lg n) ⊂ O(δn lg(δ +
1) + n lg n) coordinate comparisons.

5 Taking Advantage of Point Alignments

Running the algorithm outlined in the ﬁrst paragraph
of Section 4 over the MCS Splay tree has further consequences.

In this section we show how it makes the
algorithm adaptive to local point alignments.

The cost of our algorithm using the MCS Splay tree
can be upper bounded as follows. Let λ denote the
sum of the distances between the insertion positions of
the consecutive points according to their x-coordinate.
When we insert the points in the MCS Splay tree start-
j=1 lg(dj + 1)) ⊂
O(n + n lg(1 + λ/n)) score compositions, by convexity
j=1 dj + 1 ≤ λ + n. A
simple upper bound when considering all the n passes
of the algorithm can be obtained as follows.

ing from p1, the total cost is O(n +(cid:80)n
of the logarithm and because(cid:80)n

Lemma 5 There exists an algorithm that ﬁnds an f ()-
optimal box in O(n2(1+lg(1+λ/n))) score compositions
and O(n2(1 + lg(1 + λ/n)) + n lg n) coordinate comparisons,
 where λ ≤ n2 is the local insertion complexity
of the sequence of x-coordinates of the points sorted by
y-coordinates.

In the worst case this boils down to the O(n2 lg n)-
worst-case algorithm, whereas in the best case λ = 0
and the cost corresponds to O(n2) operations.

24th Canadian Conference on Computational Geometry, 2012

We can upper bound λ by using other two measures of
disorder in permutations. For example, let us consider
Inv, the number of inversions in the permutation π, or
said another way, the number of pairs out of order in the
sequence [12]. The measure Inv corresponds to a cost
where the “ﬁnger” is always at the end of the sequence.
This can be as small as (λ − n)/2, for example consider 
the permutation π = (m, m− 1, m + 1, m− 2, m +
2, . . . , 1, 2m− 1) for m = (n + 1)/2 and odd n. However,
Inv can be much larger than λ because it is not symmetric 
on decreasing sequences, for example when the
points are semi-aligned in a decreasing diagonal and the
permutation is π = (n, n− 1, n− 2, . . . , 1). Thus replacing 
λ by Inv in Lemma 5 yields a valid upper bound in
terms of big-O complexity.

Another well-known measure of permutation complexity 
is the number of increasing runs ρ, that is,
the minimum number of contiguous monotone increasing 
subsequences that cover π [9]. Let r1, . . . , rρ be
the lengths of the runs, computed in O(n lg n) comparisons.
 Then the sum of the values |πj+1 − πj| within
sum of the dj values. Therefore (cid:80)n
(cid:80)ρ
i=1 ri lg(1+n/ri) ≤ n+(cid:80)ρ
the i-th run telescopes to at most n, and so does the
j=1 lg(dj + 1) ≤
i=1 ri lg(n/ri) by convexity.

This leads to the following alternative upper bound.

Lemma 6 There exists an algorithm that ﬁnds an f ()-
optimal box in O(n lg n) coordinate comparison and
O(n2(1+H(r1, . . . , rρ)) ⊂ O(n2 lg(ρ+1)) score compositions,
 where r1, . . . , rρ are the lengths of ρ maximal contiguous 
increasing subsequences that cover the sequence
of x-coordinates of the points sorted by y-coordinate.

6 Taking Advantage of both Stripes and Alignments

The combination of the techniques of Sections 4 and 5
can be elegantly analyzed. A simple result is that we
need to start only from δ diﬀerent pi values, and therefore 
an upper bound to our complexity is O(nδ((1 +
lg(1 + λ/n))). We can indeed do slightly better by
sorting the points by increasing x-coordinates within
each monochromatic stripe. While the measure λ(cid:48) resulting 
from this reordering may be larger than λ, the
upper bounds related to Inv and ρ, namely Inv(cid:48), ρ(cid:48),
and H(n(cid:48)
In particular it
is easy to see that the upper bound of Theorem 4
is dominated by the combination since ρ(cid:48) ≤ δ and
ρ(cid:48)) ≤ H(n1, . . . , nδ) (because no run will cut
H(r(cid:48)
a monochromatic stripe once the latter is reordered).

ρ(cid:48)), do not increase.

1, . . . , n(cid:48)

1, . . . , r(cid:48)

Theorem 7 There exists an algorithm that ﬁnds an
f ()-optimal box in O(n lg n) coordinate comparisons
and O(nδ(1 + min(lg(1 + Inv/n), H(r1, . . . , rρ)))) ⊂
O(nδ lg(ρ + 1)) score compositions, where δ is the minimum 
number of monochromatic stripes in which the

points, sorted by increasing y-coordinate, can be partitioned;
 X is the corresponding sequence of x-coordinates
once we (re-)sort by increasing x-coordinate the points
within each monochromatic stripe; Inv ≤ n2 is the number 
of out-of-order pairs in X; and r1, . . . , rρ are the
lengths of the minimum number ρ ≤ δ of contiguous increasing 
runs that cover X. A similar result holds by
exchanging x and y axes.

Note that if these new measures are not particularly
favorable, the formula boils down to the O(nδ lg δ) time
complexity of Section 4.

7 Taking Advantage of Diagonals of Blocks

In this section we present an approach orthogonal to the
previous ones, which considers partitions of the point
set into subsets and yields to a new adaptive algorithm
which solves the Optimal Planar Box problem in
each of them and combine the solutions. Its diﬃculty
measure depends on such a partition.
For any subset A ⊆ P , a diagonalization of A is a
partition {A1, A2} of A induced by two lines (cid:96)1 and
(cid:96)2, respectively parallel to axes x and y, so that the
elements of A1 and the elements of A2 belong to opposite 
quadrants with respect to the point (cid:96)1 ∩ (cid:96)2. Note
that if p1, p2, . . . , pm denote the elements of A sorted
by x-coordinate, then any diagonalization of A has
the form {{p1, . . . , pk},{pk+1, . . . , pm}} for some index
k ∈ [1..m − 1]. Not all point sets admit a diagonalization,
 the simplest case consists of four points placed at
the four corners of a square whose sides are slightly rotated 
from the axes. We call such a point set a windmill,
due to the characteristic position of its points. Given
any bounded set S ⊂ R2, let Box(S) denote the smallest
box enclosing S and let the extreme points of any subset
A ⊆ P be those belonging to the boundary of Box(A).
Lemma 8 Let A be a point set that does not admit a diagonalization.
 Then A has exactly four extreme points.
Furthermore, A has a windmill which contains at least
one extreme point of A.

Deﬁnition 9 A diagonalization tree of P , D-tree, is a
binary tree such that: (i) each leaf u contains a subset 
S(u) ⊆ P which does not admit a diagonalization,
(ii) set {S(u) | u is a leaf } is a partition of P , and
(iii) each internal node v has exactly two children v1
(the left one) and v2 (the right one) and satisﬁes that
{A(v1), A(v2)} is a diagonalization of A(v), where for
each node v A(v) denotes the union of the sets S(u) for
all leaves u descendant of v (See Figure 1).

Lemma 10 Let P be a set of n points in the plane.
Every D-tree of P has the same number of leaves. Furthermore,
 the i-th leaves from left to right of any two
D-trees of P contain the same subset S(·) of P .

CCCG 2012, Charlottetown, P.E.I., August 8–10, 2012

Deﬁnition 12 For any non-empty subset A ⊆ P the
set of ten f ()-optimal boxes of A, denoted by Ten(A),
consists of the following f ()-optimal boxes of A, all contained 
in Box(A):
1. Box(A);
2. Bopt(A), without restriction;
3. B1(A), with the bottom-left vertex of Box(A);
4. B2(A), with the bottom-right vertex of Box(A);
5. B3(A), with the top-right vertex of Box(A);
6. B4(A), with the top-left vertex of Box(A);
7. B1,2(A), with the bottom vertices of Box(A);
8. B2,3(A), with the right vertices of Box(A);
9. B3,4(A), with the top vertices of Box(A);
10. B4,1(A), with the left vertices of Box(A).
Lemma 13 For any non-empty subset A ⊆ P and any
diagonalization {A1, A2} of A, Ten(A) can be computed
in O(1) score compositions from Ten(A1) and Ten(A2).

f ()-optimal box of P in O(n lg n+(cid:80)β
isons (on coordinates and indices) and O((cid:80)β

Theorem 14 There exists an algorithm that ﬁnds an
i=1 hc(ni)) compar-
i=1 hs(ni)+
β) score compositions, where {P1, . . . , Pβ} is the partition 
of P induced by any D-tree of P and β is the size of
this partition, ni is the cardinality of Pi, and hc(ni) and
hs(ni) are the numbers of coordinate comparisons and
score compositions used, respectively, to compute the ten
f ()-optimal boxes of Pi.

Figure 1: A D-tree of the point set {p1, . . . , p13}.

From Lemma 10 we can conclude that every D-tree
T of P induces the same partition {S(u1), . . . , S(uβ)}
of P , where u1, . . . , uβ are the leaf nodes of T.

Lemma 11 A D-tree of P requires O(n) space and can
be built in O(n lg n) comparisons.

Proof. (Sketch) Let p1, p2, . . . , pn be the elements of
P sorted by x-coordinate, and let pπ1, pπ2 , . . . , pπn be
the elements of P sorted by y-coordinate. Considering 
the computation of permutation π a preprocessing,
 we can show that:
If P admits a diagonalization 
{{p1, . . . , pk},{pk+1, . . . , pn}} then it can be determined 
in O(min{k, n − k}) comparisons. Otherwise,
if P does not admit a diagonalization, then it can be
decided in O(n) comparisons. We can then build a Dtree 
of P recursively as follows.
If a diagonalization
{{p1, . . . , pk},{pk+1, . . . , pn}} of P exists, which was determined 
in O(t) comparisons where t = min{k, n − k},
then create a root node and set as left child a Dtree 
of {p1, . . . , pk} and as right child a D-tree of
{pk+1, . . . , pn}. Otherwise, if P does not admit a diagonalization,
 which was decided in O(n) comparisons,
then create a leaf node whose set S(·) is equal to P .
This results in the next recurrence equation for the total 
number T (n) of comparisons, where 1 ≤ t ≤ (cid:98)n/2(cid:99):

 O(t) + T (t) + T (n − t)

O(n)

T (n) =

n > 1, a diagonalization 
exists.
otherwise.

Proof. Build a D-tree T of P in O(n lg n) comparisons
(Lemma 11). Let u1, . . . , uβ be the leaves of T which
satisfy S(ui) = Pi for all i ∈ [1..n]. Compute the set
Ten(S(ui)) = Ten(Pi) in hc(ni) coordinate comparisons
and hs(ni) score compositions. By using a post-order
traversal of T , for each internal node v of T compute
Ten(A(v)) from Ten(A(v1)) and Ten(A(v2)), where v1
and v2 are the children nodes of v, in O(1) score compositions 
(Lemma 13). The f ()-optimal box of P is
the box Bopt(A(r)), where r is the root node of T and
satisﬁes A(r) = P .
In total, this algorithm runs in
i=1 hc(ni)) co-
i=1 O(1) =
(cid:3)

i=1 hc(ni) = O(n lg n +(cid:80)β
O(n lg n) +(cid:80)β
ordinate comparisons and(cid:80)β
O((cid:80)β
f ()-optimal box of P in O(n lg n +(cid:80)β
parisons and O((cid:80)β

Corollary 15 There exists an algorithm that ﬁnds an
i=1 ni lg ni) comi 
lg ni + β) score compositions,
where β is the size of the partition {P1, . . . , Pβ} of P
induced by any D-tree of P , and ni = |Pi| for all i.

i=1 hs(ni) +(cid:80)β−1

i=1 hs(ni) + β) score compositions.

i=1 n2

8 Dealing with Windmills

By applying induction and using the binary entropy
function H(x) = x lg(1/x) + (1 − x) lg(1/(1 − x)), with
the fact x ≤ H(x) for x ≤ 1/2, it can be proved that
(cid:3)
T (n) is O(n lg n).

In this section we use Lemma 8 to obtain a variant of
the algorithm in Theorem 14. The set S(u) of every leaf
node u of any D-tree of P does not admit a diagonalization 
and has a windmill containing an extreme point

p1p2p3p4p5p6p7p8p9p10p11p12p13p3,...,p7p1p2p8p9p10,...,p1324th Canadian Conference on Computational Geometry, 2012

of S(u). The idea is to remove the extreme points of
S(u) and then recursively build a D-tree of the remaining 
points. This approach yields a diagonalization in
depth of the point set, potentially reducing the number
of score compositions.

Deﬁnition 16 An extended diagonalization tree of P ,
D∗-tree, is deﬁned recursively as follows: Each leaf node
u of a D-tree of P satisfying |S(u)| > 1 is replaced by
a node u(cid:48) containing the set X(u) of the four extreme
points of S(u), and if the set S(u) \ X(u) is not empty
then u(cid:48) has as its only one child a D∗-tree of S(u)\X(u).
Lemma 17 Every D∗-tree of P has the same number
σ of one-child nodes, contains n − 4σ leaves nodes, and
every leaf node u satisﬁes |S(u)| = 1 or |S(u)| = 4. A
D∗-tree of P requires O(n) space and can be built in
O(n lg n + σn) comparisons.

Proof. The ﬁrst part of the lemma can be seen from
Lemma 10 and Deﬁnition 16. A D∗-tree of P can be
built in O(n lg n + σn) comparisons by following the
same algorithm to build a D-tree of P until ﬁnding a
leaf node u such that S(u) does not admit a diagonalization.
 At this point we pay O(n) comparisons in order
to continue the algorithm with the set S(u) \ X(u) according 
to Deﬁnition 16. Since this algorithm ﬁnds σ
nodes u, the total comparisons are O(n lg n + σn). The
D∗-tree has n nodes of bounded degree and hence can
(cid:3)
be encoded in linear space.

Theorem 18 There exists an algorithm that ﬁnds an
f ()-optimal box of P in O(n lg n + σn) coordinate comparisons 
and O(σn lg n) score compositions, where σ is
the number of one-child nodes of every D∗-tree of P .

Proof. Build a D∗-tree T of P in O(n lg n + σn) comparisons 
(Lemma 17). For each of the n − 4σ leaves
nodes u of T compute Ten(S(u)) in constant score compositions.
 Then, using a post-order traversal of T , compute 
Ten(S(u)) for each internal node u as follows: If v
has two children v1 (the left one) and v2 (the right one),
then {A(v1), A(v2)} is a diagonalization of A(v) and
Ten(A(v)) can be computed in O(1) score compositions
from Ten(A(v1)) and Ten(A(v2)) (Lemma 13). Otherwise,
 if v is one of the σ one-child nodes, then Ten(A(v))
can be computed in O(n lg n) worst-case comparisons
and score compositions. Namely, if a box of Ten(A(v))
contains a at least one point of X(u) in the boundary
then it can be found in O(n lg n) comparisons and score
compositions [5]. Otherwise, it is a box of Ten(A(v(cid:48))),
where v(cid:48) is the child of v. We pay O(1) score compositions 
for each of the O(n) two-child nodes and O(n lg n)
score compositions for each of the σ one-child nodes.
Then the total score compositions is O(n + σn lg n). (cid:3)

9 Future work
The deﬁnition of Ten(·) can be used for further re-
sults: Suppose the point set P can be partitioned
into subsets P1, P2, . . . , Pk so that bounding boxes
Box(P1), Box(P2), . . . , Box(Pk) are pairwise disjoint and
any axis-parallel line stabs at most one of them. Once
Ten(P1), Ten(P2), . . . , Ten(Pk) have been computed, an
optimal box of P can be found in O(k lg k) comparisons
and O(k2 lg k) score compositions. Finding an optimal
decomposition P1, P2, . . . , Pk is our main issue.

References

[1] G. Adelson-Velskii and E. M. Landis. An algorithm for
the organization of information. In Proc. of the USSR
Academy of Sciences, volume 146, pages 263–266, 1962.
[2] C. Bautista-Santiago, J. M. D´ıaz-B´a˜nez, D. Lara,
P. P´erez-Lantero, J. Urrutia, and I. Ventura. Computing 
optimal islands. Oper. Res. Lett., 39(4):246–251,
2011.

[3] J. Bentley. Programming pearls: algorithm design techniques.
 Commun. ACM, 27(9):865–873, 1984.

[4] R. Cole, B. Mishra, J. Schmidt, and A. Siegel. On the
dynamic ﬁnger conjecture for splay trees. Part I: Splay
sorting log n-block sequences. SIAM J. Comp., 30(1):1–
43, 2000.

[5] C. Cort´es, J. M. D´ıaz-B´a˜nez, P. P´erez-Lantero,
C. Seara, J. Urrutia, and I. Ventura. Bichromatic separability 
with two boxes: A general approach. J. Algorithms,
 64(2-3):79–88, 2009.

[6] D. P. Dobkin, D. Gunopulos, and W. Maass. Computing 
the maximum bichromatic discrepancy, with applications 
to computer graphics and machine learning. J.
Comput. Syst. Sci., 52(3):453–470, 1996.

[7] D. P. Dobkin and S. Suri. Dynamically computing the
maxima of decomposable functions, with applications.
In FOCS, pages 488–493, 1989.

[8] J. Eckstein, P. Hammer, Y. Liu, M. Nediak, and
B. Simeone. The maximum box problem and its application 
to data analysis. Comput. Optim. App.,
23(3):285–298, 2002.

[9] D. E. Knuth. The Art of Computer Programming, volume 
3. Addison-Wesley, 1968.

[10] Y. Liu and M. Nediak. Planar case of the maximum box

and related problems. In CCCG, pages 14–18, 2003.

[11] H. Mannila. Measures of presortedness and optimal
In IEEE Trans. Comput., volsorting 
algorithms.
ume 34, pages 318–325, 1985.

[12] A. Moﬀat and O. Petersson. An overview of adaptive

sorting. Australian Comp. J., 24(2):70–77, 1992.

[13] D. D. Sleator and R. E. Tarjan. Self-adjusting binary

search trees. J. ACM, 32(3):652–686, 1985.

[14] T. Takaoka. Eﬃcient algorithms for the maximum subarray 
problem by distance matrix multiplication. Electronic 
Notes in Theoretical Computer Science, 61:191–
200, 2002. CATS’02.

