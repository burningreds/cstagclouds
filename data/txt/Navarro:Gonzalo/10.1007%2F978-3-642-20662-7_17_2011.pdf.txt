Practical Compressed Document Retrieval(cid:2)

Gonzalo Navarro1, Simon J. Puglisi2, and Daniel Valenzuela1

1 Dept. of Computer Science, University of Chile,

{gnavarro,dvalenzu}@dcc.uchile.cl

2 School of Computer Science and Information Technology

Royal Melbourne Institute of Technology,

simon.puglisi@rmit.edu.au

Abstract. Recent research on document retrieval for general texts has
established the virtues of explicitly representing the so-called document
array, which stores the document each pointer of the suﬃx array belongs
to. While it makes document retrieval faster, this array occupies a signiﬁcative 
amount of redundant space and is not easily compressible. In
this paper we present the ﬁrst practical proposal to compress the document 
array. We show that the resulting structure is signiﬁcatively smaller
than the uncompressed counterpart, and than alternatives to the document 
array proposed in the literature. We also compare various known
algorithms for document listing and top-k retrieval, and ﬁnd that the
most useful combinations of algorithms run over our new compressed
document arrays.

1 Introduction

Document retrieval queries aim at ﬁnding the documents of a text collection
most relevant to a given query, where relevance is usually deﬁned on frequency
grounds. Such queries have been classically privative of Natural Language collections 
and handled with inverted indexes. In the last decade, however, there
have been various research eﬀorts towards generalizing them to arbitrary text
collections, where the texts can correspond to ADN or protein sequences, text in
Oriental languages (some of which cannot be easily split into words), program
code, and symbolic sequences in general. See Gagie et al. [7] for a recent survey.
Muthukrishnan [16] established important milestones in this area. He proposed,
 among other less popular ones, the following fundamental document retrieval 
queries, which form the basis of more sophisticated retrieval activities:

– Document listing: List the ndoc distinct documents where a pattern p appears 
as a substring.

– Frequency computation: Same as above but also compute the number of times

p appears within each returned document.

– Top-k retrieval: Find the k documents where p appears most often.

(cid:2) Partially funded by the Millennium Institute for Cell Dynamics and Biotechnology
(ICDB), Grant ICM P05-001-F, Mideplan, Chile; by Fondecyt Grant 1-110066, Chile;
and by the Australian Research Council.

P.M. Pardalos and S. Rebennack (Eds.): SEA 2011, LNCS 6630, pp. 193–205, 2011.
c(cid:2) Springer-Verlag Berlin Heidelberg 2011

194

G. Navarro, S.J. Puglisi, and D. Valenzuela

Assume the text collection is formed by n documents, which are strings over
alphabet [1, σ], and let us call T [1, N] their concatenation. Classical text indexes
[1,14] can ﬁnd all the occ occurrences of pattern p in T in time O(|p| + occ)
and then ﬁlter the ndoc distinct documents. This solves document listing, but
occ can be much larger than ndoc. Muthukrishnan [16] showed how to solve the
document listing query in O(|p| + ndoc) time, which is essentially optimal.

A serious concern on this solution is space, however. It requires O(N lg N) bits,
much more than the N lg σ bits required by the text itself. Part of this space
is used by a suﬃx tree [1], which can be easily replaced by one of the many
compressed suﬃx arrays (CSAs) of the literature [17,4]. Such CSAs represent a
suﬃx array [14] plus the text, all within compressed space |CSA| ≤ N lg σ.

The other part of the space owes to a so-called document array. Much research
has been carried out around the problem of representing it in compact form
[22,20,11,8,3]. The current situation is that one either has to spend N lg n bits
for representing the document array using a wavelet tree [10], or one can simulate
it using just o(N) bits on top of |CSA|. The second choice is clearly preferable
both in theory and in practice for document listing.

However, document listing is just the most elementary activity. In order to
rank documents by importance to the query, frequency computation and top-k
retrieval are essential, and in this case the situation is very diﬀerent. The wavelet
tree representation directly computes frequencies and supports heuristics for topk 
queries. The alternative simulation requires now the space for the global CSA
and the CSA of each individual document. This turns out to be slower and
require much more space in practice than the wavelet-tree based solution [3].

Therefore, the current status is that, if we wish not only to carry out document
listing, but also to report frequencies, or to do top-k retrieval, the best alternative
in practice is to store a wavelet tree representing the document array, which
requires N lg n bits. This is possibly much more than the (at most) N lg σ bits
required by a CSA (which by itself represents T and oﬀers classical indexed text
searches). The known techniques to compress wavelet trees [10] do not work for
the document array.

In this paper we introduce the ﬁrst compressed representation of wavelet trees
that is useful for the document array. The representation uses grammar compression 
(precisely, RePair [12]) to exploit repetitions in the array. Such repetitions
arise as a consequence of the compressibility of the text collection [9,7]. Our
experiments over various collections show that our technique obtains signiﬁcant
space reductions, up to 40% of the original wavelet tree sizes. In exchange, operation 
times are higher. Yet we conﬁrm that the time (and space) is still better
than the alternative of not using wavelet trees for the problem of document
listing with frequencies. We also study the wavelet trees in combination with
various techniques for top-k retrieval [11,3], where our compressed wavelet trees
oﬀer a very attractive space/time tradeoﬀ.

Our representation might have independent interest, as it is the ﬁrst in
grammar-compressing a sequence while supporting symbol rank and select operations 
on it. Those operations are useful in a wealth of applications.

2 Related Work

Practical Compressed Document Retrieval

195

Muthukrishnan’s solution [16] made use of the so-called document array. A suﬃx
array A[1, N] points to all the suﬃxes of T [1, N] in lexicographic order [14]. All
the occurrences of any p in T are pointed from an interval A[sp, ep], which can
be found in time O(|p| lg N) (or O(|p|) with the help of the suﬃx tree [1]). The
document array D[1, N] is such that D[i] tells the document suﬃx A[i] belongs
in T . So the document listing problem is solved by ﬁrst ﬁnding [sp, ep] using
A, and then listing the distinct values in D[sp, ep]. To do this in O(ndoc) time,
Muthukrishnan uses a second array C[1, N], which at C[i] stores the last j < i
such that D[j] = D[i]. C must also answer range minimum queries (RMQs),
telling in constant time the position of the minimum in a range of C cells.

In order to reduce space, the suﬃx tree or array can be replaced by a compressed 
suﬃx array (CSA) [17,4], which stores both A and T in compressed
 )H0(T ) + o(n lg σ) bits [19] or |CSA| =
space, for example within |CSA| = (1 + 1
nHk(T ) + o(n lg σ) bits [5,10], where Hk(T ) ≤ lg σ is the empirical k-th order
entropy of T [17]. CSAs ﬁnd [sp, ep] in time as good as search(p) = O(|p| lg N)
[19] or even search(p) = O(|p| lg σ) [5,10]. They compute any A[i] or A
−1[i]
value in time tA, for example tA = O(log
N) [5,10].
They can also reproduce any text substring.

N) [19] or tA = O(log1+

The document array D, however, requires N lg n bits, which is signiﬁcant and
totally redundant: one can infer D[i] from A[i] and some information on the
limits of the documents in T . Array C is even more space-consuming, N lg N
bits, and equally redundant. The RMQ data structure [6] adds 2N + o(N) bits.
This extra space limits the applicability of the solution to document retrieval.
There have been various approaches to reduce the space of Muthukrishnan’s
solution. M¨akinen and V¨alim¨aki [22] used a wavelet tree [10] to represent D.
While the wavelet tree takes essentially the same space of the plain representation,
 N lg n+o(N lg n) bits, it can emulate array C, which is thus not represented.
The time for document listing becomes O(search(p) + ndoc lg n). The wavelet
tree also allowed them to compute the frequency of p within any document, in
time O(lg n). The RMQ data structure was still necessary.

Gagie et al. [8] showed that the wavelet tree was powerful enough to get
rid of the whole Muthukrishnan’s algorithm. The wavelet tree alone, through a
so-called range quantile operation, was able to deliver the distinct elements in
D[sp, ep], with their frequencies, in O(lg n) time per delivered item.

Culpepper et al. [3] explored diﬀerent heuristics to solve the top-k problem
using this very same wavelet tree. They found out that their so-called “greedy”
heuristic was able to ﬁnd the top-k documents much faster than listing them all
and choosing the most frequent ones. They also showed that the structure was
competitive with inverted indexes on Natural Language text collections.

A parallel development started with Sadakane [20]. He proposed to store
a bitmap B[1, N] marking with a 1 the positions in T where the documents
started. B was enhanced with rank operations: rank(B, i) tells the number of
1s in B[1, i]. Hence D[i] = rank(B, A[i]) could be computed with very little
extra space on top of the CSA: A compressed representation of B requires just

196

G. Navarro, S.J. Puglisi, and D. Valenzuela

n lg N
n + O(n) + o(N) bits and supports rank in constant time [18]. To emulate 
Muthukrishnan’s algorithm, Sadakane showed that access to C is not really
needed, just RMQ queries on C. He designed an RMQ structure using 4N +o(N)
bits that does not need to access C. The time to list each document is O(tA).
Both in theory and in practice, this solution is competitive in time and uses
much less space than those based on wavelet trees, yet it only solves document
listing. Hon et al. [11] showed how to reduce the extra space to just o(N) by
sparsifying the RMQ structure, yet the time raises to O(tA lg1+ N).

For computing frequencies, Sadakane [20] proposed to store a CSA for each
−1 a constant number of
document d of the collection. By computing A and A
times over the global CSA and that of document d, it is possible to compute
frequencies on document d. An extra, symmetric, RMQ data structure must be
stored for this sake. Thus the space is 2|CSA| + O(N) bits, which may compare
favorably to the |CSA| + N lg n + o(N lg n) bits needed by wavelet trees. The
time for computing a frequency is O(tA), which again may compare favorably
with wavelet tree’s O(lg n). In practice, however, Culpepper et al. [3] found that
many small CSAs posed a much higher space overhead than that of the global
CSA, so the structure was much larger than the wavelet tree. The speed was
also slower than that oﬀered by wavelet trees. We conﬁrm in this paper that the
solution is still slower than our slower-and-smaller compressed wavelet trees.

Hon et al. [11] showed that the second RMQ data structure introduced by
Sadakane is unnecessary if one accepts an O(lg N) slowdown factor. In the light
of the results of Culpepper et al. [3], this is unlikely to change matters in practice,
because a reduction in 2N bits is insigniﬁcant but the slowdown is not. The key
contribution of Hon et al., however, is an algorithm for top-k retrieval with time
guarantees (which the heuristics of Culpepper et al. do not oﬀer). Hon et al.
build a sparse suﬃx tree on the collection, so that top-k queries over an interval
of multiples of g = k · b, for a parameter b, are precomputed. Thus to solve for
any interval [sp, ep], only O(kb) elements at the extremes must be accessed, their
frequency counted, and possibly inserted into the precomputed result. The extra
space is O((N/b) lg N lg n) bits on top of a solution for computing frequencies.
By choosing b = Θ(lg2+ N), this space is o(n) and the time for top-k queries is
O(k tA lg3+
N). Any of the discussed solutions for computing frequencies can be
used, and thus wavelet trees are of interest as a building block of this solution.
There is no comparison in the literature, however, between this technique and
the heuristics of Culpepper et al. [3], which as explained work on wavelet trees.
Thus, the best performance in practice is given by the wavelet tree of D, but
its space is still high. The only clue at compressing it was given by Gagie et al. [7],
who noted that D contains almost the same repetitions of the diﬀerential suﬃx
array [9], and thus a grammar-based compression would reduce its size when
the text is compressible. The practical impact of this theoretical result had not
been veriﬁed, however. Moreover, the situation is more complicated because we
do not need to represent D, but the wavelet tree of D, in order to support the
various document retrieval tasks. The main point of this paper is to implement a
grammar-compressed wavelet tree for D and evaluate its practical performance.

Practical Compressed Document Retrieval

197

3 Bitmaps and Wavelet Trees
Given a bitmap B[1, N], we deﬁne, for b ∈ {0, 1}, operation rankb(B, i) as the
number of occurrences of bit b in B[1, i], and selectb(B, j) as the position in B
of the jth occurrence of bit b.

m + O(m) + o(N).

Both operations can be solved in constant time by spending o(N) bits on top
of B [15], or by representing B in compressed form [18]: Let m be the number
of 1s in B, then the total space is m lg N
A wavelet tree [10] represents a sequence S[1, N] over an alphabet [1, ρ]. At
the root it stores a bitmap B[1, N] so that B[i] = 0 iﬀ S[i] ≤ ρ/2. The left
child of the root represents the subsequence of S formed by the symbols ≤ ρ/2;
the other symbols form a subsequence at the right child. Those children are
processed recursively over their alphabet ranges, until reaching the leaves. The
wavelet tree has O(ρ) nodes and height (cid:4)lg ρ(cid:5). Its bitmaps add up N(cid:4)lg ρ(cid:5) bits.
By using rank and select on the bitmaps, the wavelet tree gives access to
any S[i] in time O(lg ρ), thus it constitutes an alternative representation of S
within about the same size, N lg ρ + o(N lg ρ) bits. Other wavelet tree traversals
compute also symbol rank and select on S, where the argument b can be any
c ∈ [1, ρ], also in time O(lg ρ). As explained, the wavelet tree is also useful for
other types of queries of interest (in particular) to document retrieval [8,3].

If the compressed bitmap representation is used [18], then the space of the
wavelet tree becomes the zero-order entropy of S, N H0(S) + o(N log σ) [10]. In
our case, however, the zero-order entropy of the document array is likely to be
lg n bits per symbol, unless the document sizes are very diﬀerent. There is no
relation to the compressibility of the text itself.

4 Grammar Compression of Bitmaps

We describe a grammar-based compression of bitmaps B[1, N] that supports
rank and select operations on the compressed representation. We focus on RePair 
[12] compressor. It successively ﬁnds the most frequent pair of symbols in
the text, yz, and replaces it by a new symbol x (which can be involved in further
pairings), adding a new grammar rule x → yz. When all the pairs are unique,
RePair terminates and delivers the remaining sequence, C, and the set of rules,
R. We use a variant that generates a balanced grammar [21], of height O(lg N).
For providing random access we use sampling. Let (cid:5)(c) = 1 for terminals c,
and for nonterminals let (cid:5)(x) be the length of the string of terminals x expands
(cid:2)i−1
j=1 (cid:5)(C[j])
to (that is, (cid:5)(x) = (cid:5)(y) + (cid:5)(z) if x → yz ∈ R). Now let L(i) = 1 +
the starting position in B of the symbol C[i] when expanded.
We sample B at regular intervals s. For each position B[i · s] we store P [i] =
(p, o, r), where p is the position in C of the symbol whose expansion will contain
B[i · s], that is, p = max{j, L(j) ≤ i · s}. The second component is the oﬀset
within that symbol, o = i· s− L(p), and the third is the rank up to that symbol,
r = rank1(B, L(p)−1). Finally, we store, for the nonterminals x, the length (cid:5)(x)
and the number of 1s, r(x), of the string of terminals they expand to.

198

G. Navarro, S.J. Puglisi, and D. Valenzuela

(cid:3)) ≤ i < L(p

(cid:3) + 1) = l + (cid:5)(C[p

(cid:3) ≥ p so that l = L(p

To answer rank1(B, i), we compute j = (cid:7)i/s(cid:8) and P [j] = (p, o, r). We then
start from C[p] with position l = L(p) = i − o and rank r. From position p we
advance in C until l > i. Each symbol of C can be processed in constant time
while l and r are updated, since we know (cid:5)(x) and r(x) for any symbol x. Finally
(cid:3)]). At
we arrive at a position p
this point we complete our computation by recursively expanding C[p
(cid:3)] = x. Let
x → yz ∈ R, then if l + (cid:5)(y) ≤ i we expand y; otherwise we increase l by (cid:5)(y), r
by r(y), and expand z. As the grammar is balanced the total time is O(s+lg N).
For select we obtain the same complexity by ﬁrst binary searching P to ﬁnd
the right interval and then traversing sequentially the block, until exceeding the
desired number of 0s or 1s, and ﬁnally expanding the last symbol of C.
Let R = |R| be the number of rules in the grammar and C = |C| the length
of the ﬁnal array. Then a RePair compressor would require O((R + C) lg R) bits.
Our representation requires O(R lg N + C lg R + (N/s) lg N), and the time for
the operations is O(s+lg N). The minimum interesting value for s is lg N, where
we achieve space O((R + C) lg N + N) bits and O(lg N) time for the operations.
We can reduce the O(N) extra space to o(N) by increasing s, which impacts
query times and makes them superlogarithmic.
The scheme can be extended to sequences S[1, N] over a small alphabet [1, ρ].
The only diﬀerence is that the nonterminals x must store rc(x) for each c ∈ [1, ρ].
Similarly we must store ρ rank values at each sampled position. This raises the
overall space to O(Rρ lg N + C lg R + (N ρ/s) lg N). The time stays the same.
In practice. There are several ways to represent R in compressed form. We
choose one [9] that allows for random access to the rules. It represents R in the
form of a directed acyclic graph (DAG) as a sequence SR and a bitmap SB.
A node is identiﬁed as a position in SB, where a 1 denotes and internal node
and a 0 a leaf. The two children of SB[i] = 1 are written next to i, thus we
obtain all the subtree by traversing SB[i . . .] until we have seen more 0s than 1s.
The 0s in SB are associated to positions in SR (that is, SB[i] = 0 is associated
to SR[rank0(SB, i)]). Those leaf symbols are either terminals or nonterminals.
Nonterminals are actually positions in SB that must be recursively expanded.
This DAG representation takes, in good cases, as little as 50% of the space
required by a plain array representation of R [9].

In order to reduce the O(R lg n) space required to store (cid:5)(x) and r(x) for
nonterminals x, we store the data only for some of them and obtain the others
via expanding the nonterminals. Given a parameter δ, we guarantee that no
nonterminal in C requires expanding at depth more than δ to determine its
length and number of 1s. That is, we expand each C[i] until depth δ or until
reaching an already sampled nonterminal. Those nonterminals at depth δ are
then sampled. We set up a bitmap Bδ where each sampled nonterminal has a 1,
and store (cid:5)(x) and r(x) of marked nonterminal x at an array E[rank1(Bδ, x)].
We use a RePair implementation by ourselves (available at www.dcc.uchile.
cl/gnavarro/software). It has a variant that, although does not guarantee
balancedness, has always produced a grammar of very small height in our experiments.
 The variant that ensures balancedness harms compression in practice.

5 Grammar Compression of Wavelet Trees

Practical Compressed Document Retrieval

199

Given now a sequence S[1, N] over alphabet [1, n], we build the wavelet tree of
S and represent its bitmaps using the compressed format of Section 4. Consider
a RePair representation (R,C) of S, where the sizes of the components is R and
C as before. Now take the top-level bitmap B of the wavelet tree. Bitmap B
can be regarded as the result of mapping the alphabet of S onto two symbols,
,C(cid:3)) where the terminals are mapped accordingly,
0 and 1. Thus, a grammar (R(cid:3)
generates B. Since the number of rules in R(cid:3) is still R and that of C(cid:3) is C,
the representation of B requires O(R lg N + C lg R + (N/s) lg N) bits (this is of
course pessimistic; many more repetitions could arise due to the mapping).

The bitmaps stored at the left and right children of the root correspond to
a partition of S into two subsequences S1 and S2. Given the grammar that
represents S, we can obtain the one that represents S1 and S2 by removing all
the terminals in the right sides that do not belong to the proper subalphabet,
and removing rules with right hands of length 0 or 1. Thus at worst the left and
right side bitmaps can also be represented within O(R lg N + C lg R) bits each,
plus O((N/s) lg N) for the whole level. Added over the n wavelet tree nodes, the
overall space is no more than n times that of the RePair compression of S. The
time for the operations raises to O((s + lg N) lg n).

Although this does not look alphabet-friendy, and actually the upper bounds
are no better than applying the method of Section 4 on a large alphabet (ρ = n),
the analysis is a (very) pessimistic upper bound. Still one can expect that the
repetitions exploited by RePair get cut by half as we descend one level of the
wavelet tree, so that after descending some levels no repetition structure can be
identiﬁed and RePair compression becomes ineﬀective.

In practice. As n is large, we use a wavelet tree design that concatenates all the
bitmaps of the same wavelet tree level [2]. We use one set of rules R per level.
As the repetitions that could be present in S get shorter when we move deeper
in the wavelet tree, we evaluate at each level whether our RePair-based compression 
is actually better than an entropy-compressed representation [18] or even a
plain one, and choose the one with smallest space. Moreover, as rank and select
operations are signiﬁcantly slower on our RePair-compressed representation, we
use a parameter 0 < α ≤ 1 so that we prefer RePair compression only when its
size is α times that of the alternatives, or less.

6 Experimental Results

In this section we compare various practical alternatives to document listing and
top-k document retrieval. We have chosen four collections of diﬀerent nature,
such as English, Chinese, biological, and symbolic sequences. We show the bpc
of its global CSA divided by lg σ to give an idea of its compressibility ratio.

ClueChin: A 2.3 MB sample of ClueWeb09 (http://boston.lti.cs.cmu.edu/
Data/clueweb09), formed by 23 Web pages in Chinese. Ratio: 5.34/7.99=0.68.

200

G. Navarro, S.J. Puglisi, and D. Valenzuela

ClueWiki: A 141 MB sample of ClueWeb09, formed by 3,334 Web pages from

the English Wikipedia. Ratio: 4.74/6.98=0.68.

KGS: A 75 MB collection of 18,838 sgf-formatted Go game records from year

2009 (http://www.u-go.net/gamerecords). Ratio: 4.48/6.93=0.65.

Proteins: A 60 MB collection formed by 143,244 sequences of Human and
Mouse proteins (http://www.ebi.ac.uk/swissprot). Ratio: 6.02/6.57=
0.92.

Our tests were run on a Intel Core2 Duo machine, 3Ghz, with 8GB RAM and
6MB cache. Our code was compiled using g++ with full optimization.

As the CSA search for the interval [sp, ep] corresponding to a pattern p is
common to all the approaches, we do not consider the time for this search
(which never exceeds 0.02 milliseconds per query) nor the space for that global
CSA (shown for each collection in the previous itemization), but only the extra
space/time to support document retrieval once [sp, ep] has been determined. We
give the space usage in bits per text character (bpc), and measure user times.

Sadakane’s representation [20] builds a separate CSA for each document.
For this sake we use a very competitive variant [13,2] available at PizzaChili
(http://pizzachili.dcc.uchile.cl/indexes/SSA). It uses a plain and fast
representation for bitmap B (from http://libcds.recoded.cl), and an eﬃcient 
implementation for the two RMQs (from http://www.uni-ulm.de/in/
theo /research/sdsl). For the space we charge only 2N bits for each RMQ
structure and zero for B, to account for possible future space reductions.

Our grammar compressed wavelet trees oﬀer a space/time tradeoﬀ depending
on the α value, which can be the same for all levels, or decreasing for the deeper
levels (where one visits more nodes and thus being slower has a higher impact).
Another space/time tradeoﬀ is obtained with the sampling parameter s. We only
show one alternative with α = 1 and one best-performing alternative with α < 1.
As explained, alternative solutions [20,11] for the basic document listing problem 
are hardly improvable. They require very little extra space and are likely to
perform similarly to wavelet trees in time. Our experiments focus on document
listing with frequencies, and in top-k retrieval.

6.1 Document Listing with Frequencies
Previous work [3] has demonstrated that the quantile approach [8] is clearly
preferable, in space and time, over previous ones based on wavelet trees [22].
Therefore we carry out the quantile algorithm over a plain wavelet tree representation 
(WT-Plain), over one where the bitmaps are statistically compressed
[18] (WT-RRR), and over our RePair-compressed ones. As explained, we show
a variant with α = 1 (WT-RP, which at each level chooses the lowest space
between RePair, plain, or statistically compressed bitmap), and the best performing 
policy we tried for choosing α < 1 values (WT-RP alpha).

We also compare Sadakane’s approach [20] (SADA) on collection ClueChin.
The construction times over the other collections, with many more documents,
was extremely high. This tiny collection will be suﬃcient to expose the practicality 
problems of this approach.

Practical Compressed Document Retrieval

201

ClueChin

ClueWiki

 100

 10

 1

 0.1

 0.01

 0.001

 2

 4

 6

 8

Size (bpc)

KGS

 100

 10

 
y
r
e
u
q
 
r
e
p
 
)
s
c
e
s

i
l
i

m

(
 
e
m
T

i

 

y
r
e
u
q
m
o
d
n
a
r
 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

WT−RP
WT−RRR
WT−RP alpha
WT−Plain
SADA

 10

 12

 14

WT−RP
WT−RRR
WT−RP alpha
WT−Plain

y
r
e
u
q
 
m
o
d
n
a
r
 
 
r
e
p
 
)
s
c
e
s

i
l
i

m

(
 
e
m
T

i

 
y
r
e
u
q

 
 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

WT−RP
WT−RRR
WT−RP alpha
WT−Plain

 1000

 100

 10

 1

 6

 7

 8

 9

 100

 12

 13

 14

 15

 10
 11
Size (bpc)

Proteins

WT−RP
WT−RRR
WT−RP alpha
WT−Plain

 1

 11

 12

 13

 14

 15

 16

 17

 18

 19

 10

 17

 17.5

 18

 18.5

 19

 19.5

 20

 20.5

 21

 21.5

 22

Size (bpc)

Size (bpc)

Fig. 1. Experiments for document listing with term frequencies

We chose 10,000 random intervals of the form [sp, ep], considering values for
ep − sp from 1, 000 to 10, 000, and listed the distinct documents in the interval
with their frequencies. The relative positions of the curves were the same for
every ep−sp value, so for lack of space we show just the plots for ep−sp = 10, 000.
Fig. 1 shows the results. Even on ClueChin, with just 23 documents, the space
overhead of indexing them separately makes Sadakane’s approach impractical
(even with the generous assumptions on extra bitmaps and RMQs). It is also
slower. For this reason we do not compare Hon et al.’s variant [11], that achieves
|CSA| + o(n) extra space, because it will be much slower and the reduction on
space (by 4N bits), would be insuﬃcient to make it competitive.

The results are diﬀerent depending on the type of collections, but in general
our compressed representation is able to reduce the space of the plain wavelet
tree by a wide margin. The compressed size is 40% to 75% of the original size.
The exception is Proteins, where the text is mostly incompressible and this
translates into the incompressibility of the document array.

While the WT-RP is signiﬁcantly slower than WT-Plain (up to 20 times slower
in the most extreme case), the WT-Alpha versions provide useful tradeoﬀs. They
achieve compression ratios of 50% to 80% and signiﬁcantly reduce time gaps, to 7
times slower in the most extreme case. The answer time over the interval [sp, ep]
of length 10,000 is around 10-20 milliseconds (msecs). We note that our slowest
version is still 10 times faster than SADA. It is also much faster than listing all
the documents individually (e.g., 500 times faster on ClueChin).

202

G. Navarro, S.J. Puglisi, and D. Valenzuela

6.2 Top-k Retrieval

Culpepper et al. [3] present and test two heuristics for top-k retrieval, which run
on wavelet trees. The one called greedy is always superior, so we test that one in
this paper, over our diﬀerent wavelet tree representations.

We also compare Hon et al.’s structure [11]. Short of implementing it, we
(quite) optimistically simulate its performance by charging zero time and zero
space to some parts of the data structure and search process. We combine it
only with the most promising wavelet tree in each plot.

Recall that the method divides the suﬃx array A into blocks of ﬁxed length
g. After ﬁnding the suﬃx array interval A[sp, ep] corresponding to a pattern, the
part of the search corresponding to the blocks fully contained in [sp, ep] is solved
with a sampled suﬃx tree (which we have not implemented and will assume costs
zero space and time). The other two subintervals from sp to the start of the next
block, and from the end of the last block to ep, are solved by brute force, that
is, extracting all the distinct documents and computing their frequency in the
whole interval A[sp, ep]. This part will be actually executed in diﬀerent ways.
Finally, the candidates obtained by brute force and those given by the suﬃx tree
are ranked and merged (which we will not do and will assume costs zero).

Various alternatives to extract the values of D and compute their frequency
are considered. WT-RP-HON and WT-RP-alpha HON use the corresponding
wavelet tree variants for this task. In case the interval [sp, ep] contains no blocks,
they switch to Culpepper et al.’s method. On ClueChin we tried other variants
related to Sadakane’s solution [20]. SADA-HON uses Sadakane’s structure just as
in the document listing experiment. HON does not use the two RMQ structures,
but instead maps the start of the interval [sp, ep] to the local CSA using A and
−1, and then binary searches the end of the local interval by mapping each
A
probe back to the global CSA [11]. Finally, Search-HON simply searches for p in
the local CSA in order to determine its frequency.

Fig. 2 shows the results. We selected 1,000 substrings at random positions,
of length 3 and 6, and retrieved the top-k documents for each, for k = 1 and
10. Longer patterns produce shorter [sp, ep] intervals. The relative space and
time performance comparisons are similar to those of document listing with
frequencies. Most times are around a few tens of msecs per query.

With respect to Hon et al.’s method, Search-HON and HON are very similar 
in time, much slower and 4N bits smaller than SADA-HON. Yet, none of
those variants of the original formulation [11] is competitive in practice. What
is much more interesting is their combination with a wavelet tree. While it is
slightly inferior to Culpepper et al.’s greedy heuristic on collections ClueChin
and ClueWiki, on the other two Hon et al.’s method speeds up the heuristic by
a factor of up to 1.5–6.5 for k = 1 and 2.2–2.5 for k = 10. While this is a spaceand 
time-optimistic simulation of Hon et al.’s method, it should be quite tight.

Final remarks. We have shown that the wavelet tree is the best data structure
to compute frequencies and support top-k algorithms, and reduced its size by up
to 40% while answering within tens of msecs. Also, theoretical top-k proposals

Practical Compressed Document Retrieval

203

ClueChin, pattern length 3, top 1

ClueChin, pattern length 6, top 1

WT−RP
WT−RRR
WT−RP alpha
WT−RP alpha+HON
WT−Plain
HON
Search+HON
SADA+HON

 2

 3

 4

 5

 6

 7
 8
Size (bpc)

 9

 10

 11

 12

 13

ClueWiki, pattern length 3

WT−RP(K=1)
WT−RRR(K=1)
WT−RP alpha(K=1)
WT−RP alpha+HON(K=1)
WT−Plain(K=1)
WT−RP(K=10)
WT−RRR(K=10)
WT−RP alpha(K=10)
WT−RP alpha+HON(K=10)
WT−Plain(K=10)

y
r
e
u
q
 
r
e
p
 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

 100

 10

 1

 0.1

 0.01

 100

y
r
e
u
q

 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

 10

 1

WT−RP
WT−RRR
WT−RP alpha
WT−RP alpha+HON
WT−Plain
HON
Search+HON
SADA+HON

 2

 3

 4

 5

 6

 7
 8
Size (bpc)

 9

 10

 11

 12

 13

ClueWiki, pattern length 6

WT−RP(K=1)
WT−RRR(K=1)
WT−RP alpha(K=1)
WT−RP alpha+HON(K=1)
WT−Plain(K=1)
WT−RP(K=10)
WT−RRR(K=10)
WT−RP alpha(K=10)
WT−RP alpha+HON(K=10)
WT−Plain(K=10)

y
r
e
u
q
 
r
e
p
 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

 100

 10

 1

 0.1

 0.01

 1000

y
r
e
u
q

 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

 100

 10

 7

 8

 9

 10
 11
Size (bpc)

KGS, pattern length 3

 12

 13

 14

 15

 1

 6

 7

 8

 9

 12

 13

 14

 15

 10
 11
Size (bpc)

KGS, pattern length 6

WT−RP(K=1)
WT−RRR(K=1)
WT−RP alpha(K=1)
WT−RP alpha+HON(K=1)
WT−Plain(K=1)
WT−RP(K=10)
WT−RRR(K=10)
WT−RP alpha(K=10)
WT−RP alpha+HON(K=10)
WT−Plain(K=10)

 0.1

 6

 100

 10

 1

 11

 40

 35

 30

 25

 20

 15

 10

 5

 0

 17

 
 
y
r
e
u
q

 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

y
r
e
u
q

 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

 
 
y
r
e
u
q

 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

y
r
e
u
q

 
r
e
p

 
)
s
c
e
s

i
l
i

m

(
 

e
m
T

i

 100

 10

 1

 11

 10

 9

 8

 7

 6

 5

 4

 3

 2

 1

 0

 17

WT−RP(K=1)
WT−RRR(K=1)
WT−RP alpha(K=1)
WT−RP alpha+HON(K=1)
WT−Plain(K=1)
WT−RP(K=10)
WT−RRR(K=10)
WT−RP alpha(K=10)
WT−RP alpha+HON(K=10)
WT−Plain(K=10)

 12

 13

 14

 15

 16

 17

 18

 19

Size (bpc)

Proteins, pattern length 3

WT−RP(K=1)
WT−RRR(K=1)
WT−RP alpha(K=1)
WT−RP alpha+HON(K=1)
WT−Plain(K=1)
WT−RP(K=10)
WT−RRR(K=10)
WT−RP alpha(K=10)
WT−RP alpha+HON(K=10)
WT−Plain(K=10)

 17.5

 18

 18.5

 19

 19.5

 20

 20.5

 21

 21.5

 22

 12

 13

 14

 15

 16

 17

 18

 19

Size (bpc)

Proteins, pattern length 6

WT−RP(K=1)
WT−RRR(K=1)
WT−RP alpha(K=1)
WT−RP alpha+HON(K=1)
WT−Plain(K=1)
WT−RP(K=10)
WT−RRR(K=10)
WT−RP alpha(K=10)
WT−RP alpha+HON(K=10)
WT−Plain(K=10)

 17.5

 18

 18.5

 19

 19.5

 20

 20.5

 21

 21.5

 22

Size (bpc)

Size (bpc)

Fig. 2. Experiments for top-k queries

204

G. Navarro, S.J. Puglisi, and D. Valenzuela

[11] are shown to be worth implementing. Yet, even our smaller indexes (except
on the tiny ClueChin) are even bigger than the CSAs of the collections (7-17 vs
4.5-6.0 bpc), thus there is much room for improvement in document retrieval. We
are still far from the asymptotic space optimality achieved for pattern matching.

References

1. Apostolico, A.: The myriad virtues of subword trees. In: Combinatorial Algorithms

on Words. NATO ISI Series, pp. 85–96. Springer, Heidelberg (1985)

2. Claude, F., Navarro, G.: Practical rank/Select queries over arbitrary sequences. In:
Amir, A., Turpin, A., Moﬀat, A. (eds.) SPIRE 2008. LNCS, vol. 5280, pp. 176–187.
Springer, Heidelberg (2008)

3. Culpepper, S., Navarro, G., Puglisi, S., Turpin, A.: Top-k ranked document search
in general text databases. In: de Berg, M., Meyer, U. (eds.) ESA 2010. LNCS,
vol. 6347, pp. 194–205. Springer, Heidelberg (2010)

4. Ferragina, P., Gonz´alez, R., Navarro, G., Venturini, R.: Compressed text indexes:

From theory to practice. ACM JEA 13, article 12 (2009)

5. Ferragina, P., Manzini, G., M¨akinen, V., Navarro, G.: Compressed representations

of sequences and full-text indexes. ACM Trans. Alg. 3(2), article 20 (2007)

6. Fischer, J., Heun, V.: A new succinct representation of RMQ-information and
improvements in the enhanced suﬃx array. In: Chen, B., Paterson, M., Zhang, G.
(eds.) ESCAPE 2007. LNCS, vol. 4614, pp. 459–470. Springer, Heidelberg (2007)
7. Gagie, T., Navarro, G., Puglisi, S.J.: Colored range queries and document
retrieval. In: Chavez, E., Lonardi, S. (eds.) SPIRE 2010. LNCS, vol. 6393, pp.
67–81. Springer, Heidelberg (2010)

8. Gagie, T., Puglisi, S.J., Turpin, A.: Range quantile queries: Another virtue of
wavelet trees. In: Karlgren, J., Tarhio, J., Hyyr¨o, H. (eds.) SPIRE 2009. LNCS,
vol. 5721, pp. 1–6. Springer, Heidelberg (2009)

9. Gonz´alez, R., Navarro, G.: Compressed text indexes with fast locate. In: Ma, B.,
Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 216–227. Springer, Heidelberg
(2007)

10. Grossi, R., Gupta, A., Vitter, J.: High-order entropy-compressed text indexes. In:

SODA, pp. 841–850 (2003)

11. Hon, W.-K., Shah, R., Vitter, J.: Space-eﬃcient framework for top-k string retrieval

problems. In: FOCS, pp. 713–722 (2009)

12. Larsson, N.J., Moﬀat, J.A.: Oﬄine Dictionary-Based Compression. Proc. of the

IEEE 88, 1722–1732 (2000)

13. M¨akinen, V., Navarro, G.: Implicit compression boosting with applications to selfindexing.
 In: Ziviani, N., Baeza-Yates, R. (eds.) SPIRE 2007. LNCS, vol. 4726, pp.
229–241. Springer, Heidelberg (2007)

14. Manber, U., Myers, G.: Suﬃx arrays: a new method for on-line string searches.

SIAM J. Comp. 22(5), 935–948 (1993)

15. Munro, I.: Tables. In: Chandru, V., Vinay, V. (eds.) FSTTCS 1996. LNCS,

vol. 1180, pp. 37–42. Springer, Heidelberg (1996)

16. Muthukrishnan, S.: Eﬃcient algorithms for document retrieval problems. In:

SODA, pp. 657–666 (2002)

17. Navarro, G., M¨akinen, V.: Compressed full-text indexes. ACM Comp. Surv. 39(1),

article 2 (2007)

Practical Compressed Document Retrieval

205

18. Raman, R., Raman, V., Rao, S.: Succinct indexable dictionaries with applications

to encoding k-ary trees and multisets. In: SODA, pp. 233–242 (2002)

19. Sadakane, K.: New text indexing functionalities of the compressed suﬃx arrays. J.

Alg. 48(2), 294–313 (2003)

20. Sadakane, K.: Succinct data structures for ﬂexible text retrieval systems. J. Discr.

Alg. 5(1), 12–22 (2007)

21. Sakamoto, H.: A fully linear-time approximation algorithm for grammar-based

compression. J. Discr. Alg. 3, 416–430 (2005)

22. V¨alim¨aki, N., M¨akinen, V.: Space-eﬃcient algorithms for document retrieval. In:
Ma, B., Zhang, K. (eds.) CPM 2007. LNCS, vol. 4580, pp. 205–215. Springer,
Heidelberg (2007)

