Asymptotically Optimal Encodings for Range
Selection∗
Gonzalo Navarro1, Rajeev Raman2, and Srinivasa Rao Satti3

1 Department of Computer Science, University of Chile, Chile

gnavarro@dcc.uchile.cl

2 Department of Computer Science, University of Leicester, UK

3

r.raman@leicester.ac.uk
School of Computer Science & Engg, Seoul National University, S. Korea
ssrao@cse.snu.ac.kr

Abstract

We consider the problem of preprocessing an array A[1..n] to answer range selection and range
top-k queries. Given a query interval [i..j] and a value k, the former query asks for the position of
the kth largest value in A[i..j], whereas the latter asks for the positions of all the k largest values
in A[i..j]. We consider the encoding version of the problem, where A is not available at query
time, and an upper bound κ on k, the rank that is to be selected, is given at construction time.
We obtain data structures with asymptotically optimal size and query time on a RAM model
with word size Θ(lg n): our structures use O(n lg κ) bits and answer range selection queries in
time O(1 + lg k/ lg lg n) and range top-k queries in time O(k), for any k ≤ κ.

1998 ACM Subject Classiﬁcation F.2.2. Nonnumerical Algorithms and Problems, E.2 Data
Storage Representations, E.4 Coding and Information Theory

Keywords and phrases Data Structures, Order Statistics, Succinct Data Structures, Spaceeﬃcient 
Data Structures

Digital Object Identiﬁer 10.4230/LIPIcs.FSTTCS.2014.291

Introduction

1
We consider the problem of preprocessing an array A[1..n] over a totally ordered universe, so
that the following queries can be eﬃciently answered:

Range selection: select(i, j, k) returns the position of the kth largest element in A[i..j].
Range top-k: top(i, j, k) returns the positions of the k largest elements in A[i..j].
We can assume that A is a permutation of [n], since replacing each element A[i] by its
rank in A yields correct answers to those queries. The range selection problem has received
a lot of interest in recent years [4, 3, 13, 5]. Following a series of earlier papers, Brodal
and Jørgensen [4] presented a structure using linear space and O(lg n/ lg lg n) time, for any
k given at query time. The model used for this result, as well as the other results in this
paper, is the word RAM model with word size w = Θ(log n) bits. Jørgensen and Larsen
[13] improved the time to O(lg k/ lg lg n + lg lg n), still within linear space, and proved that
Ω(lg k/ lg lg n) time is needed when using n lgO(1) n space. Finally, Chan and Wilkinson [5]

∗ Navarro funded in part by Millennium Nucleus Information and Coordination in Networks ICM/FIC
P10-024F; Satti partly supported by Basic Science Research Program through the National Research
Foundation of Korea (NRF) funded by the Ministry of Education, Science and Technology (Grant
number 2012-0008241).

© Gonzalo Navarro, Rajeev Raman, and Srinivasa Rao Satti;
licensed under Creative Commons License CC-BY

34th Int’l Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS 2014).
Editors: Venkatesh Raman and S. P. Suresh; pp. 291–301

Leibniz International Proceedings in Informatics
Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany

292

Asymptotically Optimal Encodings for Range Selection

matched this lower bound, obtaining O(1 + lg k/ lg lg n) time using linear space1. This result
implies, via a reduction ﬁrst observed in [4], an optimal O(k)-time solution to the range
top-k problem as well.

In this paper, we are interested in the encoding model, where the array A is not available
at query time, and therefore the data structure must contain enough information to answer
queries by itself. One can always use a non-encoding data structure such as that of Chan and
Wilkinson [5], on a copy A0 of A, and thus trivially avoid access to A at query time. This
yields an encoding that uses O(n) words, or O(n log n) bits, and has time equal to that of
the best non-encoding data structure. We aim to ﬁnd non-trivial encodings of size o(n log n)
bits (from which, of course, it is not possible to recover the sorted permutation, but one can
still answer any select query).

Existing non-trivial solutions for this problem in the encoding model are as follows. In
the case k = 1, both queries boil down to the well-known range maximum query (RMQ),
which can be answered in constant time and 2n + o(n) bits, matching the lower bound of
2n − O(lg n) bits to within lower-order terms [9]. Note that the space usage is O(n/ lg n)
words, or sublinear. The case k = 2 was recently considered by Davoodi et al. [7]. Grossi et
al. [11] considered encodings for general k, showing that Ω(n lg k) bits are needed to encode
answers to either selection or top-k queries. Therefore, interesting encodings can only exist if
an upper bound κ on k is given at construction time—the so-called κ-bounded rank variant
of this problem [13]. For general k, Grossi et al. [11] gave an asymptotically optimal-space
and O(1) time solution for the (much simpler) case where k is ﬁxed at construction time and
furthermore, only one-sided queries (i.e. query intervals of the form A[1, j]) are supported.
Optimal-space encodings for the two-sided range selection problem can be obtained via
encodings of the range top-k problem given by Grossi et al.
[11] described below; these
however have poor running times. Chan and Wilkinson gave a (bounded-rank) range selection
encoding for general k that answers select queries in O(1 + lg k/ lg lg n) time. Its space usage,
however, is O(n(lg κ + lg lg n + (lg n)/κ)) bits, which is non-optimal.

In this paper we show that the same optimal time can be obtained in the encoding model,

using asymptotically optimal space.
(cid:73) Theorem 1. Given an array A[1..n] and a value κ, there is an encoding of A that uses
O(n lg κ) bits and supports the query select(i, j, k) in O(1 + lg k/ lg lg n) time for any k ≤ κ.
Furthermore, our development allows us to obtain asymptotically optimal time and space

for the encoding range top-k problem.
(cid:73) Theorem 2. Given an array A[1..n] and a value κ, there is an encoding of A that uses
O(n lg κ) bits and supports the query top(i, j, k) in time O(k), for any k ≤ κ.

Grossi et al. [11] gave a range top-k encoding using O(n lg κ) bits that answers top-k
queries in O(κ) time, for any k ≤ κ. To achieve the optimal O(k) time, they require O(n lg2 κ)
bits. Note that Grossi et al.’s result implies an optimal-space (bounded-rank) range selection
encoding with running time O(κ).

In general, the low space usage of encoding data structures is useful when the values in A
themselves are uninteresting, and one just wants to query about their relative magnitudes.
An example of range top-k queries used for autocompletion search is given by Grossi et

1 Chan and Wilkinson claim a bound of O(1 + logw k) for the “trans-dichotomous” model where the word
size w = Ω(log n); this is, however, based on an incorrect application [17] of a result of Grossi et al. [12],
and the proof presented in [5] only yields a time bound of O(1 + log k/ log log n).

G. Navarro, R. Raman, and S. R. Satti

293

al. [11]; the problem arises frequently in data and log mining applications as well. In addition,
our result for range selection allows, for example, delivering the top-k results in sorted order.
It is also useful for interfaces where, say, the top-k results are displayed and then, upon
user request, the (k + 1)th to 2kth results are displayed, and so on. Even when A is needed,
the sub-linear space usage of encoding data structures means that multiple copies of range
selection data structures can be built over one copy of A, and still take less space than A
(this trick is used already in the non-encoding result of [5]).

The next section gives some basic concepts and the roadmap of the paper.

2

Preliminaries

Grossi et al. [11] build their results on top of the shallow cutting technique [13, 5]. We revisit
(a slight variant of) this construction, as we also build on it.

Let A[1..n] be a permutation on [n]. Furthermore, consider each entry A[i] as a point
(x, y) = (i, A[i]), and set a parameter κ. A horizontal line sweeps the space [1, n]× [1, n] from
y = n to y = 1. The points hit are included in a single root cell, which spans a three-sided
area called a slab, of the form [1, n] × [y, n], including all the points of the cell. Once we
reach a point (x∗, y∗) that makes the root cell contain 2κ points, we close the cell and leave
its ﬁnal slab as [1, n] × [y∗, n]. Then we create two children cells of κ points as follows. Let
xsplit be the κth x-coordinate in the root cell. This is called the split point. Then the new
cells contain the points whose x-coordinates are ≤ xsplit and > xsplit, respectively, and their
initial slabs are thus [1, xsplit] × [y∗, n] and [xsplit + 1, n] × [y∗, n] (these will grow downwards
as we continue with the sweeping process, independently on each cell). When those cells
reach size 2κ, they are split again, and so on. A binary tree TC is created to reﬂect the cell
reﬁnement process. The root cell is associated with the root node of TC, the ﬁrst two children
cells to the left and right children of the root, and so on. The leaves of TC are associated
with the ﬁnal cells, which have not been split and contain κ to 2κ − 1 points (unless n < κ).
At any moment of the sweeping process, there is a sequence of split points x1, x2, . . ., which
grows as further cells are split. The current leaves of TC cover an interval of x-coordinates
[xi + 1, xi+1] (we implicitly assume split points 0 and n at the extremes). When the next
split occurs, within the cell covering interval [xi + 1, xi+1], we split the cell into two new
cells covering the x-coordinate intervals [xi + 1, xsplit] and [xsplit + 1, xi+1]. We associate the
keys [xi + 1, xsplit] and [xsplit + 1, xi+1] and the extents [xi−1 + 1, xi+1] and [xi + 1, xi+2],
respectively, with the two new cells. After the sweep ﬁnishes, the sequence of split points
is of the form 0 = x0 < x1 < x2 < . . . < xn0 = n. In the following, we will use xi to refer
to this ﬁnal sequence of split points. Then we add n0 further keyless cells with extents
[xi−1 + 1, xi+1] for all 1 ≤ i ≤ n0. Note that κ ≤ xi+1 − xi ≤ 2κ for all i (if n ≥ κ).
This construction has useful properties [13]: (i) it creates O(n0) = O(n/κ) cells, each
containing κ to 2κ points (if n ≥ κ); (ii) if c is the cell of the highest (closest to the root)
node v ∈ TC whose key is contained in a query range [i..j], then [i..j] is contained in the
extent of c; and (iii) the top-κ values in [i..j] belong to the union of the points in the 3 cells
comprising the extent of c.

With these properties, Chan and Wilkinson [5] reduce the O(lg n/ lg lg n) time of Brodal
and Jørgensen [4] as follows. At each node v ∈ TC, they store the structure of Brodal and
Jørgensen for the array Av[1..O(κ)] of the y-coordinates of the points in the extent of v.
Actually, they store in Av the local permutation in [O(κ)] induced by the relative ordering
in A, thus Av requires O(κ lg κ) bits in each v and O(n lg κ) bits in total. The structure for
range selection also uses O(κ lg κ) bits and answers queries in time O(1 + lgw κ). They also

FSTTCS 2014

294

Asymptotically Optimal Encodings for Range Selection

store an array Pv[1..O(κ)], so that Pv[i] is the position in A[1..n] of the value stored in Av[i].
Property (iii) above implies that the kth largest element of A[i..j], for any k ≤ κ,
is also the kth largest value in Av[l, r], where v is the node that corresponds to interval
[i..j] by property (ii) and Pv[l − 1] < i ≤ j < Pv[r + 1] are the elements in the extent
of node v enclosing [i..j] most tightly. Thus query select(i, j, k) on A is mapped to query
p = select(l, r, k) on Av. Once the local answer is found in Av[o], the global answer is Pv[o].
Chan and Wilkinson [5] manage to store all the Pv arrays in O(n lg(κ lg n) + (n/κ) lg n) bits,
which gives O(n lg n) bits when added over a set of suitable κ values. This is linear space,
but too large for an encoding.

Grossi et al. [11] use an O(n0)-bit representation of the topology of TC [16] that carries
out a number of operations in constant time, plus a bit-vector of length n to mark the xi
values. With these and some additional structures of total size O(n) bits, they show how
to ﬁnd the appropriate node v ∈ TC, as well as the cell and extent limits, corresponding to
a range A[i..j], in constant time. They can also map between i and xi, and compute the
interval [xl, xr] of splitting points contained in any node v, all in constant time.

In the sequel we build a spaceand 
time-optimal encoding for range selection:

1. In Section 3 we provide constant-time access to any Pv using only O(n lg κ) bits in the
encoding model. This yields an O(lg κ) time algorithm for range selection, as we can
ﬁrst ﬁnd the node v in constant time, then binary search for l and r in Pv, then run the
range selection query on Av in time O(1 + lg κ/ lg lg n), to ﬁnally return Pv[o] in O(1)
time. This is obtained by a hierarchical marking of nodes plus a color-based encoding of
the inheritance of points along cells in paths of unmarked nodes in TC.

2. In Section 4 we address the bottleneck of the previous solution: we replace the binary
search by fast predecessor queries on Pv, so as to obtain O(1 + lg κ/ lg lg n) time. This is
obtained by storing succinct string B-trees (succinct SB-trees) [12] on some nodes, which
enable a denser marking, and searches on the color information along (now shorter) paths
of unmarked nodes, using global precomputed tables.

3. In Section 5 we wrap up the results in order to prove Theorem 1. Then we show how
to answer top-k queries by ﬁrst ﬁnding the kth element in Av and then using existing
techniques [15] to collect all the values larger than the kth. This proves Theorem 2.

Constant-time Access to Pv

3
We describe a data structure that gives constant-time access to the values Pv[1..O(κ)] in any
node v.

‘ ≤ s(v) < t2

‘−1. For any ‘ ≥ 1, we mark a node v ∈ TC if it is of level ‘ and:

3.1 Marking Nodes
Let s(v) be the number of descendants of v in TC. We deﬁne a decreasing sequence of sizes
as follows: t0 = n0 and t‘+1 = dlg t‘e, until reaching a z such that tz = 1. Node v will be of
level ‘ if t2
C1. it is a leaf or both its children are of level > ‘; or
C2. both its children are of level ‘; or
C3. it is the root or its parent is of level < ‘.
(cid:73) Lemma 3. The number of marked nodes of level ‘ is O(n0/t2
‘).
Proof. The key property is that the descendants of v are of the same level of v or less. So
nodes marked by C1 above cannot descend from each other, thus each such marked node
‘ descendants not shared with another. As TC has at most 2n0 nodes, there
has at least t2

G. Navarro, R. Raman, and S. R. Satti

295

cannot be more than 2n0/t2
‘ nodes marked by this condition. By the same key property,
nodes marked by C2 form a binary tree whose leaves are those marked by C1, thus there are
at most other 2n0/t2
‘ nodes marked by C2. For C3, note that all unmarked nodes of level ‘
are in disjoint paths (otherwise the parent of two nodes of level ‘ would be marked by C2),
and the path terminates in a node already marked by C1 or C2 (contrarily, a node of level ‘
marked by C3 must be a child of a node of level < ‘, and thus cannot descend from nodes of
level ‘, by the key property). Therefore, C3 marks the highest node of each such isolated
path leading to a node marked by C1 or C2, and thus the number of nodes marked this way
(cid:74)
is limited by those marked by C1 or C2.

3.2 Handling Marked Nodes
Marked nodes, across all the levels, are few enough to admit an essentially naive storage of the
array Pv. If a marked node v represents a slab with left boundary xl +1, we store all its Pv[o]
values as the integers Pv[o] − xl. As explained, from v we can determine xl, and thus obtain
Pv[o] in constant time. Since a node of level ‘ contains less than t2
‘−1 descendants (leaves, in
‘−1) positions
particular), its slab spans O(t2
in A. Thus, each such integer Pv[o] − xl can be represented using lg O(κ t2
‘−1) = O(t‘ + lg κ)
bits. The second term adds up to O(κ lg κ) bits per node and O(n lg κ) overall. Since, by
Lemma 3, there are O(n0/t2
‘) marked nodes of level ‘, the ﬁrst term, O(t‘), adds up to
‘) · (κ t‘)) = O(n/t‘) bits over all marked nodes of level ‘. Adding over all the levels
O((n0/t2
‘=0 1/t‘. Since tz = 1 and t‘−1 > 2t‘−1, it holds tz−s > 2s for s ≥ 4, and

‘−1) consecutive split points xi, and thus O(κ t2

‘ we have O(n)Pz
thus O(n)Pz

‘=0 1/t‘ ≤ O(n)(O(1) +P

s≥0 1/2s) = O(n) bits overall.

3.3 Handling Unmarked Nodes
While the problem of supporting constant-time access to Pv is solved for marked nodes,
TC may have Θ(n0) unmarked nodes. To deal with unmarked nodes, we ﬁrst observe that
an unmarked node v at level ‘ has exactly one level ‘ child and one child x at level > ‘
(otherwise v would be marked by C2). Furthermore, x is marked by C3. Finally, the marked
parent of an unmarked level ‘ node must be the root or at level ‘ itself. Thus, as already
observed, level ‘ unmarked nodes form disjoint paths in TC, and all nodes adjacent to such a
path are marked.

Now consider the points in slabs corresponding to unmarked nodes. When a cell is closed
and split into two, the leftmost (rightmost) κ points in its slab become part of its left (right)
child slab.

Thus, each child slab starts out with κ inherited points which are in common with its
parent slab and κ further original points will be added to it before it is itself closed and
split. For each point of node v, in x-coordinate order, we use a bit to specify if the point is
inherited or original. Let ov[1..2κ] be this bit-vector.

Let π be a path of unmarked nodes of level ‘, let u be the marked parent of the topmost
unmarked node, and let v be an unmarked node in π. Each original point p of v must be an
inherited point of some marked descendant v0 that is adjacent to π (recall that v0 represents
all its points explicitly). Thus the coordinate of each such original point p can be speciﬁed
by recording which marked descendant v0 contains it, and the rank of p among the points
of v0. Suppose that the j-th original point in v is in v’s marked descendant at distance dj
along π. Then we write down the bit-string bv = 1d1−101d2−10 . . . 1dκ−10. We claim that,
summed across all nodes v in the path π, this adds 2|π|κ bits: there are |π|κ 0 bits, each 1
bit represents an inherited point in a slab on the path π, and there are |π|κ inherited points

FSTTCS 2014

296

Asymptotically Optimal Encodings for Range Selection

in π. Thus,P

v∈TC

|bv| = O(n0κ) = O(n) bits. As explained, we also store O(lg κ) bits for
each original point in v telling which rank to pick in the marked node, in an array rv. This
adds O(n0κ lg κ) = O(n lg κ) bits, which completes the information necessary to identify any
original point. Section 3.4 has the details of how to obtain the point value in O(1) time.

Unfortunately, we cannot apply the same approach to the inherited points in v, as we
cannot bound the size of the bit-strings as we did for bv. For any inherited point p in v,
we instead specify which ancestor of v on π has p as an original point (we specify u if this
ancestor is outside π), and then retrieve the point as an original point in the ancestor. This
is done by coding points using 4κ colors. Of these colors, 2κ are original colors and 2κ are
inherited colors. For each original color g there is a corresponding inherited color g0. All the
points in u are given arbitrary distinct original colors. Then we traverse the nodes v in π
top to bottom. If point p in v is inherited (from its parent v0), we look at the color of p in v0.
If p has an original color g in v0, we give p color g0 in v. Otherwise, if p is also inherited in
v0, having color g0, it will also have color g0 in v. On the other hand, if point p is original in
v, we give it one of the currently unused original colors. Note that no colors g and g0 can be
present simultaneously in any v0, thus writing g0 in v unambiguously determines which color
is inherited from v0. Then any other color g such that g0 is not among the κ inherited colors
of v can be used as an original color for v.

This scheme gives suﬃcient information to track the inheritance of points across π: when
a new, original, point p appears in v, it is given an original color g. Then the point is inherited
along the descendants of v as long as color g0 exists below v. Thus, to ﬁnd the appropriate
ancestor of v that contains a given inherited point p of color g0, as an original point, we
concatenate all the colors on π into a string, and ask for the nearest preceding occurrence
of color g. The path can be encoded in O(|π|κ lg κ) bits, which adds up to O(n lg κ) bits
overall. The position of g in the nearest ancestor also tells which of the original points does
p correspond to.

3.4 Technicalities
Let us ﬁx a representation for TC using O(n0) bits and supporting a large number of
operations in constant time [16], in particular the preorder rank r(v) of any node v. We also
use structures that support two operations on bit-vectors and sequences X: ranka(X, i) is
the number of occurrences of symbol a in X[1..i], and selecta(X, j) is the position of the jth
occurrence of letter a in X.

We store a bit-vector M[1..O(n0)] in the same preorder of the nodes, where M[r(v)] = 1
iﬀ node v is marked. Further, we store a string S[1..O(n0)] where we write down the
level of each marked node, that is, S[rank1(M, r(v))] = ‘ iﬀ v is marked and of level ‘.
Operations rank and select on M can be supported in constant time and o(|M|) further
bits [6, 14]. Since there are lg∗ n0 distinct values of ‘, the alphabet of S is small and S can
be represented within |S|H0(S) + o(n0) bits so that operations rank and select on S can
be carried out in constant time [8]. Here H0(S) is the zeroth-order empirical entropy of S,
‘ n‘ lg(|S|/n‘), where n‘ is the number of occurrences of symbol
‘ in S. Since n‘ lg(|S|/n‘) is increasing2 with n‘ and n‘ = O(n0/t2
‘) by Lemma 3, we have
‘)/t2

deﬁned as |S|H0(S) =P
|S|H0(S) = O(n0)P

‘ = O(n0)P

‘ ≤ O(n0)P

‘ 1/t‘ = O(n0).

With M and S we can create separate storage areas per level for the explicit Pv arrays of

‘ lg(t2

‘ lg(t‘)/t2

2 At least for n‘ ≤ |S|/e. When n‘ is larger we can simply bound n‘ lg(|S|/n‘) = O(n‘), thus we can

remove all those large n‘ terms from the sum and add an extra O(n0) term to absorb them all.

G. Navarro, R. Raman, and S. R. Satti

297

marked nodes, each of which uses the same space for nodes of the same level: if a node v is
marked (i.e., M[r(v)] = 1) and is of level ‘ = S[rank1(M, r(v))], then we store its array Pv
as the rth one in a separate sequence for level ‘, where r = rank‘(S, ‘).

Now consider unmarked nodes. The vectors ov, rv and bv are concatenated in the same
preorder of the nodes. While vectors ov and rv are of ﬁxed size, vectors bv are not. Their
starting positions are thus indicated with 1s in a second bit-vector B[1..O(n)]. Given any
original point ov[i] = 1, it is the jth original point for j = rank1(ov, i); recall that j is used
to ﬁnd dj in bv. Now bv starts at position select1(B, r(v)) in the concatenation of all the
bv’s. Finally, we recover dj as select0(bv, j) − select0(bv, j − 1).

Now we have to ﬁnd the marked node v0 leaving π at distance dj from v. The strategy
is to ﬁnd the node u0 that is “at the end” of π. More precisely, u0 is a child of the lowest
node of π and is the only node leaving π that is of the same level ‘ of v. Indeed, u0 is the
highest marked node of level ‘ in the subtree of v. Since we can compute node depth and
level ancestors in constant time [16], we can compute the ancestor a of u0 that is at depth
depth(v) + dj − 1, and ﬁnd v0 as the child of a that is not in π, that is, is not an ancestor of
u0.

Now, to ﬁnd u0, we calculate the subtree size of v (in constant time [16]) and hence its
level ‘.3 If the nodes are arranged in preorder, u0 is the ﬁrst node appearing after r(v),
r(u0) > r(v), which is marked M[r(u0)] = 1 and whose level is S[rank1(M, r(u0))] = ‘. This
corresponds to the ﬁrst occurrence of ‘ in S after position rank1(M, r(v)). This is found in
constant time with rank and select operations on S, and then r(u0) is found with select on
M. Finally, the tree representation gives us u0 from its rank r(u0) in constant time as well.
The sequence of colors cπ of path π is also associated with the last node u0 of π, and all
are concatenated in preorder of those nodes u0. As before, a bitmap is used to mark the
starting position of each sequence cπ, and another bitmap is used to mark the preorders of
the involved nodes u0.
Now let cπ be the sequence of 2|π|κ colors for path π, writing from highest to lowest node
the 2κ colors of each node. The subarray corresponding to each v is easily found in cπ by
knowing the depth of v and of u0. In order to ﬁnd, given a position cπ[i] = g0, the largest
i0 < i such that cπ[i0] = g, we build a monotone minimum perfect hash function (MMPHF)
[1] for each original color g, recording the set of positions where either g or g0 occur in cπ. A
MMPHF can be regarded as a support for the limited operation rankg,g0(cπ, i) that counts
the number of occurrences of g or g0 in cπ[1..i], provided cπ[i] ∈ {g, g0}. This is answered in
constant time and using O(|π|κ lg lg κ) bits. In addition, for each g we store a bit-vector cg
π[rankg,g0(cπ, i)] = 1 iﬀ cπ[i] = g. Then, after computing r = rankg,g0(cπ, i), we use
so that cg
π[1..r]. This corresponds to the last occurrence
rank and select on cg
of g preceding cπ[i] = g0. The position is mapped back from cg
π[o] to cπ using a sequence
c0
π that identiﬁes g0 with g, so that the answer is selectg(c0
π, o). We use a representation for
π that requires O(|π|κ lg κ) bits and gives constant select time [10]. Thus the structures
c0
representing paths π use space O(|π|κ lg κ), which is independent of the path level ‘.

π to ﬁnd the latest 1 in cg

π

Extending access from cells to extents
We have shown how to provide constant-time access to the points in a cell. In order to extend
this to the extent of a node v, we use the technique of [11] to ﬁnd in constant time the 3
cells that form the extent of v, and simulate the concatenation of the 3 arrays P.

3 To ﬁnd the level in constant time from the subtree size, we can check directly for the case ‘ = 0, and

store the other answers in a small table of lg n0 cells.

FSTTCS 2014

298

Asymptotically Optimal Encodings for Range Selection

4

Predecessor Queries on Pv

Having constant-time access to Pv enables binary searching for the desired limits of the array
Av where the selection query is to be run. However the binary search time becomes the
bottleneck. In this section we obtain fast predecessor searches that replace the binary search.
A classical predecessor structure uses O(κ lg n) bits, as the universe is the set of positions
in A, and this adds up to O(n lg n) bits (note that this structure is needed in all the O(n0)
nodes of TC, not only the marked ones). A low-space predecessor structure when one has
independent access to the sequence is the succinct SB-tree [12, Lem. 3.3]. For κ elements over
a universe of size m, this structure supports predecessor queries in time O(1 + lg κ/ lg lg m)
using O(κ lg lg m) bits, and a precomputed table of size o(m) that depends only on m.

On a node v of level ‘, the universe of positions is of size O(κ s(v)) = O(κ t2

‘−1), thus the
succinct SB-tree would use O(κ lg lg(κ t‘−1)) = O(κ lg t‘ + κ lg lg κ) bits. The ﬁrst term is
still too large, as just considering the nodes with ‘ = 1 we add up to O(n lg lg n) bits.

To improve on this, we will use a marking that is denser than that used in Section 3 (this
marking is only used for the predecessor structures). We will further mark every (t‘/ lg2 t‘)th
node in the paths π of unmarked nodes of level ‘. All marked nodes will store a succinct
SB-tree. The number of marked nodes of level ‘ is now O(n0 lg2 t‘/t‘), so storing a succinct
SB-tree in a each marked node of level ‘ adds up to O(n lg3 t‘/t‘) bits. Adding up over all
s≥0 s3/2s) = O(n) bits. The second

‘ lg3 t‘/t‘ ≤ O(n)(O(1) +P

the levels ‘ we have O(n)P

term of the succinct SB-tree space, O(κ lg lg κ), adds up to O(n lg lg κ) bits.

As a result, the paths of unmarked nodes of level ‘ have length O(t‘/ lg2 t‘) = O(t‘).
Consider one such path. The nodes leaving the path are of level > ‘, except the node u0
leaving π at the bottom, which is of level ‘. Therefore, we can divide the range of s(v) split
points covered by v into three areas: (1) the area covered by the subtrees that leave π to the
left, (2) the area covered by the subtrees that leave π to the right, and (3) the area covered
by u0. Each of those areas is contiguous, (1) preceding (3) preceding (2). Since there are
O(t‘) nodes of type (1) and each is of level at least ‘ + 1, the total area covered by those is of
size O(t‘ · κ t2
‘). The case of (2) is analogous. Therefore, for the (unmarked) nodes
on π we store a succinct SB-tree for the values in area (1) and another for the values in area
(2), both using O(κ lg lg(κ t3
‘)) = O(κ lg lg(κ t‘)) bits. Given a predecessor request, we ﬁrst
ﬁnd the node u0 below π as in Section 3, and determine in constant time whether the query
falls in the area (1), (2), or (3) (by obtaining the limits [xl + 1, xr] of u0, as explained). If it
falls in areas (1) or (2) we use the corresponding succinct SB-tree of v, otherwise we use the
succinct SB-tree of u0 (which is marked and hence stores a regular succinct SB-tree). We use
the same techniques as in Section 3 to store and access the (variable-sized) representations
of the succinct SB-trees.

‘) = O(κ t3

With this twist, the space over a node of level ‘ is O(κ lg lg(κ t‘)) bits, adding up to at
most O(n lg lg lg n + n lg lg κ) bits, again dominated by the nodes of level ‘ = 1. This gives
a total space of O(n(lg κ + lg lg lg n)) and a time of O(lg κ/ lg lg n). Note that the time is
improved from O(lg κ/ lg lg t‘) to O(lg κ/ lg lg n) by using the same precomputed table over
a universe of size n for all the nodes, and this table requires o(n) further bits. This result is
already as desired if lg κ = Ω(lg lg lg n). In the sequel we address the case κ = O(lg lg n).

4.1 Handling Small κ Values
When κ = O(lg lg n) we will not use the mechanism of storing succinct SB-trees for areas (1)
and (2) of unmarked nodes as before, but a diﬀerent mechanism. Let π be a path of unmarked
nodes of level ‘. Let u1, u2, . . . be the nodes that leave π from the left, reading their areas in

G. Navarro, R. Raman, and S. R. Satti

299

i lg(κ t2

i t‘i) bits.

‘i

left-to-right order (i.e., top-down in π), and v1, v2, . . . be the nodes that leave π from the right,
also reading them in left-to-right order (i.e., bottom-up in π). Then the area of A covered by
π can be partitioned into the |π| consecutive areas covered by u1, u2, . . . , u0, v1, v2, . . .. All
those nodes are marked and thus store their own succinct SB-tree.

Our problem is to determine, given a node v in π, which is the predecessor in Pv of a
given position p. A ﬁrst predecessor structure, associated with π, determines in which of
those |π| areas p belongs (the node containing that area will descend from v). Let ‘i be the
‘i−1). Thus we can encode
level of node ui. Then the area covered by ui is of length O(κ t2

those lengths with, say, γ-codes [2], within O(P

‘i−1)) = O(|π| lg κ +P

On the other hand, we note that, since ‘i > ‘, it holds O(|π| lg κ +P

From a space accounting point of view, this space can be aﬀorded because we can charge
O(lg κ + t‘i) bits to the storage of ui. As ui’s level is larger than p, it is a marked node (see
Section 3). Thus there are O(n0/t2
) such nodes overall, each of which will be charged O(t‘i)
bits only once, from the path π it leaves, for a total of O(n0/t‘i) bits, adding up to O(n0)
bits overall. For the other term, note that we can always aﬀord lg κ bits of space per node.
i t‘i) = O(|π| lg κ +
|π| lg t‘). Since |π| = O(t‘/ lg2 t‘), t‘ = O(lg n) even for ‘ = 1, and κ = O(lg lg n), the space
is O(lg n/ lg lg n) = o(lg n), and thus the whole description of the ui areas ﬁts in a single
computer word, and a global precomputed table of o(n) bits can be used to answer any
predecessor query in constant time.

We proceed analogously with the areas of v1, v2, . . .. Now, a predecessor query for the
areas u1, u2, . . . , u0, v1, v2, . . . can be answered as before: We ﬁrst determine whether the
answer is u0 with a constant number of comparisons, and if not, we use the global precomputed
table with the description of the lengths of the areas of the ui or the vi nodes. This takes
O(1) time. Once we know the area where the answer lies, we use the succinct SB-tree of the
corresponding node v0 (which we remind it is marked) to ﬁnd the position of the predecessor
in its Pv0 array. Node v0 is found by ﬁrst computing its parent v00 with level ancestor queries
from u0 (found as in Section 3) and then v0 is the child of v00 not in π.

Once we have that the predecessor of p in v0 is Pv0[o0], the ﬁnal challenge is to map that
position in v0 to the corresponding position in v. We will reuse the encoding of 4κ colors
described in Section 3. Note that, in the string of 2|π|κ colors associated with the path π,
we have suﬃcient information to determine which of the points in v are inherited in v0: if
the color of the point is g or g0, we track g0 downwards in π until it does not appear in some
node v00, then the point is inherited in the sibling v0 of v00 not in π. Note that all the points
of v that are inherited in v0 are contiguous in Pv.

In addition to the color information cv, we store associated with v a sequence of numbers
nv[1..2κ], so that nv[i] is the rank of the ith point of v among the points stored in v0, where
v0 is the ﬁrst node leaving π that inherits the ith point of v. With the information of cv and
nv, and given the predecessor of a point in Pv0, we have suﬃcient information to determine
the predecessor of the point in Pv: only some of the points of Pv0 are inherited from Pv.
The set of all cv and nv arrays in π add up to O(|π|κ lg κ) bits, and since |π| = O(t‘/ lg2 t‘),
t‘ = O(lg n), and κ = O(lg lg n), this is O(lg n lg lg lg n/ lg lg n) = o(lg n). Thus a global
precomputed table of o(n) bits can precompute all the process of determining the predecessor
in any v given that the answer is at any position in any descendant v0.

Predecessors on extents
Once again, Pv refers to the extent of v, not only to its cell, whereas we support predecessors
only on the points of the cell. With a couple of comparisons we determine whether the
predecessor query must be run on the cell of v or on the cell of a neighboring node.

FSTTCS 2014

300

Asymptotically Optimal Encodings for Range Selection

5 Wrapping Up
We can now describe a structure that, given a value κ, uses O(n lg κ) bits and answers a
query select(i, j, k) for any k ≤ κ in time O(1 + lg κ/ lg lg n), as follows:
1. We ﬁnd the maximal interval [l, r] such that i ≤ xl + 1 ≤ xr ≤ j, using rank/select on a

bit-vector that marks the split points xs [11].

2. If the interval is empty, then A[i..j] is contained in a leaf of TC, which covers O(κ)
consecutive values of A. Then the query can be directly run on plain range selection
structures [4] associated with each leaf (these structures add up to O(n lg κ) bits).
3. Otherwise, we ﬁnd the highest node v ∈ TC containing [xl + 1, xr], as well as the other

two neighbor nodes that span the extent of v, all in constant time [11].

4. Using the structures of Section 4, we ﬁnd the predecessor Pv[r] of j, and the successor
Pv[l] of i (the successor needs structures analogous to the predecessor), in time O(1 +
lg κ/ lg lg n).

5. We use the range selection structure [4] associated with Pv to run the query o =

6. We use the structures of Section 3 to compute the ﬁnal answer Pv[o], in O(1) time, adding

select(l, r, k). The time is O(1 + lgw κ).

to it the starting oﬀset of node v.

t=0 lg κt = O(n)Pτ

structures is O(n)Pτ

In order to reduce the time to O(1 + lg k/ lg lg n), we build our data structures for values
< κ ≤ 22τ . The space for those
κt = 22t, for t = 0, 1, . . . , τ, where τ is such that 22τ−1
t=0 2t = O(n 2τ) = O(n lg κ). A query select(i, j, k)
is run on the structure for κt such that κt−1 < k ≤ κt, that is, 2t−1 < lg k ≤ 2t,4 and thus
its query time is O(1 + lg κt/ lg lg n) = O(1 + 2t/ lg lg n) = O(1 + lg k/ lg lg n). This proves
Theorem 1.

Answering the query top(i, j, k)
We proceed as for query select(i, j, k) until we ﬁnd the kth largest element in Av[l..r], let it be
Av[o]. Now we must ﬁnd all the elements Av[s] in Av[l..r] where Av[s] ≥ Av[o]. With an RMQ
structure over Av we can do this using Muthukrishnan’s algorithm [15]: ﬁnd the maximum
in Av[l..r], let it be Av[m1], then continue recursively with Av[l..m1 − 1] and Av[m1 + 1..r]
stoping the recursion when the maximum found at Av[m] satisﬁes Av[m] < Av[o]. Recall
that Av is a permutation on O(κ) symbols and thus we can aﬀord storing it directly. Finally,
when we have the positions m1, . . . , mk of the top-k elements, we return Pv[m1], . . . , Pv[mk].
The overall time is O(lg k/ lg lg n + k) = O(k). This proves Theorem 2.

Note that we deliver the top-k elements in unsorted order. On the other hand, after

O(1 + lg k/ lg lg n) time, each new result is delivered in O(1) time.

Conclusions

6
We have shown how to build an encoding data structure that uses asymptotically optimal
space of O(n lg κ) bits that answers κ-bounded rank range selection queries in time O(1 +
lg k/ lg lg n), and range top-k queries in O(k) time for any k ≤ κ. It would be interesting to
obtain exactly optimal space (to within lower-order terms), but the precise lower bound is
unknown even for k = 2 [7]. It would also be interesting to obtain optimal time bounds for
the general case w = Ω(lg n).

4 The search for the right t can be done in constant time by computing lg lg k and consulting a small

precomputed table of lg lg K ≤ lg lg n entries.

G. Navarro, R. Raman, and S. R. Satti

301

References

1 D. Belazzougui, P. Boldi, R. Pagh, and S. Vigna. Monotone minimal perfect hashing:

searching a sorted table with o(1) accesses. In Proc. 20th SODA, pages 785–794, 2009.

2 T. Bell, J. Cleary, and I. Witten. Text compression. Prentice Hall, 1990.
3 G. S. Brodal, B. Gfeller, A. G. Jørgensen, and P. Sanders. Towards optimal range medians.

Theor. Comp. Sci., 412(24):2588–2601, 2011.

4 G. S. Brodal and A.G. Jørgensen. Data structures for range median queries. In Proc. 20th

5 T. Chan and B.T. Wilkinson. Adaptive and approximate orthogonal range counting. In

ISAAC, LNCS 5878, pages 822–831, 2009.

Proc. 24th SODA, pages 241–251, 2013.

6 D. Clark. Compact Pat Trees. PhD thesis, University of Waterloo, Canada, 1996.
7

P. Davoodi, G. Navarro, R. Raman, and S. Srinivasa Rao. Encoding range minima and
range top-2 queries. Philosphical Transactions of the Royal Society A, 372:20130131, 2014.
P. Ferragina, G. Manzini, V. Mäkinen, and G. Navarro. Compressed representations of
sequences and full-text indexes. ACM Trans. Alg., 3(2):article 20, 2007.
J. Fischer and V. Heun. Space-eﬃcient preprocessing schemes for range minimum queries
on static arrays. SIAM J. Comp., 40(2):465–492, 2011.

8

9

10 A. Golynski, I. Munro, and S. Rao. Rank/select operations on large alphabets: a tool for

text indexing. In Proc. 17th SODA, pages 368–373, 2006.

11 R. Grossi, J. Iacono, G. Navarro, R. Raman, and S. Srinivasa Rao. Encodings for range

selection and top-k queries. In Proc. 21st ESA, LNCS 8125, pages 553–564, 2013.

12 R. Grossi, A. Orlandi, R. Raman, and S. Srinivasa Rao. More haste, less waste: Lowering
the redundancy in fully indexable dictionaries. In Proc. 26th STACS, pages 517–528, 2009.
13 A. G. Jørgensen and K. G. Larsen. Range selection and median: Tight cell probe lower

14
15

bounds and adaptive data structures. In Proc. 22nd SODA, pages 805–813, 2011.
I. Munro. Tables. In Proc. 16th FSTTCS, LNCS 1180, pages 37–42, 1996.
S. Muthukrishnan. Eﬃcient algorithms for document retrieval problems.
SODA, pages 657–666, 2002.

In Proc 13th

16 K. Sadakane and G. Navarro. Fully-functional succinct trees. In Proc. 21st SODA, pages

134–149, 2010.

17 B. T. Wilkinson. Personal Communication, 2014.

FSTTCS 2014

