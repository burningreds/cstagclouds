Indexing Text with Approximate q-Grams

Gonzalo Navarro1?, Erkki Sutinen2, Jani Tanninen2, and Jorma Tarhio2

1 Dept. of Computer Science, University of Chile

gnavarro@dcc.uchile.cl

2 Dept. of Computer Science, University of Joensuu, Finland

fsutinen,jtanni,tarhiog@cs.joensuu.fi

Abstract. We present a new index for approximate string matching.
The index collects text q-samples, i.e. disjoint text substrings of length
q, at (cid:12)xed intervals and stores their positions. At search time, part of the
text is (cid:12)ltered out by noticing that any occurrence of the pattern must
be reﬂected in the presence of some text q-samples that match approximately 
inside the pattern. We show experimentally that the parameterization 
mechanism of the related (cid:12)ltration scheme provides a compromise
between the space requirement of the index and the error level for which
the (cid:12)ltration is still e(cid:14)cient.

1 Introduction

Approximate string matching is a recurrent problem in many branches of computer 
science, with applications to text searching, computational biology, pattern 
recognition, signal processing, etc. The problem is: given a long text T1::n of
length n, and a (comparatively short) pattern P1::m of length m, both sequences
over an alphabet (cid:6) of size (cid:27), retrieve all the text substrings (or \occurrences")
whose edit distance to the pattern is at most k. The edit distance between two
strings A and B, ed(A; B), is de(cid:12)ned as the minimum number of character insertions,
 deletions and replacements needed to convert A into B or vice versa.
We de(cid:12)ne the \error level" as (cid:11) = k=m.

In the on-line version of the problem, the pattern can be preprocessed but
the text cannot. The classical solution uses dynamic programming and is O(mn)
time [23]. It is based in (cid:12)lling a matrix C0::m;0::n, where Ci;j is the minimum
edit distance between P1::i and a su(cid:14)x of T1::j. Therefore all the text positions
j such that Cm;j (cid:20) k are the endpoints of occurrences of P in T with at most k
errors. The matrix is initialized at the borders with Ci;0 = i and C0;j = 0, while
its internal cells are (cid:12)lled using

Ci;j = if Pi = Tj then Ci−1;j−1 else 1 + min(Ci−1;j; Ci−1;j−1; Ci;j−1) (1)

which extends the previous alignment when the new characters match, and otherwise 
selects the best choice among the three alternatives of insertion, deletion
? Work developed during postdoctoral stay at the University of Helsinki, partially
supported by the Academy of Finland and Fundaci(cid:19)on Andes. Also supported by
Fondecyt grant 1-000929.

R. Giancarlo and D. Sanko(cid:11) (Eds.): CPM 2000, LNCS 1848, pp. 350{363, 2000.
c(cid:13) Springer-Verlag Berlin Heidelberg 2000

Indexing Text with Approximate q-Grams

351

and replacement. Figure 1 shows an example. In an on-line searching only the
previous column C(cid:3);j−1 is needed to compute the new one C(cid:3);j, so the space
requirement is only O(m).

s
0
0
1
2
3
4
5

u
0
1
0
1
2
3
4

r
0
1
1
0
1
2
3

g
0
1
2
1
1
2
3

e
0
1
2
2
2
1
2

r
0
1
2
2
3
2
2

y
0
1
2
3
3
3
2

0
1
2
3
4
5
6

s
u
r
v
e
y

Fig. 1. The dynamic programming matrix to search the pattern "survey" inside
the text "surgery". Bold entries indicate matching text positions when k = 2.

A number of algorithms improved later this result [20]. The lower bound of
the on-line problem (proved and reached in [7]) is O(n(k + log(cid:27) m)=m), which is
of course Ω(n) for constant m.

If the text is large even the fastest on-line algorithms are not practical, and
preprocessing the text becomes necessary. However, just a few years ago, indexing 
text for approximate string matching was considered one of the main open
problems in this area [27,3]. Despite some progress in the last years, the indexing
schemes for this problem are still rather immature.

There are two types of indexing mechanisms for approximate string matching,
 which we call \word-retrieving" and \sequence-retrieving". Word retrieving
indexes [18,5,2] are more oriented to natural language text and information retrieval.
 They can retrieve every word whose edit distance to the pattern word is at
most k. Hence, they are not able to recover from an error involving a separator,
such as recovering the word "flowers" from the misspelled text "flo wers",
if we allow one error. These indexes are more mature, but their restriction can
be unacceptable in some applications, especially where there are no words (as in
DNA), where the concept of word is di(cid:14)cult to de(cid:12)ne (as in oriental languages)
or in agglutinating languages (as Finnish).

Our focus in this paper is sequence retrieving indexes, which put no restrictions 
on the patterns and their occurrences. Among these, we (cid:12)nd three types
of approaches.

Neighborhood Generation. This approach considers that the set of strings matching 
a pattern with k errors (called Uk(P ), the pattern \k-neighborhood") is (cid:12)nite,
and therefore it can be enumerated and each string in Uk(P ) can be searched using 
a data structure designed for exact searching. The data structures used have
been the su(cid:14)x tree [16,1] and DAWG [9,6] of the text. These data structures
allow a recursive backtracking procedure for (cid:12)nding all the relevant text substrings 
(or su(cid:14)x tree / DAWG nodes), instead of a brute-force enumeration and

