On NFA Reductions

Lucian Ilie1,(cid:1), Gonzalo Navarro2,(cid:1)(cid:1), and Sheng Yu1,(cid:1) (cid:1) (cid:1)

1 Department of Computer Science, University of Western Ontario

N6A 5B7, London, Ontario, CANADA

2 Department of Computer Science, University of Chile

ilie|syu@csd.uwo.ca

Blanco Encalada 2120, Santiago, CHILE

gnavarro@dcc.uchile.cl

Abstract. We give faster algorithms for two methods of reducing the
number of states in nondeterministic ﬁnite automata. The ﬁrst uses
equivalences and the second uses preorders. We develop restricted reduction 
algorithms that operate on position automata while preserving
some of its properties. We show empirically that these reductions are effective 
in largely reducing the memory requirements of regular expression
search algorithms, and compare the eﬀectiveness of diﬀerent reductions.

1 Introduction

Regular expression handling is at the heart of many applications, such as linguistics,
 computational biology, pattern recognition, text retrieval, and so on.
An elegant theory gives the support to easily and eﬃciently solve many complex
problems by mapping them to regular expressions, then obtaining a nondeterministic 
ﬁnite automaton (NFA) that recognizes it, and ﬁnally making it deterministic 
(a DFA). However, a severe obstacle in any real implementation of the
above scheme is the size of the DFA, which can be exponential in the length of
the original regular expression.

Although a simple algorithm for minimizing DFAs exists [5], it has the problem 
of requiring prior construction of the DFA to later minimize it. This can be
infeasible because of main memory requirements and construction cost.

A much more promising (and more challenging) alternative is that of directly
reducing the NFA before converting it into a DFA. This has the advantage of
working over a much smaller structure (of size polynomial in the length of the
regular expression) and of building the smaller DFA without the need to go
through a larger one ﬁrst.

However, the NFA state minimization problem is very hard (PSPACE-complete,
 [10]) and therefore algorithms such as [11, 13, 14] cannot be used in practice.
 There are also algorithms which build small NFAs from regular expressions,

(cid:1) Research partially supported by NSERC.
(cid:1)(cid:1) Supported in part by Fondecyt grant 1-020831.

(cid:1) (cid:1) (cid:1) Research partially supported by NSERC.

J. Karhum¨aki et al. (Eds.): Theory Is Forever (Salomaa Festschrift), LNCS 3113, pp. 112–124, 2004.
c(cid:1) Springer-Verlag Berlin Heidelberg 2004

On NFA Reductions

113

see [7, 4], but they consider the total size, that is, they count both states and
transitions, and they increase artiﬁcially the number of states to reduce the number 
of transitions. As the implementation crucially depends on the number of
states, such algorithms may not help.

The approach we follow is reducing the size of a given NFA. The idea of
reducing the size of NFAs by merging states was ﬁrst introduced by Ilie and Yu [8]
who used equivalence relations. Later, Champarnaud and Coulon [2] modiﬁed
the idea to work for preorders. In this paper we give fast algorithms to compute
these two reductions. We show that the algorithm based on equivalences can be
implemented in O(m log n) time on an NFA with n states and m transitions,
while that based on preorders can run in O(mn) time. Both results improve the
previous work.

When starting from a regular expression, the initial NFA, which we want
to reduce, is the position automaton. Navarro and Raﬃnot [17, 18] showed that
its special properties permit a more compact DFA representation. Our modiﬁed
reductions are restricted to preserve those properties and hence may produce
NFAs with more states than the original reductions.

Finally, we empirically evaluate the impact of the reduction algorithms. We
show that the number of NFA states can be reduced by 10%–40%. Those reductions 
translate into huge reductions in the DFA size, with factors of up to 10−6.
We also compare the alternatives of full reduction versus restricted reduction,
since the former yields less NFA states but the latter permits a more compact
DFA representation. The results show that full reduction is preferable in most
cases of interest.

2 Basic Notions

We recall here the basic deﬁnitions we need throughout the paper. For further
details we refer to [6] or [22].
Let A be an alphabet and A∗ the set of all words over A; ε denotes the empty
word. A language over A is a subset of A∗. A nondeterministic ﬁnite automaton
(NFA) is a tuple M = (Q, A, δ, I, F ), where Q is the set of states, I ⊆ Q is the
set of initial states, F ⊆ Q is the set of ﬁnal states, and δ : Q × A → 2Q is the
transition mapping; δ is extended to δ : 2Q × A∗ → 2Q by δ(S, a) =
q∈S δ(q, a)
and δ(S, ε) = S, δ(S, aw) = δ(δ(S, a), w), for S ⊆ Q, w ∈ A∗. The language
recognized by M is L(M) = {w ∈ A∗ | δ(I, w) ∩ F (cid:5)= ∅}. For a state q ∈ Q, we
denote

(cid:1)

LL(M, q) = {w ∈ A∗ | q ∈ δ(I, w)},
LR(M, q) = {w ∈ A∗ | δ(q, w) ∩ F (cid:5)= ∅};

when M is understood, we write simply LL(q) and LR(q), resp. The reversed
automaton of M is M r = (Q, A, δr, F, I), where q ∈ δr(p, a) iﬀ p ∈ δ(q, a).

3 NFA Reduction with Equivalences

The idea of reducing the size of NFAs by merging state was investigated ﬁrst by
Ilie and Yu [8]; see also [9]. We describe it brieﬂy in this section.

