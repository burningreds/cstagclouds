A Practical Index for Genome Searching

Heikki Hyyr¨o1(cid:1) and Gonzalo Navarro2(cid:1)(cid:1)

1 Dept. of Comp. and Inf. Sciences, Univ. of Tampere, Finland.

helmu@cs.uta.fi

2 Dept. of Comp. Science, Univ. of Chile.

gnavarro@dcc.uchile.cl

Abstract. Current search tools for computational biology trade eﬃciency 
for precision, losing many relevant matches. We push in the direction 
of obtaining maximum eﬃciency from an indexing scheme that
does not lose any relevant match. We show that it is feasible to search
the human genome eﬃciently on an average desktop computer.

1 Introduction

Approximate string matching [5] is a recurrent problem in many branches of
computer science, with important applications to computational biology. Eﬃciency 
is crucial to handle the large databases that are emerging, so indexes are
built on the text to speed up queries later [12, 8]. Although there exist several
indexed search tools like BLAST and FASTA, these usually trade time for precision,
 losing many relevant answers [12]. In this paper we aim at building a fast
index that does not lose any answer. We combine and optimize the best existing 
previous lossless approaches [3, 7] and focus on the simpliﬁed case of DNA
search using Levenshtein distance. This case is important in the current stage
of analyzing gene functionality once the genome projects are completing their
ﬁrst task of obtaining the DNA sequences. In particular, approximate searching
in genomes is necessary to identify homologous regions, which is fundamental to
predict evolutionary history, biochemical function, and chemical structure [12].
Our main result is a practical product that can be used to search the human
genome on an average desktop computer. Unique features of our index are: optimized 
selection of pattern pieces, bidirectional text veriﬁcation, and optimized
piece neighborhood generation. Our tools can be generalized to more complex
problem such as weighted edit distances.

2 Indexed Approximate String Matching

The problem we focus on is: Given a long text T1...n, and a (comparatively) short
pattern P1...m, both sequences over alphabet Σ of size σ, retrieve all substrings
(cid:1) Supported by the Academy of Finland and Tampere Graduate School in Information

Science and Engineering.

(cid:1)(cid:1) Partially supported by Fondecyt Project 1-020831.

M.A. Nascimento, E.S. de Moura, A.L. Oliveira (Eds.): SPIRE 2003, LNCS 2857, pp. 341–349, 2003.
c(cid:1) Springer-Verlag Berlin Heidelberg 2003

342

Heikki Hyyr¨o and Gonzalo Navarro

of T (“occurrences”) whose edit distance to P is at most k. The edit distance,
ed(A, B), is the minimum number of “errors” (character insertions, deletions
and substitutions) needed to convert one string into the other. So we permit an
“error level” of α = k/m in the occurrences of P .

The most successful approach to indexed approximate string matching [8]
is called intermediate partitioning [3, 7]. It reduces the approximate search of
P to approximate search of substrings of P . Their main principle is that, if P
matches a substring of T , j disjoint substrings are taken from P , then at least
one of these appears in the occurrence with at most (cid:1)k/j(cid:2) errors. These indexes
split P into j pieces, search the index for each piece allowing (cid:1)k/j(cid:2) errors, and
ﬁnally check whether the piece occurrences can be extended to occurrences of
P . The index is designed for exact searching of pieces, so approximate searching
is handled by generating the “d-neighborhood” of each piece S, Ud(S) = {S(cid:2) ∈
Σ∗, ed(S, S(cid:2)) ≤ d}, and searching the index for each S(cid:2) ∈ Ud(S).
In [3] all the text q-grams (substrings of length q), where q = (cid:5)logσ n(cid:6), are
stored together with their text positions. Then the pattern is recursively split
into 2 or 3 pieces at each level (dividing also the number of errors permitted),
until the ﬁnal pieces are short enough to be searchable with the index (Fig. 1).
The paper is not very explicit on how the partitioning is exactly done.

P

(cid:1)k/2(cid:2)

k

(cid:1)k/2(cid:2)

(cid:1)(cid:1)k/2(cid:2)/2(cid:2)

(cid:1)(cid:1)k/2(cid:2)/2(cid:2)

(cid:1)(cid:1)k/2(cid:2)/3(cid:2)

(cid:1)(cid:1)k/2(cid:2)/3(cid:2)

(cid:1)(cid:1)k/2(cid:2)/3(cid:2)

Fig. 1. The pattern is recursively split into smaller and smaller pieces, also dividing
the number of errors. Above each piece we show the number of errors we permit for it.

Assume that a bottom-level piece P i is to be searched with di errors. Its
occurrences are found by generating its condensed di-neighborhood U Cdi(P i):
A ∈ U Cd(B) iﬀ A ∈ Ud(B) and A(cid:2)
(cid:7)∈ Ud(B) for any A(cid:2) preﬁx of A. Any
occurrence of P i with di errors errors must have a preﬁx in U Cdi(P i). Then, all
these occurrences are located fast by searching the q-gram index for each string
in U Cdi(P i). These occurrences are then extended by going up the splitting
hierarchy in stepwise manner. Each step consists of merging pieces back together
and checking, with dynamic programming, whether the merged piece occurs in
the text with its permitted error threshold. This recursive process is continued
until either some internal node cannot be found, or we ﬁnd the whole pattern.
In [7], a suﬃx array [2] is used instead of a q-gram index, so it can choose the
partition according to optimization goals rather than guided by the constraint

