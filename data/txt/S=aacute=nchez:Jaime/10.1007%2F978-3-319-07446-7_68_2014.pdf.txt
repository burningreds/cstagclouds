 

Mobile Navigation through a Science Museum for Users 

Who Are Blind 

Márcia de Borba Campos1, Jaime Sánchez2, Anderson Cardoso Martins1,  

Régis Schneider Santana1, and Matías Espinoza2 

1 Faculty of Informatics, Pontifical Catholic University of Rio Grande do Sul,  

Porto Alegre, Brazil 

marcia.campos@pucrs.br,  

{anderson.martins.001,regis.santana}@acad.pucrs.br 

2 Department of Computer Science and Center for Advanced Research in Education (CARE), 

University of Chile, Santiago, Chile 

{jsanchez,maespino}@dcc.uchile.cl 

Abstract. This paper presents the design and implementation of mAbES, a mobile,
  audio-based  environment  simulator  to  assist  the  development  of  orientation 
 and  mobility  skills  in  people  who  are  blind.  The  modeling  scenario  of 
mAbES was a science and technology museum in Porto Alegre, Brazil. The application 
was designed for use by people who are blind without the supervision 
of  a  facilitator  or  aid.  The  mAbES  software  allows  for  testing  the  creation of 
mental maps when people who are blind navigate through the museum. 

Keywords: People who are blind, Mental map, Orientation and mobility, Navigation,
 Mobile application. 

1 

Introduction 

Lacking  vision  is  not  synonymous  with  having  low  levels  of  spatial  perception  or 
comprehension. In general, people with visual impairment, when adequately trained, 
are capable of orienting themselves, and develop a pretty precise mental representation 
of the environment. This indicates that visual experience is not strictly necessary 
in order to create mental representations of space, as other senses also provide valuable 
 spatial  information  [10].  In  his  research,  Millar  proposes  that  vision  does  influence 
 coding  and  spatial  representation,  but  that  it  is  not  a  sole  determinant  of  such 
abilities [10]. 

A person with visual impairment must be competent with orientation and mobility 
(O&M) in order to achieve a solid level of navigation, including moving about safely, 
efficiently and with agility, as well as independently in both familiar and unfamiliar 
environments  [4].  The  learning  of  O&M  skills  includes  a  set  of  defined  techniques 
that  children  who  are  blind,  young  people  and  adults  (or  those  with  visual  impair-
ment) must practice stage by stage. However, learning such skills also involves other 
aspects such as training and refining systems of perception, and both conceptual and 

C. Stephanidis and M. Antona (Eds.): UAHCI/HCII 2014, Part III, LNCS 8515, pp. 717–728, 2014. 
© Springer International Publishing Switzerland 2014 

718 

M. de Borba Campos et al. 

motor skills development [4]. Such skills are essential precedents for learning formal 
O&M techniques [4]. The primary objective of O&M is to achieve independence and 
to  improve  the  quality  of  life  for  people  who  are  blind  or  who  have  visual  impairments.
 Instruction in such skills occurs in stages, in which the level of difficulty of the 
training involved varies according the learner’s particular characteristics [4]. 

For example, mobility when navigating a route does not just require moving from 
point A to point B, but doing this efficiently and knowing where one is, where one is 
going, and how to get there [1]. 

It is important to point out that movement refers to the act and practice of moving, 
but also to the act of evaluating known facts and places in the environment in order to 
facilitate  effective  movement  and  to  exercise  one’s  own  capacity  for  autonomous 
navigation [11]. This means that when people with visual impairment relate to their 
environment,  they  encounter  certain  “spatial  problems”.  For  this  reason,  they  must 
constantly  make  “spatial  decisions”  regarding  how  to  successfully  navigate  an  
environment.  

From  a  geographical  perspective  [3],  quality  of  life  for  both  sighted  and  people 
who  are  blind  depends  on  the  individual’s  ability  to  infer  information  and  make  
spatial decisions.  

In  O&M,  the  capacity  for  orientation  ideally  progresses  from  a  concrete  understanding 
of the principals of  mobility, to a  more  functional plane  for applying such 
principals, and finally arriving at an abstract level through which the learner can function 
effectively in an unfamiliar environment [4]. In this transition, it can be inferred 
that  psycho-motor,  senso-perceptive,  conceptual  and  practical  training  in  the  use  of 
O&M techniques and materials, are important tools for being able to generate a representation 
of space. This is because these tools allow for a learner to practice and test 
out  different  methods  of  movement  in  context,  use  memory,  and  to  pick  up  on  and 
interpret his surroundings.  

The cognitive map, as a process of spatial reasoning, provides spatial information 
that is useful for mobility [12]. For some authors, the function of cognitive maps for 
an individual is to coordinate adaptive spatial behaviors, or in other words to generate 
action plans prior to or during the navigation of an environment, and to execute those 
plans effectively while moving through the environment [1]. 

Spatial knowledge, made up of simple concepts, complex ideas, locations and relations,
  is  retained  in  the  mind  through  cognitive  images  of  the  surrounding  environment,
  which  make  up cognitive  maps. The basic structure  of the images consists of 
simplified  extracts  of  reality,  built  by  using  perceptual  and  conceptual  information 
[1]. This means that people with visual impairment also form images, which can be 
quite  elaborate,  but  constructed  differently  than  sighted  people.  For  example,  these 
images could be built based on sensations and movement, memories, textures, sounds, 
etc.  

The study of spatial representation can provide relevant information regarding how 
people move,  what information they need  for  mobility, and how this information is 
distributed in a given environment [5]. 

 

 

 

Mobile Navigation through a Science Museum for Users Who Are Blind 

719 

Support on a perceptual and conceptual level is important for the development of 
orientation  skills  and  the  construction  of  cognitive  maps  [7].  The  notion  of  a  map 
speaks of an internalized representation of  space, a  mixture of objective  knowledge 
and subjective perception. As most of the information needed to form a mental map is 
collected through the visual channel [7], some authors claim that people who are blind 
use other sensory channels to compensate this and use alternative methods for exploration 
in order to construct mental maps [12]. 

If real-life surroundings are represented through virtual environments, it is possible 
to create several training applications that allow a user who is blind to interact with 
the elements in the simulated environment during navigation [13][14].  

Videogames, when integrated with virtual training environments, represent an important 
 tool  for  the  development  of  various  abilities,  and  O&M  skills  in  particular 
[16][17]. For example, the software AbES [13][14] allows for the creation of videogames,
 focusing on the mental construction of real and/or fictitious environments by 
users who are blind navigating through virtual environments, using a computer keyboard 
in order to execute actions and receive audio feedback, with the aim of supporting 
the development of O&M.  

AbES expands on the concept of using fictitious corridors used in its predecessor 
AudioDoom  [9],  in  order  to  generate  an  audio-based  virtual  representation  of  real 
environments,  thus  serving  as  a  videogame  that  allows  for  O&M  training  [14].  In 
addition, the use of audio allows increases the potential for various forms of interaction 
between the user and the computer. 

Another study presented an audio-based virtual reality system that allows the user 
to explore a virtual environment by using only his sense of hearing [2]. Other authors 
performed  empirical  evaluations  of  various  approaches  through  which  spatial  information 
on the environment is transmitted through the use of audio cues [6]. 

Various virtual environments have been designed in order to train people who are 
blind, and to assist them with the development of O&M skills [7][9][14]. To navigate 
through an environment, it is necessary to have access to the information that can be 
recovered  from  the  environment,  in  order  to  then  filter  useful  information  in  a  way 
that is coherent and comprehensible for whoever needs it.  

It is for this reason that in the case of people who are blind, the use of virtual environments 
and appropriate interfaces allows them  to improve their O&M skills [15]. 
Such interfaces can be, for example, haptic or audio based. Such resources can also be 
used for recreational purposes. Other studies have researched the use of mobile applications 
to assist in user navigation of the city [13][14][15].  

The purpose of this work is to present the design and implementation of mAbES, a 
mobile  audio  based  environment  simulator  to  assist  the  development  of  orientation 
and  mobility  skills  in  people  who  are  blind.  We  introduce  a  model  scenario  using 
mAbES together with an application for navigating through a science and technology 
museum in Porto Alegre, Brazil. The software mAbES was designed based on a previous 
model of AbES.  

 

720 

M. de Borba Campos et al. 

2 

AbES, Audio-Based Environments Simulator 

AbES represents a real, familiar or unfamiliar environment to be navigated by a person 
who is blind. The virtual environment is made up of different elements and objects 
(walls, stairways, doors, toilets or elevators) through which the user can discover 
and become familiar with his location. It is possible to interact with doors, which can 
be opened and closed. Regarding the rest of the objects, it is possible for the user to 
identify them and their location in the environment. The idea is for the user to be able 
to move about independently and to mentally map the entire environment. 

The simulator is capable of representing any real environment by using a system of 
cells through which the user moves [17]. The user receives audio feedback from the 
left, center and right side channels, and all actions are carried out through the use of a 
traditional keyboard, where a set of keys have different associated actions. All of the 
actions in the virtual environment have a particular sound associated to them. In addition 
to this audio feedback, there are also spoken audio cues that provide information 
regarding the various objects and the user’s orientation in the environment. Orientation 
is provided by identifying the room in which the user is located and the direction 
in which he is facing, according to the cardinal compass points (east, west, north and 
south). 

Stereo sound is used to achieve the user’s immersion by providing information on 
the  location  of  different  objects,  walls  and  doors  in  the  virtual  environment.  In  this 
way, the user is able create a mental model of the spatial dimensions of the environment.
 While navigating, the user can interact with each of the previously mentioned 
elements, and each of  these elements provides different kinds of feedback that help 
the user become oriented in the environment. AbES includes three modes of interac-
tion: Free Navigation, Path Navigation and Game Mode. 

The free navigation mode provides the user who is blind with the possibility of exploring 
 a  building  freely  in  order  to  become  familiar  with  it.  The  facilitator  can 
choose whether the user begins in a particular starting room, or let the AbES software 
randomly  choose  the  starting  point.  Path  navigation  provides  the  user  who  is  blind 
with the task of finding a particular room by first choosing an initial and destination 
room, and selecting the number of routes to be taken. 

The game mode provides blind users with the task of searching for “jewels” placed 
in the building. The purpose of the game is to explore the rooms and find all the jewels,
  bringing  them  outside  one  at  a  time  and  then  going  back  into  the  building  to 
continue exploring. Enemies are randomly placed in the building, and try to steal the 
user’s jewels and hide them elsewhere.  

Different versions of AbES have been developed in order to simulate various real 
life, closed spaces. One of these versions corresponds to the St. Paul’s building at the 
Carroll Center for the Blind in Newton, MA, USA. Later, other versions were developed 
 to  simulate  the  Santa  Lucia  School  and  Hellen  Keller  School,  both  located  in 
Santiago, Chile. In the version for the St. Paul’s building the entire environment could 
be navigated freely (see Fig. 1). The design and development of AbES was carried out 
by considering the ways in which blind users interact, and how audio can help them to 
increment certain spatial navigation skills and facilitate their cognitive development.  

 

 

Mobile Navigation through a Science Museum for Users Who Are Blind 

721 

Fig. 1. A screenshot of AbES 

 

3  Museum of Science and Technology 

The application introduced here, mAbES, represents the actual physical environment 
of the Museum of Science and Technology, of the Pontifical Catholic University of 
Rio Grande do Sul, Porto Alegre, Brazil (MCT-PUCRS). This museum is one of the 
largest interactive natural science museums in Latin America. Its mission is to generate,
 preserve and disseminate knowledge through its collections and exhibitions. 

It has an area of over ten thousand square meters dedicated to public exhibitions, 
and  about  700  interactive  apparatuses  that  can  be  used  by  visitors.  The  interactive 
nature of the many experimental sites provides for playful experiences that facilitate 
the  understanding of scientific concepts and theories for all ages in a creative environment.
 

Among  the  scientific  exhibitions,  the  most  impressive  are  related  to  the  areas  of 
Zoology,  Botany,  Paleontology  and  Archaeology,  which  are  utilized  by  researchers 
and some graduate and post-graduate student of PUCRS, as well as other national and 
foreign institutions.  

Despite the fact that the MCT is designed as a space of learning and information, 
there are still limitations regarding the active and autonomous participation of people 
with  certain  disabilities.  There  are  structural  accessibility  and  information  related 
problems for people who use wheelchairs, people who are deaf, people who are blind, 
or people with cognitive disabilities. In order to facilitate the construction of a more 
inclusive society that recognizes the diversity of people with disabilities and the importance 
of their individual autonomy and independence, the MCT has formed partnerships 
 for  the  development  of  activities  that  promote  accessibility  to  the  physical 
environment, education and information for people with disabilities.  

In this context, the need emerged for the development of a software application to 
support the navigation (orientation and mobility) of people who are blind that visit the 

 

722 

M. de Borba Campos et al. 

MCT-PUCRS. This software was named mAbES (mobile Audio-based Environment 
Simulator), because it was based on the AbES software.   

4  Methodology 

For  the  development  of  mAbES,  an  XP  (eXtreme  Programming)  methodology  was 
utilized,  including  weekly  technical  meetings  with  a  specialized  team  from  the  museum,
 rapid feedback loops, and the provision of weekly programming codes.  

Members of the museum team participated in meetings in order to define the scope 
and  to  prioritize  the  functionalities  of  the  software.  Following  the  definition  of  the 
areas of the MCT-PUCRS that would be included in mAbES, a museum architect and 
a professor of physics, who are also part of the Educational Coordination team of the 
MCT, joined the software development team. In order to develop the application, the 
team went on constant guided tours of the museum.  

The mAbES development model was also based on a model that proposes an iterative 
development process for mobile  videogame-based software in order to improve 
the orientation and mobility skills of blind users [16][17]. This process includes the 
following phases: 1. Definition of the cognitive skills needed for navigation; 2. The 
software engineering process for the design and development of the applications; and 
3. A validation process for the tools that are developed.  

The  mAbES  software  application  was  developed  by  using  Unity,  a  platform  for  

videogame development. In addition, the following were also utilized:  
•  Google  Translate:  used  to  convert  texts  of  up  to  101  characters  into  MP3  audio. 
The mAbES was used to generate the audio cues for the users. For example, if the 
user  crashes  into  a  wall,  mAbES  informs  him:  “This  is  a  wall”.  This  audio  was 
produced based on: http://translate.google.com/translate_tts?tl=pt&q=this is a wall. 
•  Soar MP3: Utilized to turn text conversations with over 101 characters into audio. 
Was  used  to  generate  an  audio  description  of  the  selected  MCT-PUCRS  experiments.
  

•  AutoCAD: Used to manipulate the floor plans of MCT/PUCRS in order to export 

them for use with Unity. 

•  Google  Sketchup:  Utilized  to  create  3D  objects  based  on  MCT-PUCRS,  which 

were then exported for use with Unity. 

•  AutoDesk 3DS Max Design: Used to convert the museum’s floor plan files, which 

had been generated using AutoCAD, to a file format compatible with Unity.  

•  JavaScript: Optimal programming language for the Unity environment.  

5 

Results 

The mAbES software was designed in stages, based on the decisions made regarding 
the  specific  experiments  to  be  mapped.  These  choices  were  made  according  to  the 
museum’s demands. The first phase involved the experiments in the energy section. 
This choice was based mainly on the following issues: the experiments were among 

 

 

Mobile Navigatio

on through a Science Museum for Users Who Are Blind 

723 

those that had the longest s
knowledge that people gen
will continue to map related
In  the  first  phase,  3  ex
Train, and Cool House, loc
experiments are represented
audio format. This paper de

shelf life in the museum, and those that represent areas
nerally have difficulty understanding. The posterior pha
d experiments within the energy section. 
xperiments  were  chosen:  Nuclear  Power  Station,  Ene
cated on the third floor of the  museum. In  mAbES, th
d with 3D graphics, and information on them is availabl
escribes the results of one of these experiments.  

s of 
ases 

ergy 
hese 
e in 

5.1 

Interfaces 

The mAbES software prese
PUCRS, the selected experi
the museum. The physical 
through 3D graphics, allow
vision and sighted people a
curs  mainly  through  an  aud
ware by interacting with a s
Braille system (see Figures 

ents information regarding the physical space of the MC
iments, and also responds to the user’s movements throu
space of the museum and the experiments are represen
wing for its use by people with visual disabilities, low-le
as well. The interaction between mAbES and the user 
dio  interface,  while  the  user  communicates  with  the  s
smartphone screen, which utilizes an array of points of 
2 and 3).  

CTugh 

nted 
evel 
oc-
oftf 
the 

 

Fig. 2. Matrix of Braille points 

Fig. 3. Startup screen of mAbES 

 

In following the AbES m
in  three  different  ways:  fo
museum is achieved by usin
ual steps. The right and left
The transition between f
escalators (Figure 4), in wh
interaction when moving fo

model [16][17], the user’s movement using mAbES occ
orward,  right  and  left.  The  user’s  movement  through 
ng the forward button, which represents the user’s indiv
t buttons are used when the user turns in either direction
floors in the MCT-PUCRS is achieved through the use
hich it is possible to observe the areas involved in the use
orward, turning right or turning left. When the user reac

curs 
the 
vid-
.   
e of 
er’s 
ches 

 

724 

M. de Borba Campos et al. 

an  escalator,  mAbES  provides  an  audio-description  about  its  physical  appearance, 
functioning and how the user who is blind should use the escalator in the real context 
of the Museum. 

 
 
 

 

 

Fig. 4. Transitions between floors of the MCT-PUCRS 

 

Information  on  the  museum  or  the  experiments  is  available  to  the  user  in  audio 
format. The options for hearing the audio cues are: 1 – Play, 2 – Pause, 3 – Increase 
speed, 4 – Go back, 5 – Go forward, 6 – Help. 

When the user arrives at the third floor, which is the purpose of phase 1, mAbES 
presents the experiments that are  mapped so that the user  can choose  which one  he 
wants to interact with: 1 – Nuclear Power Station, 2 – Energy Train, 3 – Cool House, 
4 – Explore the space freely, 5 – More information, 6 – Exit, according to the Braille 
matrix.  

When  the  user  crashes  into  any  object  (wall,  pillar,  or  escalator,  for  example)  or 
comes  upon  any  experiment  (Nuclear  Power  Station,  Energy  Train,  Cool  House), 
mAbES informs the user by naming the object or experiment, and the options that are 
available  to  the  user.  In  addition,  the  device’s  vibration  functionality  is  utilized  for 
each collision.  

5.2  Experiments 

In the following section, one of the experiments is described in order to illustrate the 
application of mAbES in a general area of the MCT-PUCRS, regarding the specific 
issue of Energy. 

In the MCT-PUCRS, the Nuclear Power Station experiment simulates the production 
 of  nuclear  energy,  based  on  a  mechanical  interaction  between  the  user  and  the 
technological devices involved in a nuclear power station. When a user comes upon 
this  experiment,  mAbES  presents  5  different  options  for  interaction:  Challenges  
(options 1, 2 and 3), audio-description of the experiment (option 4), and information 
for exiting the Nuclear Power Station experiment (option 6). Figure 5a illustrates the 
nuclear power station interaction screen, while Figure 5b shows the options for interaction 
that are available to the user.  

 

 

Mobile Navigation through a Science Museum for Users Who Are Blind 

725 

 

 

 

Fig. 5. (a) Nuclear Power Station, (b) Interaction options 

The options 1, 2 and 3 present questions related to a nuclear power station as well 
as  response  options.  Option  1  presents  the  challenge:  “In  the  first  stage  of  energy 
production, what happens to the water? Click 1 if you think that the water turns into 
fuel. Click 2 if you think that the water turns to steam. Click 3 if you think the water 
goes into the holding tank in liquid form”. The options are presented using the Braille 
matrix.  If  the  user  chooses  option  2,  mAbES  informs  the  user  that  the  answer  is  
correct. Otherwise, the software states that the answer is wrong. 

For  Option  2,  the  user  must  answer  the  challenge,  “What  is  the  function  of  the 
electric generator in a nuclear power station? Click 1 if you think that it is to transform 
 the energy trapped in the  movement of  the  water  vapor into electrical energy. 
Click 2 if you think that it is to turn water into steam. Click 3 if you think that it is to 
reduce  the  maximum  number  of  fission  reactions”.  If  the  user  chooses  option  1, 
mAbES  informs  the  user  that  the  answer  is  correct.  Otherwise,  it  states  that  the  
answer is wrong. 

Option  3  involves  the  following  challenge:  “What  happens  to  the  steam  after  it 
makes the turbine move? Click 1 if when the steam exits the turbine, it ends up producing 
 energy.  Click  2  if  the  steam  comes  into  direct  contact  with  the  seawater  in 
order to restart the cycle. Click 3 if the steam is cooled by the seawater, turning it into 
a net-liquid state so that the process of energy production can be resumed”. If the user 
chooses  option  3,  mAbES  informs  the  user  that  the  answer  is  correct.  Otherwise,  it 
states that the answer is wrong. 

Starting at the Nuclear Power Station experiment, in following the virtual hallway 
represented on mAbES forward, the user will come upon the Energy Train and Cool 

 

726 

M. de Borba Campos et al. 

House  experiments.  The  Energy  Train  is  made  up  of  cartoon  characters  of  energy 
scientists. The mAbES application provides information on each one of them, and the 
user must choose the correct name of the corresponding scientist. The cartoon characters 
are presented as the user moves along the train.  

The Cool House is one of the MCT-PUCRS experiments that require a guided experience,
  as  it  includes  activities  that  involve  the  manipulation  of  household  appliances 
such as a hair dryer, iron, stove, bathtub and shower, among others.  All of 
the objects in the Cool House that can be manipulated have energy performance meters.
  Based  on  this  information,  questions  are  presented  regarding  electrical  energy 
consumption.  As  the  user  navigates  the  house,  mAbES  presents  movement  options 
and  audio  descriptions  regarding  the  location  of  the  various  appliances  that  can  be 
manipulated. When exiting the Cool House, the software presents questions related to 
the experiments that the user now has the information needed to respond.   

In addition,  mAbES presents  some questions that the user must respond to  when 
visiting the MCT-PUCRS, such as those related to the use of fuel in the production of 
nuclear  energy,  how  electrical  generation  turbines  work  in  a  nuclear  power  station, 
regarding the physical appearance of the scientists presented at the Energy Train, and 
related  to  electrical  energy  consumption  when  using  certain  kinds  of  household  
appliances.  

6 

Discussion and Conclusions 

This study presents the design and implementation of mAbES, a mobile audio based 
environment simulator to assist in the development of orientation and mobility skills 
for people who are blind. We also introduce a model scenario for using mAbES together 
with an application for navigating through a science and technology museum 
in Porto Alegre, Brazil. This application was focused on a specific topic area, pertaining 
to the concept of energy and other related topics. 

We present and describe the main interfaces of mAbES including both audio and 
graphic design, and explain the different modes of user interaction. The mAbES software 
was designed for use by people with visual impairment, but without excluding 
the  possibility  that  sighted  people  can  also  use  the  application,  in  order  to  promote 
social inclusion. 

The  mAbES  software  supports  navigation  through  the  museum  by  a  group  with 
both visually impaired and sighted visitors. In this way, a blind visitor and a sighted 
visitor  can  share  the  use  of  a  smartphone  and  earphones,  and  create  collaborative 
experiences as a result of using and interacting with mAbES. This may help to avoid 
people with visual impairment being isolated while visiting the museum. The issue of 
user isolation when using a mobile museum guide is mentioned in some studies as a 
disadvantage [8]. 

Finally, future work will involve the implementation of a full usability evaluation 
of mAbES, with both visually impaired and sighted users. Such work would also imply 
the design and implementation of an impact evaluation study focusing on orientation 
and mobility skills. In this sense, measuring the impact of the use of mAbES on 
the development and practice of navigation skills is the priority for future work. 

 

 

Mobile Navigation through a Science Museum for Users Who Are Blind 

727 

Acknowledgements.  This  report  was  funded  by  the  Chilean  National  Fund  of  
Science  and  Technology,  Fondecyt  #1120330,  and  Project  CIE-05  Program  Center  
Education  PBCT-Conicyt.  It  was  also  supported  by  the  Program  STIC-AmSud-
CAPES/CONICYT/MAEE,  Project  KIGB-Knowing  and  Interacting  while  Gaming 
for the Blind, 2014. 

References 

1.  Carreiras,  M.,  Codina,  B.:  Cognición  espacial,  orientación  y  movilidad,  consideraciones 

sobre la ceguera. Integración (11), 5–15 (1993) 

2.  Frauenberger, C., Noisternig, M.: 3D audio interfaces for the blind. In: Proceedings of the 
2003 International Conference on Auditory Display, Boston, MA, USA, July 6-9, pp. 1–4 
(2003) 

3.  Golledge, R.: Geography and the disabled. A survey with special reference to vision impaired 
and blind populations. Transactions of the Institute of British Geographers, New Series 
18(1), 63–85 (1993) 

4.  Hill,  E.,  Ponder,  P.:  Orientación  y  técnicas  de  Movilidad,  Una  guía  para  el  practicante. 

Comité internacional pro-ciegos, México (1981) 

5.  Jacobson, R.D.: Cognitive mapping without sight: four preliminary studies of spatial learning.
 Journal of Environmental Psychology (18), 289–305 (1998) 

6.  Jain,  S.:  Assessment  of  audio  interfaces  for  use  in  smartphone  based  spatial  learning  
systems for the blind. Master of Science Thesis in Spatial Information Science and Engineering.
 University of Maine (2012) 

7.  Lahav,  O.,  Mioduser,  D.:  Haptic-feedback  support  for  cognitive  mapping  of  unknown 
spaces by people who are blind. International Journal of Human-Computer Studies 66(1), 
23–35 (2008) 

8.  Lanir,  J.,  Kuflik,  T.,  Dim,  E.,  Wecker,  A.J.,  Stock,  O.:  The  influence  of  location-aware 
mobile  guide  on  Museum  visitors´behavior.  Interacting  with  Computers 25(6),  443–460 
(2013) 

9.  Lumbreras, M., Sánchez, J.: Interactive 3D sound hyperstories for blind children. In: Proceedings 
of the SIGCHI Conference on Human Factors in Computing Systems: the CHI Is 
the  Limit,  CHI  1999,  Pittsburgh,  Pennsylvania,  United  States,  May  15-20,  pp.  318–325 
(1999) 

10.  Millar, S.: La comprensión y la representación del espacio, Teoría y evidencia a partir de 

estudios con niños ciegos y videntes, 406 págs. ONCE, Madrid (1997) 

11.  ONCE, Organización Nacional de Ciegos Españoles: Glosario de Términos de Rehabilitación 
Básica de las Personas Ciegas y Deficientes Visuales, Entre Dos Mundos, Revista de 
traducción sobre discapacidad visual (1998) 

12.  Sanabria, L.: Mapeo cognitivo y exploración háptica para comprender la disposición del 
espacio  de  videntes  e  invidentes.  Tecné,  Episteme  y  Didaxis:  Revista  de  la  Facultad  de 
Ciencia y Tecnología 21, 45–65 (2007) 

13.  Sánchez, J., Maureira, E.: Subway Mobility Assistance Tools for Blind Users. In: Stephanidis,
  C.,  Pieper,  M.  (eds.)  ERCIM  Ws  UI4ALL  2006.  LNCS,  vol. 4397,  pp.  386–404. 
Springer, Heidelberg (2007) 

14.  Sánchez, J., Oyarzún, C.: Mobile Audio Assistance in Bus Transportation for the Blind. International 
 Journal  on  Disability  and  Human  Development  (IJDHD) 10(4),  365–371 
(2011) 

 

728 

M. de Borba Campos et al. 

15.  Sánchez, J., de la Torre, N.: Autonomous navigation through the city for the blind. In: Proceedings 
 of  the  12th  international  ACM  SIGACCESS  Conference  on  Computers  and  
Accessibility (ASSETS 2010), pp. 195–202. ACM, New York (2010) 

16.  Sánchez,  J.,  Sáenz,  M.,  Pascual-Leone,  A.,  Merabet,  L.:  Enhancing  navigation  skills 

through audio gaming. In: Ext. Abstracts CHI 2010, pp. 3991–3996. ACM Press (2010) 

17.  Sánchez,  J.,  Tadres,  A.,  Pascual-Leone,  A.,  Merabet,  L.:  Blind  Children  Navigation 
through  Gaming  and  Associated  Brain  Plasticity.  In:  Proc.  of  the  Virtual  Rehabilitation 
2009 International Conference, Haifa, Israel, pp. 29–36. IEEE (2009) 

 
 

 

