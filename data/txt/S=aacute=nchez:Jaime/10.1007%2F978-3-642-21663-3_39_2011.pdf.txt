 

Audiopolis, Navigation through a Virtual City Using 
Audio and Haptic Interfaces for People Who Are Blind 

Jaime Sánchez and Javiera Mascaró 

Department of Computer Science 

Center for Advanced Research in Education (CARE) 

University of Chile, Blanco Encalada 2120, Santiago, Chile 

{jsanchez,jmascaro}@dcc.uchile.cl 

Abstract. This work studies the usability of an audio and haptic-based virtual 
environment  for  learners  with  visual  disabilities,  intended  for  orientation  and 
mobility purposes. To this end Audiopolis, a videogame for navigating a virtual 
city  through  interaction  with  audio  and  haptic  interfaces,  was  designed  and 
evaluated.  Iconic  and  end-user  usability  evaluations  of  the  videogame  were  
administered.  The  results  show  that  Audiopolis  is  highly  usable  and  understandable 
for end users. An ongoing cognitive evaluation of navigation skills as 
a result of using Audiopolis is being implemented. 

Keywords: Usability Evaluation, Navigation, Orientation and Mobility, Haptic 
and Audio Perception. 

1   Introduction 

Haptic perception implies two components: tactile feedback, which consists of what is 
perceived  through  the  skin  (temperature,  texture,  shape),  and  force  feedback,  which 
consists  of  what  is  perceived  through  muscles  (hardness  of  objects,  viscosity,  the 
force  of  an  object)  [9]. There  are  advanced  devices  that  allow  for  simulating  threedimensional 
spaces, forces and textures, and which are used in different applications 
such as  medical simulators,  virtual reality environment simulators, and  videogames, 
among others [3, 6]. In particular, if virtual reality is combined with haptic perception, 
it  is  possible  to  convey  visual  information  from  the  virtual  world  to  the  blind  user 
through a haptic device [8]. One device that allows for this is the “Novint Falcon” [4], 
which provides high-fidelity force feedback, allowing for movement on the three axes 
of the Cartesian plane, and thus for movement through the entire space [14]. The device 
allows to represent the textures, viscosity, hardness and force of the various objects 
in the virtual environment. This provides a higher degree of reality to the virtual 
world  represented,  and  in  this  particular  case,  allows  for  modeling  visual  elements 
and perceiving them through haptic perception [4].  

In  audio  perception  the  main  element  is  the  ear,  which  is  the  receiving  organ 
through which acoustic stimulus becomes an audio sensation that then travels to the 
brain where the auditory cortex processes it and distinguishes from what sound source 
it has come [12].  

C. Stephanidis (Ed.): Universal Access in HCI, Part II, HCII 2011, LNCS 6766, pp. 362–371, 2011. 
© Springer-Verlag Berlin Heidelberg 2011 

 

Audiopolis, Navigation through a Virtual City Using Audio and Haptic Interfaces 

363 

For people who are blind or who have serious visual limitations, the sense of hearing 
is more important than normal, in that together with haptic perception, these two 
senses become the main receptors of information from the environment, allowing people 
who are blind to interact and relate with the environment in the best way possible. 
In addition, the way in which the human being perceives sound depends on the physical 
fact that people have two ears, which allows for the perception of the direction of 
any given sound, providing spatial information regarding the location of the source of 
the sound and helping with the perception of objects in the environment [14]. 

Orientation  is  a  process  through  which  an  individual  uses  the  various  senses  to  
establish his position in relation to other significant objects in the surrounding environment.
  Mobility  is  the  ability,  will  and  facility  to  move  about  in  the  surrounding 
environment [5]. Orientation and mobility (O&M) skills are interdependent, as to be 
able to move about in space efficiently, safely and independently, one must dominate 
both skill sets [11]. 

Three basic orientation abilities can be identified: 1. Knowledge of spatial distribu-
tion:  the  ability  to  know  where  the  destination  is  located  and  to  establish  relations 
between  it  and  objects  in  space.  2.  Spatial  updating:  the  ability  for  an  individual  to 
know  his  position  in  space  at  any  given  moment,  as  well  as  in  relation  to  the  surrounding 
objects and individuals. 3. Knowledge of spatial concepts and systems: an 
individual’s ability to plan his navigation from a starting point to a destination [10]. 

To orient oneself, an individual must establish his own position and relate it to the 
relative  locations  of  the  various  significant  elements  in  the  environment.  As  one 
moves about, this position must be updated, as the relation between the individual and 
the objects is modified in a dynamic process in which both perceptive and cognitive 
factors come into play [15]. For people with visual impairment, the ability to develop 
consciousness of the environment is a result of concentration and practice following a 
period of learning [6].  

Orientation  and  mobility  in  outdoor,  unknown  spaces  for  people  with  visual  impairment 
is a significant challenge [1]. If the fact that most transit and mobile signals 
are  visual  is  considered,  simple  and  everyday  tasks  can  become  extremely  complicated 
for people who are blind [1].  

With the purpose of developing O&M skills, this study proposes the creation of a 
virtual, 3D world through audio and haptic interfaces, which allows the user to navigate 
 through  virtual  space  and  identify  the  surrounding  objects  and  thus  orient  
himself.  Other  videogames  have  been  developed  in  this  area  that  seek  to  develop 
O&M skills cognitively, as  well as through spatial-temporal structuring and  navigation 
[1, 12]. One of these videogames is AudioDoomII [2], which is a virtual space 
that consists of a maze based on a stereo-sound audio interface, through which blind 
users are able to locate elements  within a set of virtual hallways. AudioHapticMaze 
[13]  emerged  as  the  evolution  of  this  videogame,  as  it  extends  the  previously  
described  virtual  environment  by  adding  rooms,  and  an  additional  interface.  These 
projects are characterized by modeling indoor environments for users who are blind, 
for which reason it is relevant to explore the modeling of outdoor environments.  

As a result, in this work the videogame Audiopolis was designed, and its usability 
was evaluated. The objective of this  game is to develop O&M skills in people with 
visual impairment, for navigation in outdoor environments through the  use of audio 
and haptic based interfaces. Audiopolis seeks to mentally and gradually represent the 

 

364 

J. Sánchez and J. Mascaró 

map of a virtual city, in order to simulate and run practices of certain situations and 
trips,  which  increasingly  stimulate  the  creativity,  confidence  and  problem  solving 
abilities of blind users, in addition to teaching basic norms of safe pedestrian transit 
through the city in a ludic manner.  

2   Design 

Audiopolis is based on a detective metaphor, in which the user plays the part of a detective 
who must find a band of thieves and the objects they have stolen. Initially, the 
detective starts out at the crime scene, where he has to identify the first stolen object 
in which the first clue is hidden, indicating the location of the following clue. Afterwards,
 the player must navigate through the city following the various clues until he 
finds the thief. The thief, once under arrest,  will provide the detective  with a set of 
three stolen objects, and the detective has to correctly identify which is the object he 
is looking for.  

The  videogame  is  a  three-dimensional  virtual  simulation  of  the  outdoor  environment 
 of  a  city,  which  includes  the  simulation  of  floor  textures,  environmental  volumes 
and sounds. Initially, the player is provided with instructions on the tasks that 
must  be  completed,  and  afterwards  he  is  free  to  navigate  through  the  virtual  space. 
The player can ask for information in order to arrive at a given destination, utilizing 
the  clock  technique  [7]  with  the  purpose  of  providing  orientation.  Once  the  player 
arrives to the indicated destination, a contextual question about the place is formed as 
a clue, which the player must answer using the keyboard to then receive information 
regarding the next place that he must go to. When the player arrives to the last place 
in each stage,  he  must recognize a  set of objects simulated three-dimensionally and 
represented by geometric shapes.  

Fig. 1. Visual interface of Audiopolis 

 

The game has 3 modalities in accordance with the interfaces involved, and a graphic 
interface to work with a facilitator, teacher or instructor (See figure 1): 

1. Audio Interface Modality: the player must use the 3D environmental sounds to locate 
and orient himself in the environment, and the keyboard to navigate through 

 

 

Audiopolis, Navigation through a Virtual City Using Audio and Haptic Interfaces 

365 

the  space.  Recognition  of  geometric  shapes  is  achieved  through  indications  from 
special sounds regarding the shape of an object, such as the number of sides.  

2. Haptic Interface Modality: the player must achieve O&M with the information on 
the space that is provided through a haptic device, utilizing it like a cane. In this interaction,
  the  player  navigates  through  the  space  using  the  buttons  on  the  haptic 
device  or  on  the  keyboard.  Through  the  use  of  the  device  the  user  explores  the 
place in which he is located by moving the joystick control on the device. In this 
exploration, the user feels the different volumes that make up the city in his hands, 
such as the floor, sidewalks and walls. In addition, the user perceives different textures 
that provide information on the space, as for example the streets, sidewalks 
and walls all have different tactile sensations associated to them. The recognition 
of shapes is achieved by using the haptic device as a hand, and the questions are 
made through audio feedback.  

3. Haptic and Audio Interface Modality: consists of a combination of the two previously 
described modalities, in which the available information on the virtual environment 
is provided through both interfaces.  

3   Methodology 

3.1   Evaluation 

In this work, a usability evaluation of Audiopolis was implemented. This evaluation 
was designed to evaluate how easy it is to use the videogame designed, the different 
elements of the interfaces included in the videogame (sounds), and the haptic device 
associated with the game. The evaluation is made up of two parts: an iconic usability 
evaluation of the videogame’s components, and then an end-user usability evaluation. 
Regarding  the  iconic  usability,  it  was  sought  to  evaluate  whether  or  not  the  user  
correctly associates the various elements of the  videogame, for  which reason  sound 
recognition, real geometric shape recognition and geometric shape and texture recognition 
with the haptic device were all evaluated. In the end-user usability evaluation, 
the general usability of the videogame was evaluated after having made changes and 
redesigns according to the results obtained in the iconic usability evaluation.  

As the evaluation of the videogame’s cognitive impact is currently underway, it is 
sought to evaluate the learners’ development of O&M skills as a result of their interaction 
with the videogame. This evaluation consists of a preparatory stage, the application 
of a pretest, the reiterated interaction with the videogame together with a set of 
related activities, and finally a posttest. This cognitive impact evaluation is ongoing.  

3.2   Sample 

For  the  iconic  usability  evaluation  of  the  videogame,  a  sample  of  18  learners  with 
severe  visual  impairment  was  selected,  with  ages  between  10  and  15  years  old  and 
who  were  enrolled  between  fourth  and  eighth  grade  courses  at  the  Hellen  Keller  
and  Santa  Lucia  schools  for  the  blind  in  Santiago,  Chile.  In  the  end-user  usability 
evaluation a  subset of 9 learners from the previously described sample participated, 
corresponding to the group of learners from the Helen Keller School. In this case, the 
sample  population  was  divided  into  3  groups  of  3  different  learners,  in  which  each 

 

366 

J. Sánchez and J. Mascaró 

group corresponded to: (1) Interaction  with the videogame’s audio interface. (2) Interaction 
 with  the  videogame’s  haptic  interface.  (3)  Interaction  with  both  audio  and 
haptic interfaces integrated together.  

3.3   Instruments 

For the usability evaluation two questionnaires were utilized: (1) The SUE questionnaire 
 (Software  Usability  Elements),  which  serves  to  evaluate the  iconic  usability  of 
the  sound  and  graphic  elements  of  the  videogame  during  the  first  stage  of  development,
 asking the user what he associates each element with. In particular, a set of 42 
sounds, 41 real shapes, 10 virtual shapes and 8 textures was evaluated. (2) The SUBC 
Questionnaire (Software Usability for Blind Children Questionnaire [7]), which allows 
researchers to measure the degree of the users’ satisfaction regarding the videogame’s 
usability. This is made up of a set of 18 statements that the user must evaluate, based 
on a scale of appreciation with values between 1 and 10, in which 1 is ‘very unsatisfac-
tory’ and 10 is ‘very satisfactory’; it also includes 8 open-ended questions that seek to 
collect information of interest regarding the users’ opinions of the videogame.   

Prior  to  the  cognitive  evaluation,  preparatory  activities  with  the  videogame  were 
held, which consisted of activities that allowed for a preliminary experience with the 
contents, lessons and components involved in the videogame. In this way, it is assured 
that the users would be able to adjust to the videogame’s requirements. To these ends 
three  guidelines  were  applied,  in  which  each  item  is  assigned  a  score  (0  =  not 
achieved, 1 = in process, 2 = achieved): (1) Preparatory sounds guidelines: for each 
sound, it is evaluated whether or not the user correctly associates its meaning, and if it 
is  correctly  associated  in  the  context  of  the  videogame.  Here  there  is  a  total  of  26  
possible points. (2) Preparatory geometric shapes guideline: Evaluates the ability to 
recognize  concrete  and  virtual  shapes,  associate  the  concrete  shape  with  the  corresponding 
virtual shape and to concretely represent the shapes. In this guideline there 
is a total of 52 possible points. (3) Preparatory clock technique guideline: Evaluates 
the ability to recognize the location of the  various  hours on the clock  utilizing concrete 
 materials,  the  ability  to  turn  towards  different  hours  and  the  ability  to  move 
about utilizing this technique. This guideline has a total of 22 possible points.  

For the cognitive impact evaluation, three kinds of guidelines were also used: (1) 
The  guidelines  utilized  to  measure  the  videogame’s  effect  on  the  development  of 
O&M skills, which is an adaptation of the guidelines used to evaluate O&M strategies 
and knowledge, and cane mastering used in educational and rehabilitation programs 
for the blind. Just as in the case of the preparatory guidelines, each item evaluated is 
assigned a score, and in this case the total possible score is 166 points. (2) The observation 
 guideline,  which  was  constructed  in  accordance  with  the  activity  performed, 
and which seeks to measure the level of the learner’s achievement through the score 
that he is assigned. (3) The in-depth interview guideline, which is an instrument based 
on open-ended questions with which it is sought to collect the learner’s perception of 
the game and how much it contributes to his development of skills and learning.  

In addition, as part of the cognitive evaluation a pretest and posttest were both designed 
 based  on  the  O&M  guideline,  in  order  to  evaluate  the  O&M  skills  of  
each  learner  before  and  after  applying  the  cognitive  tasks  through  the  use  of  the 

 

 

Audiopolis, Navigation through a Virtual City Using Audio and Haptic Interfaces 

367 

videogame. These tests were used with the purpose of comparing the gains obtained, 
and to calculate whether or not these are statistically significant.  

3.4   Procedure 

One and a half-hour work sessions were designed, considering that the research team 
included the support of three facilitators to implement the intervention. A total of 24 
sessions were held, which involved the usability evaluation, preparatory tasks and the 
cognitive evaluation.  

The  SUE  questionnaire  was  applied  during  six,  1.5-hour  work  sessions  with  a 
group of 18 learners. In the first two work sessions with sounds, each learner worked 
for  15  minutes.  Each  sound  was  played  sequentially,  and  after  each  one  the  learner 
was  asked  to  identify  the  sounds.  In  the  following  two  work  sessions,  the  concrete 
shapes  were  evaluated  through  15  minutes  of  individual  work.  In  the  fifth  session, 
each  learner  worked  for  10  minutes  with  the  haptic  device.  The  work  consisted  of 
virtually touching, through the Novint Falcon device, the virtual contours of each of 
10 shapes modeled for haptic perception, and identifying them. In the sixth and last 
session, each learner had 10 minutes to evaluate his tactile sensation of the textures, 
virtually represented through the Novint Falcon.  

Fig. 2. Blind user interacting with the videogame and the Novint Falcon device 

 

Afterwards,  the  end-user  usability  questionnaire  was  applied  to  8  learners,  
after  each  one  had  interacted  with  the  videogame  during  a  30-minute  session  (See  
figure 2). For the cognitive impact evaluation, four kinds of tasks were planned: (1) 
Preparatory tasks: designed to level out the knowledge and skills that the users must 
possess in order to successfully utilize the videogame. (2) Navigation tasks: Designed 
so that the user is able to navigate through the simulated environment with the purpose 
of becoming  familiar  with it. (3)  Development  tasks: Designed so that the students 
perform the activities available in the game. (4) Representation tasks: Designed 
so that the student represents both graphically and concretely the mental map that he 
has constructed of the space that has been navigated.  

To date, three 45-minute preparatory sessions per student  have been  held  with a 
group  of  9  learners.  Afterwards,  the  pretest  evaluation  was  applied  during  two  

 

368 

J. Sánchez and J. Mascaró 

45-minute  sessions  with  each  of  the  same  9  students.  Currently,  a  set  of  cognitive 
tasks is being held involving the use of the videogame and the corresponding supportive 
activities, in 45-minute sessions with each learner. In this process, it is sought to 
hold a total of 12 sessions in order to then apply the posttest.  

4   Results 

Regarding the results obtained from the iconic evaluation of the videogame with the 
application of the SUE questionnaire, it was possible to observe that an initial group 
of sounds, corresponding to horns, cars, doors and environmental sound, were identified 
correctly for the most part. However, the sounds corresponding to steps over different 
kinds of surfaces were confused with bumping sounds. Due to this problem, a 
second set of sounds was utilized, which when evaluated was more readily identified.  
Concerning the iconic usability evaluation of concrete shapes, the results obtained 
from  the  guideline  show  that  the  students  correctly  identified  simple  geometric 
shapes,  such  as  regular  polygons,  but  presented  problems  with  identifying  complex 
shapes. In the same way, in evaluating shapes with the haptic device it was observed 
that most of the learners identified regular shapes with the device, achieving an average 
percentage for the correct identification of such shapes of 75.4%; however, this 
was not the case with complex shapes. This could be attributed to the fact that in order 
to recognize a shape with the device, the users obtained information by counting the 
sides or corners of each shape.  

In evaluating the iconic usability of the virtual textures represented with the haptic 
device, the results show that the learners were, for the most part, able to correctly describe 
the textures (79.4% recognition), although they were not necessarily identified 
with a specific concrete material. In addition, when asked if each texture was pleasant 
to the touch, in general the majority of the learners responded that the textures were 
pleasant,  and  that  they  did  not  have  too  much  difficulty  interacting  with  the  device 
(82.4% satisfaction).  

From the results obtained in the end-user usability evaluation, it was observed that 
Audiopolis  is  highly  usable  and  understandable  to  the  users  with  visual  impairment 
(see figure 3). For the statements that correspond to the “Satisfaction” category, those 
which  obtained  higher  scores  from  the  users  surveyed  were  “The  videogame  is  
interactive” and “I like the videogame”, with a mean score of 9.6 and 9.3 points respectively,
 out of a total of 10 possible points. The statement “The videogame is chal-
lenging” obtained the lowest score, with an average of 6.7 points, as the users found 
the videogame to be relatively easy.  

Regarding the results obtained for the statements that correspond to the  “Control 
and Use” category, it was observed that for the users it is easy to use the videogame. 
The  statement  “The  videogame  is  easy  to  use”  obtained  the  highest  score  with  9.1 
points, while the lowest score was assigned to the statement “I felt in control of the 
situations presented by the videogame”, with 7.8 points, which is still within the range 
considered to be an acceptable degree of satisfaction.  

In the “Sounds” category, all of the statements obtained average scores higher than 
9,  which  means  that  the  application  resulted  in  the  expected  results  even  before  an 
iconic usability evaluation was applied, as the sounds chosen were widely accepted by 

 

 

Audiopolis, Navigation through a Virtual City Using Audio and Haptic Interfaces 

369 

the users. In the “Haptic device” category, it was observed that the users liked to interact 
with the device and that it provided them with relevant information regarding 
the  objects  in  the  virtual  environment.  Also,  in  the  open-ended  questions,  the  users 
commented that in general the videogame was fun and interactive, but that it would be 
good to add more elements from a typical city environment.  

Regarding the preparatory activities with the clock technique, the users achieved an 
average score of 79.3% accuracy when using the instrument. In the case of geometric 
shapes  they  achieved  an  average  score  of  81.8%,  and  in  the  case  of  sounds  they 
reached an average of 83.8% accuracy.  

 

Fig. 3. Results for the End-User Usability Evaluation. (1) I like the videogame, (2) The videogame 
is fun, (3) The videogame is challenging, (4) The videogame makes me fell active, (5) I 
would  play  this  game  again,  (6)  I  felt  in  control  of  the  situation  in  the  videogame  (7)  The 
videogame is interactive, (8) The videogame is easy to use (9) The videogame is motivating, 
(10) The videogame adapts to my rhythm, (11) The videogame allowed me to understand new 
things, (12) I like the sounds of the videogame, (13) The sounds of the videogame are clearly 
identifiable, (14) The sounds of the videogame provided me with information, (15) I like the 
tactile sensation of the haptic device in the videogame. (16) The elements of the videogame are 
clearly  identifiable  by  touch  using  the  haptic  device.  (17)  The  tactile  sensation  of  the  haptic 
device provided me with information. 

5   Discussion 

This study presents the design and evaluation of Audiopolis, a virtual city represented 
by audio and haptic feedback for the development of O&M skills in people who are 
blind. In particular, this study informs about the results regarding the usability of interface 
elements from the virtual environment, the end-user usability and the tasks in 
the process for a further cognitive analysis of the skills acquired through the use of the 
videogame.  

From the usability evaluation, it was observed that most of the users perceived the 
sounds, textures and shapes (both concrete and virtual) without any trouble, through 
the use of audio and haptic interfaces. The users associate the majority of the sounds 
with the elements represented in the virtual environment thanks to the previous iconic 
usability evaluation, which allowed the development team to rule out the sounds that 
could  generate  confusion  for  the  users  at  an  early  stage.  In  the  same  way,  they  are 
able to identify various simple geometric shapes with their hands by touching the contours 
of the shape, but are unable to do so with complex shapes. This is due mainly to 

 

370 

J. Sánchez and J. Mascaró 

the fact that, in order to detect shapes in this  way, the users counted the  number of 
sides  and/or  corners  of  the  shape,  characteristics  that  are  not  common  in  irregular, 
complex shapes. In the case of textures, the users were able to recognize most of them 
adequately, although in some cases (such as glue and sand) they could only describe 
them without identifying them by name. This is due in part to the fact that such users 
are not normally familiar with these elements.  

The textures were all recognizable to the users, and although they were unable to 
always associate the textures with a concrete material in the real world, they were able 
to  identify  them  within  the  virtual  environment.  This  means  that  if  at  point  A  they 
experienced a particular texture, at point B they were able to identify if the new texture 
they encountered was the same as that from point A or not.  

In  addition,  the  users  were  able  to  interact  relatively  easily  with  the  videogame, 
and were able to quickly adapt to its mode of use. They found the videogame to be 
motivating,  and  stated  that  they  would  use  it  again.  Thanks  to  the  iconic  usability 
evaluation,  it  was  observed  during  the  end-user  usability  evaluation  that  the  sounds 
were widely accepted by the users, that the textures and the haptic interface provided 
the information desired, and that the users perceived them just as they expected to.  

Currently,  the  cognitive  impact  evaluation  is  being  performed,  through  planned 
cognitive tasks using the videogame designed to develop O&M skills. The promising 
results obtained from the preparatory tasks assure us that the elements of the video-
game’s interface have been correctly identified during the users’ interaction with the 
game. Once the cognitive evaluation has been completed, it will be possible to determine 
 if  there  are  significant  gains  in  the  development  of  O&M  skills  as  a  result  of 
having used the videogame.   
 
Acknowledgments. This report was funded by the Chilean National Fund of Science 
and Technology, Fondecyt #1090352 and Project CIE-05 Program Center Education 
PBCT-Conicyt. 

References  

1.  Mioduser,  D.,  Lahav,  O.:  Anticipatory  Cognitive  Mapping  of  Unknown  Spaces  in  
Unknown  Spaces  by  People  who  are  Blind  Using  a  Virtual  Learning  Environment.  In:  
International Conference of the Learning Sciences, pp. 334–341 (2004) 

2.  Lumbreras,  M.,  Sánchez,  J.:  Interactive  3D  Sound  Hyperstories  for  Blind  Children.  In: 

Proceedings of the ACM CHI Conference, pp. 318–325 (1999) 

3.  Lahav,  O.,  Mioduser,  D.:  Haptic-feedback  support  for  cognitive  mapping  of  un-known 
spaces by people who are blind. International Journal of Human-Computer Studies 66(1), 
23 (2008) 

4.  Novint Web Page, 

http://home.novint.com/products/novint_falcon.php 

5.  Mon, F.: Orientation and Mobility in adults. In: El Cisne, Buenos Aires (2003) 
6.  Sánchez,  J.,  Aguayo,  F.,  Hassler,  T.:  Independent  Outdoor  Mobility  for  the  Blind.  
In:  Proceedings  of  the  IEEE  Virtual  Rehabilitation  2007  Conference,  pp.  114–120.  
September 27-29, Venice, Italy (2007) 

7.  Sanchez,  J.:  Software  Usability  for  Blind  Children  Questionnaire  (SUBC),  Usability 

evaluation test, University of Chile (2003) 

 

 

Audiopolis, Navigation through a Virtual City Using Audio and Haptic Interfaces 

371 

8.  Bresciani, J.-P., Drewing, K., Ernst, M.O.: Human haptic perception and the design of hap-
tic-enhanced  virtual  environments.  Springer  Tracts  in  Advanced  Robotics,  pp.  61–106 
(2008) 

9.  Helbig,  H.,  Ernst,  M.O.:  Haptic  perception  in  interaction  with  other  senses.  Birkhäuser, 

Basel (2008) 

10.  Lederman,  S.J.,  Klatzky,  R.L.:  Haptic  perception:  A  tutorial.  Attention  Perception  and 

Psychophysics 71(7), 1439–1460 (2009) 

11.  Sánchez, J., Elías, M.: Guidelines for designing mobility and orientation software for blind 
children. In: Baranauskas, C., Abascal, J., Barbosa, S.D.J. (eds.) INTERACT 2007. LNCS, 
vol. 4662, pp. 375–388. Springer, Heidelberg (2007) 

12.  Sánchez, J., Tadres, A.: Audio and haptic based virtual environments for orientation and 
mobility in people who are blind. In: Proceedings of the 12th international ACM SIGACCESS 
Conference on Computers and Accessibility (ASSETS 2010), pp. 237–238. ACM, 
New York (2010) 

13.  Cohen, J., Humphreys, L.G.: Sensación y percepción auditiva y de los sentidos menores. 

Trillas, Mexico (1973) 

14.  Gearlog: The Novint Falcon.The ultimate 3D game controller. Pc Magazine: the Independent 
Guide to IBM-Standard Personal Computing 25(12), 167 (2006) 

15.  Carreiras, M., Codina, B.: Cognición espacial, orientación y  movilidad: considera-ciones 

sobre la ceguera. Integración 11, 5–15 (1993) 

 

