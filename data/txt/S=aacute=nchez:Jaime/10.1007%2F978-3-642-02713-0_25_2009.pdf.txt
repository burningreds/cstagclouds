Indoor Position and Orientation for the Blind 

Mauricio Sáenz and Jaime Sánchez 

Department of Computer Science, University of Chile 

Blanco Encalada 2120, Santiago, Chile 

{msaenz, jsanchez}@dcc.uchile.cl 

Abstract. This work proposes the study and design of mobile interfaces to identify 
 the  position  and  orientation  of  blind  people  in  closed  environments. 
Through this development we seek to reach a consensus on the use of a certain 
technology that would allow for the identification of the position and orientation 
of people within a closed space (such as a school or home) with the necessary 
 infrastructure.  A  focus  group  was  held  in  order  to  identify  the  users’  
problems  with  the  navigation.  In  addition  we  made  initial  and  final  usability 
tests. The results of the usability evaluation showed that the interface designed 
was highly usable for blind users and that the technology designed worked to  
improve the indoor navigation of blind people. 

Keywords: blind navigation, indoor navigation, orientation and mobility. 

1   Introduction 

For most visually disabled users the biggest obstacle to moving around is that they are 
always restricted to the same navigated spaces. This is because to change their route 
or branch off from the road could be dangerous and confusing, impeding them from 
finding their way back. As a result, blind users are limited to taking routine journeys 
and are denied from exploring new places [5]. Other obstacles for a blind person include 
the determination of their location in an environment, knowing which way they 
are  facing  or  the  direction  in  which  they  are  moving,  and  the  lack  of  information 
about  important  objects  in  the  environment,  such  as  the  distance  at  which  they  are 
located  both  in  terms  of  nearby  objects  and  those  at  a  distance  [4].  In  general,  in  a 
familiar  environment  a  visually  disabled  user  can  enjoy  a  conventional  degree  of 
navigation,  because  he/she  knows  the  surroundings,  or  because  they  have  adequate 
aid for navigation. In a closed unfamiliar environment, the experience of navigation 
can be complex and completely non-deterministic [6]. 

If the goal is to confront the problems that blind users face in the context of orientation 
and mobility, the idea to use mobility-related technologies emerges. Computer 
technology  that  aids  in  teaching  and  learning  has  traditionally  been  represented  by 
desktop  computers  to  access  learning  resources  [2].  Mobile  device  technology  provides 
opportunities for new kinds of teaching and learning support. These devices are 
becoming  part  of  the  personal  technological  resources  of  each  student,  with  the  
important advantage that they are available anytime and anywhere [2]. 

C. Stephanidis (Ed.): Universal Access in HCI, Part III, HCII 2009, LNCS 5616, pp. 236–245, 2009. 
© Springer-Verlag Berlin Heidelberg 2009 

 

Indoor Position and Orientation for the Blind 

237 

The  same  technology  cannot  be  used  to  locate  objects  in  indoor  and  outdoor  
spaces [1]. For outdoor spaces such as a neighborhood, a city or a back yard, the simplest 
mechanism to use is GPS. However, this technology is not apt for closed spaces 
such  as  parking  garages,  underground  locations,  stores  or  buildings.  This  implies 
seeking out alternative technology that would allow a user to obtain his/her location in 
places where GPS is not apt. Gill [3] proposes a hybrid method to track people’s location 
 in  closed  environments.  This  method  employs  different  measuring  devices:  a 
digital  compass,  accelerometer  and  an  infrared  sensor.  Each  time  a  new  step  is  detected,
 the system updates the user’s position. The problem with this solution is how 
awkward the machine that the user must carry around is, as it implies three elements 
that are not comfortably mobile and only work in association with the use of a portable 
computer. Na [7] in his work presents BIGS, Blind Interactive Guide System, for 
blind people to be able to move about in a building. The BIGS system consists of two 
parts:  a.  The  intelligent  placement  of  passive  RFID  tags  on  the  grid,  which  only 
transmits in ID, and b. A portable terminal embedded with an RFID device that receives 
 the  data  from  the  passive  tags  and  generates  information  about  the  person’s 
location.  This  method  also  uses  the  previous  representation  of  the  environment  and 
the location of the different tags on the ground.  In addition to this, the system can use 
Wi-Fi technology so that the security personnel in the building can constantly monitor 
the movements and the route being taken by the user.  

This  work  proposes  the  study  and  design  of  mobile  interfaces  to  identify  the  

position and orientation of blind people in closed environments. 

2   Interface Design 

From the literature it can be gathered that there are certain ways of approaching the 
orientation and mobility issue. There are studies that indicate the aspects to consider 
when  designing  an  application  in  support  of  the  orientation  and  mobility  of  blind 
people. For this reason it is necessary to know the opinions of the end users and their 
apprehensions when faced with a situation in which they are in an unknown place and 
have to move about.  

In order to obtain this information a Focus Group was held at the start of the study 
in  which 4 blind people between 19 and 34 years of age participated (see Table 1). 
The  Focus  Group  was  coordinated  by  2  interface  experts  and  1  special  education 
teacher specializing in visual disorders.  

At the start of the Focus Group the expert proposed discussing in general terms the 
“Most recurrent or most significant problems that the blind have when they want to 

 

Table 1. Participants of the Focus Group 

Age 
19 
34 
20 
27 

Ophthalmologic Diagnostic 
Retinitis Pigmentosa 
Retinitis Pigmentosa 
Retinitis Pigmentosa 
Retinal Detachment Glaucoma 

Degree of Vision 
Low Vision 
Totally Blind 
Low Vision 
Low Vision 

Case 

1 
2 
3 
4 

 

238 

M. Sáenz and J. Sánchez 

know  where  they  are”.  On  this,  case  1  commented:  “Places  that  I  don’t  know  are 
complicated  because  of  people  who  have  a  different  attitude.  I  need  some  help  or 
support”. On the same topic case 2 stated: “The blind have the capacity to calculate 
spaces, it would be great to have a device that tells you if there are obstacles to prevent 
accidents and to know where you are”. Case 3 proposed that the amount of attention 
that the blind pay to their movements is what makes locating oneself so difficult 
in general, in both familiar and unfamiliar spaces: “It’s hard to always pay attention, 
overall where there is a lot of noise. That skill has to be developed. I would say that it 
has to do with my attention span, my concentration”.  

The expert asked about the factors that could be determinant for attention. To this 
question, case 2 stated that when he talks to someone he loses his concentration on the 
space and is not able to focus on the two things at once. Case 3 mentioned that she 
always  follows  a  group  of  people,  but  that  she  gets  confused  if  there  are  too  many 
people:  “It  happens  to  me  when  there  are  a  lot  of  people,  my  route  is  established. 
People  confuse  me;  it  is  difficult  to  know  where  I  am.  I  always  follow  the  group”. 
Case 1 stated that the level of attention is not all that necessary because in the city of 
Santiago people help the blind with their navigation more than in the provinces. 

Orientation  was  discussed,  and  the  participants  were  asked  about  the  strategies 
they  used  and  the  problems  they  encountered.  Case  3  pointed  out  that  it  is  always 
important to know the point from which the trip started, because in not knowing this 
they would be completely disoriented on the return trip. Case 2 mentioned his specific 
situation in the Metro, in which he was certain that he had no difficulties because he 
knows  the  coordinates  of  his  destination  well.  Despite  this  he  states  that  he  gets  
disoriented in complex stations. The way they have to solve the problem of disorientation 
is by asking for help. On this the expert proposed discussing what basic information 
 is  necessary  to  get  to  a  destination.  On  this,  Case  3  stated:  “First,  what  
direction I have to go (straight, to the right, etc), where I have to get to and how to 
follow  the  route”.  Case  2  described  the  necessary  information  in  detail:  “…which 
hall, to take a right or a left, approximate distance, is there a wall, what will I find in 
my path, and that’s enough. I have a defined route and I look for the reference points 
that the (Metro) guard gives me”. What they need to move about are reference points 
that allow them to locate themselves in space.  

From these results the PYOM software interfaces and the ServerPYOM were designed.
 Also, thanks to the software usability evaluation we were able to improve the 
interfaces, which is reflected in the end user evaluation.  

3   Software 

3.1   ServerPYOM 

The ServerPYOM application contains all the necessary information to provide a user 
with  his/her  orientation  and  location  when  requested  through  interaction  with  the 
PocketPC device.  

In an initial version of the ServerPYOM software the user’s orientation was provided 
through laterality. The user was found to be to the right of, left of, in front of or 
behind certain objects. This mode of orientation was not sufficient for the users, and 
they needed more precise and concrete information. According to the results obtained 

 

 

Indoor Position and Orientation for the Blind 

239 

Fig. 1. Clock metaphor to spatially orient the user 

 

from the initial usability evaluation, it was found that the best method for providing 
the user with his/her orientation was by means of the clock metaphor.  

In this metaphor the user is always facing 12:00, being the center of the clock [9]. 
The directions that the system provides regarding the location of different objects or 
places correspond to the respective hours on the clock. The information is exact when 
it corresponds to an hour and is approximate if it corresponds to an intermediate direction 
between two hours. Figure 1 represents an example of the direction in which 
an object is located, at 4:00.  

The ServerPYOM interface had two designs. The first was developed based on the 
results  obtained  from  the  Focus  Group,  and  although  it  responded  to  the  users’  requirements 
 it  was  not  able  to  provide  answers  for  all  the  information  they  needed 
(Fig. 1A). In the first usability evaluation it was found that the information provided 
by the software was not sufficient, and the user had to be provided with more precise 
and detailed information. Thanks to this, the interface was redesigned to provide the 
user with the necessary information (Fig. 1B).  

Every time a PocketPC connects to the network the server detects it and is ready to 
communicate with the device. The connected devices appear listed on the upper portion 
the screen and the facilitator must select the device to which the information will be sent.  
When the user asks for his/her position or orientation, a request message appears 
on the interface, to which the facilitator must respond by sending the requested information.
 In the case of position, the facilitator must provide this information by selecting 
the place in  which the  user is located and the specific  sector in  which he/she is 
within this place. In the example provided in figure 2A the user is in the parking garage.
 The user’s orientation is provided according to the key points within the room 
 

                                (a)                                                                        (b) 

Fig. 2. ServerPYOM interfaces (a) Initial ServerPYOM interface (b) Final ServerPYOM interface 

   

 

 

240 

M. Sáenz and J. Sánchez 

that identify the direction in which this point is located. In the example given in figure 
2B, orientation is provided by the door to the meeting room, which is located at 4:00. 

3.2   PYOM 

PYOM, or Mobile Position and Orientation  System, is the name  given to the entire 
system and the user application. Totally oriented for use by blind users, all the information 
output is provided by audio. The PYOM software was developed with Microsoft 
Visual Studio .Net in  C# language  for PocketPC devices. This software can be 
executed on computers with Windows Mobile 5.0. 

The  application’s  opening  interface  uses  the  buttons  on  the  PocketPC  device  as 
well as the touch screen. Of the 4 buttons on the PocketPC only two are used, located 
at the extremes so that it is easy to find them. The left button is used to request help; 
in pressing this button the user comes to know how to interact with the application. In 
starting up PYOM, the user is provided with instructions about the buttons used in the 
device. The right button is used to quit and shut down the application. 

The  screen  is  divided  into  two  vertical  parts.  In  each  vertical  part  of  the  touch 
screen  (left  and  right)  the  user  can  interact  by  using  his/her  fingers  to  execute  the 
corresponding command. In the left rectangle the user can ask for information about 
his/her position in space, while in the right section the user can request information 
about his/her orientation. For the device to recognize the user’s instructions, it is necessary 
 for  the  user  to  trace  his/her  finger  upwards  from  below,  not  necessarily  in  a 
straight line but as straight as possible (Fig. 3). 

The output interface for blind users uses synthesized spoken text, thus achieving the 
total transfer of the information directly, or through the use of headphones connected 
to the PocketPC. This synthesized text is achieved through the use of a Text-to-Speech 
engine from the Acapella group, for which reason the information delivered is dynamic 
and can vary without presenting any problems or additional recording costs. 

There were two phases for working on the PYOM software. The first phase consisted 
of getting to know the real needs of the users for a position and location system. 
The second phase consisted of using the system in a real application.  

Phase  1.  In this phase  we  worked under a client-server architecture in  which the 
PocketPC  had  the  client  application  and  the  server  application  (ServerPYOM)  was 
run  from  a  laptop.  The  server  application  contains  all  the  information  necessary  to 
provide the user with his/her orientation and location when he/she requests it through 
interaction with the PocketPC device. 

                                                       (a)                            (b) 

     

 

Fig. 3. PYOM input interface. (A) Form of use in order to request Position. (B) Form of use in 
order to request Orientation.  

 

Indoor Position and Orientation for the Blind 

241 

Fig. 4. Diagram of communication with the PYOM system in phase 1 

 

Fig. 5. Diagram of communication with the PYOM system in phase 2 

 

Through  an  ad-hoc  network  both  applications  communicate  with  each  other. 
The  user  can  request  position  or  orientation  information  by  sending  a  message  
to  the  server,  and  then  the  server  returns  the  requested  information  to  the  device 
(Fig. 4).  

Phase 2. In this phase it is no longer necessary to use the server application. The architecture 
consists of an ad-hoc network with several access points in the room. The 
PYOM software detects the user’s location and orientation according to the data received 
from the intensity of the signals coming from the different access points in the 
room. The signal from the access points is collected and analyzed beforehand by the 
PYOMDatos software, and is then analyzed with the PYOMAnalyses software, which 
produces an XML file with all the necessary information to be compared with the data 
obtained by PYOM (Fig. 5).  

4   Evaluation 

4.1   Sample 

The  sample  was  made  up  of  5  users  between  14  and  34  years  of  age,  including  2 
women and 3 men, 3 totally blind users and 2 with partial vision (according to ophthalmologic 
diagnoses). Of all the 5 users, 3 participated in two evaluations and the 
other 2 in the final evaluation. These last two were not familiar with the testing center. 
An engineer who is an expert in interfaces, as well as a special-education teacher 

specializing in visual disabilities guided the evaluations. 

242 

M. Sáenz and J. Sánchez 

4.2   Instruments 

For  the  end-user  evaluation  Sanchez’s  Software  Usability  Questionnaire  for  Blind 
Children [8]  was used. This guideline consists of 18 statements  for  which the  users 
must define to what degree each of them was fulfilled, on a scale from ‘A Little’ to ‘A 
Lot’, with quantitative values from 1 (a little) to 10 (a lot). The sentences were: “I like 
the  software”,  “The  software  is  useful”,  “The  software  makes  me  active”,  “I  would 
use the software again”,  “I  would recommend this  software to other children/young 
people”, “I learned through this software”, “I felt I could control the software’s situa-
tions”, “The software is interactive”, “The software is easy to use”, “The software is 
motivating”, “The software adapts to my rhythm”, “The software allowed me to understand 
new things”, “I like the sounds in the software”, “The sounds in the software 
are clearly identifiable”, and “The sounds in the software provide me with informa-
tion”. In addition to this, an Evaluation Questionnaire with Open Questions containing 
10 questions regarding the use of the software and its applicability was also used. 
The  following  questions,  among  others,  were  included:  “Is  the  information  that  the 
software provides enough to know what to do and what is happening? What did you 
think about the sounds in the game? Would you add more sounds?” Finally, a PYOM 
Evaluation Questionnaire especially designed for this software including 3 open questions 
 focusing on the problems directly related to the use of the software  was used: 
“When using the software, what problems did you have with location? What problems 
did you have with orientation? Was the software useful for you?” 

4.3   Procedure 

The evaluation was carried out in the facilities of the C5 Research Center of the Computer 
Science Department at the University of  Chile. The end-user usability evaluation 
was administered for the system’s main application, PYOM. 

The end-user evaluation was carried out during two sessions. The first session was 
held for 2 hours. In this session the users executed the task of arriving at a specific 
point  within  the  C5  building.  This  route  was  taken  without  the  help  of  a  cane  and 
without  any  kind  of  assistance  beyond  that  provided  by  the  PYOM  software.  The 
starting point was the center’s meeting room, and the users had to get to the front hall 
(Fig. 6). 

The  second  session  also  took  place  in  the  C5  center,  and  lasted  3  hours.  In  this 
session the users arrived to a point in the building where they had never been before, 
for  which  reason  the  route  and  its  location  were  totally  unknown.  The  route  in  
questions  consisted  of  going  from  the  meeting  room  to  the  center’s  research  and  
development office (Fig. 6). 

As we sought to test the mode of using and operating the interface, in both usability 
tests the PYOM software worked together with the ServerPYOM software, which 
provided  the  user  with  the  position  and  orientation  information  as  described  in  the 
ServerPYOM sub-section of the Design section in this paper.   

The evaluation was performed individually with each of the users, in which they 
had to get to the previously defined destination at their own pace. Once the users had 
finished  the  route,  the  Software  Usability  Questionnaire  for  Blind  Children,  the 
Evaluation Questionnaire with Open Questions and the PYOM Evaluation Questionnaire 
were administered. 

 

Indoor Position and Orientation for the Blind 

243 

Fig. 6. Routes taken during the evaluation sessions. The First path is the route that the users 
took during the first session, and the Second path is the route taken in the second session. 

 

4.4   Results 

For  the  analysis  of  the  End-User  Usability  Questionnaire,  the  statements  were 
grouped into three categories: Satisfaction, Control & Use, and Sounds. For each of 
these categories an average score from the values provided by the users in the sample 
was obtained, achieving a detailed evaluation of different aspects of the software. 

Of the maximum total of 10 points that each category could receive, the results of 
the  first  usability  test  were  rated  in  the  middle.  The  satisfaction  and  control  &  use 
categories obtained the lowest score, both with 5.3 points, while the sounds category 
was rated slightly higher with 6.2 points (Fig. 7A). 

Despite these general results, particular statements in each category show relevant 
results.  The  sensation  of  controlling  all  the  software’s  actions  was  positively  
evaluated  (7.6  points),  as  well  as  that  which  stated  that  the  software  is  easy  to  
use  (9.3  points).  The  fact  that  the  sounds  transmit  information  was  a  very  highly 
evaluated  point  with  an  average  of  9.3  points.  The  lowest-evaluated  statements  
were:  “The  software  adapts  to  my  rhythm”  (3.3  points),  “I  like  the  sounds  in  the  
software”  and  “The  software  is  motivating”,  these  last  two  obtaining  4.3  points. 
 

                                  (a)                                                            (b) 

Fig. 7. (a) Results of the first usability test (b) Result of the second usability test 

    

 

244 

M. Sáenz and J. Sánchez 

 

Fig. 8. Comparative results between the first usability test and the second usability test of the 
PYOM software 

“The software is easy to use” and “The sounds provide me with information” were 
the  two  statements  that  obtained  the  highest  evaluations,  with  9.8  points  and  9.6 
points respectively. “The software adapts to my rhythm” was still the statement with 
the lowest evaluation, receiving a score of 3.6. This is explained by the fact that the 
software provides information on position and orientation according to what the user 
requests, and the process and information are the same whether the user is a novice or 
more experienced. 

Although there were no statistically significant differences (t=-1.756, p>0.05), the 
scores for the second usability test were higher than the first, and there was a considerable 
improvement expected for the changes made to the software based on the results 
of the first evaluation. The category that obtained the highest evaluation was still 
that regarding the sounds, with 8.3 points, followed by satisfaction with 7.9 points and 
finally control & use with 7.4 points (Fig. 7B). 

The final test received a higher evaluation than the first, but without statistically 
significant  differences,  reaching  2.6  points  more  in  satisfaction  (t=-1.015,  p>0.05; 
pretest=  5.3  points,  posttest=7.9  points),  2.1  points  difference  in  control  &  use  
(t=-1.973, p>0.05; pretest=5.3 points, posttest=7.4 points), and 2.1 points difference 
in sounds (t=-2.113, p<0.05; pretest=6.2 points, posttest=8.3 points) (Fig. 8). 

5   Conclusions 

This work proposes the study and design of mobile interfaces to identify the position 
and orientation of blind people in closed environments. 

From the usability evaluation we were able to obtain the relevant information that 
blind users need in order to locate and orient themselves spatially in a certain place. 
Also, the way in which the information is provided is a critical point that was identified 
in this study. The users worked correctly  with the clock system for orientation, 
achieving clarity as far as where they had to go in the environment, thus being able to 
arrive to their destination independently. 

Although there were no significant differences in the usability evaluations for both 
tests,  including  differences  by  gender,  the  PYOM  software  was  highly  evaluated, 
achieving high scores in the Software Usability Questionnaire for Blind Children and 
the  Evaluation  Questionnaire  with  Open  Questions.  The  final  usability  evaluation 
achieved the highest results of all three aspects evaluated, which were user satisfaction,
 control & use and sound quality. This implies an improvement in the system’s 
interface both in the way it presents data and in the data itself. 

 

Indoor Position and Orientation for the Blind 

245 

The  entire  process  of  the  design  and  development  was  carried  out  with  a  usercentered 
methodology, for which reason the results were usable by and accessible to 
the end-users. The main application, PYOM, has a touch screen and audio interface 
that allows for simple use by blind users, which is demonstrated by the results of the 
usability evaluations. 

Acknowledgments. This report was funded by the Chilean national Fund of Science 
and Technology, Fondecyt #1060797 and Project CIE-05 Program Center Education 
PBCT-Conicyt. 

References 

[1]  Caballero, M.: Networks. Reflexions about Mesh, Wi-Fi and WiMax technologies. WiFi 
Localization/Mesh  (2005),  http://www.redesmalladas.com/?p=37  November 
21 (2005) (last accessed, January 2009) 

[2]  Csete, J., Wong, Y.-H., Vogel, D.: Mobile devices in and out of the classroom. In: Cantoni, 
L., McLoughlin, C. (eds.) ED-MEDIA 2004, Proceedings of the 16th World Conference 
on  Educational  Multimedia  and  Hypermedia  &  World  Conference  on  Educational  Telecommunications,
 pp. 4729–4736. Association for the Advancement of Computing in Education,
 Lugano (2004) 

[3]  Gill, J.: An Orientation and navigation System for Blind Pedestrians,  

http://isgwww.cs.uni-magdeburg.de/projects/mobic/mobiruk.html 
(last access, January 2009) 

[4]  Hub, A., Diepstraten, J., Ertl, T.: Design and Development of  an Indoor Navigation and 
Object Identification System for the Blind. In: Proceedings of the 6th ACM SIGACCESS 
conference on Computers and Accessibility ASSETS 2004, Atlanta, GA, USA, Designing 
for Accessibility, vol. 77&78, pp. 147–152 (2004) 

[5]  Jacquet,  C.,  Bellik,  Y.,  Bourda, Y.:  Electronic  Locomotion  Aids  for  the  Blind:  Towards 
More Assistive Systems. In: Ichalkaranje, N., Ichalkaranje, A., Jain, L.C. (eds.) Intelligent 
Paradigms  for  Assistive  and  Preventive  Healthcare,  pp.  133–163.  Springer,  Heidelberg 
(2006) 

[6]  Kulyukin,  V.,  Gharpure,  C.,  Nicholson,  J.,  Pavithran,  S.:  RFID  in  robot-assisted  indoor 
navigation for the visually impaired. In: IEEE/RSJ Intelligent Robots and Systems (IROS 
2004)  Conference,  September  -  October  2004,  pp.  1–6.  Sendai  Kyodo  Printing,  Sendai 
(2004) 

[7]  Na, J.: The Blind Interactive Guide System Using RFID-Based Indoor Positioning System. 
In: Miesenberger, K., Klaus, J., Zagler, W.L., Karshmer,  A.I., et al. (eds.) ICCHP 2006. 
LNCS, vol. 4061, pp. 1298–1305. Springer, Heidelberg (2006) 

[8]  Sánchez,  J.:  End-user  and  facilitator  questionnaire  for  Software  Usability.  Usability 

evaluation test. University of Chile, Santiago (2003) 

[9]  Sánchez, J., Aguayo, F., Hassler, T.: Independent Outdoor Mobility for the Blind. In: Proceedings 
 of  Virtual  Rehabilitation  2007,  Venice,  Italy,  September  27-29,  pp.  114–120 
(2007) 

