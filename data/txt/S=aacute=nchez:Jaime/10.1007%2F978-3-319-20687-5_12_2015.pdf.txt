Usability Evaluation of a Mobile Navigation

Application for Blind Users

Márcia de Borba Campos1(&), Jaime Sánchez2, Juliana Damasio1,

and Tasmay Inácio1

1 Faculty of Informatics (FACIN), Pontiﬁcal Catholic University of Rio Grande

do Sul (PUCRS), Porto Alegre, Brazil

marcia.campos@pucrs.br, {juliana.damasio,

tasmay.inacio}@acad.pucrs.br

2 Department of Computer Science, Center for Advanced Research

in Education (CARE), University of Chile,

Blanco Encalada 2120, Santiago, Chile

jsanchez@dcc.uchile.cl

Abstract. This paper presents a usability evaluation of a mobile gaming
application (mAbES) for blind users. mAbES was evaluated with the participation 
of HCI specialists and experts in video gaming (Group 1) and mAbES
end-users who are blind (Group 2). The instruments used by Group 1 were the
audio feedback questionnaire and the usability evaluation questionnaire. It also
included questions based on video games and game mechanics. For Group 2,
both the audio evaluation and the O&M, tactile feedback and ease of use
questionnaires were applied. Semi-structured interviews were also carried out.
User perceptions and interaction behaviors identiﬁed during study and data
analysis allowed to reﬁne the methodology used for evaluating the usability of
mAbES and proposed suggestions for improvements in the use of this application,
 as well as to make recommendations for developing video games for
blind users for navigation purposes.

Keywords: Users who are blind  Mental map  Orientation and mobility 
Navigation  Mobile application  Usability evaluation

1 Introduction

This paper discusses the usability evaluation of a mobile navigation application for
people who are blind. The mobile Audio-Based Environments Simulator (mAbES) was
evaluated with the participation of HCI specialists, experts in video gaming and mAbES 
blind end-users. The evaluation included whether or not mAbES would allow the
user to recognize the Science and Technology Museum building at the Pontiﬁcal
Catholic University of Rio Grande do Sul (MCT/PUCRS) and, consequently, whether
they could move in this environment from the virtual interaction experience using
mAbES. The main research question was whether mAbES could assist a sightless user
in understanding the real space that it represents without replacing the visitation to the
museum.

© Springer International Publishing Switzerland 2015
M. Antona and C. Stephanidis (Eds.): UAHCI 2015, Part IV, LNCS 9178, pp. 117–128, 2015.
DOI: 10.1007/978-3-319-20687-5_12

118

M. de Borba Campos et al.

Following AbES’s functionality [1], mAbES is a mobile audio-haptic environments
simulator to assist the reﬁnement of orientation and mobility (O&M) skills in people
who are blind. Thus, during navigation the end-user can develop O&M skills that are
validated through the construction of mental maps [2]. The navigation capability is
related to a person’s ability to safely move from one point of origin to a destination.
Vision-based navigation is more of a perceptual process, whereas blind navigation
is more cognitively demanding and often requires conscious moment-to-moment
problem solving [3]. A person with visual impairment must be competent with orientation 
and mobility in order to achieve a solid level of navigation, including moving
about safely, efﬁciently and agilely, as well as independently in both familiar and
unfamiliar environments [4]. The learning of O&M skills includes a set of predeﬁned
techniques that blind or visually impaired children, young people and adults must
practice stage by stage. However, learning such skills also involves other aspects such
as training and reﬁning perception systems and developing both conceptual and motor
skills [2, 4].

Support on a perceptual and conceptual level is important for the development of
orientation skills and the construction of cognitive maps [1, 2, 5]. The notion of a map
refers to an internalized representation of space, a mixture of objective knowledge and
subjective perception.

If real-life surroundings are represented through virtual environments, it is possible
to create several training applications that allow a blind user to interact with the
elements in the simulated environment during navigation [6, 7].

There are different technological resources that have been developed to aid navigation,
 and thus allow blind users to better understand the world around them. There
are vibrating canes, tactile models, GPS-based applications, indoor environment simulators,
 RFID (radiofrequency identiﬁcation) tags, and camera image streaming to a
central server via cell phone to process unknown environmental features. There are
others navigational technologies available to unseeing users that focus on large scale
blind navigation, unfamiliar environments and well-known spaces, besides being
potentially useful to users with low vision [3]. The mAbES software was employed
including a multimodal interface integrating information feedback via audio and haptic
responses. mAbES uses a gaming interaction model proposed by [8, 9] to analyze the
barriers that a blind user faces when using a game. The application uses click-based
interaction on a Braille matrix, which is represented on a smartphone screen.

There is a research effort towards building interactive systems that can be used
autonomously by people who are blind [1–3, 5, 7–11] and that are easy and simple to
use. The terms ‘usability’ and ‘accessibility’ are related and should be borne in mind
along the stages of design, development and evaluation of computer applications [10].
In the mAbES usability evaluation, related accessibility issues were included.

There are different categories of usability and accessibility evaluation methods [12]:

(cid:129) Automated veriﬁcation of compliance with guidelines and standards
(cid:129) Evaluations conducted by experts
(cid:129) Evaluations using models and simulations
(cid:129) Evaluations with users or potential users
(cid:129) Evaluations of data collected during eSystem usage

Usability Evaluation of a Mobile Navigation Application

119

mAbES’s evaluation was conducted with Human-Computer Interaction and video
gaming experts in Group 1 and users, or potential users, in Group 2. The goal of the
evaluation was to verify mAbES’s adequacy to usability criteria (Group 1) and to check
that mAbES can help visually impaired people understand a real space that is represented 
in a virtual environment (Group 2).

The instruments used by Group 1 were the audio feedback questionnaire and the
usability evaluation questionnaire. The former identiﬁes the degree of understanding of
audio as well as the conformity of the audios to the Brazilian speciﬁcations requirements 
for the description of images in the design of accessible digital material [13]. The
latter includes questions that aim to gather information about the suitability of mAbES
to the heuristics [14]. It also includes questions based on video games and gaming
mechanics [1, 3, 8–11, 15].

For Group 2, the audio evaluation and the O&M questionnaires were applied. The
ﬁrst aimed at verifying if the user could be oriented in space and perceive the objects
around them by hearing audio information. The second questionnaire contained
questions related to O&M, tactile feedback, ease of use and user satisfaction. In
addition to the questionnaires, semi-structured interviews were also carried out.

Tasks were given to the participants of the two groups. Group 1’s tasks referred to
the use of mAbES without the users been physically in the Museum of Science and
Technology of the Pontiﬁcal Catholic University of Rio Grande do Sul. Group 2 was
organized into two subgroups because some users used mAbES before as well as
during the visit to the Museum, whereas others used it only during the visit to the
Museum. During the tasks performance, the use of mAbES was videotaped. In the case
of Group 2, the videotape served to verify the effect of the use of mAbES on users’
perception of the environment, alongside with their behavior when interacting with the
technology. After performing the tasks, all participants reproduced the mental map of
the museum using concrete material.

Users’ perception and interaction behavior identiﬁed in the study and the data
analysis allowed for reﬁning the methodology used for evaluating mAbES’s usability,
proposing suggestions for improvements in the use of this application and making
recommendations for developing video games for people who are blind for navigation
purposes. These issues, together with a description and analysis of the results of the
usability evaluation, are presented and discussed in the next sections.

2 AbES

mAbES - mobile Audio-Based Environments Simulator - is a videogame based on
AbES [1, 15]. AbES replicates a real, familiar or unfamiliar environment to be navigated 
by a person who is blind (Fig. 1). The virtual environment is made up of different
elements and objects (walls, stairways, escalators, doors, toilets or elevators) through
which the user can discover and become familiar with their location. AbES includes
three modes of interaction: free navigation, path navigation and game mode.

The user receives audio feedback from the left, center and right side channels, and
all actions are carried out through the use of a traditional keyboard, where each set of

120

M. de Borba Campos et al.

Fig. 1. A screenshot of AbES (Source: Sánchez et al., 2009)

keys has different associated actions. All of the actions in the virtual environment have
a particular sound associated to them.

3 mAbES

In the development of mAbES, members of the museum team took part in meetings in
order to deﬁne the scope and to prioritize the functionalities of the software. Then 3
experiments were chosen: Nuclear Power Station (Fig. 2), Energy Train, and Cool
House, located on the third ﬂoor of the museum.

Fig. 2.

(a) Picture of nuclear power station (b) (c) screenshot of nuclear power station

Interface. mAbES is a multisensory (auditory, haptic, graphic) virtual environment
simulating real-life space.

The audio interface is responsible for conveying museum information as well as
information resulting from user interaction with mAbES. There are four types of audio
feedback: (i) when the user collides with an object, the sound is triggered identifying
is an escalator”. mAbES also provides an
this object,

for example “This

Usability Evaluation of a Mobile Navigation Application

121

audio-description about its physical appearance, its operation and how the user should
use the escalator in the real context of the museum; (ii) during navigation, there is a set
of sounds associated with the objects. For example, if the user walks, the step sound
cue can be heard; (iii) the instructive component has an audio description of the
selected MCT-PUCRS experiments; (iv) while the user interacts with the experiments,
they are presented with quizzes/challenges that must be answered.

The haptic interface consists of vibration feedback provided by the smartphone.
Every time the user bumps into an object, they feel an intermittent vibration on their
hand.

The Graphic Interface represents the characteristics of the museum: size, shape and
position of the spaces, the selected experiments (Nuclear Power Station, Energy Train,
and Cool House) and objects (escalators, walls, chairs, tables, shelves, etc.). This
graphical representation allows mAbES to be used by low-level vision and sighted
people alike.

Interaction. The user communicates with the software by interacting with a smartphone 
screen, which utilizes an array of points of the Braille system (Fig. 3). The
movement of the user through the museum is achieved by using the forward button,
which represents the user’s individual steps. The right and left buttons are used when
the user turns either direction (Fig. 4).

Fig. 3.

(a) Braille matrix (b) (c) screenshot of the menu

Fig. 4.

(a)(b)(c) Screenshot of transitions between ﬂoors in MCT-PUCRS

122

M. de Borba Campos et al.

When the user arrives at the third ﬂoor, mAbES presents the experiments that are
mapped so that the user can choose which one they want to interact with: 1 – Nuclear
Power Station, 2 – Energy Train, 3 – Cool House, 4 – Explore the space freely, 5 –
More information, 6 – Exit, according to the Braille matrix. When the user comes upon
any experiment (Nuclear Power Station, Energy Train, Cool House), mAbES informs
the user by naming the object or experiment, and the options or quizzes/challenges that
are available to the user. Information on the museum or the experiments is available to
the user in audio format. The options for hearing the audio cues are: 1 – Play, 2 –
Pause, 3 – Increase speed, 4 – Go back, 5 – Go forward, 6 – Help.

4 METHOD

4.1

Sample

(cid:129) Group 1: an intentional sample was selected, made up of 3 HCI specialists and 2

experts in video gaming for blind users.

(cid:129) Group 2: the sample selected for the use with mAbES was made up of 6 learners (3
female; 3 male), of which 2 are between 10 and 14 years old and 2 are between 20
and 36 years old. The 2 remaining users are 44 years old. Across the entire sample,
5 learners were totally blind and 1 person had low vision. All of them were legally
blind. This sample was divided into 2 subgroups of 3 users. Subgroup 1 visited
MCT without having used mAbES beforehand. Subgroup 2 used mAbES before
visiting the museum. The requirement to participate was to not be acquainted with
the Museum of Science and Technology, of the Pontiﬁcal Catholic University of
Rio Grande do Sul.

4.2

Instruments

Sound Evaluation Instrument. Assessment of sound information occurred in two
stages: (i) by the authors of this work and (ii) with the participants of Group 1 and
Group 2.

The authors of this study evaluated mAbES’s sounds from the Technical Note [13].
The authors assessed whether the sounds used in mAbES met the speciﬁcations of the
Technical Note. In the case of non-compliance, it was indicated that the requirement
was not fulﬁlled and a sound transcription was suggested (Table 1).

Table 1. Example of the comparison between mAbES’s sounds

Original Sound
You are on the second ﬂoor. To
move up to the third ﬂoor, you
must use the escalator, which is a
few steps ahead.
This is a counter.

Requirements
2

Sound suggestion
You are on the second ﬂoor. To
move up to the third ﬂoor, you
must use the escalator, which is
six steps ahead.

3, 13

This is a white counter 88 cm high.

Usability Evaluation of a Mobile Navigation Application

123

Of the 156 sounds in mAbES, 30 did not meet what is speciﬁed in the Technical
Note. Afterwards, a selection was made to discard sounds that referred to the same
unmet requirement. Finally, 16 sounds were selected to compose the audio test
instrument with the participants in Group 1 and Group 2.

In the second stage, the participants in groups 1 and 2 evaluated the sounds. The
instrument contained the identiﬁcation of the sound cue, the number of times it was run
by the user (so as to indicate their preference for the original or the suggested version)
and an optional ﬁeld to include comments on each sound.

Usability Evaluation Tool. Usability evaluation instruments for groups 1 and 2 were
based on [1, 11].
(cid:129) Group 1: 35 questions, of which 28 were based on ten Usability Heuristics for User
Interface Design [14], 4 were related to the haptic interface and 3 referred to the
sound interface.

(cid:129) Group 2: 22 closed questions, of which 1 was related to menus, 3 were related to the
sound interface, 4 were related to the haptic interface, 2 were related to the graphical
interface, 7 were related to ease of use, 1 was related to the Braille matrix and 4
were related to satisfaction. It also had 5 open questions associated with ease of use
and user satisfaction.

Evaluation Tool for Orientation and Mobility (O&M). After using mAbES, participants 
in both groups had to draw the museum’s environment. In Group 2, a sheet of
paper was used on synthetic foam to enable the drawing to be traced for touch
recognition.

4.3 Procedure

Evaluation of Sound Interface. In the evaluation of audio, Group 1 heard the original
audio and the audio suggested for each selected sound in mAbES. During execution,
they replied to the sound assessment questionnaire.

For respondents in Group 2, the procedure differed in completing the questionnaire,
which was conducted with the aid of the authors of this work. The Technical Note [13]
was made available in Braille for use as reference.

Usability Evaluation - Orientation and Mobility Evaluation. Participants in Group 1
and Group 2 were explained what mAbES is and the context in which it appears. The
application can be used without time restriction.
(cid:129) Group 1: after using mAbES freely, users drew the museum’s environment and

gave answers to the usability evaluation tool.

(cid:129) Group 2: they received the following task: You are on the ground ﬂoor of the
museum, near the entrance. You should go to the third ﬂoor, and explore the
Nuclear Power Station experiment. Afterwards, you should explore the Cool House
experiment. In Nuclear Power Station, you should hear the information and
respond to challenges. In Cool House, you should come in and see what’s in the
room.

124

M. de Borba Campos et al.

– Subgroup 1 used mAbES directly at the museum, without having previously
used the software. Then they answered the usability evaluation tool and made
the graphic representation of the environment they had visited.

– Subgroup 2 used mAbES and answered the usability evaluation tool and
graphically represented the environment of the museum. Only then did they visit
the Museum and later they should conﬁrm their answers and, once again, draw
their graphic representation. Users in Group 2 (Subgroup 1 and Subgroup 2)
were allowed to use headphones during the test, in which case they were to
report out loud what happened while moving about with mAbES (Fig. 5).

Fig. 5. A user who is blind interacting with mAbES

5 Results

Evaluation of Sound Interface.
(cid:129) Group 1: considering the 3 experts in HCI, only one participant chose a set of 5
original sounds instead of their suggestions. The other experts preferred the suggested 
versions. All experts in video games preferred the suggested sounds.
According to their accounts, the option suggested by the sounds was compliant with
[13], by which objects are thoroughly detailed.

(cid:129) Group 2: despite having a strong preference for suggested sound (71 %) in place of
the original sound (29 %), according to participants, compliance with the Technical
Note [13] made some sounds have excessive information.

Usability Evaluation. For data analysis, the categories ‘Strongly agree’ and ‘Partly
agree’ were grouped into ‘Agree’ and the categories ‘Strongly disagree’ and ‘Partly
disagree’ were grouped into ‘Disagree’.
(cid:129) Group 1: the instrument was organized considering the ten Usability Heuristics for
User Interface Design [14], the sound interface and the haptic interface. The result
can be seen in Table 2.

Usability Evaluation of a Mobile Navigation Application

125

Table 2. Usability evaluation – group 1

Category
Usability heuristics
- Visibility of system status
- Match between system and the real world
- User control and freedom
- Consistency and standards
- Error prevention
- Recognition rather than recall
- Flexibility and efﬁciency of use
- Aesthetics and minimalist design
- Aid in recognizing, diagnosing, and recovering from

errors

- Help and documentation
Sound interface
Haptic interface

Questions
28
3
4
3
2
2
3
3
2
3

3
3
4

Disagree

Agree
63.5 % 36.5 %
53.3 % 46.7 %
85 %
26.6 % 73.3 %
90 %
20 %
86.7 % 13.3 %
66.7 % 33.3 %
80 %
60 %

20 %
40 %

15 %

10 %
80 %

66.7 % 33.3 %
86.7 % 13.3 %
100 %

0 %

(cid:129) Group 2: out of the total of 57 questions, Subgroup 1 agreed with 88.2 % and
disagreed with 8.5 %. They were neutral about 3.3 % of the questions. With regard
to Subgroup 2, there were differences between pre-test and post-test:
– Pre-test: 80.3 % agree, 10.8 % disagree and 8.9 % neutral.
– Post-test: 82.5 % agree, 10.5 % disagree and 7 % neutral.

The answers to the open questions, along with observing mAbES use and the visit

to the museum, allowed for a few remarks:
– Rotation: the turns are made based on the hours on a clock. Thus, a 90° rotation
requires 3 clicks on the right button. This similarity should be more strongly
emphasized.

– Graphical interface:

the information should be adjustable and customizable to

enable the user to obtain more information on the Museum.

– Haptic feedback: it should be adjustable to the user’s preferences. Research has
shown that this feature was more useful during the ﬁrst interactions. After them,
users have grasped more from the sound information.

– Help system: it should be contextual to help the user depending on their current
virtual location in the museum as well as on the challenges that require responses.
– Routes: when the user leaves an expected route, the application should provide
support so that they could recognize the environment and return to the desired point.
– User position: mAbES needs a resource to indicate the user’s location in the virtual
museum space and should provide information so that they could recognize the
space around themselves.

Orientation and Mobility Evaluation.
(cid:129) Group 1: users were able to understand the Museum space from the use of mAbES

and reproduce it in different ways (Fig. 6).

126

M. de Borba Campos et al.

(a) Representation of museum space by the authors (b)(c) group 1: examples of museum

Fig. 6.
representations.

(cid:129) Group 2: the majority of participants had no experience in drawing (Fig. 7 Subgroup 
1 and Fig. 8 Subgroup 2). Participants of Subgroup 2 could reﬁne their
understanding of space when using mAbES before making the visit to the museum
(Fig. 8).

Fig. 7.

(a)(b)(c) Group 2 – subgroup 1: examples of museum representations

Fig. 8.

(a)(b) Group 2 – subgroup 2: drawings made during preand 
post-test stages

Usability Evaluation of a Mobile Navigation Application

127

Considerations for the Development of Applications to Support Navigation to
Users who are Blind. This work allowed making a few suggestions, which may be
considered when designing applications for blind users:
(cid:129) Use of audio cues to describe the images and spaces that are represented in the

application.

(cid:129) Enable control of the user to monitor sound and haptic information.
(cid:129) Add a contextual help system that can help the user recognize the space in which

they are as well as the activities that must be carried out.

(cid:129) Prevent error that can be triggered when the user performs an action not expected by

the software.

(cid:129) Prioritize sound information over detailing the graphical interface.
(cid:129) Maintain a standard throughout the actions expected by the user with regard to

interacting with the software.

6 Conclusion and Future Work

This paper deals about usability evaluation of a mobile navigation application for users
who are blind: mAbES. The evaluation of mAbES was carried out with experts in
Human-Computer Interaction and in video gaming (Group 1) and users or potential
users (Group 2). Group 1 indicated that mAbES conforms to most usability criteria
deﬁned by Nielsen [14].

Group 2 had participants who had never drawn and still been able to establish
spatial relationships between the experiments and the space they occupy in the
museum. Usage of mAbES before the visit allowed users to explore the museum more
autonomously and safely.

Groups 1 and 2 also indicated that most of the original mAbES sounds did not meet
that which is speciﬁed in the Technical Note [13]. They approved the suggested
sounds.

The results obtained regarding O&M skills in blind users who interacted with
mAbES demonstrated the positive impact of the software on such skills. Users who are
blind understand the space of the museum and interact with the environment based on
their use of the software.

This research also collaborates with the design and development of similar
applications, and it makes suggestions and precautions that should be considered for
users who are blind to better use a system based on sound, haptic and graphic
interfaces.

Acknowledgments. This work was supported by the Program STIC-AmSud-CAPES/CONICYT/
MAEE, Project KIGB-Knowing and Interacting while Gaming for the Blind, 2014. It was also
supported by the Museum of Science and Technology, of the Pontiﬁcal Catholic University of Rio
Grande do Sul, Porto Alegre, Brazil (MCT-PUCRS).

128

M. de Borba Campos et al.

References

1. Sánchez, J., Tadres, A., Pascual-Leone, A., Merabet, L. Blind children navigation through
gaming and associated brain plasticity. In: Proceedings of the Virtual Rehabilitation 2009
International Conference, pp. 29–36. IEEE, Haifa, Israel (2009)

2. Mioduser, D., Lahav, O.: Blind persons’ acquisition of spatial cognitive mapping and
orientation skills supported by virtual environment. Int. J. Disabil. Hum. Dev. 4(3), 231–238
(2005)

3. Giudice, N.A., Legge, G.E.: Blind navigation and the role of technology. In: Helal, A.,
Mokhtari, M., Abdulrazak, B. (eds.) Engineering Handbook of Smart Technology for Aging,
Disability, and Independence, pp. 479–500. John Wiley & Sons, New York (2008)

4. Hill, E., Ponder, P.: Orientación y técnicas de Movilidad, Una guía para el practicante.

Comité internacional pro-ciegos, México (1981)

5. Lahav, O., Mioduser, D.: Haptic-feedback support for cognitive mapping of unknown

spaces by people who are blind. Int. J. Hum Comput Stud. 66(1), 23–35 (2008)

6. Sánchez, J., Maureira, E.: Subway mobility assistance tools for blind users. In: Stephanidis,
C., Pieper, M. (eds.) ERCIM Ws UI4ALL 2006. LNCS, vol. 4397, pp. 386–404. Springer,
Heidelberg (2007)

7. Sánchez, J., Oyarzún, C.: Mobile audio assistance in bus transportation for the blind. Int.

J. Disabil. Hum. Dev. (IJDHD) 10(4), 365–371 (2011)

8. Connors, E.C., Yazzolino, L.A., Sánchez, J., Merabet, L.B.: Development of a audio-based
virtual gaming environment to assist with navigation skills in the blind. J. Vis. Exp. 73,
e50272 (2014). http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3641639/pdf/nihms546296.
pdf

9. Yuan, B., Folmer, E., Harris Jr., F.C.: Game accessibility: a survey. In: Yuan, B., Folmer, E.,
Harris Jr., F.C. (eds.) Universal Access in the Information Society, vol. 10(1), pp. 81–100.
Springer, Heidelberg (2011)

10. Stephanidis, C.: User interfaces for all: new perspectives into human-computer interaction.
In: Stephanidis, C. (ed.) User Interfaces for All - Concepts, Methods, and Tools, pp. 3–17.
Lawrence Erlbaum Associates, Mahwah, NJ (2001)

11. Sánchez, J., Campos, M.B., Espinoza, M.: Multimodal gaming for navigation skills in
players who are blind. In: XIII Brazilian Symposium on Human Factors in Computer
Systems. SBC (2014)

12. Petrie H., Bevan, N.: The evaluation of accessibility, usability and user experience. In: The

Universal Access Handbook, Stepanidis, C. (ed.). CRC Press (2009)

13. BRASIL. Ministério Da Educação. Nota Técnica nº 21 / 2012 / MEC / SECADI /DPEE.
Orientações para descrição de imagem na geração de material digital acessível – Mecdaisy
(2012)

14. Nielsen, J.: Usability Engineering, p. 362. Elsevier, California (1993)
15. Sánchez, J., Sáenz, M., Pascual-Leone, A., Merabet, L.: Enhancing navigation skills through
audio gaming. In: Proceedings of CHI EA 2010, pp. 3991–3996. ACM, New York, USA
(2010)

