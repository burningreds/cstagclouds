Mobile Audio Navigation Interfaces for the Blind 

Jaime Sánchez 

Department of Computer Science, University of Chile 

Blanco Encalada 2120, Santiago, Chile 

jsanchez@dcc.uchile.cl 

Abstract. In this paper we present a set of mobile, audio-based applications to 
assist with the navigation of blind users through real environments. These applications 
are used with handheld PocketPC devices and are developed for different 
contexts such as the neighborhood, bus transportation, the Metro network and the 
school.  The  interfaces  were  developed  with  the  use  of  verbalized  and  soundbased 
environments. The usability of the hardware and the software was evaluated,
 obtaining a high degree of acceptance of the sound and user control, as well 
as a high level of satisfaction and motivation expressed by the blind users.   

Keywords: blind navigation, orientation and mobility, mobile audio interfaces. 

1   Introduction 

The  problems  faced  by  blind  users  in  mobile  contexts  are  diverse  and  nondeterministic.
 This makes it difficult for such users to make decisions on what routes 
to follow, resulting in movement with very little autonomy.  

Furthermore, blind users orient themselves in space by using straight angles, which 
does not allow them to develop a full representation of the real environment. One way 
to resolve this problem is by navigating through the use of a clock system 10. A clock 
system in combination with mobile technology can be a valuable alternative to help 
with the mobility and orientation of blind users.  

Having a mental map of the space in which we travel is essential for the efficient 
development of orientation and mobility techniques. As is well known, the majority of 
the information needed for the mental representation of space is obtained through the 
visual  channel  [5,  12].  For  blind  people,  key  environmental  information  is  received 
through the spatial relations constructed by the remaining senses. Despite this limitation,
 the cognitive mapping skills of blind people are flexible enough to adapt to this 
sensory loss. Even the congenitally blind are able to manage spatial concepts and are 
competent navigators [3]. 

Some generic problems blind people have when moving about have to do with localization 
and their perception of the environment, as well as choosing and maintaining 
a correct orientation, and detecting possible obstacles [14]. Jacobson & Kitchin 4 
point out that the most important problem for the blind has to do with their incapacity 
for independent navigation and interacting with the rest of the world. Also, exploration 
 can  lead  to  disorientation,  which  is  accompanied  by  the  fear,  stress  and  panic 
associated with the feeling of being lost. There is also a risk associated with obstacles 

C. Stephanidis (Ed.): Universal Access in HCI, Part II, HCII 2009, LNCS 5615, pp. 402–411, 2009. 
© Springer-Verlag Berlin Heidelberg 2009 

 

Mobile Audio Navigation Interfaces for the Blind 

403 

that cannot be detected by the body or with mobile aids such as the cane [13]. Ran et 
al. [8] propose that the main difficulty for the blind in the context of orientation and 
mobility is knowing where they are at any given time and which way they are going, 
and that reorienting themselves is especially complicated if they get lost.  

2   Related Work  

There  are  several  ways  to  help  blind  users  achieve  autonomous  movement  with  the 
aid of mobile technology. One way is helping them with in situ assistive technologies 
in order to provide them with additional contextual information while they are moving;
 this is  known as  location technology.  Such technology uses a variety of  means 
such as RFID, IrDA, Bluetooth or WIFI, with which several solutions have been designed 
and developed to assist with the movement of blind users [2,6,7,8,15]. Some 
studies propose different modes of interaction for blind users who use mobile devices, 
which implies the implementation of entry modes that use tactile or voice commands, 
and outputs provided through verbal and/or iconic sounds [10,1].  

Loomis et al. [6] has presented a study on the use of a GPS device that can guide a 
blind  user  in  an  outdoor  environment.  The  synthesized  voice-based  system  helped 
users to be able to identify the shortest route between two points. GPS does not work 
in indoor spaces, and in such contexts it is necessary to recur to other methods. Gill 
[2]  presents  a  solution  by  using  infrared  technology  standards  (IrDa)  that  work  as  
sensors to determine the user’s indoor location.  

The  Drishti  system,  developed  by  Ran  et  al.  [8],  uses  a  combination  of  GPS  for 
outdoor  navigation  and  ultrasonic  sensors  for  indoor  navigation.  One  problem  concerning 
 GPS  is  the  error  associated  with  the  measurements  taken,  more  so  when  
associated with a cloudy climate or if there are very tall buildings in the area. For the 
indoor environment, the blind user must carry two ultrasonic sensors that receive signals 
 that  are  transmitted  from  different  points  in  the  rooms.  With  these  signals  it  is 
possible to detect the location of the users by processing and analyzing the data.  

A grid with RFID technology (Radio Frequency Identification) informs us on the 
location and proximity of a user in a certain environment [15]. Combined with Bluetooth 
technology the reading apparatus sends data to the user’s handheld device or a 
cellular phone, which analyzes the information and indicates the user’s position.  

Finally, Na [7] proposes BIGS (Blind Interactive Guide System), a grid system that 
contains a group of RFID tags that are placed on the floor of a room, and an RFID 
reader carried by the user. In addition, this system is capable of constantly monitoring 
the movements of and the route taken by the user, thanks to communication via WIFI. 

3   Methodology  

3.1   Mobile Audio Interfaces 

The  4  software  programs  presented  in  this  paper  are  oriented  towards  developing 
navigation (orientation & mobility) abilities and strategies in blind users through the 
use of a mobile PocketPC device: 1. aGPS is used to navigate a neighborhood, which 
is  a  space  that  they  travel  daily,  but  deficiently  and  not  in  all  its  magnitude.  Also, 

404 

J. Sánchez 

throughout their lives they may need to visit and navigate various unknown neighborhoods;
 2. AudioTransantiago is a mobile application that provides assistance for using 
public  transportation,  particularly  a  bus;  3.  mBN  is  mobile  software  that  helps  to 
move  through  and  use  the  Metro  network;  and  4.  MOSS  is  a  system  that  provides 
necessary  assistance  for  moving  about  without  problems  in  an  indoor  environment 
such as a school or a specific building.  
 
aGPS.  In  the  aGPS  software  the  entry  interface  consists  of  3  buttons  on  the  PocketPC.
 The first button is used to enter the starting point of a path, which could be the 
first  position  entered  when  starting  the  software,  or  a  location  entered  after  having 
changed  directions.  The  second  button  is  used  to  ask  the  system  for  information. 
When the user presses this button, the Text-to-Speech engine (TTS) replies with the 
distance to and direction of the destination (using the clock system to express the di-
rection).  The  third  button  is  used  to  change  the  destination  point.  When  the  user 
presses this button, he/she navigates a circular list 11 with different destinations read 
by the TTS.  

The output interface is made up mostly of the TTS. As previously mentioned the 
TTS responds to the user’s requests  when  he/she presses  a certain button. The only 
output provided to the user consists of the distance to and direction of the destination 
point, and the names of the destination points. The user is not provided with the routes 
to be taken. The user must decide the paths to follow in order to arrive at the destination.
 There is also a visual interface that provides information regarding the destination 
point, the distance to and the direction of the destination point at any given time. 
This interface is used to help the facilitators to be able to support blind users in their 
learning for navigation purposes.   
 
AudioTransantiago.  AudioTransantiago stores contextual information on each stop 
of the Transantiago routes, from which the user chooses in order to plan his/her trips 
in advance. In addition, this software navigates the stops of a previously planned trip 
in order to strengthen orientation and facilitate the blind user’s journey. 

AudioTransantiago uses an audio-based interface consisting of a TTS engine and 
non-verbal  sounds  that  help  to  identify  the  navigational  flow  within  the  application 
menus and through  which it  conveys information to the  user. The interface is  made 
even better by a minimalist graphic interface that includes only the name of the selection 
that is being used and the option that has been selected, including a strong color 
contrast  (yellow  letters  over  a  blue  background)  that  is  useful  for  users  with  partial 
vision, but legally blind,  who can only distinguish shapes when displayed as highly 
contrasting colors. 

Navigation  through  the  software  application’s  different  functions  is  performed 
through circular menus 11 and the use of the lower buttons on the PocketPC. The advantage 
of these menus is that they facilitate searches within the lists, which have a 
large number of different elements. The software application’s two operational functions 
 can  be  accessed  through  this  structure  (planning  a  trip  and  making  a  trip),  as 
well as their respective submenus, which are explained in the next section. 
 
mBN.  The  mBN, or  mobile  Blind Navigation, is a  navigational system for use in a 
Metro  network.  The  mBN  software  contents  are  presented  in  a  hierarchy  of  menus 

 

Mobile Audio Navigation Interfaces for the Blind 

405 

displayed on the screen and also as audio cues.  A  menu  has a  heading and a set of 
items; the number of elements in each set has to meet the cognitive usability load restriction 
 of  7  ±  2  chunks  of  information.  Menus  can  be  defined  as  circular  11  or  
normal according to the way in which they are explored. 

When  using  mBN  software,  users  have  to  execute  commands  through  the  touch 
screen  of  a  PocketPC.  The  interface  was  designed  and  developed  “with”  and  “for” 
users  with  visual  impairments.  The  interaction  is  achieved  with  the  corners  of  the 
PocketPC  screen  by  joining  adjacent  corners.  Thus  the  software  registers,  analyzes, 
and  interprets  the  movements  and  jumps  of  the  pointer.  With  this  information,  the 
software knows whether a command was executed. A blind user’s interaction with the 
touch screen is performed without the need for the pointer pen (stylus) by using touch 
to map the relief of the four corners needed to construct and execute a command. 

The information managed by mBN is represented internally by strings transmitted 
to the user via spoken audio texts and high contrast color text on the screen. A TTS 
engine performs the translation of the written information to audio speech messages. 
These  messages  are  complemented  by  earcons  for  a  higher  degree  of  attention  and 
motivation when interacting with the software. 

 

MOSS.  This  interface  is  mainly  audio-based,  in  which  information  is  provided 
through sound in two different ways. On one hand, iconic sounds (sound effects) associated 
 with  the  different  actions  that  the  user  performs  (walk,  navigate  the  menu, 
etc.) were used, which also provide contextual information (pass through a door, walk 
down  a  hall,  bump  into  a  wall,  etc.).  On  the  other  hand,  a TTS  engine  was  used  to 
provide  information  verbally  (for  the  description  of  an  element,  or  current  position, 
etc.). 

One of the  main actions that the user can perform is SoundTracing  (ST). ST follows 
the metaphor that the individual emits a ray that detects all the objects that are in 
a certain direction, even if there are solid objects in the way. To generate an ST, the 
user must make a gesture on the touch screen of the PocketPC device that represents a 
line in the direction that he/she wants the ray to go.  

3.2   Evaluation 

For each one of the mobile audio interfaces a usability evaluation was made in order 
to detect the level of acceptance for the applications and their potential for use. This 
was done to determine whether the users were able to interact with the PocketPC device 
by using the sound-based interfaces. It was expected that users would be able to 
recognize both entry and output means of interaction (buttons, screen and audio).  
 
Sample.  The  participants  in  the  usability  test  for  the  aGPS  software  consisted  of  4 
users (two boys and two girls) with ages ranging from 11 to 13 years old, and all of 
who  attended  the  Santa  Lucia  School  for  the  Blind  in  Santiago,  Chile.  They  had  a 
variety of ophthalmic diagnoses and degrees of vision.  

The sample for the evaluation of the AudioTransantiago prototype consisted of 6 
legally blind participants between the ages of 27 and 50 years old, all of  who  were 
residents of Santiago, Chile. They had a variety of ophthalmic diagnoses, 3 of them 
had partial vision and all were men.  

406 

J. Sánchez 

The sample for the usability evaluation of mBN consisted of 5 people, aged 19 to 
28 years old, from the Santa Lucia School for the Blind in Santiago, Chile. Four of 
them  had  partial  vision  and  one  was  blind.  It  is  important  to  mention  that  none  of 
these users had any previous experience interacting with PDA devices. 

The sample to evaluate MOSS consisted of five children aged 8 to 11 years old, including 
 three  girls  and  two  boys.  Two  of  them  attended  a  segregated  school  (fifth 
grade),  while the rest attended integrated  schools (3rd, 4th and 6th grade) and  were 
held to the same standards as their sighted classmates. Of all the participating users, 
only one had partial vision (non-functional). On the other hand, the users did not present 
any additional deficit other than their visual disability.  

All of users were legally blind (totally blind and partial vision). For all the usability 
evaluation sessions, two special education teachers specializing in visual disabilities 
and one usability evaluation engineer participated.  
 
Instruments. For the usability evaluation of the aGPS, an End-User Usability Questionnaire 
was used that consisted of two parts: (1) A set of 24 closed questions with a 
scale of appreciation from 1 to 5; 12 questions regarding the software and 12 on the 
hardware, and (2) A set of 7 open questions that were extracted from Sanchez’s Software 
Usability Questionnaire 9. The questionnaires were read and explained by facilitators 
and answered by users. 

The usability evaluation of AudioTransantiago was performed by means of a Software 
 Usability  Questionnaire  9  adapted  for  adult  users  in  the  context  of  this  study. 
This questionnaire includes 18 closed questions on specific aspects of the software’s 
interface,  together  with  5  more  general,  open-ended  questions  regarding  trust  in  the 
system, the way the system is used, and the perceived sense of utilizing these devices 
as a  way to  help users travel on a bus system. The results obtained can be grouped 
into four categories: (1) Satisfaction, (2) Control and Use, (3) Sound, and (4) Image. 

To evaluate the usability of the mBN software, automatic data recording was used. 
This consisted of data structured in XML format that is internally stored by the software 
during the user’s interaction, registering data on every key used, the Metro stations 
taken, and the time used to perform each action. To support the data collection 
process  for  usability  testing,  complementary  software  was  created  (AnalisisSesion). 
This  software  checks  the  data  recorded  during  mBN  sessions  (automatic  data  
recording). 

The end user usability evaluation of MOSS focused on user acceptance, with questions 
on whether the user liked the software, which things he/she would change or add 
to the software,  what  use the software  had for  him/her, and other similar questions. 
These questions  were based on Sanchez’s Software Usability Questionnaire 9. Each 
statement on the software was evaluated with a score from 1 (strongly disagree) to 10 
(strongly agree).  
 
Procedure. Each usability evaluation was completed during two 60-minute sessions. 
In each session, the users interacted with the software for 25-30 minutes in order to 
evaluate  the  effectiveness  of  their  interaction  with  the  buttons  and  the  PocketPC 
screen, control and use, and the clarity of the audio support. 

Each  session  involved  the  following  steps:  (1)  Introduction  to  the  software.  The 
functions of the software application and its use through the PocketPC buttons were 

 

Mobile Audio Navigation Interfaces for the Blind 

407 

explained to the participants. (2) Interaction with the software. The users tried out the 
software’s functions and the use of its buttons. At this point they also planned a trip as 
their final task. This trip was arbitrarily defined so as to be used in a later cognitive 
impact  evaluation.  (3)  Documentation.  Sessions  were  documented  in  detail  through 
the use of digital photographs. (4) Evaluation. The Software Usability Questionnaire 
was administered. Based on the comments and recommendations the participants provided,
 the software was modified and redesigned in order to improve its usability. 

3.3   Results 

Figure 1 shows the average scores obtained for the software and the hardware used. 
All scores are over 4.2 points, on a range that varies from 1 to 5 points. This means 
that the users’ evaluation of the software and hardware’s usability was quite satisfactory.
 These results are the same for the four dimensions of the software that were analyzed,
 in that all average scores are 4 or above, which indicates a high degree of user 
acceptance regarding each of the dimensions analyzed.  

Fig. 1. Usability results of the software aGPS 

 

The dispersion of the data is similar for both the software and hardware variables 
and the satisfaction and control & use variables. For software and hardware the standard 
deviation is between 0.348 (software) and 0.357 (hardware), with a kurtosis of 
2.980 (software); 3.210 (hardware) and skew of 1.673 (software); 1.725 (hardware), 
which means that the evaluations of the software and hardware received very similar 
opinions, with a slight deviation towards higher scores. For control & use, the standard 
deviation is slightly lower than that for satisfaction (SD = 0.479 and 0.5 points 
respectively). The case of the image dimension is distinct, in that the degree of dispersion 
is far greater than that observed in the other dimensions (SD = 0.816). A kurtosis 
of -1.289 for control & use and of -3.901 for satisfaction was obtained, with skew of  
- 0.855 for control & use and skew of -0.37 for satisfaction.  

Users  were able to construct  a correct map of the software. Their mental  models 
easily grasped the application. The usability data showed that the proposed interface 
was easy to use and easily understood by blind users. 

The  usability  questions  for  AudioTransantiago  were  evaluated  on  a  scale  ranging 
from 1 to 10 points, 10 being the highest. On average, the values obtained for all the 
items were quite satisfactory, obtaining an average of over 9 points for each item. The 
totally blind users assigned a score of 10 points for all the questions, while those users 
with partial vision assigned slightly lower scores (average of 9.02 points) (Fig. 2). As 

408 

J. Sánchez 

can be seen in table 1, users assigned high scores to all 4 dimensions. The scores are 
higher than 9.2 points for all dimensions. The most highly evaluated dimension is image,
 although this dimension was only analyzed by three users who were not total blind. 
This  dimension  also  has  the  lowest  degree  of  dispersion  among  the  answers,  with  a 
standard deviation of 0.577. The degree of dispersion increased slightly for control & 
use (SD=0.698), satisfaction (SD=0.816) and sound (SD=1.123). The control & use and 
sound dimensions obtained a kurtosis of -0.053 and – 1.646 points respectively. Satisfaction 
obtained a Kutosis of 2.774. The skews for all the dimensions were the follow-
ing: -1.732 (images); -1.276 (control & use); -1.783 (satisfaction); -1.006 (sound). This 
means that the highest degree of agreement is reached in the satisfaction dimension, and 
a comparatively lower degree of agreement is reached for control & use and sound. 

Fig. 2. Usability results of AudioTransantiago software 

 

In the case of mBN software the usability evaluation sessions provided information 
that validated the event and sound feedback, the logic of the interface, the design, and 
the programming strategy. It also favored the improvement of the design and coding 
for the following milestones. Information was gathered on the time that a user needed 
to use the functions through the proposed input interface by dragging the pointer from 
one corner to another. The average time taken by the users for the different tasks assigned 
was 0.693 seconds, with a standard deviation that reaches 172.48 points. The 
distribution of the users’ times shows a kurtosis of 2.358 and a skew of -1.225. With 
this  information,  a  2.5-second  limit  was  established  for  entering  a  command.  After 
this time, the action is timed out (Table 1).  

Table 1. Action spent time 

 

Minimum 
Average 
Maximum 
Timed Out 

Seconds 
0,325 
0,69625 

1,35 
2,5 

The device’s screen can be used as support for the audio interface in the case of users 
with partial vision and for teachers involved in the testing. The same restrictions 
were obtained as those observed for the mBN software, with functions that should be 
implemented in the logic for menus, requirements, organization, and the debugging of 

 

Mobile Audio Navigation Interfaces for the Blind 

409 

contents presented in the software, such as including a menu with the value of a ticket 
over time, and including relevant information about the station’s surroundings. 

The proposal to present information on the stations’ surroundings is related to the 
orientation  and  mobility  cues  that  blind  people  use  when  navigating  urban  environments.
 These cues are: street numbers, cardinal points regarding traffic direction, cardinal 
 points  regarding  street  curbs,  street  intersections  and  other  urban  landmarks 
(sidewalks, stairs, rails and traffic lights). 

Figure 3 displays the users’ satisfaction with the MOSS software.  This dimension 
obtained 9.5 points of a total of 10, and is followed by control & use with 9.17 points, 
and  interface  with  8.20  points.  The  standard  deviation  for  the  first  two  dimensions 
was  0.16,  reaching  0.60  for  interface.  A  kurtosis  of  0  and  a  skew  of  0  for  all  three 
dimensions  show  that  the  distribution  for  the  three  dimensions  is  symmetrical.  On 
average a score of 8.88 points was obtained, which is an extremely relevant result that 
assures the usability and acceptance of the software. Some of the most highly evaluated 
statements  were: “I like the software’s sounds (9.8 points), “I learned with this 
software” (9.6 points), and “I like the software” (9.4 points). The lowest scores were 
obtained for the statements, “The software adapts to my rhythm” (8.0 points) and “I 
felt in control of the software’s situations” (8.2 points), which reveals the existence of 
a  certain  learning  and  appropriation  curve.  In  general,  however,  a  high  degree  of  
appreciation was obtained from the end users.  

Fig. 3. Results of the end user evaluation of the MOSS software 

 

4   Conclusions 

Four prototype software applications were evaluated that seek to support the navigation 
of blind users in real environments such as a neighborhood, public bus transportation,
 the Metro network and the school or a closed building. 

The interfaces of all prototypes evaluated are adequate for use by blind users. During 
the interaction it was possible to observe that users easily learned and recognized 
the  audio  cues  and  the  functions  used  in  the  software,  as  well  as  their  meaning. 
Through the evaluation of all the  software applications  we could determine that the 
use of a PocketPC was appropriate for the end goals of this study, in that the participants 
learned to use the device  without any  major difficulties, demonstrating a high 
level of skill in using the buttons on the PocketPC. Users were highly receptive to the 
4 software applications, and were motivated by their use of the system.  

410 

J. Sánchez 

Also, the use of both the synthesized voice and the non-verbal sounds in the audio 
system were highly accepted by the users. In this case, the natural sound of the TTS 
and the clarity of the sounds in general were highlighted. 

In  particular,  the  clock  system  that  the  software  used  to  transmit  information  regarding 
directions was easily assimilated by users with visual disabilities. 

The use of all the software applications allowed for relevant navigation by the users 
because it provided specific information to guide them during their travel. Because 
the handheld apparatus was a new device for them, there were some difficulties in the 
very beginning, but users slowly began to adjust to using the device. They discovered 
solutions such as using it from their pockets with earphones in order to avoid losing 
the  auditory  references  in  their  surroundings,  and  choosing  a  safe  and  comfortable 
place in which to handle them. 

5   Discussion  

The interfaces of the software applications developed were evaluated by using a sample 
made up of participants with different ages and degrees of blindness, verifying in 
all cases that the users were able to interact with all the mobile software applications 
independently. At the same time they demonstrated that the handheld device, the interfaces 
 designed  and  the  model  of  interaction  were  all  appropriate  for  users  with 
visually disabilities. Although the samples used for this evaluation were limited, the 
different contexts of use and the various users’ backgrounds allowed us to detect several 
usability problems (real and potential), as well as to measure the level of understanding 
 the  objective  of  the  software,  embedded  representation  and  the  ways  to  
navigate and interact with it. During the interaction it was possible to observe that the 
users  quickly  learned  and  recognized  the  audio  cues  used  in  the  software  and  their 
meanings.  They  were  able  to  understand  the  model  of  interaction  and  the  metaphor 
used. As far as the use of the device, none of the users had a hard time finding and 
identifying the buttons, the joystick or the screen. Besides these significant usability 
results, the evaluation became a useful opportunity to detect problems and opportunities 
to improve the design, as well as to correct the software’s programming and modeling 
errors.     

Acknowledgements. This report was funded by the Chilean national Fund of Science 
and Technology, Fondecyt #1060797 and Project CIE-05 Program Center Education 
PBCT-Conicyt. 

References 

[1]  Dowling, J., Maeder, A., Boldes, W.: A PDA based artificial human vision simulator. In: 
Proceedings of the WDIC 2005, APRS Workshop on Digital Image Computing. Griffith 
University 2005, pp. 109–114 (2005) 

[2]  Gill, J.: An Orientation and navigation System for Blind Pedestrians (2005),  

http://isgwww.cs.uni-magdeburg.de/projects/mobic/ 
mobiruk.html (last Accessed, January 2009) 

 

Mobile Audio Navigation Interfaces for the Blind 

411 

[3]  Jacobson, R.: Navigation for the visually handicapped: Going beyond tactile cartography. 

Swansea Geographer 31, 53–59 (1994) 

[4]  Jacobson, R., Kitchin, R.: GIS and people with visual impairments or blindness: Exploring 
 the  potential  for  education, orientation,  and  navigation.  Transactions  in  Geographic 
Information Systems 2(4), 315–332 (1997) 

[5]  Lahav,  O.,  Mioduser,  D.:  Construction  of  cognitivemap0s  of  unknown  spaces  using  a 
multi-sensory virtual environment for people who are blind. Computers in Human Behavior 
24(3), 1139–1155 (2008) 

[6]  Loomis, J., Marston, J., Golledge, R., Klatzky, R.: Personal Guidance System for People 
with Visual Impairment: A Comparison of Spatial Displays for Route Guidance. Journal 
of Visual Impairment & Blindness 99, 219–232 (2005) 

[7]  Na, J.: The Blind Interactive Guide System Using RFID-Based Indoor Positioning System.
  In:  Miesenberger,  K.,  Klaus,  J.,  Zagler,  W.L.,  Karshmer,  A.I.,  et  al. (eds.)  ICCHP 
2006. LNCS, vol. 4061, pp. 1298–1305. Springer, Heidelberg (2006) 

[8]  Ran,  L.,  Helal,  A.,  Moore,  S.:  Drishti:  An  Integrated  Indoor/Outdoor  Blind  Navigation 
System and Service. In: Proceedings of the 2nd IEEE Pervasive Computing Conference, 
Orlando, Florida, March 2004, pp. 23–30 (2004) 

[9]  Sánchez,  J.:  End-user  and  facilitator  questionnaire  for  software  usability,  Usability 

Evaluation Test, University of Chile (2003) 

[10]  Sánchez, J., Aguayo, F.: Mobile Messenger for the Blind. In: Stephanidis, C., Pieper, M. 
(eds.) ERCIM Ws UI4ALL 2006. LNCS, vol. 4397, pp. 369–385. Springer, Heidelberg 
(2007) 

[11]  Sánchez, J., Maureira, E.: Subway Mobility Assistance Tools for Blind Users. In: Stephanidis,
  C., Pieper,  M.  (eds.)  ERCIM  Ws  UI4ALL  2006.  LNCS,  vol. 4397,  pp.  386–404. 
Springer, Heidelberg (2007) 

[12]  Sánchez, J., Zúñiga, M.: Evaluating the Interaction of Blind Learners with Audio-Based 

Virtual Environments. Cybersychology & Behavior 9(6), 717 (2006) 

[13]  Sasaki, H., Tateishi, T., Kuroda, T., Manabe, Y., Chihara, K.: Wearable computer for the 
blind – aiming to a pedestrian’s intelligent transport system. In: Proceedings of the 3rd International 
Conference on Disability, Virtual Reality and Associated Technologies, ICDVRAT 
2000, pp. 235–241 (2000) 

[14]  Virtanen,  A.,  Koskinen,  S.:  NOPPA:  Navigation  and  Guidance  System  for  the  Blind 
(last  

(2004),  http://virtual.vtt.fi/noppa/noppa%20eng_long.pdf 
Accessed, January 2009) 

[15]  Willis, S., Helal, S.: A Passive RFID Information Grid for Location and Proximity Sensing 
for the Blind User. University of Florida Technical Report number TR04-009 (2005), 
http://nslab.ee.ntu.edu.tw/iSpace/seminar/papers/ 
2005_percom/passive_RFID_information_grid.pdf  
(last Accessed, January 2009) 

