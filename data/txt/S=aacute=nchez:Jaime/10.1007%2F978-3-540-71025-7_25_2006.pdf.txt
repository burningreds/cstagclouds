Subway Mobility Assistance Tools for Blind Users 

Jaime Sánchez and Eduardo Maureira 

Department of Computer Science 

{jsanchez, emaureir}@dcc.uchile.cl 

University of Chile 

Abstract. In this study, we introduce software for blind users that represents a 
subway system in a desktop computer. A user can organize and prepare a travel 
with the assistance of the software before riding the subway. After a usability 
study  and  cognitive  evaluation,  we  detected  the  need  for  creating  a  mobile 
solution with similar goals as the desktop application. This software for mobile 
devices has also the capacity to help the user to solve mobility and orientation 
problems in real subway stations. In order to design a handheld version it was 
necessary to consider new features such as travel duration, tickets fare, and the 
estimated  time  duration  of  the  travel.  Conclusions  from  the  usability  study 
revealed  the  importance  of  using  interface  elements  such  as  the  audio-based 
hierarchy  menu,  the  travel  simulation,  and  the  information  about  the  subway 
network,  stations  and  their  surroundings.  The  cognitive  study  results  revealed 
important gains in the development of orientation and mobility skills to use the 
subway  system  in  blind  users,  which  help  them  to  be  more  integrated  to  the 
society. 

1   Introduction 

Biological  beings  have  the  inherent  necessity  of  autonomous  and  effective  ways  of 
mobilizing. Human beings depend on their particulars qualities to  meet  these  goals. 
Users  with  visual  disabilities  differ  in  their  capacity  of  learning  autonomy  and 
mobilizing  effectively  to  sighted  people,  mainly  because  the  latter  understand  the 
world  through  vision.  People  with  visual  disabilities  use  orientation  and  mobility 
techniques  to  learn  the  capacities  to  recognize  the  environment,  the  spatial  relation 
between  objects  and  themselves,  and  tactile,  auditory  and  olfactory  stimuli.  Once 
blind  people  acquire  the  ability  to  use  orientation  and  mobility  techniques,  they 
increase their capacity to use ways of moving efficiently.   

Through  discrimination  and  localization  of  audio  cues  the  auditory  sense  convey 
information  to  people  with  visual  disabilities,  becoming  one  of  the  most  critical 
senses to them. Along with this, the auditory sense favors the perception of points of 
reference,  the  description  of  some  physical  places,  the  development  of  abstract 
thinking, the capacity of concentration, and the creation of mental schema of diverse 
physical environments [10, 11, 13, 14, 15, 16, 17]. 

Sighted  users  tend  to  utilize  increasingly  technological  devices  in  different 
contexts.  They  can  also  interact  with  applications  without  graphical  interfaces.  For 

C. Stephanidis and M. Pieper (Eds.): ERCIM UI4ALL Ws 2006, LNCS 4397, pp. 386 – 404, 2007. 
© Springer-Verlag Berlin Heidelberg 2007 

 

Subway Mobility Assistance Tools for Blind Users 

387 

example,  telephone-based  interfaces  are  designed  to  facilitate  the  access  to  a 
telephone service such as voice-mail, electronic bank, and web sites [1, 3]. 

The navigation through real  environments by blind users  exposes them  to higher 
risks  than  sighted  users  because  the  physical  cane  cannot  help  them  to  identify  all 
objects  in  the  space.  For  this  reason,  it  is  necessary  to  provide  cues  to  users  with 
visual  disabilities  to  get  a  more  reliable  mobility,  allowing  them  to  access  to  more 
information from the environment. Providing excessive information to the user in an 
unnecessary way may have a counter effect leading to confusion [6, 7, 8]. 

Today the  use of  sound as support mean to graphical interfaces is a  fundamental 
requirement in diverse interactive tools for sighted users. Technology advancement is 
allowing better capabilities in sound representation of different environments such as 
greater and better immersion of users into virtual environments. Thus, entertainment 
and communication requirements demand the use of better sounds. Blind users need 
audio-based interfaces because they use the sense of hearing as the principal source of 
awareness  and  knowledge  construction  for  learning  purposes  [9].  Sound  conveys 
information  to  know  reference  points,  receive  place  descriptions  or  visualizations, 
develop abstraction and concentration capabilities, and create a mental schema of the 
surrounding. 

Audio-based interfaces  may include a speech or a non-speech audio. Non-speech 
audio  facilitates  the  interaction  with  information  and  the  representation  through 
different devices. This helps blind users to concentrate on navigation of the physical 
environment, being aware that the information is perceived through their ears [12]. 

In  the  case  of  supporting  mobility  in  the  subway  for  sighted  people,  Métro  is 
proposed  as  a  solution.  This  software  designed  for  handheld  devices,  considers  an 
interactive  visual  interface.  Métro  is  a  free  guide  of  subway  networks  around  the 
world  to  know  the  ways  of  making  a  travel  and  to  get  contextual  information  of 
stations to orient users in a mobile way during their travel [19].  

Users  with  visual  disabilities  have  many  mobility  problems.  One  of  them  is  the 
specific case of mobilizing through a subway network. In Santiago city, the subway is 
a  highly  used  public  transport  on  way  of  expansion,  providing  better  comfort  and 
faster  travels  than  other  types  of  public  transportation.  Then  it  is  very  important  to 
take into account these benefits for blind users. 

The ways of learning, entertaining and communicating are rapidly changing thanks 
to new wireless technologies. Currently, handheld devices functionality is not only a 
high priority, but also their access capabilities to diverse applications such as games, 
messages, and office tools, allowing users to stay connected, with greater mobility but 
at the same time, depending more on the technology. Thanks to these new devices, the 
promise “anytime, anywhere” is becoming a reality for users, to get freedom from the 
desk work, and make the interactive work more dynamic, mobile, and active [2]. 

2   Research Problem 

The  lack  of  knowledge  about  some  aspects  of  the  subway  network  is  the  principal 
difficulty for subway users. To obtain a complete knowledge of the subway network a 
person has to reach three levels of knowledge: 

388 

J. Sánchez and E. Maureira 

1. Conceptual:  To  understand  subway  network  concepts  such  as  subway  lines, 
stations and platforms. This level refers mainly to basic and general concepts of a 
subway network in any city of the world. Once the concepts are learned, the user 
continues to the next level. 

2. Knowledge:  To  comprehend  specific  information  about  a  particular  subway 
network such as the subway station name, surroundings, location, lines names that 
identify a route or path, and the type of station (transfer and local). 

3. Articulation: To utilize different knowledge and concepts learned by the user for an 
efficient  use  of  the  subway  network.  It  includes  mainly  the  planning,  estimation 
cost, and spatial orientation of the travel. 

When these three levels are accomplished, the user has also to be able to master the 
orientation  into  the  space  to  become  independent.  When  the  user  looses  spatial 
orientation, also looses autonomy. 

Users  with  or  without  visual  impairments  that  understand  and  use  the  subway 
network  as  a  transportation  vehicle  have  different  problems  with  their  level  of 
knowledge  and  spatiality.  Spatial  problems  are  easier  to  solve  for  sighted  users 
because  they  can  visually  order  and  classify  the  physical  environment  taking 
advantage  of  their  visual  memory,  thanks  to  the  use  of  visual  references  such  as 
stores, colors, and signals of a subway network. Users with visual disabilities orient 
themselves through sound interpreting the surrounding world and learning to localize 
sounds that serve as signals for orienting and mobilizing with greater autonomy. 

In the real world, sounds are not necessarily fixed; nevertheless, visual references 
are fixed. For this reason, it is necessary to have available better tools to support and 
solve orientation problems. Blind people can face a major knowledge issue because 
vision can be used as an imitation channel to learn how to use a certain tool, together 
with the affordance of related interface elements. 

3   Purpose of the Study 

The main purpose of this study was to create, improve, and evaluate the usability of 
audio-based software to stimulate and develop tempo-spatial sensory, cognitive skills, 
and specific mobility and orientation techniques in people with visual disabilities. All 
of these processes allow users safe and independent mobility favoring their autonomy 
when using different transportation systems such as the subway. 

In  this  study,  we  also  implemented  a  usability  study  during  the  design  and 
development  of  software  to  assist  the  mobilization  and  orientation  in  a  subway 
system.  In  order  to  determine  the  cognitive  impact  of  using  the  software,  learners 
practiced with cognitive tasks specially tailored for this purpose.  

4   Model 

We  designed  a  software  model  that  incorporates  diverse  functionalities  in  order  to 
evaluate  and  identify  an  appropriate  feedback,  and  to  establish  differences  when 
developing educational software for either blind or sighted people [18]. 

 

Subway Mobility Assistance Tools for Blind Users 

389 

Our  software  has  a  metaphor  that  represents  a  simulation  of  a  subway  travel 
through a wagon. Travels are implemented in a logical way because the software does 
not consider spatial representations of virtual spaces. The metaphor considers notions 
of consecutive, transfer, and terminal stations. 

In  the  particular  case  of  the  Chilean  subway  network  in  Santiago,  wagons  travel 
between two stations from one extreme to the other, through a specific line that covers 
both directions. The stations have two platforms, one on each side of the rail. In these 
platforms, passengers wait for subway wagons at specific directions. Transfer stations 
consist of different levels; each level has a specific line and each line crosses to the 
other, allowing to associate each line to a level. 

In  a  typical  software  simulation  session,  the  user  has  to  choose  previously  the 
departure and arrival stations of the  travel. In order to be aware at any  moment the 
state  of  the  game  and  to  provide  the  functionalities  to  be  implemented  in  a  virtual 
travel,  the  software  utilizes  object-oriented  programming  techniques  to  model  the 
stations, lines, network lines, and travels. The model calculates the optimal route from 
the  current  station  to  the  arrival  station  in  order  to  take  strategic  decisions  during 
simulations. 

The  application  displays  information  to  the  user  through  an  interactive  menu 
hierarchy  to  transfer  information  to  the  three  levels  of  knowledge.  This  menu  is 
presented  through  audio  and  can  be  complemented  with  contextual  help  to  interact 
with the software. 

User actions are saved in a session log  file for later analysis to evaluate learning 

when using the software. 

5   Software Description 

A  work  session  with the software consists of  two stages.  During  the first  stage, the 
user  prepares  a  travel  by  defining  the  departure  and  arrival  stations.  In  the  second 
stage, the user virtually moves through the subway network, starting at the departure 
station.  

At the beginning, the  software does a random selection of values for each of the 
three  main  variables  in  a  travel  through  the  subway  network.  These  variables  are 
subway line, travel platform (direction), and starting station (transfer or local). 

Fig. 1 shows a travel from the Pedro de Valdivia station (line 1) to Toesca station 

(line 2) of the Santiago’s subway network.   

The software was programmed in Java using the Swing library. The software code 

is divided into four main packages: 

 

1. Metro: Defines the objects that represent a subway network 
2. DomArea: Groups all classes related to XML document management 
3. Navegacion: Represents the navigation through menu hierarchies, feedback, sound 

coordination, and other functionalities of the software  
4. Sonido: Groups all methods related to the use of sound 

 
 

390 

J. Sánchez and E. Maureira 

1

L1  -  Line 

L2  -  Line 

2

Transfer stations 

L5  -  Line 

5

The way from departing to arriving stations

Represent the direct way from departing 

to arriving stations 

 

Fig. 1. A travel through the Santiago’s subway network 

The  Navegacion  package  behaves  as  an  API  that  allows  a  quick  structuring  of 
hierarchic  menus  for  audio-based  software.  Although  this  API  was  designed  and 
developed  for  this  software,  we  believe  that  the  API  logic  may  be  re-used  in  other 
audio-based software, independently of the programming language, framework, final 
user, and objectives of the software.   

The  menu  hierarchy  of  this  API  contains  a  header  and  a  group  of  items.  These 
items  can  be  linked  to  other  menus  to  create  menu  hierarchies  and  menu  networks. 
The messages associated to the header and each item of the menu, are displayed as a 
sequence of sound files.  

The logic of the sound sequence is managed by the Sonido package. This logic let a 
message  to  belong  to  either:  (1)  Always  the  same  sound  sequence,  (2)  A  sound 
sequence chosen randomly from a set of sound sequences, or (3) A sound sequence 
chosen from a play list (not randomly). 

5.1   User-Software Interaction 

The graphical objects of the interface are organized into three panels. When starting 
the  software  the  user  has  to  input  personal  information  in  the  first  panel.  This 

 

Subway Mobility Assistance Tools for Blind Users 

391 

information is  saved into the  session registry  for later analysis. Then, in the  second 
panel,  the  user  chooses  both  the  departure  and  arrival  stations.  Finally,  in  the  third 
panel,  the  user  explores  the  subway  network  and  associated  contents  in  the  three 
levels of knowledge (see Fig. 2). 

The software has a sequential and unidirectional flow. In the third panel, the user 
can choose to begin a new simulation and select the departure and arrival stations in 
the  second  panel.  The  main  graphical  objects  are  text  boxes,  combo  boxes,  and 
buttons, using the keyboard as input. The software provides audio feedback to users 
with  visual  disabilities  when  using  these  visual  components.  When  navigating  by 
using  menu  hierarchies,  at  the  third  panel,  the  user  interacts  exclusively  with  a  text 
box. This box captures keyboard events without changing the focus between different 
graphic components. 

 

(A) 

 (B) 

 

 

(C) 

 

Fig. 2. Software interfaces. (A) User. (B) Prepare the travel. (C) Travel. 

6   Cognitive Evaluation 

6.1   Participants 

The study was designed with a sample of 10 users from the rehabilitation level of the 
School  for  the  Blind  “Santa  Lucía”  in  Santiago,  Chile,  ages  ranging  from  20  to  32 
years old. This group was divided into two equal subgroups, a control subgroup, that 
did  not  interact  with  the  software,  and  an  experimental  group.  The  subgroups  were 
created in such a way that the age and the number of users with residual vision were 
balanced. 

392 

J. Sánchez and E. Maureira 

6.2   Concrete Materials  

To model the mental image that users created about the geographic distribution of the 
Santiago Subway, we worked with two types of materials: 
•  Cardboard base and LEGO© bricks. The use of this material allows users to represent 
in detail the stations of the Santiago subway network by building them with different 
bricks, which vary according to whether it is a local or a transfer station.  

•  Cardboard  base  with  stakes.  By  using  this  material,  users  represent  the 
geographical  distribution  of  the  Santiago  Subway  network  lines,  by  joining 
different stakes through rubber bands. 

6.3   Methodology 

The activities were divided into four steps: 
1. Pre-test Application. Users made a real travel route through the Santiago subway 
to  evaluate  and  register  the  actions  of  users  and  their  control  in  an  independent 
journey.  

2. Software Interaction. The experimental group got familiar and interacted with 
the software by means of interactive concrete activities to assimilate, generalize, 
and  reflect  on  their  learning.  The  control  group  was  exposed  to  the  same 
information embedded in the software but through a lecture class with a teacher 
teaching the main concepts and helping students to prepare the travels through 
the subway.  

3. Cognitive  Tasks  (see  Fig.  3).  There  were  four  cognitive  tasks  to  observe  the 
development of the following skills: To know and apply tempo-spatial concepts, to 
make an efficient use of senso-perceptive organs, and to select and apply concepts 
provided  by  the  software  for  independent  mobilization  through  the  Santiago 
subway network. 
−  Task 1: To know and apply tempo-spatial orientation and mobility concepts 
by  modeling  the  subway  network  with  concrete  materials,  according  to  the 
mental representation that each user had about the subway 

−  Task  2:  To  make  another  modeling  representation  of  the  Santiago  subway 
network  by  using  concrete  materials.  In  order  to  develop  this  task  the 
experimental group had to attain the activities of step 2 

−  Task 3: To make virtual travels. The experimental group made them by using 
the  software  and  the  control  group  performed  them  verbally.  These  travels 
had  to  be  accomplished  in  two  stages.  In  the  first  one,  there  were  three 
predefined routes to perform; in the second one, the route was defined by the 
user 

−  Task 4: To take a defined route in the real world using the subway network  
4. Post-test Application. In the same way as in the pre-test, users made a real travel 
route  in  the  Santiago  subway  to  evaluate  and  register  the  actions  of  learners  and 
control in an independent journey. 

 

Subway Mobility Assistance Tools for Blind Users 

393 

Fig. 3. Users solving cognitive tasks 

 

6.4   Instruments 
•  Pre-test and post-test, the Specific Route Displacement Test, SRD, was used. A 
particular  route  was  elaborated  to  test  the  participants.  We  evaluated  their 
performance  in  a  given  subway  route  using  appreciation  scales  consisting  in  a 
group of statements describing actions and skills used. In order to elaborate both 
the  route  and  the  evaluation  scale,  we  considered:  1.  The  user  orientation  and 
mobility skills, 2. The same route for everyone, 3. Departure time, 4. Number of 
transfers,  5.  Number  of  stations,  6.Visual  degree,  and  7.  Knowledge  of  real 
displacements through the Santiago subway. 

•  Cognitive  task  evaluation  test,  for  each  cognitive  task  an  evaluation  test  was 
created  to  observe  and  register  orientation  and  mobility  skills  to  be  developed, 
stimulated or enhanced through the activities. This test consisted in statements that 
evaluate mobility and orientation skills involved in the tasks. 

•  Record graphs, the software record graphed actions performed by learners during 

their interaction. 

6.5   Procedure 

Cognitive  testing  was  carried  out  during  four  months.  As  the  stages  of  the  applied 
methodology were attained, and depending on the group to which each user belonged, 
cognitive  testing  was  carried  out  in  different  places.  Pre-tests  and  post-tests  were 
applied on site. Users from the experimental group interacted with the software in a 
computer room whereas the users from the control group attended classes in a lecturetype 
 classroom.  Both  groups  performed  cognitive  tasks  with  concrete  materials.  In 
order to avoid distortions in the results of the cognitive testing, only the experimental 
group  interacted  with  the  software  and  all  users  utilized  the  same  version  of  the 
software. 

394 

J. Sánchez and E. Maureira 

6.6   Results 

These  results  analyzed  correspond  to  the  experimental  subgroup,  which  obtained  a 
better performance than the control subgroup. 

Results  are  divided  in  three  areas:  behaviors,  skills,  and  competences.  Behaviors 
refer to the specific handling of techniques with the white cane, which correspond to 
the orientation and mobility program applied to environments of medium complexity. 
Skills  include  aspects  needed  to  perform  an  independent  movement.  Finally, 
competences describe the level of development of a user in each described skill.  

The results show that the highest gain took place in the competence domain (20% 
out  of  the  total),  followed  by  the  skills  domain  (16%),  and  the  behaviors  domain 
(6%).  Nevertheless,  all  areas  obtained  gains  after  using  the  software  and  cognitive 
tasks.  

From  this  study,  some  questions  emerged  about  the  impact  that  a  mobile-device 
application  would  have  on  mobility  and  orientation  in  a  subway  system.  For  this 
reason,  we later developed mBN (Mobile Blind Navigation), a pocketPC version of 
our  former  software.  We  believed  that  this  mobile  software  should  not  be  just  a 
portable version of the former software. We should also redefine and study both the 
interface  and  the  information  displayed.  We  had  to  define  the  functionality  to  be 
exploited in the mobile version and the cognitive impact. Although this new software 
aims to the same users, it is subtly different since it is oriented to a different context 
of use, and thus complementing the desktop version. The primary goal of the mobile 
version  was  to  help  to  solve  unexpected  problems  and  issues  during  mobilization 
through the subway that cannot be anticipated in the desktop version.  

7   Software Description of mBN 

Our  software  was  also  developed  for  a  pocketPC  device.  We  used  Microsoft 
Windows  Mobile  2003  operating  system  compatible  framework.  mBN  software 
contents are presented in a hierarchy of menus displayed into the screen and also as 
audio cues. A menu has a heading and a set of items, the number of elements in each 
set  has  to  meet  the  usability  cognitive  restriction  of  7  ±  2  elements.  Menus  can  be 
defined as circular or normal according to the way to explore them. 

Navigating  through  the  menu  of  the  software  creates  the  need  to  offer  the 
following command set: Next, a command to go forward in the item of the menu list; 
Back, a command to go backwards in the menu; Enter, a connected item to enter to a 
submenu;  Quit,  to  return  to  a  container  from  its  submenu;  Know  Current  Item,  to 
provide to the user and the program, the option to recognize and capture the name of 
the item available at a certain time; Know Title, to recognize and capture the name of 
a current menu title.  

When  a  menu  is  not  circular,  the  software  provides  audio  interfaces  with 
information  about  starting  and  finishing  the  menu.  When  identifying  a  menu  that 
contains  submenus,  the  software  has  to  provide  feedback  to  the  user  to  interact 
naturally with the displayed menu structure.  

When  using  mBN  software  users  have  to  execute  commands  through  the  touch 
screen  of  a  pocketPC.  The  interface  was  designed  and  developed  “with”  and  “for” 

 

Subway Mobility Assistance Tools for Blind Users 

395 

users  with  visual  impairments.  The  interaction  is  achieved  using  the  corners  of  the 
pocketPC  screen  by  joining  the  adjacent  corners.  Thus,  the  software  registers, 
analyzes,  and  interprets  the  movements  and  jumps  of  the  pointer.  With  this 
information,  the  software  knows  whether  a  command  was  executed.  Blind  user’s 
interaction  with  the  touch  screen  is  performed  without  needing  the  pointer  pen  by 
using the tact to map the relief of the four corners needed to construct and execute a 
command.  

The  input  interface  allows  the  user  to  execute  eight  different  commands  by 
displacing  the  pointer  to  adjacent  corners.  When  the  user  needs  to  select  a  specific 
command, the software presents the user three specific feedback sounds. The first one 
identifies  the  initial  selected  corner; the  second one identifies the corner to the left; 
and the last sound refers to the command represented by the second corner sequence.  
In order to select a command, the user has a fixed time. If the time ends, the software 
reproduces a fourth sound. The names of corners are related to the names of the six 
dots used in the Braille code (see Fig. 4). 

 

 

Fig. 4. mBN corner’s names 

The commands for the input interface are next, last, mute, repeat, quit, enter, title 
and  help.  The  combination  of  corners  to  follow  in  order  to  achieve  the  desired 
command is shown in Fig. 5. 

The information managed by mBN is represented internally by strings transmitted 
to the user via spoken audio texts and high contrast color text on the screen. A Text-
to-Speech  engine  does  the  translation  of  the  written  information  to  speech  audio 
messages (TTS). These messages are complemented by earcons for a better attention 
and motivation when interacting with the software. 

The  information  about  the  subway  network  is  stored  in  XML  files  (eXtensible 
Markup  Language).  Thus,  it  is  possible  to  add  stations  and  lines  to  the  system. 
Desktop  software  was  created  in  order  to  update  mBN  by  adding,  editing,  and 
deleting the information about the context of each station.  

 
 

396 

J. Sánchez and E. Maureira 

Command 

Initial 
Corner 

Final 
Corner 

Next 

Last 

Mute 

Repeat 

Quit 

Enter 

Title 

Help 

4 

6 

6 

3 

3 

1 

1 

4 

6 

4 

3 

6 

1 

3 

4 

1 

Side/Direction 

Right/Vertical 

Right/Vertical  

Down/Horizontal  

Down/Horizontal 

Left/Vertical 

Left/Vertical 

Up/Horizontal  

Up/Horizontal  

Fig. 5. Commands and sequences of mBN 

7.1   Menus Map 

The main menu has four items: Travel, ticket fee, subway network, and quit.  
1. Travel: The user must choose both departure and arrival stations. Once the stations 
are chosen, the user enters into a new schema of menus where a real travel around 
the subway network is simulated.  

2. Ticket  Fee:  This  menu  displays  the  current  time,  schedule,  and  the  ticket  fee 

depending on the time of purchasing. 

3. The subway network: This menu has three submenus with lines, terminal stations, 

and transfer stations. 

8   Usability Evaluation of mBN 

8.1   Participants 

The sample for the usability evaluation of mBN consisted in 5 people, aged 19 to 28 
years old, from the Blind School “Santa Lucía” in Santiago, Chile. Four of them had 
residual vision and one was blind. It is important to mention that these users did not 
have experience interacting with PDA devices. 

8.2   Methodology 

The development of mBN software was planned around three goals. For each one, it 
was necessary to  have completely validated the preceding  objective before going to 
the  next  one.  The  validation  of  each  of  them  was  implemented  with  a  series  of 
specific usability tests. The objectives were the following: 
1. Input  Interface.  This  evaluates  the  interaction  of  the  user  with  the  software,  so 

that the software favors actions to be expressed on it. 

 

Subway Mobility Assistance Tools for Blind Users 

397 

2. Hierarchy of menus  based  on Audio. The idea is to achieve a prototype  where 
the user, based on commands learned in the Input Interface, can navigate through a 
familiar concept map of contents.  

3. mBN. This is a hierarchy of  menus based on audio including contents that  mBN 

has to transfer to the user. 
The first two goals were evaluated in a laboratory and the last goal was evaluated 
in a real setting by using the subway as a transportation vehicle. In laboratory testing, 
users interacted  with a tutorial to introduce them to the software and hardware, and 
performed a guide of activities with the prototype. 

The field-testing consisted in analyzing and applying the functions provided by the 
tool  in  a  real  setting.  During  the  field-testing  users  were  provided  with  extra 
earphones to interact with the pocketPC. 

8.3   Instruments 

1. End-user questionnaire, consisted in two sections: 1. A set of 29 closed questions 
with a 1 to 5 scale, and 2. A set of five open-ended questions taken from a usability 
questionnaire  by  Sánchez  [13,  14].  Questionnaires  were  read  and  explained  by 
facilitators to users, and then answered by them. 

2. Anecdotic  record,  consisted  in  recording  the  information  captured  through 

observation while the user was interacting with the software. 

3. Automatic  record,  consisted  in  data  structured  in  XML  format  that  is  internally 
stored by the software while the user interacts with it, registering every used key, 
the stations taken, and the time used to perform every action. 
To  support  the  process  of  gathering  data  in  the  usability  testing,  complementary 
software  was  created  (AnalisisSesion).  This  software  checks  the  session  recorded 
during sessions of mBN (automatic record) to calculate statistical values. 

8.4   Procedure 

Laboratory  testing  was  implemented  during  5  sessions  in  two  months.  Field-testing 
was done during 4 sessions in one month. Different interface features were evaluated 
during sessions of laboratory testing (see Fig. 6). 

Laboratory Test ID 

PL1 
PL2 
PL3 
PL4 
PL5 

Prototype 

Input Interface 
Input Interface 
Menu Hierarchy 

mBN 
mBN 

Fig. 6. Prototype testing in each session 

The objective of sessions PL1 and PL2 was to determine the understandability of 
the  input  interface.  There  was  a  dictation  of  each  command  with  the  objective  of 
determining  the  following  aspects:  The  ability  of  the  user  to  identify  corners,  the 

398 

J. Sánchez and E. Maureira 

ability  of  the  user  to  memorize  the  eight  commands  and  their  associated  lines,  the 
timeline required to execute a command, and the border space for a good functioning 
of the interface. 

In session PL3, input interface commands were associated to real actions. A simple 
prototype was designed including a set of connected menus with familiar information 
to  users,  measuring  the  affordance  of  commands  in  the  context  of  a  hierarchy  of 
menus.  Sessions  PL4  and  PL5  consisted  in  having  a  more  advanced  prototype 
embedded  with  all  contents  for  end-users  of  mBN.  The  work  done  during  testing 
corresponded to guided activities with the prototype. 

8.5   Results 

The first sessions (PL1 and PL2) provided information that validated the events and 
sound feedback, the logic of the interface, the design, and the programming strategy. 
It  also  favored  the  improvement  of  the  design  and  coding  for  the  following 
milestones.  It  reflected  the  mapping  of  commands  and  the  associated  lines  for 
execution. From PL3 session, information was gathered about the time spent by one 
user when utilizing functionalities through the proposed input interface, by dragging 
the pointer from one corner to another. 

In  the  testing  of  the  menu  hierarchy  there  was  a  need  for  implementing  circular 
menus  due  to  their  size.  The  screen  of  the  device  could  be  used  as  support  for  the 
audio interface in the case of users with residual vision and teachers involved in the 
testing.  As  a  result,  we  got  the  same  restrictions  for  mBN  software,  functions  that 
should be implemented in the logic of the menus, requirements, organization, and the 
debugging of contents presented in the software, such as including a menu with the 
value  of  a  ticket  in  accordance  with  the  time,  and  including  relevant  information 
about the surroundings of the station. 

9   Cognitive Testing of mBN 

9.1   Participants 

In order to implement the cognitive testing we selected a sample of six users from the 
School for the Blind “Santa Lucía” of Santiago, Chile, ages 19 to 28. Four people in 
the sample had residual vision and two of them had total blindness. 

9.2   Methodology 

Four cognitive tasks to evaluate the interaction with the software were developed. All 
of  them  pursued  the  use  of  tempo-spatial,  cognitive,  psychomotor,  and  specific 
orientation  and  mobility  skills  to  allow  people  with  visual  disabilities  secure  and 
independent  displacements  through  different  places  of  interest,  improving  their 
autonomy  when  riding  the  subway  transportation  and  mobilizing  through  its 
surrounding area. In the first task, we used scaled representations of the city. For the 
rest of the tasks, we used mBN software: 
a.  Task 1, Let’s get to know the city through the Metro: The goal was to mentally 
represent the surroundings of the subway network, stimulating senso-perceptive 

 

Subway Mobility Assistance Tools for Blind Users 

399 

organs, exercising the analysis of the information given and recognizing the four 
cardinal points along with associating them to reference points. 

b.  Task  2,  Let’s  travel  to  a  known  place:  The  objective  was  to  support  secure 
autonomous movement towards a point of interest close to the subway network, 
to use the information given by mBN, in order to arrive at the destination place 
and select relevant information. 

c.  Task  3,  I  want  to  know  new  places:  The  idea  behind  it  was  to  analyze  the 
information  given,  in  order  to,  afterwards,  select  what  is  relevant,  apply  the 
contents  embedded  in  the  software,  and  discriminate  the  information  for  an 
efficient path. 

d.  Task  4,  What  do  I  do  if  I  have  a  problem?:  The  objective  was  to  use  tempospatial 
references given by the software, achieve autonomy and efficiency when 
mobilizing through the subway network in Santiago to arrive at a point of interest 
to and react positively towards unexpected problems. 

Two special education teachers with experience with people with visual disabilities 
participated in the cognitive testing along with users. There were three stages in the 
implementation of the cognitive study: 
1. The application of a pre-test to evaluate skills, competences, and initial behaviors. 
2. The implementation of cognitive tasks. 
3. A post-test to evaluate skills, competences, and behaviors at the end of the study to 
contrast  them  with  initial  results  in  order  to  determine  the  impact  of  the  use  of 
mBN on users. 

9.3   Instruments 

Three evaluation tests were applied during the process: 
1.  Pre-test  and  post-testing  including  43  statements  to  be  answered  by  end-users  and 
special education teachers. The section for end-users was completed with statements 
related to behaviors in the subway and when using mBN. The section for the teacher 
consisted of three domains: skills, competences, and social and personal aspects. 

2. A  test  for  the  first  cognitive  task,  consisting  in  25  statements  divided  in 
psychomotor,  cognitive  and  social/affective  areas.  The  motor  area  was  related  to 
the manipulation of the concrete materials used. The cognitive area was related to 
the  use  of  concrete  material  (recognition  of  lines,  main  streets,  transfer  stations, 
etc.). Finally, the social/affective area was related to behaviors and attitudes during 
the implementation of the activity. 

3. Tests for cognitive tasks 2, 3, and 4. The statements included behaviors observed in 
the subway and the use of mBN software. These statements considered behaviors, 
skills, and social and personal competences. 

9.4   Procedure 

Depending  on  the  type  of  activity,  two  places  were  used  for  cognitive  testing.  The 
first one was the computer laboratory where we developed cognitive task 1 and users 
interacted with the software for the rest of the activities. The second place used was 
the real subway network along with the surrounding area of one station. The testing 
was developed during two months with two-hour sessions per week. 

400 

J. Sánchez and E. Maureira 

9.5   Results 

One of the variables evaluated was the behavior of users in the subway, meaning the 
handling  with  different  elements  such  as  the  ticket  offices  and  turnstiles.  We  have 
observed that there was a significant gain between pre-test and post-test results in the 
evaluation of the interaction with these elements, with a gain of six points in average 
over a total of 30 points (see Fig. 7). Users also evaluated themselves in the control of 
activities and their behavior when using different areas of the subway. 

Fig. 7. Pre-test/post-test user’s behavior in the subway network 

 

 

Fig. 8. Pre-test/post-test skills 

 

 

Subway Mobility Assistance Tools for Blind Users 

401 

Users achieved independent mobilization. There also was an improvement in areas 
such  as  processing  of  sensory-perceptual 
their 
surroundings, classification of auditory information, and obtaining information from 
mBN software embedded in the pocketPC (see Fig. 8). 

information,  observation  of 

In relation to competences, users showed considerable improvements in areas such 
as spatial orientation, time orientation, verbal interaction, autonomy, choose a route, 
and  achievement  of  a  travel  through  a  planned  route.  At  a  smaller  scale,  there  was 
also improvement in problem solving (see Fig. 9). 

Fig. 9. Pre-test/post-test competences 

 

In social and personal aspects, there  was a consensus in the increase in trust and 
security  of  users  when  facing  the  subway  network,  evidencing  gains  when  using 
mBN. When a user dominated a function, the security and trust also increased when 
facing  this  type  of  transportation.  Additional  information  provided  by  the  software 
related to the ticket cost and estimated time of the travel was very useful because they 
did not manage these terms correctly. 

10   Discussion 

At  a  conceptual  level,  the  glossary  embedded  in  the  software  allowed  users  to 
familiarize with basic concepts about the subway as a transportation source. The most 
important  concepts  such  as  transfer  stations,  platforms,  end  stations,  consecutive 
stations,  and  lines,  were  reinforced  by  the  affordance  created  by  interacting  with 
travel simulations. 

The desktop application was more useful for blind users in a pre-cane stage. At the 
beginning, users did not have the autonomy to move throughout the subway network. 
However, after they interacted with the application they were able to understand the 
subway  network  as  a  transportation  source  in  the  three  levels  of  knowledge 

402 

J. Sánchez and E. Maureira 

implemented without the need of a guide. Teachers also valued the application as an 
aid to apply, reinforce, and complement their lessons.  

The  variation  in  the  mastering  of  behaviors  by  the  user  obtained  the  lower 
indicators because learners  needed to understand certain prerequisites related to this 
type  of  transportation  and  know  how  to  apply  them.  Among  these  concepts,  there 
were  behaviors  such  as  using  the  stairs  to  have  access  to  the  stations,  the  ability  to 
move  inside  the  stations,  identify  ticket  offices,  turnstiles,  platforms,  recognition  of 
textures, and staying  in a safe place  when  getting in and  out of the  subway  wagon. 
These  behaviors  did  not  vary  significantly  because  they  are  pre-requisites  for 
independent movements. However, there was an improvement in the learning of the 
names of the stations, their sequence, and their relation to a corresponding line. 

The  execution  of  some  actions  needed  certain  skills  such  as  spatial  orientation, 
observation  of  the  surroundings,  and  classification  of  auditory  information.  These 
aspects increased significantly after using the software and performing the cognitive 
tasks. Users were able to construct a mental idea of the spatial distribution closer to 
reality and were able to mobilize in a secure and autonomous way. 

The  most  relevant  results  were  observed  in  the  domain  of  competences  of  users, 
explained by the use of information given by the software and its immediate transfer 
to  reality,  favoring  gains  in  sensorial-perception  information  processing,  problem 
solving without the need of a sighted guide, and a much more independent movement 
in and out of the subway network. This, undoubtedly, represents a contribution to the 
development of blind users and one-step towards real social integration. 

mBN  software  helped  users  to  travel  through  the  subway  network  and  access  to 
nearby places and streets. However, we need to find out more information about the 
mobilization inside the stations, because it is difficult to identify exits, line changes, 
access,  and  the  like.  In  this  sense,  the  help  provided  by  the  software  should  be 
improved  by  using  our  data.  In  spite  of  this,  there  were  improvements  in  the 
independent  mobilization  of  users  and  their  orientation  skills,  providing  them  more 
security when using the subway.  

The  use  of  mBN  allows  the  displacement  of  users  because  it  provides  specific 
information to guide them during their travel. Because it is a new device, there were 
some dificulties at the very beginning, but users slowly began to adjust ways of using 
it.  They  found  solutions  such  as  using  it  from  their  pockets,  using  an  earphone  in 
order to avoid losing the auditory reference in their surroundings, and choosing a safe 
and comfortable place to handle them. 

The testing  showed  satisfactory results  when  using different elements around the 
subway transportation, and thus assuring a better performance of end-users in a given 
station, and in the use of turnstiles, platforms, wagons, and ticket offices. 

Finally,  it  was  very  relevant  that  users  achieved  independence  and  autonomy  in 
management and displacement throughout the subway  network. This evidenced that 
the  software  displayed  in  a  mobile  device,  as  the  pocketPC,  provided  them  certain 
keys  and  helped  to  improve  independent  ways  of  moving  in  the  subway  network, 
emerging new ideas such as the possibility to extend this tool to other transportation 
systems. 

 

 

Subway Mobility Assistance Tools for Blind Users 

403 

Acknowledgments. This report was funded by the Chilean National Fund of Science 
and Technology, Fondecyt, Project 1030158.  

References 

1.  Brewster,  S.,  Raty,  V.,  Kortekangas,  A.:  Using  Earcons  to  Provide  Navigation  Cues  in 

Telephone-Based Interfaces, ACM Interactions, 1996, pp 9-10. 

2.  Brewster, S., Capriotti, A., Hall, C.: Using Compound Earcons to Represent Hierarchies, 

Publishing in BCS HCI’97 Conference Companion HCI Letters, 1997, pp 19-22. 

3.  Brewster, S.: Using Earcons to Provide Navigation Cues in Telephone-Based Interfaces, 

ACM Interactions 6, 1999, pp 9-10. 

4.  Dowling,  J.,  Boles,  W.:  Mobility  assessment  using  simulated  Artificial  Human  Vision. 
2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 
CVPR'05 - Workshops p.32 

5.  Gaudissart, V., Ferreira, S., Mancas-Thillou, C., Gosselin, B.: Sypole: a Mobile Assistant 
for  the  Blind,  Proceedings  of  European  Signal  Processing  Conference,  EUSIPCO  2005, 
Antalya (Turkey). 

6.  Koruda, T., Sasaki, H., Tateishi, T., Maeda, K., Yasumuro, Y., Manabe, Y. & Chihara, K.: 
Walking aids based on wearable/ubiquitous computing – aiming at pedestrian’s intelligent 
transport  systems.  Proceedings  of  the  IV  International  Conference  Disability,  Virtual 
Reality  &  Associated  Technologies,  2002  ICDVRAT  2002.  Veszprém,  Hungary,  pp  
117-122. 

7.  Lahav, O., Mioduser, D.: Multisensory virtual environment for supporting blind persons’ 
acquisition of spatial cognitive mapping, orientation, and mobility skills. In Proceedings of 
the  4th  International  Conference  on  Disability,  Virtual  Reality  and  Associated 
Technologies, ICDVRAT 2002,  Veszprém, Hungary, 2002. pp. 213-220. 

8.  Lahav,  O.,  Mioduser,  D.:  Blind  Persons’  Acquisition  of  Spatial  Cognitive  Mapping  and 
Orientation  Skills  Supported  by  Virtual  Environment.  In  Proceedings  of  the  5th 
International  Conference  on  Disability,  Virtual  Reality  and  Associated  Technologies, 
ICDVRAT 2004,  Oxford, UK, 2004. pp. 131-138. 

9.  Mereu,  S.,  Kazman,  R.:  Audio  enhanced  3D    interfaces  for  visually  impaired  users.  In 

Proceedings of CHI’96, ACM Press. 

10.  Sánchez,  J.:  Interactive  Environments  for  Blind  Children:  Computing,  Usability,  and 
Cognition.  Proceedings of the International Conference on New Technologies in Science 
Education (I), Aveiro, Portugal, 4-6 July, 2001. pp. 17-27. 

11.  Sánchez, J., Zuñiga, M.: Evaluating the Interaction of Blind Learners  with Audio-Based 
Virtual  Environments.  11th  Annual  CyberTherapy  2006  Conference:  Virtual  Healing: 
Designing Reality. June 13 - 15, 2006 . Gatineau, Canada, pp. 66 

12.  Sánchez,  J.:  Blind  Children  Centered  Technology.  Human  Centered  Technology 

Workshop 2006. Pori , Finland , June 11-13, 2006, pp. 104-112 

13.  Sánchez,  J.,  Sáenz,  M.:  3D  Sound  Interactive  Environments  for  Problem  Solving. 
Proceedings of The Seventh International ACM SIGACCESS Conference on Computers 
and Accessibility, Assets 2005, Baltimore, Maryland, USA, October 9-12, pp. 173-178 

14.  Sánchez,  J.,  Sáenz,  M.:  Sound  Immersed  Virtual  Environments  for  Blind  Children. 
Proceedings of The Fourth International Workshop on Virtual Rehabilitation IWVR ’05. 
Catalina Island, California, USA. September 19-21, 2005, pp. 192-202 

404 

J. Sánchez and E. Maureira 

15.  Sánchez, J., Flores, H.: Training Blind Children to Develop Mathematics Skills Through 
Audio.  Proceedings  of  the  Cybertherapy  2005,  Basel,  Switzerland,  June  6-10,  2005,  pp. 
123-124 

16.  Sánchez,  J.,  Sáenz,  M.:  Developing  Mathematics  Skills  through  Audio  Interfaces. 
Proceedings  of  11  th  International  Conference  on  Human-Computer  Interaction,  HCI 
2005. Las Vegas , Nevada , USA , July 22-27, 2005 . 

17.  Sánchez,  J.,  Sáenz,  M.:  Three-Dimensional  Virtual  Environments  for  Blind  Children. 

CyberPsychology and Behavior, CP&B, Apr 2006, Vol. 9, No. 2, pp. 200-206. 

18.  Sánchez, J., Baloian, N., Flores H.: A methodology for developing audio-based interactive 
environments for learners with visual disabilities. Proceedings of the World Conference on 
Educational Multimedia, Hypermedia & Telecommunications ED-MEDIA 2004, Lugano, 
Switzerland , (June 21-26, 2004), pp. 124 

19.  Van Caenegem, F., Bernard, P.: Métro, The ultimate public transport guide for your PDA 

or Smartphone. http://nanika.net/Metro 

 
 

