Journal of Universal Computer Science, vol. 19, no. 18 (2013), 2677-2697
submitted: 4/3/13, accepted: 30/10/13, appeared: 1/12/13 © J.UCS

Development of Navigation Skills through Audio Haptic 

Videogaming in Learners who are Blind 

(Department of Computer Science and Center for Advanced Research in Education (CARE) 

Jaime Sánchez  

University of Chile, Santiago, Chile 

jsanchez@dcc.uchile.cl) 

Marcia de Borba Campos 

Porto Alegre, Brazil 

marcia.campos@pucrs.br) 

 
 

 

 
 
 

(Faculty of Informatics, Pontifical Catholic University of Rio Grande do Sul – PUCRS 

Abstract:  This  study  presents  the  development  of  a  video  game  with  audio  and  haptic 
interfaces that allows for the stimulation of orientation and mobility skills in people who are 
blind through the use of virtual environments. We evaluate the usability and the impact of the 
use of an audio and haptic-based videogame on the development of orientation and mobility 
skills  in  school-age  learners  who  are  blind.  The  results  show  that  the  interfaces  used  in  the 
videogame are usable and appropriately designed, and that the haptic interface is as effective as 
the audio interface for orientation and mobility purposes. 
 
Keywords: haptic and audio interfaces, orientation, mobility, people who are blind 
Categories: H.3.1, H.3.2, H.3.3, H.3.7, H.5.1 

1 

Introduction  

For people who are blind, navigation through unfamiliar spaces can be a complex task 
compared  to  a  sighted  person.  In  order  to  achieve  orientation  &  mobility  (O&M) 
[Sánchez, 10], people who are blind need to use other resources to receive feedback 
from the environment, such as sounds or textures. 

Blindness is  not synonymous  with difficulty in  navigation. As the collection of 
environmental  information  in  the  blind  is  based  on  different  sensory  channels  than 
sight,  the  integration  of  this  information  is  different  when  creating  mental 
representations  of  the  environment.  For  example,  learning  the  environment  through 
touch means having to rely on sequential observations and building a mental image 
from  its  components  and  not  from  the  whole.  In  general,  people  with  visual 
disabilities,  properly  trained,  are  able  to  navigate  and  have  a  representation  of  the 
environment. In the case of blind children, whose learning process of O&M skills is 
in development, it may be difficult to process spatial information if they have not had 
enough experience to determine their own position and relationship to objects using 
the rest of their senses. 

Various virtual environments have been designed in order to train people who are 
blind, and to assist them with the development of O&M skills [Lahav, 08][Lumbreras, 
99][Sánchez, 09b]. To navigate through an environment it is necessary to have access 

 

2678

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

to the information that can be recovered from the environment, in order to then filter 
out  useful  information  in  a  way  that  is  coherent  and  comprehensible  for  whoever 
needs it. It is for this reason that in the case of people who are blind, the use of virtual 
environments  and  appropriate  interfaces  allows  them  to  improve  their  O&M  skills 
[Sánchez, 09a]. This kind of interfaces can be, for example, haptics or audio based. 
Such resources can also be used for recreational purposes. 

Overall  blind  children  learn  their  environment  using  their  own  perception  and 
experience. A factor in this learning is the motivation to interact with the environment 
and explore their physical properties [Warren, 94]. From small suggested receive O & 
M  training  to  develop  skills  that  enable  them  to  travel  safely  and  efficiently.  Since 
they are small it is suggested that they receive O&M training to develop skills that 
enable them to travel safely and efficiently. 

Due to the impossibility of obtaining information through sight, people who are 
blind must employ other senses, such as touch, in order to be able to perceive their 
surroundings [Lutz, 06]. In this way, it has been possible to establish two categories 
of perceptions used by people who are blind [Ballesteros, 93]: (i) Tactile Perception, 
which  is  information  perceived  exclusively  by  the  skin,  and  (ii)  Kinesthetic 
Perception, which is information provided by muscles and tendons. The combination 
of both concepts, in order to benefit a person who is blind regarding the acquisition of 
information, is called haptic perception [Ballesteros, 93] [Oakley, 00].  

[Jütte,  08]  discusses  the  use  of  haptic  perception  in  health-related  applications, 
citing for example the development of prosthesis for patients with spinal cord injuries, 
which can result in an extended reach of the human hand. In the case of people who 
are blind it is possible to simulate, through a virtual environment, a return to what was 
originally  based  on  visual  channels,  providing  a  perception  of  space  as  the  user 
interacts with the application.    

Unlike  the  sense  of  sight,  the  functionality  of  haptic  perception  lays  in  the 
codification  of  the  various  properties  of  elements,  objects  and  substances  such  as 
hardness,  texture,  temperature  and  weight.  Such  properties  are  difficult  to  quantify 
through the sense of sight [Travieso, 07].  

Haptic interfaces have been provided through the use of devices that are capable 
of creating feedback through interaction with muscles and tendons [Lahav, 08]. This 
provides  for  the  feeling  of  applying  force  over  a  certain  object  [Lahav,  08].  More 
recently,  research  on  haptic  interfaces  has  become  increasingly  relevant,  and  in 
particular  the  use  of  the  Novint  Falcon  device  with  videogames  for  training  and 
rehabilitation has enjoyed growing attention [Reuters, 09]. This device is reasonably 
useful  for representing virtual environments, and provides force feedback in such a 
way that when it is used the user can feel the volume and force of a virtual object in 
his hand [Sánchez, 09b]. 

Several studies [GauBert, 11][GauBert, 12][Heller, 01][Norman, 04] have sought 
to  compare  vision  with  haptic  perception,  showing  that  for  the  perception  of 
properties that are visible, such as a bumpy texture or porosity, haptic perception is 
able to match or even overcome visual perception in terms of specificity [Travieso, 
07][Hu, 06], and match it in the spatial perception of objects [Rosa, 93]. From this it 
can be gathered that the use of haptic perception is feasible as an alternative form of 
providing contextual information on volumes and objects [Sarmiento, 03]. 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2679

There are several studies that include the use of haptic perception by people who 
are  blind  in  various  contexts  [De  Felice,  05][Homa,  09]  [Huang,  09]  [Murphy,  07] 
[Yu,  00][Yu,  03].  In  the  context  of  O&M,  one  study  is  that  of  [Lahav,  02],  who 
presents  and  evaluates  an  application  that  allows  for  the  construction  of  a  virtual 
environment based on the design of a layout formed by using geometric shapes. Once 
the  design  phase  has  been  concluded,  the  user  who  is  blind  can  interact  with  the 
virtual environment thanks to the use of a haptic device. The user takes on an aerial 
perspective of the environment, for which reason the feedback that the user receives is 
equivalent to having a hard model of the environment and tracing possible paths by 
using a pencil, in which collisions are transmitted through the sense of touch [Lahav, 
02].  The  use  of  the  haptic  perception  as  a  strategy  for  understanding  visual 
information was also discussed by [Kim, 10], who points to the importance of the idea 
that  the  heterogeneous  needs  of  users  must  be  considered  in  the  design  of  assisted 
technology. This author researches the individual differences between various users’ 
capacities  for  the  use  of  haptic  perception,  mainly  related  to  age  differences  and 
visual disability. She also discusses more accessible and applicable design approaches 
for users with visual disability based on haptic user interfaces. 

Another alternative for providing information to people who are blind is through 
audio-based interfaces. Through the use of audio-based cues, a person who is blind is 
able to locate objects of interest in the same way as a sighted person [Crossan, 06]. 
This kind of interface requires careful design, as it is necessary to assure that the end 
user does not feel saturated by an excessive amount of information [Loomis, 05]. One 
example  of  audio-based  virtual  environments  can  be  seen  in  the  videogame  AbES 
[Sánchez,  09b].  This  videogame  expands  on  the  concept  of  the  fictitious  corridors 
used in its predecessor AudioDoom [Lumbreras, 99], in order to generate an audiobased 
 virtual  representation  of  real  environments,  thus  serving  as  a  videogame  that 
allows for O&M training [Sánchez, 09b]. Together with a three-dimensional interface, 
the  use  of  audio  allows  to  increase  the  potential  for  various  forms  of  interaction 
between the user and the computer. [Frauenberger, 03] presents an audio-based virtual 
reality  system  that  allows  the  user  to  explore  a  virtual  environment  using  only  his 
sense  of  hearing.  [Jain,  12]  performed  empirical  evaluations  of  various  approaches 
through which spatial information on the environment is transmitted through the use 
of audio cues. Audio-based applications are also being developed for mobile devices 
with users who are blind as the target audience. One example of this is a puzzle game 
in  which  the  pieces  with  images  originally  used  for  puzzles  are  replaced  with 
randomized musical patterns [Carvalho, 12]. 

The  purpose  of  this  work  was  to  investigate  whether  the  use  of  an  audio  and 
haptic-based videogame has an impact on the development of O&M skills in schoolage 
learners who are blind. To attain this goal, it was necessary to design, implement 
and evaluate the usability of Audio Haptic Maze (AHM), an audio and haptic-based 
videogame.  We  also  conducted  a  cognitive  evaluation  to  determine  the  impact  of 
AHM on the development of O&M skills in learners who are blind. 

2 

Audio Haptic Maze 

Audio Haptic Maze (AHM) is a videogame based on AbES [Sánchez, 09b], and was 
designed for use by users who are blind either autonomously or with the supervision 

 

2680

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

of a facilitator in contexts of research and practice. The game includes the use of both 
audio and haptic-based interfaces, that can be used either together o separately. AHM 
is a first-person videogame in which the user must escape from a maze. In order to 
fulfill the mission, the player must find treasure chests dispersed throughout several 
corridors  and  rooms  in  the  maze,  which  contain  keys  and  treasures.  The  keys  have 
geometric  shapes  that  correspond  to  certain  doors  in  the  maze.  The  user  must  pick 
them up and try them out one at a time, until he identifies which key can be used to 
open  the  doors  needed  to  get  out  of  the  maze.  In  order  to  add  another  entertaining 
component to the game, the score of the game increases with each treasure that the 
player finds. The time that the player takes to get out of the maze is also a factor, in 
which the less amount of time taken implies a higher score. 

The entire process for the design and development of AHM was based on a usercentered 
 design  methodology  [ISO,  99],  working  directly  with  the  end-user  and 
making 
interactions, 
conversations, interviews and end-user usability evaluations. The researchers’ entire 
range  of  abundant  team  experience  regarding  interface  design  for  children  who  are 
blind was also used in this design process. 

the  user  an  active  participant 

AHM  is  based  on  a  model  for  implementing  educational  software  focused  on 
children  with  visual  disabilities  [Sánchez,  04].  The  model  is  centered  on  providing 
facilities for evaluation purposes and prompting feedback from the end user. It also 
clarifies  similarities  and  differences  between  software  for  people  with  and  without 
visual disabilities, for implementation purposes. 

in 

the  design 

through 

2.1  Development 
The videogame was developed utilizing C++ language in the Microsoft Visual Studio 
.NET  2010  development  environment,  in  which  GLUT  libraries  were  used  for  the 
graphic  display,  OpenAL  for  the  use  of  spatial  audio,  and  the  SDK  of  the  Novint 
Falcon was used to generate haptic feedback. 

In order to execute the videogame, a computer with an Intel Core2 Duo processor 
or higher is needed, with 2GB of RAM and a 16MB graphic card, with at least 20MB 
of free space on the hard drive for installation. It is necessary to have an audio output 
for stereo headphones and a free USB port in order to connect the Novint Falcon to 
the computer from which the videogame is executed.  

Interfaces 

2.2 
AHM  includes  different  interfaces  in  order  to  provide  feedback  to  the  user  and 
information to the facilitator. 

2.2.1  Graphic Interface 
The Graphic Interface, used by the facilitator, represents the current state of the game, 
using a third person perspective to show where the user who is blind is in real time. 
Fig.  1.i  represents  a  screenshot  of  the  graphic  interface  of  AHM  with  the  elements 
that can be found on the  map, in  which: (A) represents a treasure chest,  which can 
have a key or a treasure inside; (B) represents the character controlled by the user; (C) 
represents a door in the maze. Fig. 1.ii illustrates a user who is blind interacting with 
the videogame. 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2681

 

 

 

Figure 1: i) AHM graphic interface, used by the facilitator.  ii) A user who is blind 

interacting with the videogame 

2.2.2  Audio Interface 
The Audio Interface is utilized by the user who is blind. AHM uses spatialized sound 
to represent the ambience of the corridors. For example, if the user has a corridor to 
the left, he can hear an ambience sound through the left-hand channel. The same kind 
of interaction is possible  with other objects such as doors and keys,  which are also 
represented by certain audio cues. All of the actions in the virtual environment have a 
particular sound cue associated to them. For example, if the user walks, a step sound 
cue can be heard. Examples of other possible actions are to bump into an object, turn 
in  a  specific  direction,  and  pick  up  an  object.  In  addition  to  this  audible  feedback, 
verbal audio is used to indicate certain situations. For example, when the user picks 
up a key, the context of the game changes, and the user is informed through verbal 
audio  so  that  he  can  now  listen  to  a  sequence  of  beeps  indicating  the  number  of 
vertices on the key.  

Through  the  audio  description,  the  system  transmits  information  on  the 
environment that would normally be understood visually in real time. This procedure 
aids the users in creating points of reference, that help him to determine places and 
objects, as well as the distribution of these objects throughout the virtual environment. 

 

2682

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

Based  on  this  information,  the  user  is  able  to  construct  a  mental  map  of  the  AHM 
environment.  

2.2.3  Haptic Interface 
The Haptic Interface is utilized by the user who is blind. By using the haptic device, 
the user can control a 3D cursor inside the virtual environment. All of the audio-based 
feedback  is  emulated  by  using  haptics.  Thus,  haptic  textures  are  used  to  represent 
distinct objects on the map, so if the user touches a wall with the 3D cursor, the haptic 
feedback  of  that  object’s  texture  will  be  different  compared  to  that  associated  with 
touching  a  door.  Also,  the  user  will  be  able  to  identify  shapes  within  the  map. 
Regarding  the  feedback  for  actions,  like  walking  or  turning  left  or  right,  force 
feedback is applied, such as a vibration in the direction of the user’s movement. In 
this  way,  if  the  user  decides  to  walk  forward,  there  is  a  vibration  to  the  front  and 
corresponding vibrations to either side if the user turns left or right. In this way, the 
audio-based information is complemented by haptic perception, facilitating the user’s 
interaction with the system/environment.  

Interaction 

2.3 
The  interaction  with  the  videogame  is  carried  out  through  the  use  of  a  standard 
computer keyboard, a Novint Falcon haptic device and earphones (See Fig.1. ii).  

In the case of the audio-based interface, the entirety of the user’s immersion is 
achieved through the use of stereo sound, in order to provide information regarding 
the  location  of  objects,  such  as  walls  and  doors,  in  the  virtual  environment.  In  this 
way, the user can create a mental model of the spatial dimensions of the environment. 
In navigating, the user can interact with each of the previously mentioned elements, 
and each of these elements provides feedback that helps the user to become oriented 
in the environment.  

The Novint Falcon device was used for haptic feedback, which works as a three 
dimensional pointer that allows for an interaction with 3D volumes, generating force 
feedback. 

Logging actual use 

2.4 
During the entire process of interaction in which the user plays with the videogame, 
the  actions  taken  are  stored  in  files  that  can  then  be  visualized  by  the  facilitator 
through a special application called “Path Analyzer”, which marks the places on the 
map through which the user has navigated (Fig. 2). This allows for a more complete 
user route analysis, session after session, in order to show the evolution of the user’s 
movements as the various areas of the  map that  have been navigated are integrated 
into the user’s mental map. 
 
 
 
 
 
 
 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2683

 

Figure 2: Screenshot of the Path analyzer application 

 

3 

Usability Evaluation 

First, we conducted a usability evaluation with end users to validate the design of the 
game. Below is the methodology used and the results obtained. 

Sample 

3.1 
For the usability evaluation of AHM, a sample consisting of 10 learners who are blind 
with  ages  ranging  from  10  to  15  years  old  was  selected.  None  of  these  research 
participants have any additional, associated disabilities other than visual impairment. 

Instruments 

3.2 
For  usability  testing,  several  key  instruments  were  used.  The  Software  Usability 
Elements questionnaire (SUE) allows for quantifying the degree to which the audio 
and  haptic  feedback  used  in  the  videogame  were  recognizable.  The  Open  Question 
Usability questionnaire (OQU) that was applied to the users included questions such 
as: Was it possible to perceive the relative position of the objects? Did you like the 
audio/haptic  interface  used  for  feedback  in  the  software?  The  idea  was  to  collect 
knowledge  regarding  aspects  related  to  O&M  that  represent  the  focus  of  the  AHM 
videogame, as well as regarding the use of the controls, the information provided by 
the software, and the user’s navigation of the virtual environment. The results of this 
evaluation allowed researchers to redesign and improve the user interfaces. Once the 
corrections  and  redesign  of  the  software  had  been  carried  out,  Sánchez’s  Software 
Usability for Blind Children (SUBC) [Sánchez, 03] questionnaire was administered. 

 

2684

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

This  questionnaire  consists  of  14  items  for  which  the  users  had  to  define  to  what 
degree each item was fulfilled, on a scale ranging from 1 ("a little") to 10 ("a lot"). 
The  results  allowed  for  an  evaluation  of  the  software’s  usability  according  to  the 
user’s level of  satisfaction,  using  sentences such as,  “I  like the  software” and  “The 
software is motivating”. 

Procedure 

3.3 
The first step was to establish an activity revolving around the usability of each of the 
proposed interfaces. To these ends, two 20-minute sessions were held with each user. 
During these sessions the users were asked to listen to a set of 40 sounds, identifying 
or  relating  the  object  or  action  that  each  sound  represented,  and  focusing  their 
attention  mainly  on  the  contextual  sounds  to  be  used  in  the  videogame  such  as 
footsteps and bumping sounds. Also, a set of 20 high relief objects and a set of the 
same 20 objects with low relief were used, and users were asked to interact with these 
objects  through  the  haptic  device  to  establish  the  haptic  characteristics  regarding 
shape and texture, in order to identify the object or element that was represented.   

The SUE questionnaire was completed by the facilitators after each work session, 
in order to identify which of these audio and haptic elements were easier for the users 
to recognize and associate. Based on these results, the most appropriate sounds and 
elements were selected for use in the videogame. 

Afterwards, the users interacted with AHM in a 40-minute session, in which they 
were asked to take a path from point A to point B on the map. During this process, the 
facilitator observed the user’s position on the map through a graphic interface in order 
to detect if there were any difficulties regarding their navigation, and whether or not 
they  were  able  to  perceive  the  audio  and  haptic  elements  within  the  maze  and  use 
them as references for orientation and mobility.  

After  having  finished  this  activity,  the  users  completed  the  OQU  questionnaire 

with the help of a facilitator during a period of 10 minutes.  

Finally, the users proceeded to respond to the SUBC questionnaire with the help 
of the facilitator, who read the questions out loud and filled in their responses. Based 
on the results of these questionnaires, the team proceeded to make all of the changes 
and redesigns that would allow for an improved version of the videogame, in order to 
make it even more usable. 

3.4  Results 
Initially, it was planned that the sounds utilized in the videogame would represent a 
“metallic”  environment,  which  would  create  a  spatial  maze  atmosphere  in  order  to 
make  the  game  more  attractive  to  the  students.  However,  according  to  the  results 
obtained from the application of the SUE questionnaire for the evaluation of iconic 
sounds, it was observed that the sounds, which were altered in order to achieve the 
desired effect, confused the users. For this reason it was decided to use pure sounds.  

For the usability evaluation of shapes through the use of didactical materials, the 
results obtained from the questionnaire showed that the students correctly identified 
simple geometric shapes, but had problems identifying complex shapes. In the same 
way, in evaluating shapes through the use of the haptic device, it was observed that 
the majority of the users identified regular shapes with the device, but not complex 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2685

shapes. Finally, in evaluating the usability of the virtual textures represented through 
the use of the haptic device, the results showed that most users correctly described the 
textures. 

When the users responded to the question “Did you like the videogame?” on the 
OQU questionnaire, all users answered positively, with phrases such as: “I liked the 
environment  that  the  videogame  generates,  it  is  very  realistic”,  “It  is  fun  to  move 
around in the corridors and escape from the maze”. In response to the question “Do 
you want to add something else to the videogame?”, in general the users replied that 
they would like the maze to include enemies to fight against. According to the results 
of this questionnaire, the videogame was generally well accepted, and in the future it 
would be possible to consider adding other components that would make it even more 
attractive. One relevant aspect regarding the use of the interface based on audio and 
combined  sounds  was  the  users’  comments  that  the  experience  was  very  enriching, 
but  not  necessarily  because  of  the  ability  to  transmit  information  from  the  virtual 
environment to the user; rather they noted that, in part, the sound helped to generate 
an  environment  that  is  more  associated  with  what  they  would  expect  from  a 
videogame.  

The  results  provided  by  the  Software  Usability  for  Blind  Children  (SUBC) 
questionnaire showed that AHM is usable for users with visual disability (see Fig. 3).  

 

 

Figure 3: Results of the Software Usability for Children Who Are Blind, SUBC 

In order to perform the evaluation, the three kinds of interfaces involved in the 
videogame  were  analyzed:  haptic,  audio  and  haptic  plus  audio.  The  results  showed 
that the mean level of the “users’ satisfaction” was 7.0, 8.5 and 7.1 points respectively 
for  each  kind  of  interface,  on  a  scale  with  a  maximum  of  10  points.  For  the 
“Satisfaction” category, the sentence  with the  highest  score across the board for all 
three interfaces was “I would play this game again”, with a score of 7.6 for the haptic 
interface, 9.2 for the audio and 7.5 for the audio and haptic combined. This aspect is 
fundamental, as it shows that users maintain an interest in the videogame, and did not 

 

2686

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

become bored too quickly. This result was consistent with the results obtained from 
the OQU questionnaire as well. 

The  “Control  and  Use”  category  obtained  a  score  of  6.7,  7.5  and  7.8  points 
respectively for haptic, audio and haptic plus audio interfaces, respectively, on a scale 
with  a  maximum  of  10  points.  As  all  of  these  scores  are  above  6.0,  they  are 
considered  to  be  acceptable.  The  score  is  lower  for  the  haptic  interface,  as  for  the 
users  the  exclusive  use  of  the  Novint  Falcon  in  order  to  obtain  feedback  from  the 
game required a certain learning curve, as none of the participants in the sample had 
ever used this device before. 

In the “Audio” category, a score of 10 points was obtained for the audio interface 
regarding the sentence “The sounds of the videogame provided me with information”, 
while  for  the  haptic  interface  the  sentence  “I  like  the  sounds  of  the  videogame” 
obtained a maximum of 8 points. This variation of maximums was due to the fact that 
in  the  case  of  the  audio-based  interface,  this  was  the  only  way  to  obtain  feedback 
from the videogame, while for the haptic plus audio interface, the users felt that the 
sounds were complementary to the haptic elements, which made the videogame more 
exciting. 

Within  the  “Haptic”  category,  the  highest  score  was  obtained  in  the  haptic  and 
haptic  plus  audio  interfaces,  for  the  sentence  “The  tactile  sensation  of  the  device 
provided me with information”, which obtained 10 points and 8 points respectively. It 
is clear that the higher score is associated with the haptic interface, as in this case it 
was the only means of obtaining feedback from the videogame. 

Importantly,  the  results  of  the  haptic  plus  audio  interface  were  lower  than  the 
audio interface in the dimensions Satisfaction and Audio. This could be explained by 
the fact that use of the device implied an adaptation period and therefore an additional 
difficulty in the development of the evaluation activities. This is probably why the use 
of audio-based interface was more relevant. 

4 

Cognitive Impact 

Once validated the interfaces of the game, we proceeded with the assessment of the 
cognitive impact on end users as a result of using the tool. Below is the methodology 
used and the results obtained. 

Sample 

4.1 
An intentional sample was selected, made up of 7 learners who are blind with ages 
between and 10 and 15 years old, including four males and three females, all from the 
Metropolitan  Region  of  Santiago.  All  of  the  participants  attend  the  Santa  Lucia 
School for the Blind. The requirements to participate were: 1. Being between 10 and 
15 years of age, 2. Presenting Total Blindness, 3. Being enrolled in between Third and 
Eighth grade of General Elementary Education. The details of the sample can be seen 
in Table 1. 

To perform the analysis of the results, the sample was segmented into two user 
groups. The first group considered users of 10-12 years of age, and the second group 
considered users of 13-15 years of age. 

 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2687

 

Degree of Vision 

Gender  Ophthalmological Diagnostic 
F 
M 
M 
F 
M 
M 
F 

Blindness Caused by Brain tumor  Totally Blind 
Totally Blind 
Retinopathy of prematurity 
Totally Blind 
Bilateral Blindness 
Microphthalmia 
Totally Blind 
Totally Blind 
Leber’s congenital amaurosis 
Totally Blind 
Congenital amaurosis 
Retinopathy of prematurity 
Totally Blind 

Table 1: Sample description 

Instruments 

4.2 
In order to study the degree of the videogame’s impact, together with the cognitive 
tasks  performed,  on  the  development  of  the  participants’  O&M-related  skills,  an 
O&M skills checklist was created for children with visual disability between 10 and 
15 years of age. This checklist was designed by special education teachers who are 
specialists in visual disabilities. The validation of the instruments was performed by 
these  teachers applying the O&M  skills checklist to  users  who are blind other than 
those  involved  in  the  sample,  in  order  to  detect  errors  in  comprehension  and  the 
measurement of results. 

This evaluative instrument was applied individually to each user at the beginning 
and at the end of the cognitive intervention, in order to determine in what way the use 
of the videogame had affected the development of O&M skills. 

The dimensions contained within this instrument are: 

  Sensory  perception.  The  perception  of  information  through  the  auditory  and 
haptic channels are evaluated, taking into account the fact that sensory capacities 
are the primary functions that are developed to pick up on, integrate and react to 
information and stimulus from the environment. 

  Tempo-spatial development. The users’ knowledge regarding their position in 
space  is  evaluated,  in  being  able  to  understand  the  distribution  and  location  in 
space  of  various  elements  based  on  their  own  bodies,  while  at  the  same  time 
being  able  to  establish  a  relation  between  these  aspects  in  order  to  navigate 
through the space. 

  O&M  skills.  The  skills  regarding  navigation  based  on  O&M  training  is 
evaluated,  either  through  use  of  the  cane  as  a  technical  aid  in  order  to  detect 
obstacles in the environment or not. The purpose of this was to show whether or 
not  the  users  are  able  to  navigate  both  real  and  virtual  environments  based  on 
these  techniques,  thus  validating  them  for  facilitating  and  strengthening  their 
navigation. 

 

2688

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

4.3  Cognitive Tasks with the use of Audio Haptic Maze 
These  tasks  sought  to  develop  and/or  strengthen  O&M  Skills  in  learners  who  are 
blind,  based  on  the  use  of  Audio  Haptic  Maze  and  its  audio  and/or  haptic-based 
interfaces.  

4.3.1  Tasks regarding the Comprehension of Dynamic Components 
These tasks were sub-divided into: 
 

Integration of Elements. In this task, it was sought to integrate each of the audio 
and/or haptic elements used in the videogame into the user’s mental map, in order 
to establish the dynamics of the videogame that are related to movement.  

  Establishment of Distances and Sizes on the Map. This task sought to solidify 
the  establishment  of  the  relationship  of  equivalence  between  one  step  and  one 
cell.  The  maze  is  made  up  of  a  certain  number  of  cells,  corresponding  both  to 
rooms  and  hallways.  By  integrating  knowledge  of  this  dynamic,  the  user  can 
establish distances to doors and keys, and can determine the size of the various 
environments by counting the cells while moving from one place to another.   

  Directionality and Movement on the Map. This task sought to strengthen the 
establishment of relations between the segments on the map and the direction in 
which the learners are facing and moving, so that the  user is able to locate the 
various  elements  on  the  map.  In  addition,  players  were  asked  to  delimit  their 
movements  regarding  the  direction  that  they  took,  mainly  in  order  to  verify 
whether or not they noticed when they moved forwards or backwards, or turned 
in one direction or another.  

  Composition and Distribution of the Map. This task was related to all of the 
map-based sessions, and sought to work on the identification of hallways, rooms, 
elements represented through the use of audio and/or haptics, and the search for 
these elements based on the character’s location on the map.  

4.3.2  Map Appropriation and Navigational Tasks 

These  tasks  were  centered  on  establishing  a  mental  representation  of  the 
navigated  environment  based  on  the  videogame’s  dynamics  that  strengthen  the 
establishment of relationships useful for orientation and mobility in the virtual space.  
The  maze  in  the  videogame  was  divided  into  different  sectors  (see  Figure  4), 

which determined the following tasks: 
  Sector  A.  This  task  sought  to  establish  the  number  of  hallways,  rooms  and/or 
elements available in this area. In addition, it sought to establish the direction of 
movement, relationships of distance and size pertaining to the elements, hallways 
and  rooms,  in  order  to  facilitate  the  formation  of  movement  strategies. 
Afterwards, each player was asked to represent the space he had navigated with 
representative material of the elements of the videogame.  

  Sector  B.  This  task  had  as  an  objective  that  through  the  audio  and/or  hapticbased 
interfaces, the players would move through sector B in the maze, locating 
the  different  hallways  and  elements.  After  navigating  this  sector  of  the  maze, 
each player was asked to represent the space that had been navigated, describing 
the  route  taken  and  the  elements  that  the  player  had  located  on  that  route,  in 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2689

addition to describing  whether or not the  user  was  walking down a  hallway or 
through a room.   

  Elements  and  Size  Dynamics.  This  task  consisted  of  comprehending  the 
videogame’s dynamic regarding the execution of actions, and the interaction with 
various elements in the videogame such as doors and differently shaped keys that 
could be used to open  specific doors. Based on this, the  learner had to resolve 
problems  such  as  inferring  the  need  to  find  a  specific  key  in  order  to  open  a 
particular  door,  understanding  if  he  was  walking  down  a  hallway  or  through  a 
room, determining the number of steps taken when moving about, and based on 
the  latter,  establishing  the  size  of  the  space  in  which  the  user  is  located.  In 
addition, the users had to comprehend the functionality of the Novint Falcon, the 
buttons  on  the  keypad,  and  learn  to  orient  themselves  based  on  audio  and/or 
haptic  cues,  in  order  to  determine  and  identify  the  elements  within  the 
videogame.  

  Sectors A, B and C, Directionality and Movement. The objective of this task 
was  to  establish  the  relationships  of  movement  performed  by  the  player  when 
moving through the 3 sectors of the maze, using the respective interface assigned 
to each particular  work  group. Each user  had to identify  each sector (based on 
characteristics  that  had  already  been  established  during  prior  navigational 
exercises),  and  the  directions  and  elements  located  both  in  a  hallway  and/or  a 
room. Once the route had been navigated, each player was asked to represent the 
space that had been navigated with representative material, requiring knowledge 
of  the  number  of  cells  for  each  hallway  and  room,  and  the  elements  such  as 
intersections, doors, treasure chests and keys.    

  Total  Navigation  of  the  Map.  This  last  task  was  based  on  navigating  freely 
throughout the entire maze, applying all of the strategies and dynamics involved 
in the videogame that are needed in order to successfully complete the mission of 
opening  all  of  the  doors  and  navigating  between  the  3  sectors  of  the  virtual 
environment. In addition, the need to establish the directions in which the learner 
was moving was emphasized, as well as the need to establish the relationships of 
size  regarding  hallways  and  rooms,  the  relationship  between  the  audio  and/or 
haptic  elements  of  the  videogame  as  associated  with  concrete  objects,  and  the 
verbal description of everything the player had identified and the routes taken. In 
this task, the learners  were also asked to graphically represent the environment 
that had been navigated, adding arrows to indicate the directions that had to be 
followed in order to move from one sector to another.  

Procedure 

4.4 
Initially, the O&M skills checklist was applied as a pretest, in 45-minute sessions with 
each user. During these sessions, the users were provided with a set of materials in 
order to perform some of the actions required by the instrument (see Fig. 5).  

In  a  second  stage,  the  users  performed  cognitive  tasks  through  the  use  of  the 
videogame  in  which  each  of  the  dimensions  contained  in  the  O&M  skills  checklist 
was  worked  on  (Perceptual  development,  Temporal-spatial  development,  O&M 
skills) in order to strengthen the development of these skills by using AHM (see Fig. 
6). This stage involved a total of twelve, 40-minute sessions with each user. 
 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2690

 

Figure 4: Sectors within the Maze of Audio Haptic Maze 

 

 

Figure 5: Activities performed by the user during the pre-test 

Once the user had finished navigating through the maze, he was asked to create a 
graphic  representation  of  the  environment  through  representative  material  of  the 
elements  of  the  videogame,  in  order  to  determine  if  the  mental  image  created 
coincided with the spaces that had been navigated virtually while interacting with the 
videogame. This does not mean that the representation was made through a freehand 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2691

drawing, but through  manipulative  materials by the learner, who should place them 
according to his personal perception of the environment. 

 

Figure 6: Learner performing cognitive tasks with Audio Haptic Maze 

 

Complementary  to  the  cognitive  evaluation,  during  each  work  session,  once 
navigation through the virtual environment had been completed, each user was asked 
(in order of age) to form a graphic representation of the virtual environment they had 
navigated, in order to determine the adoption and restructuring of the mental model 
based on audio and haptic cues (see Fig. 7).  

Finally, in a third stage the same O&M skills checklist used in the first stage was 

applied as a post-test. 

 

 
Figure 7: Learners forming graphic representations of the environments navigated 

4.5  Results 
The  results  obtained  from  the  evaluation  of  the  10-12  year  old  age  group  from  the 
sample  showed  an  increment  in  the  pretest/posttest  performance  means  in  all 
dimensions. Based on a T Test that was performed with this data, it was found that the 
differences in the pretest/posttest means for the “Sensory perception” (pretest mean = 
65.75 points; posttest mean = 70.75 points; range of scores from 0 to 72 points) and 

 

2692

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

“Tempo-spatial  development”  (pretest  mean  =  24.45  points;  posttest  mean  =  28.75 
points;  range  of  scores  from  0  to  34  points)  dimensions  were  not  statistically 
significant.  However,  for  the  “O&M  skills”  (pretest  mean=32.31  points;  posttest 
mean=48.75  points;  range  of  scores  from  0  to  52  points)  dimension  the  difference 
between the two means was statistically significant (t = -4,323; p < 0.05). 

The results obtained for the evaluation of the 13-15 year old age group from the 
sample  showed  increments  in  their  pretest/posttest  performance  means  in  all 
dimensions as well. Based on a T Test that was performed with this data, it was found 
that the differences in the pretest/posttest means for the “Tempo-spatial development” 
(pretest mean = 33.33 points; posttest mean = 34.00 points; range of scores from 0 to 
34  points)  and  “O&M  skills”  (pretest  mean  =  34.00  points;  posttest  mean  =  43.76 
points;  range  of  scores  from  0  to  44  points)  dimensions  were  not  statistically 
significant.  However,  for  the  “Sensory  perception”  (pretest  mean  =  59.00  points; 
posttest  mean  =  68.00  points;  range  of  scores  from  0  to  68  points)  dimension  the 
difference between the two means was statistically significant (t = -5,197; p < 0.05). 

Also, the  users  were able to navigate  through all of the areas that  make  up the 
maze  designed,  making  intelligent  decisions  regarding  what  direction  to  follow  in 
order to go from point A to point B based on the information provided. 

Evidence  of  this  point  is  reflected  in  Fig.  8,  which  shows  the  result  of  a 
behavioral  analysis  of  one  of  the  13-15  year-old  user’s  navigations  through  the 
environment.  It  can  be  observed  that  the  user  integrates  both  interfaces  in  order  to 
completely  navigate  all  of  the  areas  on  the  map  of  the  maze  in  the  virtual 
environment. 

As for the graphic representations of the users’ mental maps after having finished 
the navigation sessions, these representations included all of the elements involved in 
the  videogame’s  virtual  environment,  but  lacked  precision  regarding  specific 
dimensions and the orientation of the corridors and rooms (see Fig. 9). The problem 
associated  with  spatial  dimensions  is  due  to  the  users’  tendency  to  perform  a 
peripheral exploration while navigating in real life, a tendency that is transferred to 
their navigation in the virtual environment. This situation is only visible through the 
representations  with  representative  material,  in  that  virtually  the  users  were  able  to 
successfully establish the dimensions that correspond to each area of the maze. 

5 

Conclusions 

The purpose of this study  was to design, implement and evaluate the  Audio Haptic 
Maze (AHM) videogame and determine whether the use of an audio and haptic-based 
videogame has an impact on the development of O&M skills in school-age learners 
who are blind. The results showed that playing and training with AHM improved the 
development of O&M skills in learners who are blind. 

The  contribution  of  this  work  is  to  show  how  through  the  integration  of 
multimodal  interfaces  into  a  video  game  the  development  of  O&M  skills  can  be 
promotes  in  blind  learners.  The  playful  aspects  of  the  game  and  its  associated 
technology positively influenced the motivation of end users. 

 
 
 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2693

 

Figure 8: Result of the Path Analyzer for one of the user’s navigations. The clear 

cells correspond to the places visited by the user 

 

Figure 9: Graphic representation of the mental map of the virtual environment 

navigated. 

 

 

2694

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

Regarding the usability associated with the videogame, it was found that the use 
of appropriate audio icons is crucial to be able to provide correct information. For this 
reason, applying sound effects to these audio cues could generate a  kind of special 
environment that can have a negative effect on usability. 

Both  the  haptic  and  the  audio-based  interfaces  are  able  to  transmit  the  same 
information  on  the  user’s  state  within  the  virtual  environment.  However,  it  is 
necessary to reiterate that both interfaces were complemented with the use of Text-
To-Speech, used in order to indicate contextual and/or status changes, which would 
have  been  difficult  to  transmit  to  users  through  either  audio  or  haptic  icons.  These 
contextual  changes  have  a  favorable  effect  on  the  associations  that  the  users  make 
between the elements that make up the different areas in the maze, as through the use 
of these elements users are able to determine the specific sector of the maze in which 
the  various  elements  are  located,  and  the  actions  that  they  must  take  in  order  to 
resolve  the  videogame’s  dynamics  and  continue  with  their  navigation  into  other 
sectors of the virtual environment. 

The  use  of  audio  and  haptic  interfaces  together  showed  that,  more  than  just 
complementing  the  provision  of  information  regarding  the  user’s  state  within  the 
virtual environment, this combination allows for the creation of an environment that is 
much closer to what the user would expect from a videogame. The users utilized the 
haptic interface to navigate and the audio interface to imagine the situation in which 
they were immersed within the videogame’s maze. 

As such, the use of the haptic and audio interfaces together allows the user who is 
blind  navigating  the  videogame’s  virtual  environment  to  be  able  to  form  a  better 
perception  of  distances,  shapes  and  the  orientation  of  the  objects  on  the  map  when 
updating his position.  

Regarding the cognitive impact, the results of this study show that all the audio 
and  haptic  icons  are  useful  for  establishing  navigational  paths  in  the  virtual 
environment. The icons that allow the users to measure the spaces that they navigate 
are especially helpful for this process, not only to establish a mental map of the virtual 
environment, but to apply this information to real navigational contexts as well. This 
was corroborated by the results regarding the effect that the intervention had on the 
users in the “O&M skills” dimension. 

The results allow for the confirmation that all of the users within the 10-12 year 
old age group presented significant development of  their  O&M  skills as a result of 
their interaction with the AHM videogame. The results also indicate that the “O&M 
skills”  dimension  was  that  which  experienced  the  most  significant  quantitative 
development, which is directly related to the efficiency of the user’s movements when 
navigating within the videogame’s virtual environment.  

As far as the results for the 13-15 year old age group, all of the users presented a 
development in their O&M skills after  having completed the cognitive tasks. There 
was  an  important  increase  in  their  scores  as  a  result  of  their  interaction  with  the 
videogame,  although  this  increase  was  not  statistically  significant  in  the  “O&M 
skills”  dimension.  Case  studies  were  observed  in  which  some  users  were  seen  to 
develop the skills involved in entire indicators that had not been present in the pretest. 
One example of this is the development of techniques for the search and location of 
objects in the environment,  which became  visible in the  videogame  when the  users 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2695

had to locate the treasure chests that contained the keys needed to open the doors of 
the maze. 

The game presented limitations in the development of abstract representation that 
end  users  could  achieve  working  with  the  proposed  interfaces.  We  attempted  to 
overcome  these  limitations  by  proposing  the  use  of  low  and  bounded  complexity 
spaces  in  the  game  (number  of  items,  size  of  the  maze,  and  choices  of  paths  to 
follow).  As  future  work  plans,  we  intend  to  expand  the  complexity  of  the  virtual 
environment. 

It  is  proposed  as  future  work  to  explore  how  learners  construct  their  mental 
models.  In  this  paper,  the  evaluation  criteria  of  the  graphic  representation  of  the 
navigated virtual environment, was based on the accuracy of representation achieved 
by learners. However, it will be pertinent and appropriate to study how users represent 
mental  maps,  focusing  the  analysis  on  the  utility  for  themselves  related  to  the 
functional elements of the environment. 

Acknowledgements 
This  report  was  funded  by  the  Chilean  National  Fund  of  Science  and  Technology, 
Fondecyt #1120330 and Project CIE-05 Program Center Education PBCT-Conicyt. 

References 

[Ballesteros,  93]  Ballesteros,  S.:  Percepción  Háptica  de  Objetos  y  Patrones  Realzados:  Una 
Revisión. Departamento de Psicología Básica. Universidad Nacional de Educación a Distancia. 
Psiocthema, 1993, vol.5, nº2,  311-321. 
[Carvalho, 12] Carvalho, J., Guerreiro, T., Duarte, L.,  Carriç, L.: Audio-Based Mobile Puzzle 
Gaming for Blind People. In: MOBACC 2012: Mobile Accessibility Workshop at MobileHCI 
2012, San Francisco, USA, September 2012. 
[Crossan,  06]  Crossan,  A.,  Brewster,  S.:  Two-Handed  Navigation  in  a  Haptic  Virtual 
Environment.  In  Proceedings  of  International  Conference  on  Human  Factors  in  Computing 
Systems, pp.676-681, Montréal, Québec, (Canada), 2006. 
[De Felice, 05] De Felice, F., Renna, F., Attolico, Distante, A.: Haptic fruition of 3D virtual 
scene by blind people. In Proceedings of the 18th international conference on Innovations in 
Applied Artificial Intelligence (IEA/AIE'2005), Ali M & Esposito F (Eds.). Springer-Verlag, 
London, UK, 269-278, 2005. 
[Frauenberger,  03]  Frauenberger,  C.,  Noisternig,  M.:  3D  audio  interfaces  for  the  blind.  In: 
Proceedings  of  the  2003  International  Conference  on  Auditory  Display,  Boston,  MA,  USA, 
July 6-9, 2003, pp. 1-4. 
[Gaißert, 11] Gaißert, N., Bülthoff, h. h., Wallraven, C.: Similarity  and categorization: From 
vision  to  touch.  Acta  Psychologica,  Volume  138,  Issue  1,  September  2011,  Pages  219–230. 
http://dx.doi.org/10.1016/j.actpsy.2011.06.007 
[Gaißert,  12]  Gaißert,  N.,  Waterkamp,  S.,  Fleming,  R.  W.,  Bülthoff,  I.:  Haptic  Categorical 
Perception of Shape. PLoS One. 2012; 7(8): e43062. Published online 2012 August 10. doi:  
10.1371/journal.pone.0043062 

 

2696

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

blind.  Attention, 

Percept  & 

Psychophys. 

2009  May;71(4):690-8. 

[Heller,  01]  Heller,  M.  A.,  Brackett,  D.  D.,  Scroggs  E.,  Allen,  A.  C.,  Green,  S.:  Haptic 
perception of the horizontal by blind and low-vision individuals. In: Perception 30, 5, 601 – 
610, 2001. 
[Homa, 09] Homa, D., Kahol, K., Tripathi, P., Bratton, L., Panchanathan, S.: Haptic concepts in 
the 
doi: 
10.3758/APP.71.4.690. 
[Hu, 06] Hu, W., Lin, T., Sakai, K., Imamiya, A., Omata, M.: Setup Consistent Visual Textures 
for Haptic Surfaces in a Virtual Reality World. In Proceedings of the 9th conference on User 
interfaces  for  all  (ERCIM'06),  Stephanidis  C  &  Pieper  M  (Eds.).  Springer-Verlag,  Berlin, 
Heidelberg, 78-87, 2006. 
[Huang, 09] Huang, Y. Y.: Exploration of interface usability in a haptic 3D virtual labyrinth for 
visually impaired users. In: proceeding of IADIS Interfaces and Human Computer Interaction 
(IHCI). ALGALVE, Portugal, June 17-23, 2009. 
[ISO,  99]  ISO:  Human  centered  design  processes  for  interactive  systems.  International 
Organization for Standardization, ISO 13407. Available from: 
http://www.iso.org/iso/catalogue_detail.htm?csnumber=21197 (accessed 19 August 2011). 
[Jain, 12] Jain, S.: Assessment of audio interfaces for use in smartphone based spatial learning 
systems  for  the  blind.  Master  of  Science  Thesis  in  Spatial  Information  Science  and 
Engineering. University of Maine, 2012. 
[Jütte,  08]  Jütte,  R.:  Haptic  perception:  an  historical  approach.  In:  Matin  Grunwald  (Ed.). 
Human  haptic  perception:  basics  and  applications.  Leipzig  (Alemanha),  2008,  3  -  13.  ISBN 
978-3-7643-7611-6 
[Kim, 10] Kim, H. N.: Usable accessibility and haptic user interface design approach. Doctoral 
Thesis  in  Industrial  and  Systems  Engineering.  Virginia  Polytechnic  Institute  and  State 
University, 2010. 
[Lahav, 02] Lahav, O., Mioduser, D.: Multisensory Virtual Environment for Supporting Blind 
Person’s  Acquisition  of  Spatial  Cognitive  Mapping,  Orientation,  and  Mobility  Skills.  In 
Proceedings  of  the  International  Conference  on  Disability,  Virtual  Reality  and  Associated 
Technologies, ICDVRAT 2002, Veszprém, Hungary, 213-220. 
[Lahav,  08]  Lahav,  O.,  Mioduser,  D.:  Haptic-feedback  support  for  cognitive  mapping  of 
unknown spaces by people who are blind. Int. J. Hum.-Comput. Stud. 66, 1, Jan. 2008, 23-35. 
[Loomis, 05] Loomis, J., Marston, J., Golledge, R., Klatzky, R.: Personal guidance system for 
visually  impaired  people:  Comparison  of  spatial  displays  for  route  guidance.  In  Journal  of 
Visual Impairment Blindness 99, 4, 219-232, 2005. 
[Lumbreras,  99]  Lumbreras,  M.,  Sánchez,  J.:  Interactive  3D  sound  hyperstories  for  blind 
children. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems: 
the CHI Is the Limit, CHI '99, Pittsburgh, Pennsylvania, United States, May 15 – 20 1999, 318325.
 
[Lutz,  06]  Lutz,  R.:  Prototyping  and  evaluation  of  landcons:  auditory  objects  that  support 
wayfinding  for  blind  travelers.  SIGACCESS  Access.  Comput.  86,  September  2006,  8-11. 
Available from: http://doi.acm.org/10.1145/1196148.1196150. 
[Murphy, 07] Murphy, E., Kuber, R., Strain, P., McAllister, G., Yu, W.: Developing Sounds 
For A Multimodal Interface: Conveying Spatial Information To Visually Impaired Web Users. 
In  Proc.  of  the  13th  International  Conference  on  Auditory  Display  (ICAD  2007),  Montréal, 
Canada, June 26-29, 2007. 

 

Sanchez J., de Borba Campos M.: Development of Navigation Skills ...

2697

[Norman, 04] Norman, J.F., Norman, H.F., Clayton, A.M., Lianekhammy, J., Zielke, G.: The 
visual and haptic perception of natural object shape. In: Perception & Psychophysics 66: 342–
351. 2004 Feb; 66(2):342-51. 
[Oakley, 00] Oakley, I., McGee, M. R., Brewster, S., Gray, P.: Putting the feel in ’look and 
feel‘.  In: Proceedings  of  the  SIGCHI  Conference  on  Human  Factors  in  Computing  Systems. 
CHI '00. ACM, New York, NY, 415-422. 2000. 
[Reuters, 09] Reuters: Novint Awarded Subcontract to Develop Physical Rehabilitation Game 
for  Military,  Edition  U.S.,  Tue  Sep  1,  2009  8:02am  EDT.  Available 
from: 
http://www.reuters.com/article/2009/09/01/idUS132915+01-Sep-2009+MW20090901 
(accessed 19 August 2011). 
[Rosa, 93] Rosa, A., Ochaita, E.: Psicología de la ceguera. Alianza editorial, Madrid (España), 
ISBN 84-206-6539-8, 1993. 
[Sánchez,  03]  Sánchez,  J.:  Software  Usability  for  Blind  Children  Questionnaire  (SUBC), 
Usability evaluation test, University of Chile, 2003. 
[Sánchez, 04] Sánchez, J., Baloian, N., Flores, H.: A methodology for developing audio-based 
interactive  environments  for  learners  with  visual  disabilities.  In  Proceedings  of  the  World 
Conference  on  Educational  Multimedia,  Hypermedia  &  Telecommunications  ED-MEDIA 
2004. June 21-26, 2004. Lugano, Switzerland, 540-545. 
[Sánchez, 09a] Sánchez, J., Sáenz, M., Ripoll, M., 2009. Usability of a Multimodal Videogame 
to Improve Navigation Skills for Blind Children. In Proceedings of the Eleventh International 
ACM  SIGACCESS  Conference  on  Computers  and  Accessibility,  Pittsburgh,  PA,  USA, 
October 26-28, 2009, 35-42. 
[Sánchez,  09b]  Sánchez,  J.,  Tadres,  A.,  Pascual-Leone,  A.,  Merabet,  L.:  Blind  children 
navigation  through  gaming  and  associated  brain  plasticity.  In  Virtual  Rehabilitation 
International Conference 2009, June 29-July 2, 2009, Haifa, Israel, 29-36. 
[Sánchez,  10]  Sánchez,  J.,  Tadres,  A.:  Augmented  reality  application  for  the  navigation  of 
people who are blind, In Proceedings of the 8th International Conference Series on Disability, 
Virtual Reality and  Associated  Technologies, ICDVRAT 2010, Viña del Mar, Chile, August 
31-September 2, 2010, 51-60. 
[Sarmiento,  03]  Sarmiento,  L.C.:  Ayudas  aumentativas  en  discapacitados  visuales  para  la 
representación espacial utilizando las tecnologías de la información y las comunicaciones. Tesis 
de Maestría en TIAE. Bogotá: UPN, 2003. 
[Travieso,  07]  Travieso,  D.:  Haptic  and  proprioceptive  experience.  Fundación  Infancia  y 
Aprendizaje. Estudios de Psicología, Vol.28, number 2, June 2007, 141-153(13). 
[Warren,  94]  Warren,  D.H.:  Blindness  and  Children:  An  Individual  Differences  Approach. 
Cambridge: Cambridge University Press. (1994) Mentioned in Ungar, S.: Cognitive mapping 
without  visual  experience:  in  Kitchin,  R.  &  Freundschuh,  S.  (eds)  Cognitive  Mapping:  Past 
Present and Future. London: Routledge (2000). 
[Yu,  00]  Yu,  W.,  Ramloll,  R.,  Brewster,  S.:  Haptic  Graphs  for  Blind  Computer  Users.  In 
Proceedings  of  the  First  International  Workshop  on  Haptic  Human-Computer  Interaction, 
Brewster S & Murray-Smith R (Eds.). Springer-Verlag, London, UK, 41-51, 2000. 
[Yu, 03] Yu, W., Kangas, K., Brewster, S.: Web-Based Haptic Applications for Blind People to 
Create Virtual Graphs. In Proceedings of the 11th Symposium on Haptic Interfaces for Virtual 
Environment and Teleoperator Systems, HAPTICS'03. IEEE Computer Society,  Washington, 
DC, USA, 318-325, 2003. 

 

