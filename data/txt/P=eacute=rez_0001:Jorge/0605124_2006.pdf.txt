6
0
0
2

 

y
a
M
 
6
2

 
 
]

B
D
.
s
c
[
 
 

1
v
4
2
1
5
0
6
0
/
s
c
:
v
i
X
r
a

Semantics and Complexity of SPARQL

Jorge P´erez1, Marcelo Arenas2, and Claudio Gutierrez3

1 Universidad de Talca

2 Pontiﬁcia Universidad Cat´olica de Chile

3 Universidad de Chile

Abstract. SPARQL is the W3C candidate recommendation query language 
for RDF. In this paper we address systematically the formal study
of SPARQL, concentrating in its graph pattern facility. We consider for
this study a fragment without literals and a simple version of ﬁlters which
encompasses all the main issues yet is simple to formalize. We provide a
compositional semantics, prove there are normal forms, prove complexity 
bounds, among others that the evaluation of SPARQL patterns is
PSPACE-complete, compare our semantics to an alternative operational
semantics, give simple and natural conditions when both semantics coincide 
and discuss optimizations procedures.

1 Introduction

The Resource Description Framework (RDF) [14] is a data model for representing 
information about World Wide Web resources. Jointly with its release in
1998 as Recommendation of the W3C, the natural problem of querying RDF
data was raised. Since then, several designs and implementations of RDF query
languages have been proposed (see [11] for a recent survey). In 2004 the RDF
Data Access Working Group (part of the Semantic Web Activity) released a ﬁrst
public working draft of a query language for RDF, called SPARQL [16], whose
speciﬁcation does not include RDF Schema. Currently (April 2006) SPARQL is
a W3C Candidate Recommendation.

Essentially, SPARQL is a graph-matching query language. Given a data
source D, a query consists of a pattern which is matched against D, and the
values obtained from this matching are processed to give the answer. The data
source D to be queried can be composed of multiple sources. A SPARQL query
consists of three parts. The pattern matching part, which includes several interesting 
features of pattern matching of graphs, like optional parts, union of
patterns, nesting, ﬁltering (or restricting) values of possible matchings, and the
possibility of choosing the data source to be matched by a pattern. The solution 
modiﬁers, which once the output of the pattern is ready (in the form of
a table of values of variables), allows to modify these values applying classical
operators like projection, distinct, order, limit, and oﬀset. Finally, the output of
a SPARQL query can be of diﬀerent types: yes/no queries, selections of values of
the variables which match the patterns, construction of new triples from these
values, and descriptions about resources queries.

Although taken one by one the features of SPARQL are simple to describe
and understand, it turns out that the combination of them makes SPARQL into
a complex language, whose semantics is far from being understood. In fact, the
semantics of SPARQL currently given in the document [16], as we show in this
paper, does not cover all the complexities brought by the constructs involved in
SPARQL, and includes ambiguities, gaps and features diﬃcult to understand.
The interpretations of the examples and the semantics of cases not covered in
[16] are currently matter of long discussions in the W3C mailing lists.

The natural conclusion is that work on formalization of the semantics of
SPARQL is needed. A formal approach to this subject is beneﬁcial for several
reasons, including to serve as a tool to identify and derive relations among the
constructors, identify redundant and contradicting notions, and to study the
complexity, expressiveness, and further natural database questions like rewriting 
and optimization. To the best of our knowledge, there is no work today addressing 
this formalization systematically. There are proposals addressing partial
aspects of the semantics of some fragments of SPARQL. There are also works
addressing formal issues of the semantics of query languages for RDF which can
be of use for SPARQL. In fact, SPARQL shares several constructs with other
proposals of query languages for RDF. In the related work section, we discuss
these developments in more detail. None of these works, nevertheless, covers
the problems posed by the core constructors of SPARQL from the syntactic,
semantic, algorithmic and computational complexity point of view, which is the
subject of this paper.

Contributions An in depth analysis of the semantics beneﬁts from abstracting
some features, which although relevant, in a ﬁrst stage tend to obscure the interplay 
of the basic constructors used in the language. One of our main goals was
to isolate a core fragment of SPARQL simple enough to be the subject matter
of a formal analysis, but which is expressive enough to capture the core complexities 
of the language. In this direction, we chose the graph pattern matching
facility, which is additionally one of the most complex parts of the language. The
fragment isolated consists of the grammar of patterns restricted to queries on
one dataset (i.e. not considering the dataset graph pattern) over RDF without
vocabulary of RDF Schema and literals. There are other two sources of abstractions 
which do not alter in essential ways SPARQL: we use set semantics as
opposed to the bag semantics implied in the document of the W3C, and we
avoid blanks in the syntax of patterns, because in our fragment can be replaced
by variables [10, 5].

The contributions of this paper are:

– A streamlined version of the core fragment of SPARQL with precise Syntax
and Semantics. A formal version of SPARQL helps clarifying cases where
the current english-wording semantics gives little information, identify areas
of problems and permits to propose solutions.

– We present a compositional semantics for patterns in SPARQL, prove that
there is a notion of normal form for graph patterns in the fragment considered,
 and indicate optimization procedures and rules for the operators based
on them.

– We give thorough analysis of the computational complexity of the fragment.
Among other bounds, we prove that the complexity of evaluation of a general
graph pattern in SPARQL is PSPACE-complete even if we not consider ﬁlter
conditions.

– We formalize a natural procedural semantics which is implicitly used by developers.
 We compare these two semantics, the operational and the compositional 
mentioned above. We show that putting some slight and reasonable
syntactic restrictions on the scope of variables, they coincide, thus isolating 
a natural fragment having a clear semantics and an eﬃcient evaluation
procedure.

1.1 Related Work

Works on the SPARQL semantics. A rich source on the intended semantics of the
constructors of SPARQL are the discussions around W3C document [16], which
is still in the stage of Candidate Recommendation. Nevertheless, systematic and
comprehensive approaches to deﬁne the semantics are not present, and most of
the discussion is based on use cases.

Cyganiak [4] presents a relational model of SPARQL. The author uses relational 
algebra operators (join, left outer join, projection, selection, etc.) to model
SPARQL SELECT clauses. The central idea in [4] is to make a correspondence
between SPARQL queries and relational algebra queries over a single relation
T (S, P, O). Indeed a translation system between SPARQL and SQL is outlined.
The system needs extensive use of COALESCE and IS NULL operations to resemble
SPARQL features. The relational algebra operators and their semantics in [4]
are similar to our operators and have similar syntactic and semantic issues. With
diﬀerent motivations, but similar philosophy, Harris [12] presents an implementation 
of SPARQL queries in a relational database engine. He uses relational
algebra operators similar to [4]. This line of work, which models the semantics
of SPARQL based on the semantics of some relational operators, seems to be
very inﬂuent in the decisions on the W3C semantics of SPARQL.

De Bruin et al. [5] address the deﬁnition of mapping for SPARQL from a
logical point of view. It slightly diﬀers from the deﬁnition in [16] on the issue of
blank nodes. Although De Bruin et al.’s deﬁnition allows blank nodes in graph
patterns, it is similar to our deﬁnition which does not allow blanks in patterns.
In their approach, these blanks play the role of “non-distinguished” variables,
that is, variables which are not presented in the answer.

Franconi and Tessaris [6], in an ongoing work on the semantics of SPARQL,
formally deﬁne the solution for a basic graph pattern (an RDF graph with vari-
ables) as a set of partial functions. They also consider RDF datasets and several 
forms of RDF–entailment. Finally, they propose high level operators (J oin,
Optional, etc.) that take set of mappings and give set of mappings, but currently
they do not have formal deﬁnitions for them, stating only their types, i.e., the
domain and codomain.

Works on semantics of RDF query languages. There are several works on the
semantics of RDF query languages which tangentially touch the issues addressed
by SPARQL. Gutierrez et al. [10] discuss the basic issues of the semantics and
complexity of a conjunctive query language for RDF with basic patterns which
underlies the basic evaluation approach of SPARQL.

Haase et al. [11] present a comparison of functionalities of pre-SPARQL query
languages, many of which served as inspiration for the constructs of SPARQL.
There is, nevertheless, no formal semantics involved.

The idea of having an algebraic query language for RDF is not new. In
fact, there are several proposals. Chen et al. [3] present a set of operators for
manipulating RDF graphs, Frasincar et al. [7] study algebraic operators on the
lines of the RQL query language, and Robertson [17] introduces an algebra
of triadic relations for RDF. Although they evidence the power of having an
algebraic approach to query RDF, the frameworks presented in each of these
works makes not evident how to model with them the constructors of SPARQL.
Finally, Serﬁotis et al. [19] study RDFS query fragments using a logical framework,
 presenting results on the classical database problems of containment and
minimization of queries for a model of RDF/S. They concentrate on patterns
using the RDF/S vocabulary of classes and properties in conjunctive queries,
making the overlap with our fragment and approach almost empty.

Organization of the paper The rest of the paper is organized as follows. Section 
2 presents a formalized algebraic syntax and a compositional semantics for
SPARQL. Section 3 presents the complexity study of the fragment considered.
Section 4 presents and in depth discussion of graph patterns not including the
UNION operator. Finally, Section 5 presents some conclusions. Appendix A contains 
detailed proofs of all important results.

2 Syntax and Semantics of SPARQL

In this section, we give an algebraic formalization of the core fragment of SPARQL
over simple RDF, that is, RDF without RDFS vocabulary and literal rules. This
allows us to take a close look at the core components of the language and identify
some of its fundamental properties (for details on RDF formalization see [10],
or [15] for a complete reference including RDFS vocabulary).

Assume there are pairwise disjoint inﬁnite sets I, B, and L (IRIs, Blank
nodes, and RDF literals, respectively). A triple (v1, v2, v3) ∈ (I ∪ B) × I × (I ∪
B ∪ L) is called an RDF triple. In this tuple, v1 is the subject, v2 the predicate
and v3 the object. We denote by T the union I ∪ B ∪ L. Assume additionally the
existence of an inﬁnite set V of variables disjoint from the above sets.

Deﬁnition 1. An RDF graph [13] is a set of RDF triples. In our context, we
refer to an RDF graph as an RDF dataset, or simply a dataset.

2.1 Syntax of SPARQL graph pattern expressions

In order to avoid ambiguities in the parsing, we present the syntax of SPARQL
graph patterns in a more traditional algebraic way, using the binary operators
UNION, AND and OPT, and FILTER. We fully parenthesize expressions and
make explicit the left associativity of OPTIONAL and the precedence of AND over
OPTIONAL implicit in [16].

A SPARQL graph pattern expression is deﬁned recursively as follows:

(1) A tuple from (T ∪ V ) × (I ∪ V ) × (T ∪ V ) is a graph pattern (a triple pattern).
(2) If P1 and P2 are graph patterns, then expressions (P1 AND P2), (P1 OPT P2),

and (P1 UNION P2) are graph patterns.

(3) If P is a graph pattern and R is a SPARQL built-in condition, then the

expression (P FILTER R) is a graph pattern.

A SPARQL built-in condition is constructed using elements of the set V ∪ T and
constants, logical connectives (¬, ∧, ∨), inequality symbols (<, ≤, ≥, >), the
equality symbol (=), unary predicates like bound, isBlank, and isIRI, plus other
features (see [16] for a complete list).

In this paper, we restrict to the fragment of ﬁlters where the built-in condition

is a boolean combination of terms constructed by using = and bound, that is:

(1) If ?X, ?Y ∈ V and c ∈ I ∪ L, then bound(?X), ?X = c and ?X =?Y are

built-in conditions.

(2) If R1 and R2 are built-in conditions, then (¬R1), (R1 ∨ R2) and (R1 ∧ R2)

are built-in conditions.

Additionally, we assume that for (P FILTER R) the condition var(R) ⊆ var(P )
holds, where var(R) and var(P ) are the sets of variables occurring in R and
P , respectively. Variables in R not occurring in P bring issues that are not
computationally desirable. Consider the example of a built in condition R deﬁned
as ?X =?Y for two variables not occurring in P . What should be the result of
evaluating (P FILTER R)? We decide not to address this discussion here.

2.2 Semantics of SPARQL graph pattern expressions

To deﬁne the semantics of SPARQL graph pattern expressions, we need to introduce 
some terminology. A mapping µ from V to T is a partial function µ : V → T .
Abusing notation, for a triple pattern t we denote by µ(t) the triple obtained
by replacing the variables in t according to µ. The domain of µ, dom(µ), is the
subset of V where µ is deﬁned. Two mappings µ1 and µ2 are compatible when for
all x ∈ dom(µ1) ∩ dom(µ2), it is the case that µ1(x) = µ2(x), i.e. when µ1 ∪ µ2
is also a mapping. Note that two mappings with disjoint domains are always
compatible, and that the empty mapping (i.e. the mapping with empty domain)
µ∅ is compatible with any other mapping. Let Ω1 and Ω2 be sets of mappings.
We deﬁne the join of, the union of and the diﬀerence between Ω1 and Ω2 as:

Ω1 ⋊⋉ Ω2 = {µ1 ∪ µ2 | µ1 ∈ Ω1, µ2 ∈ Ω2 are compatible mappings},
Ω1 ∪ Ω2 = {µ | µ ∈ Ω1 or µ ∈ Ω2},
Ω1 r Ω2 = {µ ∈ Ω1 |

for all µ′ ∈ Ω2, µ and µ′ are not compatible}.

Based on the previous operators, we deﬁne the left outer-join as:

Ω1 Ω2 = (Ω1 ⋊⋉ Ω2) ∪ (Ω1 r Ω2).

We are ready to deﬁne the semantics of graph pattern expressions as a function
[[ · ]]D which takes a pattern expression an returns a set of mappings. We follow
the approach in [10] deﬁning the semantics as the set of mappings that matches
the dataset D. For simplicity, in this work we assume all datasets are already
lean, i.e. (for simple RDF graphs) this means they do not have redundancies,
which as is proved in [10], ensures that the property that for all patterns and
datasets, if D ≡ D′ then [[P ]]D = [[P ]]D′. This issue is not discussed in [16].

Deﬁnition 2. Let D be an RDF dataset over T , t a triple pattern and P1, P2
graph patterns. Then the evaluation of a graph pattern over D, denoted by [[ · ]]D,
is deﬁned recursively as follows:

(1) [[t]]D = {µ | dom(µ) = var(t) and µ(t) ∈ D}, where var(t) is the set of

variables occurring in t.

(2) [[(P1 AND P2)]]D = [[P1]]D ⋊⋉ [[P2]]D .
[[P2]]D.
(3) [[(P1 OPT P2)]]D = [[P1]]D
(4) [[(P1 UNION P2)]]D = [[P1]]D ∪ [[P2]]D.

The semantics of FILTER expressions goes as follows. Given a mapping µ and
a built-in condition R, we say that µ satisﬁes R, denoted by µ |= R, if:

(1) R is bound(?X) and ?X ∈ dom(µ);
(2) R is ?X = c, ?X ∈ dom(µ) and µ(?X) = c;
(3) R is ?X =?Y , ?X ∈ dom(µ), ?Y ∈ dom(µ) and µ(?X) = µ(?Y );
(4) R is (¬R1), R1 is a built-in condition, and it is not the case that µ |= R1;
(5) R is (R1 ∨ R2), R1 and R2 are built-in conditions, and µ |= R1 or µ |= R2;
(6) R is (R1 ∧ R2), R1 and R2 are built-in conditions, µ |= R1 and µ |= R2.

Deﬁnition 3. Given an RDF dataset D and a FILTER expression (P FILTER R),

[[(P FILTER R)]]D = {µ ∈ [[P ]]D | µ |= R}.

Example 1. Consider the RDF dataset D:

D = { (B1, name,
(B2, name,
(B3, name,
(B4, name,
(B4, webPage, www.starr.edu),

paul),
john),
george),
ringo),

777-3426),
john@acd.edu),

(B1, phone,
(B2, email,
(B3, webPage, www.george.edu),
(B4, email,
(B4, phone,

ringo@acd.edu),
888-4537),

}

The following are graph pattern expressions and their evaluations over D according 
to the above semantics:

(1) P1 = ((?A, email, ?E) OPT (?A, webPage, ?W )). Then

[[P1]]D =

?A

?E

?W

µ1 : B2 john@acd.edu
µ2 : B4 ringo@acd.edu www.starr.edu

(2) P2 = (((?A, name, ?N ) OPT (?A, email, ?E)) OPT (?A, webPage, ?W )).

Then

[[P2]]D =

?E

?A ?N
µ1 : B1 paul
µ2 : B2
www.george.edu
µ3 : B3 george
µ4 : B4 ringo ringo@acd.edu www.starr.edu

john john@acd.edu

?W

(3) P3 = ((?A, name, ?N ) OPT ((?A, email, ?E) OPT (?A, webPage, ?W ))).

Then

[[P3]]D =

?E

?A ?N
µ1 : B1 paul
µ2 : B2 john john@acd.edu
µ3 : B3 george
µ4 : B4 ringo ringo@acd.edu www.starr.edu

?W

Note the diﬀerence between [[P2]]D and [[P3]]D. These two examples show
that [[((A OPT B) OPT C)]]D 6= [[(A OPT (B OPT C))]]D in general.

(4) P4 = ((?A, name, ?N ) AND ((?A, email, ?E) UNION (?A, webPage, ?W ))).

Then

[[P4]]D =

?A ?N

?E

?W

john john@acd.edu

µ1 : B2
µ2 : B3 george
µ3 : B4 ringo ringo@acd.edu
µ4 : B4 ringo

www.george.edu

www.starr.edu

(5) P5 = (((?A, name, ?N ) OPT (?A, phone, ?P )) FILTER ?P =777-3426).

Then

[[P5]]D =

?A ?N

?P

µ1 : B1 paul 777-3426

2.3 A simple normal form for graph patterns

We say that two graph pattern expressions P1 and P2 are equivalent, denoted
by P1 ≡ P2, if [[P1]]D = [[P2]]D for every RDF dataset D.

Proposition 1. Let P1, P2 and P3 be graph pattern expressions and R a built-in
condition. Then:

(1) AND and UNION are associative and commutative.
(2) (P1 AND (P2 UNION P3)) ≡ ((P1 AND P2) UNION (P1 AND P3)).
(3) (P1 OPT (P2 UNION P3)) ≡ ((P1 OPT P2) UNION (P1 OPT P3)).
(4) ((P1 UNION P2) OPT P3) ≡ ((P1 OPT P3) UNION (P2 OPT P3)).
(5) ((P1 UNION P2) FILTER R) ≡ ((P1 FILTER R) UNION (P2 FILTER R)).

The application of the above equivalences permits to translate any graph pattern
into an equivalent one of the form:

P1 UNION P2 UNION P3 UNION · · · UNION Pn,

(1)

where each Pi (1 ≤ i ≤ n) is a UNION-free expression. In Section 4, we study
UNION-free graph pattern expressions.

3 Complexity of Evaluating Graph Pattern Expressions

A fundamental issue in any query language is the complexity of query evaluation
and, in particular, what is the inﬂuence of each component of the language in this
complexity. In this section, we address these issues for graph pattern expressions.
As it is customary when studying the complexity of the evaluation problem
for a query language, we consider its associated decision problem. We denote
this problem by Evaluation and we deﬁne it as follows:

INPUT
QUESTION : Is µ ∈ [[P ]]D?

: An RDF dataset D, a graph pattern P and a mapping µ.

We start this study by considering the fragment consisting of graph pattern
expressions constructed by using only AND and FILTER operators. This simple
fragment is interesting as it does not use the two most complicated operators in
SPARQL, namely UNION and OPT. Given an RDF dataset D, a graph pattern
P in this fragment and a mapping µ, it is possible to eﬃciently check whether
µ ∈ [[P ]]D by using the following algorithm. First, for each triple t in P , verify
whether µ(t) ∈ D. If this is not the case, then return false. Otherwise, by using
a bottom-up approach, verify whether the expression generated by instantiating
the variables in P according to µ satisﬁes the FILTER conditions in P . If this
is the case, then return true, else return false. Thus, we conclude that:

Theorem 1. Evaluation can be solved in time O(|P | · |D|) for graph pattern
expressions constructed by using only AND and FILTER operators.

We continue this study by adding to the above fragment the UNION operator.
It is important to notice that the inclusion of UNION in SPARQL is one of the
most controversial issues in the deﬁnition of this language. In fact, in the W3C
candidate recommendation for SPARQL [16], one can read the following: “The
working group decided on this design and closed the disjunction issue without
reaching consensus. The objection was that adding UNION would complicate
implementation and discourage adoption”. In the following theorem, we show
that indeed the inclusion of UNION operator makes the evaluation problem for
SPARQL considerably harder:

Theorem 2. Evaluation is NP-complete for graph pattern expressions constructed 
by using only AND, FILTER and UNION operators.

We conclude this study by adding to the above fragments the OPT operator.
This operator is probably the most complicated in graph pattern expressions
and, deﬁnitively, the most diﬃcult to deﬁne. The following theorem shows that
the evaluation problem becomes even harder if we include the OPT operator:

Theorem 3. Evaluation is PSPACE-complete for graph pattern expressions.

It is worth mentioning that in the proof of Theorem 3, we actually show that
Evaluation remains PSPACE-complete if we consider expressions without FILTER 
conditions, showing that the main source of complexity in SPARQL comes
from the combination of UNION and OPT operators.

When verifying whether µ ∈ [[P ]]D, it is natural to assume that the size of P
is considerably smaller that the size of D. This assumption is very common when
studying the complexity of a query language. In fact, it is named data-complexity
in the database literature [20] and it is deﬁned as the complexity of the evaluation
problem for a ﬁxed query. More precisely, for the case of SPARQL, given a graph
pattern expression P , the evaluation problem for P , denoted by Evaluation(P ),
has as input an RDF dataset D and a mapping µ, and the problem is to verify
whether µ ∈ [[P ]]D. From known results for the data-complexity of ﬁrst-order
logic [20], it is easy to deduce that:

Theorem 4. Evaluation(P ) is in LOGSPACE for every graph pattern expression 
P .

4 On the Semantics of UNION-free Pattern Expressions

The exact semantics of graph pattern expressions has been largely discussed on
the mailing list of the W3C. There seems to be two main approaches proposed to
compute answers to a graph pattern expression P . The ﬁrst uses an operational
semantics and consists essentially in the execution of a depth-ﬁrst traversal of
the parse tree of P and the use of the intermediate results to avoid some computations.
 This approach is the one followed by ARQ [1] (a language developed by
HPLabs) in the cases we test, and by the W3C when evaluating graph pattern
expressions containing nested optionals [18]. For instance, the computation of
the mappings satisfying (A OPT (B OPT C)) is done by ﬁrst computing the
mappings that match A, then checking which of these mappings match B, and
for those who match B checking whether they also match C [18]. The second
approach, compositional in spirit and the one we advocate here, extends classical
conjunctive query evaluation [10] and is based on a bottom up evaluation of the
parse tree, borrowing notions of relational algebra evaluation [4, 12] plus some
additional features.

As expected, there are queries for which both approaches do not coincide
(see Section 4.1 for examples). However, both semantics coincide in most of
the “real-life” examples. For instance, for all the queries in the W3C candidate
recommendation for SPARQL, both semantics coincide [16]. Thus, a natural
question is what is the exact relationship between the two approaches mentioned
above and, in particular, whether there is a “natural” condition under which
both approaches coincide. In this section, we address these questions: Section 4.1
formally introduces the depth-ﬁrst approach, discusses some issues concerning
it, and presents queries for which the two semantics do not coincide; Section 4.2
identiﬁes a natural and simple condition under which these two semantics are
equivalent; Section 4.3 deﬁnes a normal form and simple optimization procedures
for patterns satisfying the condition of Section 4.2

Based on the results of Section 2.3, we concentrate in the critical fragment

of UNION-free graph pattern expressions.

4.1 A depth-ﬁrst approach to evaluate graph pattern expressions

As we mentioned earlier, one alternative to evaluate graph pattern expressions
is based on a “greedy” approach that computes the mappings satisfying a graph
pattern expression P by traversing the parse tree of P in a depth-ﬁrst manner
and using the intermediate results to avoid some computations. This evaluation
includes at each stage three parameters: the dataset, the subtree pattern of P to
be evaluated, and a set of mappings already collected. Formally, given an RDF
dataset D, the evaluation of pattern P with the set of mappings Ω, denoted by
Eval D(P, Ω), is a recursive function deﬁned as follows:

EvalD(P : graph pattern expression, Ω: set of mappings)

if Ω = ∅ then return(∅)
if P is a triple pattern t then return(Ω ⋊⋉ [[t]]D)
if P = (P1 AND P2) then return Eval D(P2, Eval D(P1, Ω))
if P = (P1 OPT P2) then return Eval D(P1, Ω)
if P = (P1 FILTER R) then return {µ ∈ Eval D(P1, Ω) | µ |= R}

Eval D(P2, Eval D(P1, Ω))

Then, the evaluation of P against a dataset D, which we denote simply by
Eval D(P ), is Eval D(P, {µ∅}), where µ∅ is the mapping with empty domain.

Example 2. Assume that P = (t1 OPT (t2 OPT t3)), where t1, t2 and t3
are triple patterns. To compute Eval D(P ), we invoke function Eval D(P, {µ∅}).
This function in turn invokes function Eval D(t1, {µ∅}), which returns [[t1]]D
since t1 is a triple pattern and [[t1]]D ⋊⋉ {µ∅} = [[t1]]D, and then it invokes
Eval D((t2 OPT t3), [[t1]]D). As in the previous case, Eval D((t2 OPT t3), [[t1]]D)
ﬁrst invokes Eval D(t2, [[t1]]D), which returns [[t1]]D ⋊⋉ [[t2]]D since t2 is a triple
pattern, and then it invokes Eval D(t3, [[t1]]D ⋊⋉ [[t2]]D). Since t3 is a triple pattern,
 the latter invocation returns [[t1]]D ⋊⋉ [[t2]]D ⋊⋉ [[t3]]D. Thus, by the definition 
of Eval D we have that Eval D((t2 OPT t3), [[t1]]D) returns ([[t1]]D ⋊⋉
[[t2]]D)

([[t1]]D ⋊⋉ [[t2]]D ⋊⋉ [[t3]]D). Therefore, Eval D(P ) returns

[[t1]]D

(cid:0)([[t1]]D ⋊⋉ [[t2]]D)

([[t1]]D ⋊⋉ [[t2]]D ⋊⋉ [[t3]]D)(cid:1).

Note that the previous result coincides with the evaluation algorithm proposed
by the W3C for graph pattern (t1 OPT (t2 OPT t3)) [18], as we ﬁrst compute
the mappings that match t1, then we check which of these mappings match
t2, and for those who match t2 we check whether they also match t3. Also
note that the result of Eval D(P ) is not necessarily the same as [[P ]]D since
[[t3]]D). In Example 3 we actually
[[(t1 OPT (t2 OPT t3))]]D = [[t1]]D
show a case where the two semantics do not coincide.

([[t2]]D

Some issues on the depth-ﬁrst approach There are two relevant issues to consider 
when using the depth-ﬁrst approach to evaluate SPARQL queries. First,
this approach is not compositional. For instance, the result of Eval D(P ) cannot 
in general be used to obtain the result of Eval D((P ′ OPT P )), or even
the result of Eval D((P ′ AND P )), as Eval D(P ) results from the computation

of Eval D(P, {µ∅}) while Eval D((P ′ OPT P )) results from the computation of
Ω = Eval D(P ′, {µ∅}) and Eval D(P, Ω). This can become a problem in cases
of data integration where global answers are obtained by combining the results
from several data sources; or when storing some pre–answered queries in order
to obtain the results of more complex queries by composition. Second, under the
depth-ﬁrst approach some natural properties of widely used operators do not
hold, which may confuse some users. For example, it is not always the case that
Eval D((P1 AND P2)) = Eval D((P2 AND P1)), violating the commutativity of
the conjunction and making the result to depend on the order of the query.

Example 3. Let D be the RDF dataset shown in Example 1 and consider the pattern 
P = ((?X, name, paul) OPT ((?Y, name, george) OPT (?X, email, ?Z))).
Then [[P ]]D = { {?X → B1} }, that is, [[P ]]D contains only one mapping.
On the other hand, following the recursive deﬁnition of Eval D we obtain that
Eval D(P ) = { {?X → B1, ?Y → B3} }, which is diﬀerent from [[P ]]D.

Example 4 (Not commutativity of AND). Let D be the RDF dataset in Example
1, P1 = ((?X, name, paul) AND ((?Y, name, george) OPT (?X, email, ?Z)))
and P2 = (((?Y, name, george) OPT (?X, email, ?Z)) AND (?X, name, paul)).
Then Eval D(P1) = { {?X → B1, ?Y → B3} } while Eval D(P2) = ∅. Using the
compositional semantics, we obtain [[P1]]D = [[P2]]D = ∅.

Let us mention that ARQ [1] gives the same non-commutative evaluation.

4.2 A natural condition ensuring [[P ]]D = Eval D(P )

If for a pattern P we have that [[P ]]D = Eval D(P ) for every RDF dataset D,
then we have the best of both worlds for P as the compositional approach gives
a formal semantics to P while the depth-ﬁrst approach gives an eﬃcient way of
evaluating it. Thus, it is desirable to identify natural syntactic conditions on P
ensuring [[P ]]D = Eval D(P ). In this section, we introduce one such condition.

One of the most delicate issues in the deﬁnition of a semantics for graph
pattern expressions is the semantics of OPT operator. A careful examination of
the conﬂicting examples reveals a common pattern: A graph pattern P mentions
an expression P ′ = (P1 OPT P2) and a variable ?X occurring both in P2 and
outside P ′ but not occurring in P1. For instance, in the graph pattern expression
shown in Example 3:

P = ((?X, name, paul) OPT ((?Y, name, george) OPT (?X, email, ?Z))),

the variable ?X occurs both in the optional part of the sub-pattern P ′ = ((?Y ,
name, george) OPT (?X, email, ?Z)) and outside P ′ in the triple (?X, name,
paul), but it is not mentioned in (?Y , name, george).

What is unnatural about graph pattern P is the fact that (?X, email, ?Z) is
giving optional information for (?X, name, paul) but in P appears as giving optional 
information for (?Y, name, george). In general, graph pattern expressions
having the condition mentioned above are not natural. In fact, no queries in the
W3C candidate recommendation for SPARQL [16] exhibit this condition. This
motivates the following deﬁnition:

Deﬁnition 4. A graph pattern P is well designed if for every occurrence of a
sub-pattern P ′ = (P1 OPT P2) of P and for every variable ?X occurring in P ,
the following condition holds:

if ?X occurs both in P2 and outside P ′, then it also occurs in P1.

Graph pattern expressions that are not well designed are shown in Examples 3
and 4. For all these patterns, the two semantics diﬀer. The next result shows
a fundamental property of well-designed graph pattern expressions, and is a
welcome surprise as a very simple restriction on graph patterns allows the users
of SPARQL to alternatively use any of the two semantics shown in this section:

Theorem 5. Let D be an RDF dataset and P a well-designed graph pattern
expression. Then Eval D(P ) = [[P ]]D.

4.3 Well-designed patterns and normalization

Due to the evident similarity between certain operators of SPARQL and relational 
algebra, a natural question is whether the classical results of normal forms
and optimization in relational algebra are applicable in the SPARQL context.
The answer is not straightforward, at least for the case of optional patterns and
its relational counterpoint, the left outer join. The classical results about outer
join query reordering and optimization by Galindo-Legaria and Rosenthal [8] are
not directly applicable in the SPARQL context because they assume constraints
on the relational queries that are rarely found in SPARQL. The ﬁrst and more
problematic issue, is the assumption on predicates used for joining (outer join-
ing) relations to be null-rejecting [8]. In SPARQL, those predicates are implicit
in the variables that the graph patterns share and by the deﬁnition of compatible
mappings they are never null-rejecting. In [8] the queries are also enforced not to
contain Cartesian products, situation that occurs often in SPARQL when joining
graph patterns that do not share variables. Thus, speciﬁc techniques must be
developed in the SPARQL context.

In what follows we show that the property of a pattern being well designed
has important consequences for the study normalization and optimization for a
fragment of SPARQL queries. We will restrict in this section to graph patterns
without FILTER.

We start with equivalences that hold between sub-patterns of well-designed

graph patterns.

Proposition 2. Given a well-designed graph pattern P , if the left hand sides of
the following equations are sub-patterns of P , then:

(P1 AND (P2 OPT P3)) ≡ ((P1 AND P2) OPT P3),
((P1 OPT P2) OPT P3) ≡ ((P1 OPT P3) OPT P2).

(2)

(3)

Moreover, in both equivalences, if one replaces in P the left hand side by the
right hand side, then the resulting pattern is still well designed.

From this proposition plus associativity and commutativity of AND, it follows:

Theorem 6. Every well-designed graph pattern P is equivalent to a pattern in
the following normal form:

(· · · (t1 AND · · · AND tk) OPT O1) OPT O2) · · · ) OPT On),

(4)

where each ti is a triple pattern, n ≥ 0 and each Oj has the same form (4).

The proof of the theorem is based on term rewriting techniques. The next example 
shows the beneﬁts of using the above normal form.

Example 5. Consider dataset D of Example 1 and well-designed pattern P =
(((?X, name, ?Y ) OPT (?X, email, ?E)) AND (?X, phone, 888-4537)). The normalized 
form of P is P ′ = (((?X, name, ?Y ) AND (?X, phone, 888-4537)) OPT
(?X, email, ?E)). The advantage of evaluating P ′ over P follows from a simple
counting of maps.

Two examples of implicit use of the normal form. There are implementations
(not ARQ[1]) that do not permit nested optionals, and when evaluating a pattern 
they ﬁrst evaluate all patterns that are outside optionals and then extend
the results with the matchings of patterns inside optionals. That is, they are
implicitly using the normal form mentioned above. In [4], when evaluating a
graph pattern with relational algebra, a similar assumption is made. First the
join of all triple patterns is evaluated, and then the optional patterns are taken
into account. Again, this is an implicit use of the normal form.

5 Conclusions

The query language SPARQL is in the process of standardization, and in this
process the semantics of the language plays a key role. A formalization of a semantics 
will be beneﬁcial on several grounds: help identify relationships among
the constructors that stay hidden in the use cases, identify redundant and contradicting 
notions, study the expressiveness and complexity of the language, help
in optimization, etc.

In this paper, we provided such a formal semantics for the graph pattern
matching facility, which is the core of SPARQL. We isolated a fragment which
is rich enough to present the main issues and favor a good formalization. We
presented a formal semantics, made observations to the current syntax based
on it, and proved several properties of it. We did a complexity analysis showing
that unlimited used of OPT could lead to high complexity, namely PSPACE.
We presented an alternative formal procedural semantics which closely resembles 
the one used by most developers. We proved that under simple syntactic
restrictions both semantics are equivalent, thus having the advantages of a formal
compositional semantics and the eﬃciency of a procedural semantics. Finally, we
discussed optimization based on relational algebra and show limitations based

on features of SPARQL. On these lines, we presented optimizations based on
normal forms.

Further work should concentrate on the extensions of these ideas to the whole
language and particularly to the extension –that even the current speciﬁcation
of SPARQL lacks– to RDF Schema.

References

1. ARQ - A SPARQL Processor for Jena, version 1.3 March 2006, Hewlett-Packard

Development Company. http://jena.sourceforge.net/ARQ.

2. F. Baader, T. Nipkow, Term Rewriting and all that, Cambridge, 1999.
3. L. Chen, A. Gupta and M. E. Kurul. A Semantic-aware RDF Query Algebra. In

COMAD 2005.

4. R. Cyganiak. A Relational Algebra for Sparql. HP-Labs Technical Report, HPL-

2005-170. http://www.hpl.hp.com/techreports/2005/HPL-2005-170.html.

5. J. de Bruijn, E. Franconi, S. Tessaris. Logical Reconstruction of normative RDF.

In OWLED 2005, Galway, Ireland, November 2005

6. E. Franconi and S. Tessaris. The Sematics of SPARQL. Working Draft 2 November

2005. http://www.inf.unibz.it/krdb/w3c/sparql/.

7. F. Frasincar, C. Houben, R. Vdovjak and P. Barna. RAL: An algebra for querying

RDF. In WISE 2002.

8. C. A. Galindo-Legaria and A. Rosenthal. Outerjoin Simpliﬁcation and Reordering

for Query Optimization. In TODS 22(1): 43–73, 1997.

9. M. Garey and D. Johnson. Computer and Intractability: A Guide to the Theory of

NP-Completeness. W. H. Freeman 1979.

10. C. Gutierrez, C. Hurtado and A. Mendelzon. Foundations of Semantic Web

Databases. In PODS 2004, pages 95–106.

11. P. Haase, J. Broekstra, A. Eberhart and R. Volz. A Comparison of RDF Query

Languages. In ISWC 2004, pages 502–517.

12. S. Harris. Sparql query processing with conventional relational database systems.

In SSWS 2005.

13. G. Klyne, J. J. Carroll and B. McBride.

Resource Description Framework 
(RDF): Concepts and Abstract Syntax. W3C Rec. 10 February 2004.
http://www.w3.org/TR/rdf-concepts/.

14. F. Manola, E. Miller, B. McBride. RDF Primer, W3C Rec. 10 February 2004.
15. D. Marin. RDF Formalization, Santiago de Chile, 2004. Tech. Report Univ. Chile,

TR/DCC-2006-8. http://www.dcc.uchile.cl/~cgutierr/ftp/draltan.pdf

16. E. Prud’hommeaux and A. Seaborne. SPARQL Query Language for RDF. W3C

Candidate Rec. 6 April 2006. http://www.w3.org/TR/rdf-sparql-query/.

17. E. L. Robertson. Triadic Relations: An Algebra for the Semantic Web. In SWDB

2004, pages 91–108

18. A. Seaborne. Personal Communication. April 13, 2006.
19. G. Serﬁotis, I. Koﬃna, V. Christophides and V. Tannen. Containment and Minimization 
of RDF/S Query Patterns. In ISWC 2005, pages 607–623.

20. M. Vardi. The Complexity of Relational Query Languages (Extended Abstract). In

STOC 1982, pages 137–146.

A Proofs and Intermediate Results

A.1 Some technical results

Lemma 1. All the following equivalences hold:
(1) If P is a graph pattern and R1, R2 are built-in conditions such that var(R1) ⊆

var(P ) and var(R2) ⊆ var(P ), then

((P FILTER R1) FILTER R2) ≡ (P FILTER (R1 ∧ R2)),

(P FILTER (R1 ∨ R2)) ≡ ((P FILTER R1) UNION (P FILTER R2)).

(2) If P1 and P2 are conjunctions of triple patterns and R is a built-in condition

such that var(R) ⊆ var(P1), then

((P1 FILTER R) AND P2) ≡ ((P1 AND P2) FILTER R).

(1.1) Let D be an RDF database. Assume ﬁrst

∈
Proof:
[[((P FILTER R1) FILTER R2)]]D. Then µ ∈ [[(P FILTER R1)]]D and µ |= R2.
Thus, µ ∈ [[P ]]D, µ |= R1 and µ |= R2. Therefore, µ |= (R1 ∧ R2) and,
hence, we conclude that µ ∈ [[(P FILTER (R1 ∧ R2))]]D. Now assume that
µ ∈ [[(P FILTER (R1 ∧ R2))]]D. Then µ ∈ [[P ]]D and µ |= (R1 ∧ R2). Thus,
µ ∈ [[P ]]D, µ |= R1 and µ |= R2. We conclude that µ ∈ [[(P FILTER R1)]]D and,
therefore, given that µ |= R2, we have that µ ∈ [[((P FILTER R1) FILTER R2)]]D.
(1.2) Given an RDF database D, we have that:

that µ

[[(P FILTER (R1 ∨ R2))]]D = {µ ∈ [[P ]]D | µ |= (R1 ∨ R2)}

= {µ ∈ [[P ]]D | µ |= R1 or µ |= R2)}
= {µ ∈ [[P ]]D | µ |= R1} ∪ {µ ∈ [[P ]]D | µ |= R2)}
= [[(P FILTER R1)]]D ∪ [[(P FILTER R2)]]D

= [[((P FILTER R1) UNION (P FILTER R2))]]D.

ﬁrst

µ

Let D be

an RDF

that

database. Assume

∈
(2)
[[((P1 FILTER R) AND P2)]]D. Then there exist µ1 ∈ [[(P1 FILTER R)]]D
and µ2 ∈ [[P2]]D such that µ1 and µ2 are compatible and µ = µ1 ∪ µ2. Since
µ1 ∈ [[(P1 FILTER R)]]D, we have that µ1 ∈ [[P ]]D and µ1 |= R. Given that P1 is a
conjunction of triple patterns and var(R) ⊆ var(P1), we have that µ1(?X) is deﬁned
for every ?X ∈ var(R). Thus, given that µ1 |= R and µ1 is contained in µ, we conclude 
that µ |= R. Therefore, given that µ1 ∈ [[P1]]D and µ2 ∈ [[P2]]D, we have that
µ = µ1 ∪ µ2 ∈ [[(P1 AND P2)]]D and, hence, µ ∈ [[((P1 AND P2) FILTER R)]]D.
Now assume that µ ∈ [[((P1 AND P2) FILTER R)]]D. Then µ |= R and
µ ∈ [[(P1 AND P2)]]D and, therefore, there exist µ1 ∈ [[P1]]D and µ2 ∈ [[P2]]D
such that µ1 and µ2 are compatible and µ = µ1 ∪ µ2. Given that (P1 AND P2)
is a conjunction of triple patterns and var(R) ⊆ var(P1) ⊆ var((P1 AND P2)),
we have that µ(?X) is deﬁned for every ?X ∈ var(R). Moreover, given that
P1 is a conjunction of triple patterns and var(R) ⊆ var(P1), we have that
µ1(?X) = µ(?X) for every ?X ∈ var(R) and, hence, µ1 |= R. We deduce that
µ1 ∈ [[(P1 FILTER R)]]D and, hence, µ = µ1 ∪µ2 ∈ [[((P1 FILTER R) AND P2)]]D.
This concludes the proof of the equivalence of ((P1 FILTER R) AND P2) and
((P1 AND P2) FILTER R).
(cid:3)

Lemma 2. Let P be a UNION-free graph pattern expression. Then we have that

(P AND P ) ≡ P.

Proof: Next we show by induction on the structure of P that for every RDF
database D and pair of mappings µ1, µ2 ∈ [[P ]]D, if µ1 and µ2 are compatible,
then µ1 = µ2. It is easy to see that this condition implies that (P AND P ) ≡ P .
If P is a triple pattern, then the property trivially holds. Assume ﬁrst that P =
(P1 AND P2), where P1 and P2 satisfy the condition, that is, if ξ, ζ ∈ [[Pi]]D
(i = 1, 2) and ξ, ζ are compatible, then ξ = ζ. Let µ1 and µ2 be compatible
mappings in [[P ]]D. Then there exist ν1, ω1 ∈ [[P1]]D and ν2, ω2 ∈ [[P2]]D such
that µ1 = ν1 ∪ ω1 and µ2 = ν2 ∪ ω2. Given that µ1 and µ2 are compatible, we
have that ν1, ν2 are compatible and ω1, ω2 are compatible. Thus, by induction
hypothesis we have that ν1 = ν2 and ω1 = ω2 and, hence, µ1 = µ2. Second, assume
that P = (P1 OPT P2), and let µ1 and µ2 be compatible mappings in [[P ]]D. We
consider four cases.
(1) If there exist ν1, ω1 ∈ [[P1]]D and ν2, ω2 ∈ [[P2]]D such that µ1 = ν1 ∪ ω1 and
µ2 = ν2 ∪ ω2, then we conclude that µ1 = µ2 as in the case P = (P1 AND P2).
(2) If µ1, µ2 ∈ [[P1]]D and both are not compatible with any mapping in [[P2]]D,

then by induction hypothesis we conclude that µ1 = µ2.

(3) If µ1 ∈ [[P1]]D, µ1 is not compatible with any mapping in [[P2]]D, µ2 = ν2 ∪ ω2,
ν2 ∈ [[P1]]D and ω2 ∈ [[P2]]D, then given that µ1 and µ2 are compatible, we have
that µ1 and ν2 are compatible. Thus, by induction hypothesis we conclude that
µ1 = ν2 and, therefore, µ1 is compatible with ω2 ∈ [[P2]]D, which contradicts
our original assumption.

(4) If µ1 = ν1 ∪ ω1, ν1 ∈ [[P1]]D, ω1 ∈ [[P2]]D, µ2 ∈ [[P1]]D and µ2 is not compatible
with any mapping in [[P2]]D, then we obtain a contradiction as in the previous
case.

Finally, assume that P = (P1 FILTER R), where P1 satisfy the condition. Let µ1
and µ2 be compatible mappings in [[P ]]D. Then µ1 ∈ [[P1]]D, µ1 |= R, µ2 ∈ [[P2]]D,
µ2 |= R and, thus, µ1 = µ2 by induction hypothesis. This concludes the proof of
the lemma.
(cid:3)

A.2 Proof of Proposition 1

(1) Associative and commutative are consequences of the deﬁnitions of operators

AND and UNION.

(2) To

prove

that

(P1

(P2

P3))

AND

UNION

≡
((P1 AND P2) UNION (P1 AND P3)), we consider two cases. First, we show
that for every RDF database D, we have that [[(P1 AND (P2 UNION P3))]]D ⊆
[[((P1 AND P2) UNION (P1 AND P3))]]D. Assume that D is an RDF database
and that µ ∈ [[(P1 AND (P2 UNION P3))]]D. Then there exists µ1 ∈ [[P1]]D
and µ2 ∈ [[(P2 UNION P3)]]D such that µ1 and µ2 are compatible and
µ = µ1 ∪ µ2. If µ2 ∈ [[P2]]D, then we have that µ = µ1 ∪ µ2 ∈ [[(P1 AND P2)]]D
and, therefore, µ ∈ [[((P1 AND P2) UNION (P1 AND P3))]]D. Analogously, if
µ2 ∈ [[P3]]D, then we have that µ = µ1 ∪ µ2 ∈ [[(P1 AND P3)]]D and, therefore,
µ ∈ [[((P1 AND P2) UNION (P1 AND P3))]]D. Second, we prove that for every
RDF database D, we have that [[((P1 AND P2) UNION (P1 AND P3))]]D ⊆
[[(P1 AND (P2 UNION P3))]]D. Assume that D is an RDF database and that
µ ∈ [[((P1 AND P2) UNION (P1 AND P3))]]D. Then µ ∈ [[(P1 AND P2)]]D

(3) To

(P1

(P2

that

P3))

prove

UNION

or µ ∈ [[(P1 AND P3)]]D. If µ ∈ [[(P1 AND P2)]]D, then we conclude that
there exists µ1 ∈ [[P1]]D and µ2 ∈ [[P2]]D such that µ1 and µ2 are compatible
and µ = µ1 ∪ µ2. Since µ2 ∈ [[P2]]D, we have that µ2 ∈ [[(P2 UNION P3)]]D
and, hence, µ = µ1 ∪ µ2 ∈ [[(P1 AND (P2 UNION P3))]]D.
If
µ ∈ [[(P1 AND P3)]]D, then we conclude that there exists µ1 ∈ [[P1]]D
and µ3 ∈ [[P3]]D such that µ1 and µ3 are compatible and µ = µ1 ∪ µ3.
Since µ3 ∈ [[P3]]D, we have that µ3 ∈ [[(P2 UNION P3)]]D and,
therefore, µ = µ1 ∪ µ3 ∈ [[(P1 AND (P2 UNION P3))]]D. This concludes 
the proof of the equivalence of (P1 AND (P2 UNION P3)) and
((P1 AND P2) UNION (P1 AND P3)).
OPT

≡
((P1 OPT P2) UNION (P1 OPT P3)), we consider two cases. First, we show
that for every RDF database D, we have that [[(P1 OPT (P2 UNION P3))]]D ⊆
[[((P1 OPT P2) UNION (P1 OPT P3))]]D. Let D be an RDF database and
assume that µ ∈ [[(P1 OPT (P2 UNION P3))]]D. Then there exists
µ1 ∈ [[P1]]D such that either (a) there exists µ2 ∈ [[(P2 UNION P3)]]D
such that µ1 and µ2 are compatible and µ = µ1 ∪ µ2, or (b) there is
no µ2 ∈ [[(P2 UNION P3)]]D such that µ1 and µ2 are compatible and
µ = µ1. In case (a), if µ2 ∈ [[P2]]D, then µ = µ1 ∪ µ2 ∈ [[(P1 OPT P2)]]D,
and if µ2 ∈ [[P3]]D, then µ = µ1 ∪ µ2 ∈ [[(P1 OPT P3)]]D. In both
cases, we conclude that µ ∈ [[((P1 OPT P2) UNION (P1 OPT P3))]]D.
In case (b), we have that there is no µ2 ∈ [[P2]]D such that µ1 and µ2
are compatible and, hence, µ = µ1 ∈ [[(P1 OPT P2)]]D. We conclude that
µ ∈ [[((P1 OPT P2) UNION (P1 OPT P3))]]D. Second, we show that for every
RDF database D, we have that [[((P1 OPT P2) UNION (P1 OPT P3))]]D ⊆
[[(P1 OPT (P2 UNION P3))]]D. Let D be an RDF database and assume
that µ ∈ [[((P1 OPT P2) UNION (P1 OPT P3))]]D. Then there exists
µ1 ∈ [[P1]]D such that (a) there exists µ2 ∈ [[P2]]D such that µ1 and µ2 are
compatible and µ = µ1 ∪ µ2, or (b) there exists µ3 ∈ [[P3]]D such that µ1
and µ3 are compatible and µ = µ1 ∪ µ3, or (c) µ = µ1 and there is neither
µ2 ∈ [[P2]]D compatible with µ1 nor µ3 ∈ [[P3]]D compatible with µ1. In
case (a), given that µ2 ∈ [[P2]]D, we have that µ2 ∈ [[(P2 UNION P3)]]D
and, therefore, µ = µ1 ∪ µ2 ∈ [[(P1 OPT (P2 UNION P3))]]D. In case
(b), given that µ3 ∈ [[P3]]D, we have that µ3 ∈ [[(P2 UNION P3)]]D and,
therefore, µ = µ1 ∪ µ3 ∈ [[(P1 OPT (P2 UNION P3))]]D. Finally, in case (c)
we have that there is no µ′ ∈ [[(P2 UNION P3)]]D such that µ1 and µ′ are
compatible and, therefore, µ = µ1 ∈ [[(P1 OPT (P2 UNION P3))]]D. This
concludes the proof of the equivalence of (P1 OPT (P2 UNION P3)) and
((P1 OPT P2) UNION (P1 OPT P3)).

(4) To

that

for

P2)

((P1

prove

UNION

P3))
two

show that

OPT
consider

every RDF database D, we have

≡
cases.
((P1 OPT P3) UNION (P2 OPT P3)), we
First, we
that
[[((P1 UNION P2) OPT P3)]]D ⊆ [[((P1 OPT P3) UNION (P2 OPT P3))]]D. Let
D be an RDF database and assume that µ ∈ [[((P1 UNION P2) OPT P3)]]D.
Then either (a) there exist µ1 ∈ [[(P1 UNION P2)]]D and µ2 ∈ [[P3]]D such
that µ1 and µ2 are compatible and µ = µ1 ∪ µ2, or (b) µ ∈ [[(P1 UNION P2)]]D
and there is no µ3 ∈ [[P3]]D such that µ and µ3 are compatible. In case
(a), if µ1 ∈ [[P1]]D, then µ = µ1 ∪ µ2 ∈ [[(P1 OPT P3)]]D. In case (a), if
µ1 ∈ [[P2]]D, then µ = µ1 ∪ µ2 ∈ [[(P2 OPT P3)]]D. In case (b), if µ ∈ [[P1]]D,
then µ ∈ [[(P1 OPT P3)]]D since µ is not compatible with any µ3 ∈ [[P3]]D. In

case (b), if µ ∈ [[P2]]D, then µ ∈ [[(P2 OPT P3)]]D since µ is not compatible
with any µ3 ∈ [[P3]]D. In any of the previous cases, we conclude that
µ ∈ [[((P1 OPT P3) UNION (P2 OPT P3))]]D. Second, we show that for every
RDF database D, we have that [[((P1 OPT P3) UNION (P2 OPT P3))]]D ⊆
[[((P1 UNION P2) OPT P3))]]D. Let D be an RDF database and assume that
µ ∈ [[((P1 OPT P3) UNION (P2 OPT P3))]]D. Without loss of generality, we
assume that µ ∈ [[(P1 OPT P3)]]D. Then either (a) there exists µ1 ∈ [[P1]]D
and µ2 ∈ [[P3]]D such that µ1 and µ2 are compatible and µ = µ1 ∪ µ2,
or (b) µ ∈ [[P1]]D and there is no µ3 ∈ [[P3]]D such that µ and µ3 are
compatible. In case (a), we have that µ1 ∈ [[(P1 UNION P2)]]D and, hence,
µ = µ1 ∪ µ2 ∈ [[((P1 UNION P2) OPT P3)]]D. In case (b), we have that
µ ∈ [[(P1 UNION P2)]]D and, therefore, µ ∈ [[((P1 UNION P2) OPT P3)]]D
since µ is not compatible with any µ3 ∈ [[P3]]D. This concludes
the proof of
equivalence of
((P1 UNION P2) OPT P3) and
((P1 OPT P3) UNION (P2 OPT P3)).

the

(5) Clearly,

for every RDF database D and built-in condition R, we have
that {µ ∈ [[P1]]D | µ |= R} ⊆ {µ ∈ [[(P1 UNION P2)]]D | µ |= R}
and {µ ∈ [[P2]]D | µ |= R} ⊆ {µ ∈ [[(P1 UNION P2)]]D | µ |= R}
since [[P1]]D ⊆ [[(P1 UNION P2)]]D and [[P2]]D ⊆ [[(P1 UNION P2)]]D.
Thus, we only need to show that for every RDF database D and builtit 
is the case that [[((P1 UNION P2) FILTER R)]]D ⊆
in condition R,
[[((P1 FILTER R) UNION (P2 FILTER R))]]D. Assume that µ ∈
[[((P1 UNION P2) FILTER R)]]D. Then µ ∈ [[(P1 UNION P2)]]D and
µ |= R. Thus,
if µ ∈ [[P1]]D, then µ ∈ [[(P1 FILTER R)]]D, and if
µ ∈ [[P2]]D, then µ ∈ [[(P2 FILTER R)]]D. Therefore, we conclude that
µ ∈ [[((P1 FILTER R) UNION (P2 FILTER R))]]D.

A.3 Proof of Theorem 2

It is straightforward to prove that Evaluation is in NP for the case of graph pattern 
expressions constructed by using only AND, UNION and FILTER operators.
To prove the NP-hardness of Evaluation for this case, we show how to reduce
in polynomial time the satisﬁability problem for propositional formulas in CNF
(SAT-CNF) to our problem. An instance of SAT-CNF is a propositional formula
ϕ of the form:

C1 ∧ . . . ∧ Cn,

where each Ci (i ∈ [1, n]) is a clause, that is, a disjunction of propositional variables
and negations of propositional variables. Then the problem is to verify whether
there exists a truth assignment satisfying ϕ. It is known that SAT-CNF is NPcomplete 
[9].
In the reduction from SAT-CNF, we use a ﬁxed RDF database:

D = {(a, b, c)}

Assume that x1, . . ., xm is the list of propositional variables mentioned in ϕ. For
each xi (i ∈ [1, m]), we use SPARQL variables ?Xi, ?Yi to represent xi and ¬xi,
respectively. Then for each clause C in ϕ of the form:

xi1 ∨ · · · xik ∨ ¬xj1 ∨ · · · ¬xjℓ ,

we deﬁne a graph pattern PC as:

((a, b, ?Xi1 ) UNION · · · UNION (a, b, ?Xik ) UNION

(a, b, ?Yj1 ) UNION · · · UNION (a, b, ?Yjℓ )),

and we deﬁne a graph pattern Pϕ for ϕ as:

(P AND ((PC1 AND · · · AND PCn ) FILTER R)),

where:

P = ((a, b, ?X1) AND · · · AND (a, b, ?Xm) AND

(a, b, ?Y1) AND · · · AND (a, b, ?Ym)),

R = ((¬ bound(?X1) ∨ ¬ bound(?Y1)) ∧ · · · ∧ (¬ bound(?Xm) ∨ ¬ bound(?Ym))).

Let µ = {?X1 → c, . . . , ?Xm → c, ?Y1 → c, . . . , ?Ym → c}. Then it is straightforward 
to prove that ϕ is satisﬁable if and only if µ ∈ [[Pϕ]]D.

A.4 Proof of Theorem 3

Membership in PSPACE is a corollary of the membership in PSPACE of the evaluation 
problem for ﬁrst-order logic [20].
To prove the PSPACE-hardness of Evaluation for the case of graph pattern expressions 
not containing FILTER conditions, we show how to reduce in polynomial
time the quantiﬁed boolean formula problem (QBF) to our problem. An instance
of QBF is a quantiﬁed propositional formula ϕ of the form:

∀x1∃y1∀x2∃y2∀x3∃y3 · · · ∀xm∃ym ψ,

where ψ is a quantiﬁer-free formula of the form C1∧. . .∧Cn, with each Ci (i ∈ [1, n])
being a disjunction of literals, that is, a disjunction of propositional variables and
negations of propositional variables. Then the problem is to verify whether ϕ is
valid. It is known that QBF is PSPACE-complete [9].
In the reduction from QBF, we use a ﬁxed RDF database:

D = {(a, tv, 0), (a, tv, 1), (a, false, 0), (a, true, 1)}.

Then for each clause C in ψ of the form

(cid:18) k
_i=1

ui(cid:19) ∨(cid:18) ℓ
_j=1

¬vj(cid:19),

we deﬁne a graph pattern PC as:

((a, true, ?U1) UNION · · · UNION (a, true, ?Uk) UNION

(a, false, ?V1) UNION · · · UNION (a, false, ?Vℓ)),

and we deﬁne a graph pattern Pψ for ψ as:

(PC1 AND · · · AND PCn ).

It is easy to see that ψ is satisﬁable if and only if there exists a mapping µ ∈ [[Pψ]]D.
In particular, for each mapping µ, there exists a truth assignment σµ deﬁned as
σµ(x) = µ(?X) for every variable x in ψ, such that µ ∈ [[Pψ]]D if and only if σµ
satisﬁes ψ.
Now we explain how we represent quantiﬁed propositional formula ϕ as a graph
pattern expression Pϕ. We use SPARQL variables ?X1, . . ., ?Xm and ?Y1, . . ., ?Ym
to represent propositional variables x1, . . ., xm and y1, . . ., ym, respectively, and we
use SPARQL variables ?A0, ?A1, . . ., ?Am, ?B0, ?B1, . . ., ?Bm and operators OPT
and AND to represent the quantiﬁer sequence ∀x1∃y1 · · · ∀xm∃ym. More precisely,
for every i ∈ [1, m], we deﬁne graph pattern expressions Pi and Qi as follows:

Pi

:= (cid:0)(a, tv, ?X1) AND · · · AND (a, tv, ?Xi) AND

(a, tv, ?Y1) AND · · · AND (a, tv, ?Yi−1) AND

Qi

(a, false, ?Ai−1) AND (a, true, ?Ai)(cid:1),

:= (cid:0)(a, tv, ?X1) AND · · · AND (a, tv, ?Xi) AND

(a, tv, ?Y1) AND · · · AND (a, tv, ?Yi) AND

and then we deﬁne Pϕ as:

(a, false, ?Bi−1) AND (a, true, ?Bi)(cid:1),

((a, true, ?B0) OPT (P1 OPT (Q1 OPT (P2 OPT (Q2 OPT ( · · ·

(Pm OPT (Qm AND Pψ)) · · · )))))),

Next we show that we can use graph expression Pϕ to check whether ϕ is valid.
More precisely, we show that ϕ is valid if and only if µ ∈ [[Pϕ]]D, where µ is a
mapping such that dom(µ) = {?B0} and µ(?B0) = 1.
(⇐) Assume that µ ∈ [[Pϕ]]D. It is easy to see that [[P1]]D = {µ0, µ1}, where
µ0 = {?X1 → 0, ?A0 → 0, ?A1 → 1} and µ1 = {?X1 → 1, ?A0 → 0, ?A1 → 1}.
Thus, given that these two mappings are compatible with µ and that µ ∈ [[Pϕ]]D,
there exist mappings ν0 and ν1 in [[Q1]]D such that µ0, ν0 are compatible, µ1, ν1
are compatible and

µ0 ∪ ν0 ∈ [[(P1 OPT (Q1 OPT (P2 OPT (Q2 OPT ( · · ·

Pm OPT (Qm AND Pψ)) · · · )))))]]D,

(5)

µ1 ∪ ν1 ∈ [[(P1 OPT (Q1 OPT (P2 OPT (Q2 OPT ( · · ·

(Pm OPT (Qm AND Pψ)) · · · )))))]]D.

(6)

We note that ν0(?X1) = µ0(?X1) = 0, ν1(?X1) = µ1(?X1) = 0 and ν0(?Y1),
ν1(?Y1) are not necessarily distinct.
Since P1 mentions triple (a, true, ?A1) and P2 mentions triple (a, false, ?A1), there
is no mapping in [[P1]]D compatible with some mapping in [[P2]]D. Furthermore,
since Q1 mentions (a, true, ?B1) and Q2 mentions triple (a, false, ?B1), there is
no mapping in [[Q1]]D compatible with some mapping in [[Q2]]D. Thus, given that
(5) holds, for every mapping ζ ∈ [[P2]]D, we have that if ν0 and ζ are compatible,
then there exist ξ ∈ [[Q2]]D such that ζ and ξ are compatible and

ζ ∪ ξ ∈ [[(P2 OPT (Q2 OPT ( · · · (Pm OPT (Qm AND Pψ)) · · · )))]]D.

There are two mappings in [[P2]]D which are compatible with ν0:

µ00 = {?X1 → 0, ?X2 → 0, ?Y1 → ν0(?Y1), ?A1 → 0, ?A2 → 1},
µ01 = {?X1 → 0, ?X2 → 1, ?Y1 → ν0(?Y1), ?A1 → 0, ?A2 → 1}.

Thus, from the previous discussion we conclude that there exist mappings ν00 and
ν01 such that µ00, ν00 are compatible, µ01, ν01 are compatible and

µ00 ∪ ν00 ∈ [[(P2 OPT (Q2 OPT ( · · · (Pm OPT (Qm AND Pψ)) · · · )))]]D,
µ01 ∪ ν01 ∈ [[(P2 OPT (Q2 OPT ( · · · (Pm OPT (Qm AND Pψ)) · · · )))]]D.

Similarly, there are two mapping in [[P2]]D which are compatible with ν1:

µ10 = {?X1 → 1, ?X2 → 0, ?Y1 → ν1(?Y1), ?A1 → 0, ?A2 → 1},
µ11 = {?X1 → 1, ?X2 → 1, ?Y1 → ν1(?Y1), ?A1 → 0, ?A2 → 1}.

Thus, given that (6) holds, we conclude that there exist mappings ν10 and ν11 such
that µ10, ν10 are compatible, µ11, ν11 are compatible and

µ10 ∪ ν10 ∈ [[(P2 OPT (Q2 OPT ( · · · (Pm OPT (Qm AND Pψ)) · · · )))]]D,
µ11 ∪ ν11 ∈ [[(P2 OPT (Q2 OPT ( · · · (Pm OPT (Qm AND Pψ)) · · · )))]]D.

If we continue in this fashion, we conclude that for every i ∈ [2, m − 1] and
n1 · · · ni ∈ {0, 1}i, and for the following mappings in [[Pi+1]]D:

µn1 ···ni0 = {?X1 → n1, . . . , ?Xi → ni, ?Xi+1 → 0,

?Y1 → νn1 (?Y1), . . . , ?Yi → νn1···ni (?Yi), ?Ai−1 → 0, ?Ai → 1},

µn1 ···ni1 = {?X1 → n1, . . . , ?Xi → ni, ?Xi+1 → 1,

?Y1 → νn1 (?Y1), . . . , ?Yi → νn1···ni (?Yi), ?Ai−1 → 0, ?Ai → 1},

there exist mappings νn1 ···ni0 and νn1···ni1 in [[Qi+1]]D such that µn1 ···ni0, νn1 ···ni0
are compatible, µn1 ···ni1, νn1···ni1 are compatible and

µn1 ···ni0 ∪ νn1···ni0 ∈ [[(Pi+1 OPT (Qi+1 OPT ( · · ·

µn1 ···ni1 ∪ νn1···ni1 ∈ [[(Pi+1 OPT (Qi+1 OPT ( · · ·

(Pm OPT (Qm AND Pψ)) · · · )))]]D.

(Pm OPT (Qm AND Pψ)) · · · )))]]D,

for

every n1 · · · nm ∈ {0, 1}m, given that νn1···nm

∈
In particular,
[[(Qm AND Pψ)]]D, Qm is a conjunction of triple patterns and var(Pψ) ⊆ var(Qm),
we conclude that νn1 ···nm ∈ [[Pψ]]D. Hence, if σn1···nm is a truth assignment deﬁned
as σn1···nm (x) = νn1 ···nm (?X) for every variable x in ψ, then σn1···nm satisﬁes ψ.
Thus, given that for every n1 · · · nm ∈ {0, 1}m we have that:

µn1 ···ni (?Xj ) = νn1 ···ni (?Xj ) = µn1 ···nm (?Xj )
µn1 ···ni (?Yk) = νn1 ···ni (?Yk) = µn1 ···nm (?Yk)
νn1 ···ni (?Yi) = µn1 ···nm (?Yi)

i ∈ [1, m] and j ∈ [1, i],
i ∈ [1, m] and k ∈ [1, i − 1],
i ∈ [1, m],

we conclude that ϕ is valid.
(⇒) The proof that ϕ is valid implies µ ∈ [[Pϕ]]D is similar to the previous proof.

A.5 Proof of Theorem 5

To prove Theorem 5, we need some technical lemmas.

Lemma 3.

(1) Let Ω1, Ω2, and Ω3 be set of mappings, then Ω1 ⋊⋉ (Ω2 rΩ3) ⊆ (Ω1 ⋊⋉ Ω2)rΩ3.
(2) Let Ω1 and Ω2 be set of mappings, then Ω1 r Ω2 = Ω1 r (Ω1 ⋊⋉ Ω2).
(3) Let P1, P2 be UNION-free graph pattern expressions and Ω1, Ω2 set of map-
(Ω1 ⋊⋉ Ω2) =

pings such that Ω1 ⊆ [[P1]]D and Ω2 ⊆ [[P2]]D. Then Ω1
Ω1

Ω2.

Proof:
(1) Let µ ∈ Ω1 ⋊⋉ (Ω2 r Ω3) then µ = µ1 ∪ µ2 where µ1 ∈ Ω1, and µ2 ∈ Ω2 r Ω3
with µ1 and µ2 compatible mappings. From µ2 ∈ Ω2 rΩ3 we have that µ2 ∈ Ω2
and for every mapping µ′ ∈ Ω3, µ2 is not compatible with µ′. Note that since
µ1 and µ2 are compatible mappings, then µ = µ1 ∪ µ2 ∈ Ω1 ⋊⋉ Ω2, Thus, given
that µ2 is not compatible with any mapping µ′ ∈ Ω3, we conclude that µ is
not compatible with any mapping µ′ ∈ Ω3. Thus, µ ∈ (Ω1 ⋊⋉ Ω2) r Ω3.

(2) First we show that Ω1 r Ω2 ⊆ Ω1 r (Ω1 ⋊⋉ Ω2). Let µ ∈ Ω1 r Ω2. Then µ ∈ Ω1
and for all µ′ ∈ Ω2, µ is not compatible with µ′. Let µ′′ be any mapping in
Ω1 ⋊⋉ Ω2, then µ′′ = µ1 ∪ µ2 with µ1 ∈ Ω1, µ2 ∈ Ω2 and then, since µ is not
compatible with µ2, necessarily µ is not compatible with µ′′. Then µ is not
compatible with every µ′′ ∈ Ω1 ⋊⋉ Ω2, and ﬁnally µ ∈ Ω1 r (Ω1 ⋊⋉ Ω2). Now
we show that Ω1 r (Ω1 ⋊⋉ Ω2) ⊆ Ω1 r Ω2. Let µ ∈ Ω1 r (Ω1 ⋊⋉ Ω2), then
µ ∈ Ω1 and for every µ′ ∈ Ω1 ⋊⋉ Ω2, µ is not compatible with µ′. Suppose
that µ is compatible with some µ′′ ∈ Ω2, then µ ∪ µ′′ ∈ Ω1 ⋊⋉ Ω2 and µ
is compatible with µ ∪ µ′′ which is a contradiction with the assumption that
µ ∈ Ω1 r (Ω1 ⋊⋉ Ω2). Finally, µ ∈ Ω1 is not compatible with any µ′′ ∈ Ω2 and
then µ ∈ Ω1 r Ω2.

(3) By deﬁnition of

, we have that Ω1

(Ω1 ⋊⋉ Ω2) = (Ω1 ⋊⋉ (Ω1 ⋊⋉ Ω2)) ∪
(Ω1 r (Ω1 ⋊⋉ Ω2)). By associativity of AND, we have that Ω1 ⋊⋉ (Ω1 ⋊⋉ Ω2)) =
((Ω1 ⋊⋉ Ω1) ⋊⋉ Ω2), which in turn is equal to Ω1 ⋊⋉ Ω2 since Ω1 ⋊⋉ Ω1 = Ω1 by
Lemma 2 and the fact that Ω1 ⊆ [[P1]]D and P1 is a UNION-free expression.
Furthermore, by property (2), we conclude that (Ω1 r (Ω1 ⋊⋉ Ω2)) = Ω1 r Ω2
(Ω1 ⋊⋉ Ω2) = (Ω1 ⋊⋉ (Ω1 ⋊⋉ Ω2)) ∪ (Ω1 r (Ω1 ⋊⋉ Ω2)) =
and, therefore, Ω1
(Ω1 ⋊⋉ Ω2) ∪ (Ω1 r Ω2) = Ω1 Ω2.

(cid:3)

Lemma 4. Let P be a UNION-free graph pattern and ?X ∈ var(P ) a variable of
P . If there is a single occurrence of ?X that appear in P but in no right hand size
of any OPT subpattern of P , then ?X ∈ dom(µ) for all µ ∈ [[P ]]D.

Proof: First note that the Lemma speaks of occurrence of a variable ?X and not
of the variable itself. The intuition of this lemma is that, if an occurrence of ?X
appear at least in one of the mandatory parts of P , then the variable must be
bounded in all the mappings of [[P ]]D. The formal proof is by induction in the
construction of the pattern.
(1) If P is a triple pattern and ?X ∈ var(P ) then clearly ?X ∈ dom(µ) for all

µ ∈ [[P ]]D.

(2) Suppose P = (P1 AND P2) . Then if the occurrence of ?X that concern us is
in P1 then by induction hypothesis, ?X ∈ dom(µ) for all µ ∈ [[P1]]D and then
?X ∈ dom(µ) for all µ ∈ [[(P1 AND P2)]]D. The case for P2 is the same.

(3) Suppose P = (P1 OPT P2), then the occurrence of ?X that concern us is
necessarily in P1. By induction hypothesis ?X ∈ dom(µ) for all µ ∈ [[P1]]D and
then by the deﬁnition of OPT, ?X ∈ dom(µ) for all µ ∈ [[(P1 OPT P2)]]D.

(cid:3)

Lemma 5. Let D be an RDF database and P a well-designed graph pattern expression.
 Assume that P ′ = (P1 OPT P2) is a sub-pattern of P and ?X is a variable
such that ?X occurs in P2 and ?X occurs in P outside P ′. Then ?X ∈ dom(µ) for
every µ ∈ [[P1]]D.

Proof: Let P ′ = (P1 OPT P2) be a subpattern of a well designed graph pattern P
such that ?X ∈ var(P1) and ?X occurs outside P ′. By the property of P of being
well designed, we have that ?X ∈ var(P1). We concetrate now in subpatterns of P1.
Note that because ?X ∈ var(P2) and by the hypothesis of P being well designed
for every occurrence of ?X in the right hand size of an OPT subpattern of P1 there
is an occurrence of ?X in the left hand size of the same OPT subpattern. The
last statement imply that there is necessarily an occurrence of ?X that is not at
the right hand size of any of the OPT subpatterns of P1, because if it were not
the case P1 would have an inﬁnite number of occurrence of ?X (we would never
stop applying the property of well designed pattern). Then applying Lemma 4 we
obtain that for every µ ∈ [[P1]]D, ?X ∈ dom(µ), completing the proof.
(cid:3)

Lemma 6. Let D be an RDF database and P a well-designed graph pattern expression.
 Suppose that P ′ is a sub-pattern of P and ?X is a variable such that
?X occurs in P ′ and ?X occurs in P outside P ′. Then ?X ∈ dom(µ) for every
µ ∈ [[P ′]]D.

Proof: By induction on P ′.
(1) If P ′ is a triple pattern t, then ?X ∈ dom(µ) for every µ ∈ [[t]]D.
(2) Let P ′ = (P1 AND P2). If ?X ∈ var(P1), then by induction hypothesis 
?X ∈ dom(µ) for every µ ∈ [[P1]]D, and then ?X ∈ dom(ν) for every
ν ∈ [[(P1 AND P2)]]D. If ?X ∈ var(P2) the proof is similar.

(3) Let P ′ = (P1 OPT P2). If ?X ∈ var(P1) then by induction hypothesis 
?X ∈ dom(µ) for every µ ∈ [[P1]]D, and then ?X ∈ dom(ν) for every 
ν ∈ [[(P1 OPT P2)]]D. If ?X ∈ var(P2), then given that P is a welldesigned 
graph pattern expression and ?X occurs in P outside P ′, we have that
?X ∈ var(P1). We conclude that ?X ∈ dom(ν) for every ν ∈ [[(P1 OPT P2)]]D
as in the previous case.

(4) Let P ′ = (P1 FILTER R). Then ?X ∈ var(P1) and, thus, by induction hypothesis 
?X ∈ dom(µ) for every µ ∈ [[P1]]D. Now by deﬁnition [[(P1 FILTER R)]]D ⊆
[[P1]]D and, therefore, ?X ∈ dom(ν) for every ν ∈ [[(P1 FILTER R)]]D

(cid:3)
Proof of Theorem 5: We will prove that during the execution of EvalD( · ), for
every call EvalD(P, Ω) it holds that EvalD(P, Ω) = Ω ⋊⋉ [[P ]]D. This immediatelty
implies that EvalD(P ) = [[P ]]D because EvalD(P ) = EvalD(P, {µ∅}).
The property trivially holds when Ω = ∅ since EvalD(P, Ω) = ∅ = ∅ ⋊⋉ [[P ]]D.
Thus, we assume that Ω 6= ∅. Now the proof goes by induction on P .

– If P is a triple pattern t, then EvalD(P, Ω) = Ω ⋊⋉ [[t]]D.
– Suppose that P = (P1 AND P2). Computing EvalD(P, Ω) is equivalent to compute 
EvalD(P2, EvalD(P1, Ω)) then by induction hypothesis, EvalD(P, Ω) =
EvalD(P2, Ω ⋊⋉ [[P1]]D) = Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D = Ω ⋊⋉ [[(P1 AND P2)]]D.

– Suppose that P = (P1 OPT P2). Computing EvalD(P, Ω) is equivalent to
EvalD(P2, EvalD(P1, Ω)) and then by induction
(Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D). Thus, we

compute EvalD(P1, Ω)
hypothesis EvalD(P, Ω) = (Ω ⋊⋉ [[P1]]D)
need to show that

(Ω ⋊⋉ [[P1]]D)

(Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) = Ω ⋊⋉ ([[P1]]D

[[P2]]D).

[[P2]]D) ⊆ (Ω ⋊⋉ [[P1]]D)
(Ω ⋊⋉ [[P1]]D ⋊⋉
[[P2]]D) then µ = µ1 ∪ µ2 where µ1 ∈ Ω,
[[P2]]D), and µ1, µ2 are compatible mappings. We consider two

First we show that Ω ⋊⋉ ([[P1]]D
[[P2]]D). Let µ ∈ Ω ⋊⋉ ([[P1]]D
µ2 ∈ ([[P1]]D
cases:
(a) µ2 ∈ [[P1]]D ⋊⋉ [[P2]]D. Then µ ∈ Ω ⋊⋉ ([[P1]]D ⋊⋉ [[P2]]D) and, hence,
by commutativity and associativity of the AND operator and Lemma 2,
we have that µ ∈ (Ω ⋊⋉ [[P1]]D) ⋊⋉ (Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) ⊆ (Ω ⋊⋉
[[P1]]D)

(Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D).

(b) µ2 ∈ [[P1]]D r [[P2]]D. Then µ ∈ Ω ⋊⋉ ([[P1]]D r [[P2]]D) ⊆ (Ω ⋊⋉ [[P1]]D) r
[[P2]]D (by Lemma 3 (1)) and, thus, µ ∈ (Ω ⋊⋉ [[P1]]D) r (Ω ⋊⋉ [[P1]]D ⋊⋉
[[P2]]D) (by Lemma 3 (2) and conmutativity and associativity of the AND
operator). We conclude that µ ∈ (Ω ⋊⋉ [[P1]]D)
(Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D).
(Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) ⊆ Ω ⋊⋉
it is suﬃcient to show that
[[P2]]D), and that

Now we show that (Ω ⋊⋉ [[P1]]D)
([[P1]]D
(Ω ⋊⋉ [[P1]]D) ⋊⋉ (Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) ⊆ Ω ⋊⋉ ([[P1]]D
(Ω ⋊⋉ [[P1]]D) r (Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) ⊆ Ω ⋊⋉ ([[P1]]D
(a) By commutativity and associativity of the AND operator and Lemma 2,
we have that (Ω ⋊⋉ [[P1]]D) ⋊⋉ (Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) = Ω ⋊⋉ [[P1]]D ⋊⋉
[[P2]]D ⊆ Ω ⋊⋉ ([[P1]]D

[[P2]]D). By the deﬁnition of

[[P2]]D).

,

[[P2]]D):

(b) By Lemma 3 (2), to show that (Ω ⋊⋉ [[P1]]D) r (Ω ⋊⋉ [[P1]]D ⋊⋉ [[P2]]D) ⊆
[[P2]]D) is equivalent to show that (Ω ⋊⋉ [[P1]]D) r [[P2]]D ⊆
Ω ⋊⋉ ([[P1]]D
[[P2]]D). Let µ ∈ (Ω ⋊⋉ [[P1]]D) be such that for every
Ω ⋊⋉ ([[P1]]D
µ′ ∈ [[P2]]D, µ is not compatible with µ′. Then µ = µ1 ∪ µ2 with µ1 ∈ Ω,
µ2 ∈ [[P1]]D, and µ1, µ2 compatible mappings. Furthermore, for every µ′ ∈
[[P2]]D, µ1∪µ2 is not compatible with µ′. Suppose that µ2 is not compatible
with any µ′ ∈ [[P2]]D, then µ2 ∈ [[P1]]D r [[P2]]D ⊆ [[P1]]D
[[P2]]D,
and then µ = µ1 ∪ µ2 ∈ Ω ⋊⋉ ([[P1]]D
[[P2]]D). Suppose now that µ2
is compatible with some ν ∈ [[P2]]D, but µ1 is not compatible with ν.
Then there exists a variable ?X ∈ dom(µ1) such that ?X ∈ dom(ν) and
µ1(?X) 6= ν(?X). Since µ2 is compatible with both µ1 and ν, we have
that ?X 6∈ dom(µ2). This implies that ?X is in the domain of a mapping
in Ω since µ1 ∈ Ω and, hence, ?X is deﬁned outside P = (P1 OPT P2).
Furthermore, ?X ∈ var(P2) since ?X ∈ dom(ν) and there exists a mapping
ω = µ2 ∈ [[P1]]D such that ?X 6∈ dom(ω), which contradicts Lemma 5.
This conclude the proof of the inclusion (Ω ⋊⋉ [[P1]]D) r (Ω ⋊⋉ [[P1]]D ⋊⋉
[[P2]]D) ⊆ Ω ⋊⋉ ([[P1]]D

[[P2]]D).

– Suppose that P = (P1 FILTER R). Computing EvalD(P, Ω) results in the set
of mappings {µ ∈ EvalD(P1, Ω) | µ |= R}. By induction hypothesis this set is
equal to {µ ∈ Ω ⋊⋉ [[P1]]D | µ |= R}. Thus, we need to show that this set is equal
to Ω ⋊⋉ [[(P1 FILTER R)]]D. First, assume that ν ∈ Ω ⋊⋉ [[(P1 FILTER R)]]D.
Then ν = ν1 ∪ ν2 with ν1 ∈ Ω, ν2 ∈ [[(P1 FILTER R)]]D and ν1, ν2 compatible
mappings. Since ν2 ∈ [[(P1 FILTER R)]]D we have that ν2 ∈ [[P1]]D and
ν2 |= R. Next we show that ν |= R. By contradiction, assume that ν 6|= R.
Then given that ν2 |= R and ν = ν1 ∪ ν2, there is a variables ?X ∈ var(R) such
that ?X ∈ dom(ν) but ?X 6∈ dom(ν2). But this implies that ?X ∈ dom(ν1)
and, therefore, ?X occurs outside P since ν1 ∈ Ω. We conclude that ?X occurs
in P , ?X occurs outside P and there exists a mapping ω = ν2 ∈ [[P ]]D such
that ?X 6∈ dom(ω), which contradicts Lemma 6. Thus, we conclude that ν |= R
and, therefore, ν = ν1 ∪ ν2 ∈ {µ ∈ Ω ⋊⋉ [[P1]]D | µ |= R}. Second, assume
that ν ∈ {µ ∈ Ω ⋊⋉ [[P1]]D | µ |= R}. Then ν |= R and ν = ν1 ∪ ν2 with

ν1 ∈ Ω, ν2 ∈ [[P1]]D and ν1, ν2 compatible mappings. Next we show that
ν2 |= R. By contradiction, assume that ν2 6|= R. Then given that ν |= R
and ν = ν1 ∪ ν2, we have that there exists variable ?X ∈ var(R) such that
?X ∈ dom(ν) but ?X 6∈ dom(ν2). But this implies that ?X ∈ dom(ν1) and,
therefore, ?X occurs outside P1 since ν1 ∈ Ω. We conclude that ?X occurs in
P1 since var(R) ⊆ var(P1), ?X occurs outside P1 and there exists a mapping
ω = ν2 ∈ [[P1]]D such that ?X 6∈ dom(ω), which contradicts Lemma 6. Thus,
we conclude that ν2 |= R and, therefore, ν2 ∈ [[(P1 FILTER R)]]D. Hence, we
deduce that ν = ν1 ∪ ν2 ∈ Ω ⋊⋉ [[(P1 FILTER R)]]D. This concludes the proof
of the theorem.

(cid:3)

A.6 Proof of Proposition 2

First we show that for every subpattern (P1 AND (P2 OPT P3)) of a well designed
pattern P , it holds that (P1 AND (P2 OPT P3)) ≡ ((P1 AND P2) OPT P3).
Proof: To simplify the notation we will suppose that µ1 ∈ [[P1]]D, µ2 ∈ [[P2]]D,
and µ3 ∈ [[P3]]D.

– First [[(P1 AND (P2 OPT P3))]]D ⊆ [[((P1 AND P2) OPT P3)]]D. Let µ ∈
[[P3]]D). Then µ = µ1 ∪ µ′
[[P3]]D, depending on

[[(P1 AND (P2 OPT P3))]]D = [[P1]]D ⋊⋉ ([[P2]]D
with µ1 and µ′ compatible mappings, and µ′ ∈ [[P2]]D
µ′ there are two cases:

• If µ′ ∈ [[P2]]D ⋊⋉ [[P3]]D then µ ∈ [[P1]]D ⋊⋉ ([[P2]]D ⋊⋉ [[P3]]D), and then

µ ∈ ([[P1]]D ⋊⋉ [[P2]]D) ⋊⋉ [[P3]]D ⊆ [[((P1 AND P2) OPT P3)]]D

• If µ′ ∈ [[P2]]D r [[P3]]D then µ′ ∈ [[P2]]D and is incompatible with every
µ3 ∈ [[P3]]D, then µ = µ1 ∪ µ′ is incompatible with µ3 and then µ ∈
[[P3]]D and then µ ∈
([[P1]]D ⋊⋉ [[P2]]D) r [[P3]]D ⊆ ([[P1]]D ⋊⋉ [[P2]]D)
[[((P1 AND P2) OPT P3)]]D.

– Now [[((P1 AND P2) OPT P3)]]D ⊆ [[(P1 AND (P2 OPT P3))]]D. Let u ∈
[[P3]]D. There are two

[[(P1 AND P2) OPT P3))]]D = ([[P1]]D ⋊⋉ [[P2]]D)
cases:

• µ ∈ ([[P1]]D ⋊⋉ [[P2]]D) ⋊⋉ [[P3]]D = ([[P1]]D ⋊⋉ [[P3]]D) ⋊⋉ [[P2]]D then

µ ∈ [[((P1 AND P2) OPT P3)]]D.

[[P3]]D and then µ1 ∪ µ2 ∈ [[P1]]D ⋊⋉ ([[P2]]D

• µ ∈ ([[P1]]D ⋊⋉ [[P2]]D) r [[P3]]D, then µ = µ1 ∪ µ2 with µ1 and µ2 compatible 
mappings and for every µ3, µ1 ∪ µ2 is incompatible with µ3. Suppose 
ﬁrst that µ2 is incompatible with µ3, then µ2 ∈ [[P2]]D r [[P3]]D ⊆
[[P2]]D
[[P3]]D) =
[[(P1 AND (P2 OPT P3))]]D. Suppose now that µ1 is incompatible with
µ3, then there exists a variable ?X ∈ dom(µ1), ?X ∈ dom(µ3) such that
µ1(?X) 6= µ3(?X). This last statement imply that ?X ∈ var(P1) ∩ var(P3)
and then because P is well designed by Lemma 5 we obtain ?X ∈ dom(µ2)
and because µ2 is compatible with µ1 we have that µ2(?X) 6= µ3(?X). Finally 
µ2 ∈ [[P2]]D r [[P3]]D ⊆ [[P2]]D
[[P3]]D, and then µ = µ1 ∪ µ2 ∈
[[(P1 ⋊⋉ (P2

P3))]]D.

(cid:3)
Now we show that for every subpattern ((P1 OPT P2) OPT P3) of a well designed
pattern P , it holds that ((P1 OPT P2) OPT P3) ≡ ((P1 OPT P3) OPT P2).
Proof:

– First [[((P OPT P1) OPT P2)]]D ⊆ [[((P OPT P2) OPT P1)]]D. Let µ ∈
[[P2]]D. Suppose that

[[P1]]D)

[[((P OPT P1) OPT P2)]]D then µ ∈ ([[P ]]D
µ ∈ ([[P ]]D

[[P1]]D) ⋊⋉ [[P2]]D, there are two cases:

• µ ∈ ([[P ]]D ⋊⋉ [[P1]]D) ⋊⋉ [[P2]]D ⊆ ([[P ]]D ⋊⋉ [[P2]]D) ⋊⋉ [[P1]]D ⊆

[[((P OPT P2) OPT P1)]]D.

• µ ∈ ([[P ]]D r [[P1]]D) ⋊⋉ [[P2]]D ⊆ ([[P ]]D ⋊⋉ [[P2]]D) r [[P1]]D, by proposition 
3 (1), then µ ∈ [[((P OPT P2) OPT P1)]]D.

[[P1]]D) r [[P2]]D There are two cases: (i assume

Suppose now that µ ∈ ([[P ]]D
µ′ ∈ [[P ]]D, µ1 ∈ [[P1]]D, µ2 ∈ [[P2]]D).

• µ ∈ ([[P ]]D ⋊⋉ [[P1]]D) r [[P2]]D, then µ = µ′ ∪ µ1 compatibles mappings,
and for every µ2, µ′ ∪ µ1 is incompatible with µ2. If µ′ is incompatible
with µ2 then µ′ ∈ [[P ]]D r [[P2]]D and then µ′ ∪ µ1 ∈ ([[P ]]D r [[P2]]D) ⋊⋉
[[P1]]D) and then µ ∈ [[((P OPT P2) OPT P1)]]D. Suppose that µ1 is
incompatible with µ2, then there is ?X such that µ1(?X) 6= µ2(?X). Then
?X ∈ var(P1) ∩ var(P2) and because the whole pattern is well designed,
by Lemma 5 we obtain that ?X ∈ µ′ and by µ′ compatible with µ1 we
obtain that µ′(?X) 6= µ2(?X), and then µ′ is incompatible with µ2. Then
µ ∈ [[((P OPT P2) OPT P1)]]D.

• µ ∈ ([[P ]]D r [[P1]]D) r [[P2]]D, then µ ∈ [[P ]]D and is such that for all µ1
and for all µ2, µ is incompatible with µ1 and µ2, and then µ ∈ ([[P ]]D r
[[P2]]D) r [[P1]]D ⊆ [[((P OPT P2) OPT P1)]]D.

– Now we show that [[((P OPT P2) OPT P1)]]D ⊆ [[((P OPT P1) OPT P2)]]D.
Let µ ∈ [[((P OPT P1) OPT P2)]]D then µ ∈ ([[P ]]D
[[P1]]D.
(again i assume µ′ ∈ [[P ]]D, µ1 ∈ [[P1]]D, µ2 ∈ [[P2]]D). Suppose that µ ∈
([[P ]]D

[[P2]]D) ⋊⋉ [[P1]]D, there are two cases:

[[P2]]D)

• µ ∈ ([[P ]]D ⋊⋉ [[P2]]D) ⋊⋉ [[P1]]D ⊆ [[((P OPT P1) OPT P2)]]D.
• µ ∈ ([[P ]]D r [[P2]]D) ⋊⋉ [[P1]]D ⊆ ([[P ]]D ⋊⋉ [[P1]]D) r [[P2]]D by prop. 3 (1)

and then µ ∈ [[((P OPT P1) OPT P2)]]D.

Suppose now that µ ∈ ([[P ]]D

[[P2]]D) r [[P1]]D, there are two cases:

• µ ∈ ([[P ]]D ⋊⋉ [[P2]]D) r [[P1]]D, then µ = µ′ ∪ µ2 compatible mappings
such that for every µ1 ∈ [[P1]]D, µ′ ∪ µ2 is incompatible with µ1. If µ′
is incompatible with µ1 then µ′ ∈ [[P ]]D r [[P1]]D and then µ′ ∪ µ2 ∈
([[P ]]D r [[P1]]D) ⋊⋉ [[P2]]D ⊆ ([[P ]]D r [[P1]]D)
[[P2]]D and then µ ∈
[[((P OPT P1) OPT P2)]]D. If µ2 is incompatible with µ1 then there exists
a variable ?X ∈ dom(µ1) ∩ dom(µ2) such that µ1(?X) 6= µ2(?X). Then
?X ∈ var(P1) ∩ var(P2) and because the whole pattern is well designed,
by Lemma 5 we obtain that ?X ∈ µ′ and by µ′ compatible with µ2 we
obtain that µ′(?X) 6= µ1(?X), and then µ′ is incompatible with µ1. Then
µ ∈ [[((P OPT P1) OPT P2)]]D.

• µ ∈ ([[P ]]D r [[P2]]D) r [[P1]]D ⊆ ([[P ]]D ⋊⋉ [[P1]]D) r [[P2]]D ⊆

[[((P OPT P1) OPT P2)]]D

(cid:3)
To ﬁnish the proof we must show that replacing the respective equivalences do
not aﬀect the property of P of being well designed. Let (P1 AND (P2 OPT P3))
be a subpattern of P . Well designed says that, if a variable ?X occurs outside
(P2 OPT P3) and inside P3 then it occurs in P2. Suppose that this is the case and
that ?X occurs outside (P1 AND (P2 OPT P3)), then because ?X occurs in ?P2
then ?X occurs in (P1 AND P2) and the pattern P ′ obtained from P by replacing
(P1 AND (P2 OPT P3)) by (P1 AND P2) OPT P3)) is well designed. Suppose now
that ?X occurs in P1 but does not occur outside (P1 AND (P2 OPT P3)), then
?X does not occur outside ((P1 AND P2) OPT P3) and then the pattern obtained
from P is well designed.
The proof for P ′ = ((P1 OPT P2) OPT P3) is similar. There are various cases for
variables occurring inside P2, P3.

– ?X occurs in P2 and in P3,
– ?X occurs in P2 and outside P ′ but not in P3,
– ?X occurs in P3 and outside P ′ but not in P2,

in all cases because P is well designed ?X occurs in P1 and then the pattern
obtained from P replacing P ′ by ((P1 OPT P3) OPT P2) is well designed.

A.7 Proof of Theorem 6

To prove Theorem 6 we use the following Lemma. In the Lemma we use rewriting
concepts and results (see [2]).

Lemma 7. Let us consider the theory E formed by the equations of associativity
and commutativity for AND (Proposition 1), and equation

((X OPT Y ) OPT Z) ≡ ((X OPT Z) OPT Y )

Then the rule

(X AND (Y OPT Z)) −→ ((X AND Y ) OPT Z)

(7)

is E-terminating and E-conﬂuent in the set of well designed patterns, and hence
has E-normal forms in the set of well designed patterns.

Proof:
(1) First we prove that rule (7) is terminating. Consider the measure

m(P ) : number of OPT inside AND -trees in the parsing of P.

Then clearly the theory E keeps m(P ) constant. Let P ′ and P ′′ be the left and
right hand side in rule (7) respectively, then m(P ′) > m(P ′′). Hence successive
application of rule (7) must terminate.

(2) Now we prove that rule (7) is E-locally conﬂuent. Note that the only critical
pair (see [2]) is: ((P1 OPT P2) AND (P3 OPT P4)) Then it only left to check
that both applications of rule (7)

and

(((P1 OPT P2) AND P3) OPT P4)

(((P3 OPT P4) AND P1) OPT P2)

can be rewritten to a common term using the axioms of E and the rule (7):

(((P1 OPT P2) AND P3) OPT P4)

(((P3 OPT P4) AND P1) OPT P2)

E
≡ ((P3 AND (P1 OPT P2)) OPT P4)
(7)
→ (((P3 AND P1) OPT P2) OPT P4)
E
≡ (((P1 AND P3) OPT P2) OPT P4)

E
≡ ((P1 AND (P3 OPT P4)) OPT P2)
(7)
→ (((P1 AND P3) OPT P4) OPT P2)
E
≡ (((P1 AND P3) OPT P2) OPT P4)

(cid:3)
Theorem 6 follows from the existence of E normal forms for rule (7), and the
application of (7) and E identities to well designed graph patterns.

