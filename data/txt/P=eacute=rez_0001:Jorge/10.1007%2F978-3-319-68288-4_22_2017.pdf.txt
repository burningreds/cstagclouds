A Formal Framework for Comparing Linked

Data Fragments

Olaf Hartig1(B), Ian Letter2, and Jorge P´erez3(B)

1 Department of Computer and Information Science (IDA), Link¨oping University,

2 Departamento de Ingenier´ıa Matem´atica, Universidad de Chile, Santiago, Chile

Link¨oping, Sweden
olaf.hartig@liu.se

3 Department of Computer Science, Universidad de Chile, Santiago, Chile

iletter@dim.uchile.cl

jperez@dcc.uchile.cl

Abstract. The Linked Data Fragment (LDF) framework has been proposed 
as a uniform view to explore the trade-oﬀs of consuming Linked
Data when servers provide (possibly many) diﬀerent interfaces to access
their data. Every such interface has its own particular properties regarding 
performance, bandwidth needs, caching, etc. Several practical challenges 
arise. For example, before exposing a new type of LDFs in some
server, can we formally say something about how this new LDF interface
compares to other interfaces previously implemented in the same server?
From the client side, given a client with some restricted capabilities in
terms of time constraints, network connection, or computational power,
which is the best type of LDFs to complete a given task? Today there are
only a few formal theoretical tools to help answer these and other practical 
questions, and researchers have embarked in solving them mainly
by experimentation.

In this paper we propose the Linked Data Fragment Machine (LDFM)
which is the ﬁrst formalization to model LDF scenarios. LDFMs work
as classical Turing Machines with extra features that model the server
and client capabilities. By proving formal results based on LDFMs, we
draw a fairly complete expressiveness lattice that shows the interplay
between several combinations of client and server capabilities. We also
show the usefulness of our model to formally analyze the ﬁne-grain interplay 
between several metrics such as the number of requests sent to the
server, and the bandwidth of communication between client and server.

1 Introduction

The idea behind Linked Data Fragments (LDFs) is that diﬀerent Semantic Web
servers may provide (possibly many) diﬀerent interfaces to access their datasets
allowing clients to decide which interface better satisﬁes a particular need. Every
such interface provides a particular type of so-called “fragments” of the underlying 
dataset
[13]. Moreover, every interface has its own particular properties
regarding performance, bandwidth needs, cache eﬀectiveness, etc. Clients can
c(cid:2) Springer International Publishing AG 2017
C. d’Amato et al. (Eds.): ISWC 2017, Part I, LNCS 10587, pp. 364–382, 2017.
DOI: 10.1007/978-3-319-68288-4_22

A Formal Framework for Comparing Linked Data Fragments

365

analyze the trade-oﬀs when using one of these interfaces (or a combination of
them) for completing a speciﬁc task. There are a myriad of possible interfaces in
between SPARQL endpoints and RDF data dumps. Some interfaces that have
already been proposed in the literature include Linked Data Documents [4,5],
Triple Pattern Fragments (TPF) [13], and Bindings-Restricted Triple Pattern
Fragments (brTPF) [7]. Diﬀerent options for LDF interfaces are shown in Fig. 1.

Fig. 1. Unidimensional view of Linked Data Fragments (ﬁgure taken from [7, 13])

LDFs have already had a considerable practical impact. For instance, since
the proposal of the TPF interface, the LOD Laundromat Website has published
more than 650,000 datasets on the Web with this interface [3]. Moreover, DBpedia 
has also published a TPF interface which had an uptime of 99.99% during
its ﬁrst nine months [13]. Up to now, the research and development of LDFs
has produced interesting practical results, but the studied interfaces are deﬁnitely 
not the ﬁnal answer to querying semantic data on the Web, and one may
expect that many new interfaces with diﬀerent trade-oﬀs can be made available
by Semantic Web data servers in the near future.

Several practical challenges arise. On the server side, developers need to
construct LDF interfaces that ensure a good cost/performance trade-oﬀ. Before
implementing a new interface in some server, can we formally say something
about the comparison of this new type of LDFs with earlier-proposed types? If
the new interface is somehow subsumed in capabilities and cost by previously
implemented interfaces (or by a simple combination of them), then there might
be no reason to implement it. Answering this question requires an answer to the
more general question on how to formally compare the properties of two diﬀerent
LDF interfaces given only their speciﬁcations.

On the client side, developers need to eﬃciently use and perhaps combine
LDF interfaces. Thus, an interesting problem is the following: given a client
with some restricted capabilities (in terms of time constraints, small budget,
little computational power, restricted local expressiveness, etc.) and a task to be
completed, which is the best interface that can be used to complete the task? Or
even more drastically, can the task be completed at all given the restrictions on
the client and a set of LDF interfaces to choose from? Today there are only a few
formal tools to help answer the previously described questions, and researchers
have embarked in solving them mainly by experimentation. The main goal of
this paper is to help ﬁll this gap by developing solid theoretical foundations for
studying and comparing LDF interfaces.

366

O. Hartig et al.

It is not diﬃcult to see that one can compare LDF interfaces in diﬀerent
ways. For instance, in Fig. 1 (taken from [7,13]) three criteria are considered:
(1) general vs. speciﬁc requests, (2) client vs. server eﬀort, and (3) high vs. low
availability. We note however that this ﬁgure is not meant to provide an accurate
account of the trade-oﬀs of the included interfaces but to highlight the existence
of such trade-oﬀs. To this end, the ﬁgure has been kept deliberately simplistic by
organizing the criteria and the interfaces along a single axis. While serving the
intended purpose, this deliberate simpliﬁcation has the disadvantage of suggesting 
that the given three criteria are correlated and, for example, the Linked Data
Documents interface is always in between data dumps and SPARQL endpoints.
A counterexample to the latter can be shown if we consider expressiveness as
another criterion; more speciﬁcally, lets consider the type of queries that can be
answered if we allow the client to use full computational power (Turing com-
plete) to process data after making as many requests to the server as it needs.
Assume that we have a server that provides data dumps, Linked Data Documents,
 and a SPARQL endpoint. Then, one can formally prove that the client
is strictly less expressive when accessing the Linked Data Documents instead of
the data dump or the SPARQL endpoint. To see this, consider a query of the
following form:

Q1: “Give me all the subjects and objects of RDF triples whose predicate

is rdf:type.”

This query cannot be answered completely over a dataset by using the Linked
Data Document interface no matter how many requests the client sends to the
server [6]. On the other hand, it is not diﬃcult to show that both, data dumps and
SPARQL endpoints, can answer the query completely. Thus, when considering
the expressiveness dimension, Linked Data Documents are not longer in between
data dumps and SPARQL endpoints.

Consider another scenario in which one wants to measure only the number
of requests that the client sends to the server in order to answer a speciﬁc query.
Lets assume this time that the server provides a data dump, a SPARQL endpoint,
and a TPF interface, and consider the following query.

Q2: “Give me all the persons reachable from Peter by following two foaf:knows

links.”

It is straightforward to see that a client using either the data dump or the
SPARQL endpoint can answer this query by using a single request to the server,
while a TPF client needs at least two requests. Thus, in this case, data dumps
are more eﬃcient than TPFs in terms of number of server requests. On the other
hand it is clear that in terms of the amount of data transferred, TPFs are more
desirable for Q2 than data dumps.

Although the two examples described above are very simple, they already
show that the comparison of LDF interfaces is not always one-dimensional. Moreover,
 the comparison can quickly become more complex as we want to analyze
and compare more involved scenarios. For instance, in both cases above we just
analyzed a single query. In general, one would like to compare LDF interfaces in

A Formal Framework for Comparing Linked Data Fragments

367

terms of classes of queries. Another interesting dimension is client-side computational 
power. In both cases above we assumed that the client is Turing complete,
and thus the client is able to apply any computable function to the fragments
obtained from an LDF interface. However, one would like to consider also clients
with restricted capabilities (e.g., in terms of computational power or storage).
Moreover, other dimensions such as bandwidth from client to server, bandwidth
from server to client, time complexity on the server, cacheability of results, and
so on, can substantially add diﬃculty to the formal analysis. In this paper we
embark on the formal study of Linked Data Fragments by proposing a framework
in which several of the aforementioned issues can be formally analyzed.

Main contributions and organization of the paper: As our main conceptual 
contribution we propose the Linked Data Fragment Machine (LDFM).
LDFMs work as classical Turing Machines with some extra features that model
the server and client capabilities in an LDF scenario. Our machine model is
designed to clearly separate three of the main tasks done when accessing a
Linked Data Fragment server: (1) the computation that plans and drives the
overall query execution process by making requests to the server, (2) the computation 
that the server needs to do in order to answer requests issued by the
client, and (3) the computation that the client needs to do to create the ﬁnal
output from the server responses. These design decisions allow us to have a
model that is powerful enough to capture several diﬀerent scenarios while simple 
enough to allow us to formally prove properties about it. The LDFM model
is presented in Sect. 2.

As one of our main technical contributions, we use our machine to formalize
the notion of expressiveness of an LDF scenario and we draw a fairly complete 
lattice that shows the interplay between several combinations of client
and server capabilities. While expressiveness is studied in Sect. 3, in Sect. 4 we
analyze LDF scenarios in terms of classical computational complexity. Moreover,
 our machine model also allows us to formally analyze LDFs in terms of
two additional important metrics, namely, the number of requests sent to the
server, and the bandwidth of communication between the server and the client.
Both notions are formalized as speciﬁc computational-complexity measures over
LDFMs. We present formal results comparing diﬀerent scenarios and demonstrate 
the suitability of our proposed framework to also analyze the ﬁne-grain
interplay between complexity metrics. These results are presented in Sect. 5.
For the sake of space most of the details on the proofs have been omitted
but can be found in the appendix at http://dcc.uchile.cl/∼jperez/ldfm-ext.pdf.

2 Linked Data Fragment Machine

This section introduces our abstract machine model that captures possible clientserver 
systems that execute user queries, issued at the client side, over a serverside 
dataset.

Informally, the machine in our model captures the whole of a clientserver 
system (i.e., both, the server and the client). However, the program of the

368

O. Hartig et al.

machine can be considered to be executed on the client side. To communicate
with the server the machine uses a server language, LS, which essentially represents 
the type of requests that the server interface is able to answer. Additionally,
the machine is also in charge of producing the result of the given user query by
combining the responses from the server. The corresponding result-construction
capability is captured by a response-combination language, LC, which is an algebra 
over the server responses. To answer a user query the machine performs
the following general process: The machine begins by creating requests for the
server in the form of LS queries. After issuing such a request, the corresponding
response becomes available in an internal result container. Then, the machine can
decide to continue with this process by issuing another request. Every response
from the server is stored in a diﬀerent result container, and moreover, a result
container cannot be modiﬁed after it is ﬁlled with a server response (i.e., it can
only be read by the machine). In the ﬁnal step, the machine uses the responsecombination 
language LC to create a query over the result containers. The execution 
of this LC-query produces the ﬁnal output of the process (that is, the
result of the user query). In the following, we deﬁne the machine formally. We
ﬁrst formally capture the diﬀerent types of query languages involved and next we
provide the formal deﬁnition of the machine; thereafter, we describe the rationale
of the diﬀerent parts of the machine and we introduce notions of computability
and expressiveness based on the machine.

2.1 Preliminaries

Our model assumes the following three types of queries.

User queries are queries that are issued at the client side and that the
client-server system (captured by our machine) executes over the server-side
dataset. We assume that this dataset is represented as an RDF graph without
blank nodes. Then, a possible class of user queries could be SPARQL queries.
However, to make our model more general we allow user queries to be expressed
also in other query languages. To this end, for our model we introduce the
abstract notion of an RDF query. Formally, an RDF query is an expression q for
which there exists an evaluation function that is deﬁned for every RDF graph
G and that returns a set of SPARQL solution mappings, denoted by (cid:2)q(cid:3)G.

Requests are queries that the client sends to the server during the execution
of a user query. The form of these requests depends on the type of interface
provided by the server. We capture such interface types (and, thus, the possible
requests) by introducing the notion of a server language; that is, a language LS
that is associated with an evaluation function that, for every query qR ∈ LS
and every RDF graph G, returns a set of SPARQL solution mappings, which
we denote by (cid:2)qR(cid:3)G. Examples of server languages considered in this paper are
given as follows:

– coreSparql is the core fragment of SPARQL that considers triple patterns,
And, Opt, Union, Filter, and Select. Due to space limitations, we refer
to [2,10] for a formal deﬁnition of this fragment and its evaluation function.

A Formal Framework for Comparing Linked Data Fragments

369

– Bgp is the basic graph pattern fragment of SPARQL (i.e., triple patterns and

And).

– Tpf is the language composed of queries that are a single triple pattern.
Hence, this language captures servers that support the triple pattern fragments
interface [13].

– Tpf+Filter is the language composed of queries of the form (tp Filter θ)
where tp is a triple pattern and θ is a SPARQL built-in condition as deﬁned
in [10].

– brTpf is the language composed of queries of the form (tp, Ω), where tp
is a triple pattern and Ω is a set of solution mappings. This language captures 
the bindings-restricted triple pattern interface [7]. The evaluation function 
is deﬁned such that for every RDF graph G it holds that (cid:2)(tp, Ω)(cid:3)G =
πvars(tp)((cid:2)tp(cid:3)G (cid:2)(cid:3) Ω) where π is the projection operator [11], vars(tp) is the
set of variables in tp, (cid:2)tp(cid:3)G is the evaluation of tp over G [10], and (cid:2)(cid:3) is the
join operator [10]. For simplicity we assume that a triple pattern tp is also a
brTpf query in which case the evaluation function is simply (cid:2)tp(cid:3)G.

– Dump is the language that has a single expression only, namely the triple
pattern (?s, ?p, ?o) where ?s, ?p, and ?o are diﬀerent variables. This language
captures interfaces for downloading the complete server-side dataset.

For any two server languages LS and L(cid:4)
is also in L(cid:4)

S. For instance, Dump ⊆ Tpf ⊆ Bgp ⊆ coreSparql.

S we write LS ⊆ L(cid:4)

S if every query in LS

Response-combination queries are queries that describe how the result
of a user query can be produced from the server responses. Since each server
response in our model is a set of solution mappings, and so is the result of
any user query, we assume that response-combination queries can be expressed
using languages that resemble an algebra over sets of solution mappings. We call
such a language a response-combination language. In this paper we denote such
response-combination languages by the set of algebra operators that they implement.
 For instance, the response-combination language denoted by the set {(cid:2)(cid:3), π}
can be used to combine multiple sets Ω1, . . . , Ωn of solution mappings by applying 
the aforementioned join and projection operators in an arbitrary manner.
Other algebra operators that we consider in this paper are the union and the
left outer join [2], denoted by ∪ and (cid:2)(cid:3), respectively. Note that based on our notation,
 the empty operator set (∅) also denotes a response-combination language.
This language can be used only to simply select one Ωi out of multiple given
sets Ω1, . . . , Ωn of solution mappings (i.e., without being able to modify Ωi).

2.2 Formalization

A Linked Data Fragment Machine (LDFM) M is a multi-tape Turing Machine
with the following special features. In addition to several ordinary working tapes,
M has ﬁve special tapes: a query tape TQ, a data tape TD, a server-request
tape TR, a client tape TC, and an output tape TO. Tapes TQ and TD are read-only
tapes, while TR, TC, and TO are write-only tapes. As another special component,

370

O. Hartig et al.

Fig. 2. (LC ,LS)-LDFM M

the machine has an unbounded sequence D1, D2, . . . , Dk, . . . of result containers 
(which can also be considered as read-only tapes), and a counter cM , called
the result counter, that deﬁnes the last used result container. M also has four different 
modes: computing the next server request (R), waiting for response (W ),
computing client query (C), and done (F ). In all these modes the machine may
use the full power of a standard Turing Machine. Additionally, M has access
to two oracle machines: a server oracle OS, which is associated with a server
language LS, and a client oracle OC, associated with a response-combination
language LC.
An LDFM M receives as input an RDF query q and an RDF graph G. Before
the computation begins, q is assumed to be in tape TQ and G is assumed to be
in tape TD. All other tapes as well as the result containers are initially empty,
the counter cM is 0, and the machine is in mode R. Then, during the computation,
 the machine can use its ordinary working tapes arbitrarily (read/write).
However, the access to the special tapes is restricted. That is, tape TR can be
used by the machine only when it is in mode R, and tape TC can be used only
in mode C. Moreover, the machine does not have direct access to the tapes TD
and TO; instead, the read-only tape TD can be accessed only by the oracle OS,
and the write-only tape TO can be accessed only by oracle OC. Regarding the
result containers, M is only able to read from them, and only oracle OS can
write in them. Figure 2 illustrates an LDFM and Fig. 3 shows the possible state
transitions.
The computation of an LDFM M works as follows. While in mode R, the
machine can construct a query qR ∈ LS and write it in tape TR. When the
machine is ﬁnished writing qR, it may change to mode W, which is a call to
oracle OS. The oracle then increments the counter cM , deletes the content of
tape TR, and writes the set of mappings (cid:2)qR(cid:3)G in the container DcM . Next, the
computation continues, M changes back to mode R, and the previous process
may be repeated. Alternatively, at any point when in mode R, the machine may
decide to change to mode C. In this mode, M constructs a query qC ∈ LC,
writes it in tape TC, and changes to mode F , which is a call to oracle OC. Then,

A Formal Framework for Comparing Linked Data Fragments

371

Fig. 3. Possible state transitions of an LDFM

oracle OC evaluates qC over data D1, . . . , DcM , and writes the result of this
evaluation in tape TO which is the ﬁnal output of M. Hence, at this point the
computation terminates. We denote the ﬁnal output as M(q, G).

Example 1. A typical SPARQL endpoint based client-server scenario may be
captured by an LDFM M whose server language LS is coreSparql and the
response-combination language LC is ∅. For any user query q, assuming q is in
coreSparql, the machine simply copies q into tape TR and enters mode W.
After obtaining (cid:2)q(cid:3)G from oracle OS in result container D1, the machine enters
mode C, writes D1 (as an expression in LC = ∅) in tape TC, and changes to
mode F . Then, oracle OC writes the query result (cid:2)q(cid:3)G from D1 to the output
tape.

Example 2. Let M be an LDFM such that LS = brTpf and LC = {(cid:2)(cid:3),∪}.
Hence, M has access to a server capable of handling brTpf requests, and M
can do joins and unions to construct the ﬁnal output. Assume now that a user
wants to answer a SPARQL query q of the form ((?X, a, ?Y ) And (?X, b, ?Y )),
which is initially in tape TQ. Then, to evaluate q over a graph G (in tape TD),
M may work as follows: First, M writes query (?X, a, ?Y ) in tape TR and calls
OS by entering mode W. After this call we have that D1 = (cid:2)(?X, a, ?Y )(cid:3)G. Now,
M can write (?X, b, ?Y ) in tape TR, which is another call to OS that produces
D2 = (cid:2)(?X, b, ?Y )(cid:3)G. Finally, M writes query D1 (cid:2)(cid:3) D2 in tape TC and calls
OC, which produces the output, M(q, G), in tape TO. It is not diﬃcult to see
that M(q, G) = (cid:2)q(cid:3)G. We may have an alternative LDFM M(cid:4) that computes q
as follows. Initially, M(cid:4) calls the server oracle OS with query (?X, a, ?Y ) to
obtain D1 = (cid:2)(?X, a, ?Y )(cid:3)G. Next, M(cid:4) performs the following iteration: for every
mapping μ ∈ D1 it writes the brTpf query ((?X, b, ?Y ),{μ}) in TR and calls
the oracle OS to produce (cid:2)((?X, b, ?Y ),{μ})(cid:3)G = (cid:2)(?X, b, ?Y ))(cid:3)G (cid:2)(cid:3) {μ} in one
of its result containers. After all these calls, M(cid:4) writes query (D2∪ D3∪···∪ Dk)
in tape TC, where k = cM(cid:2) is the index of the last used result container. The
oracle OC then produces the ﬁnal output M(cid:4)(q, G). In this case we also have
that M(cid:4)(q, G) = (cid:2)q(cid:3)G.

2.3 Rationale and Limitations of LDFMs

Machine models to formalize Web querying have been previously proposed in
the literature [1,6,9]. Most of the early work in this context is based on an
understanding of the Web as a distributed hypertext system consisting of Web

372

O. Hartig et al.

pages that are interconnected by hyperlinks. These machines then formalized the
notion of navigation and of data retrieval while navigating, and their focus was
on classical computability issues (what can, and what cannot be computed in
a distributed Web scenario). Though similar in motivation, our machine model
in contrast formalizes a diﬀerent approach to access and to query Web data. In
this section we explain the rationale behind our design.

The perhaps most important characteristic of our model is that it separates 
the computation that creates the ﬁnal output (as done by the client oracle 
OC) from the computation that plans and drives the overall query execution 
process (as done by the LDFM itself). Hence, the expressive power of the
response-combination language LC only determines how the query result to be
returned to the user can be computed by using the result containers, but it does
not have any impact whatsoever on the computations that the machine can do
when it generates any of the server requests (in mode R) or when it generates
the ﬁnal LC-query (in mode C). This separation allows us to precisely pinpoint
the computational power needed for the latter without mixing it up with the
power needed for constructing the output (and vice versa). Of course, in practice 
the two tasks do not need to be separated into two consecutive phases as
suggested by our model. In fact, an alternative version of our model could allow
the machine to use oracle OC multiple times to produce the ﬁrst elements of the
complete output as early as possible.

Another separation, which is perhaps more natural because it also exists in
practice, is the delegation of the computation of the server responses to the
server oracle OS. Besides also avoiding a mix-up when analyzing required computational 
power, this separation additionally allows us to prevent the LDFM
from accessing the data tape TD directly. This features captures the fact that,
in practice, a client also has to use the server interface instead of being able to
directly access the server-side dataset.

The

result

containers

corresponding result
counter (cM ), provide us with an abstraction based on which notions of network
cost of diﬀerent pairs of client/server capabilities can be quantiﬁed. We shall use
this abstraction to deﬁne network-related complexity measures in Sect. 5.

(D1, D2, . . .), with their

While our notion of the LDFM provides us with a powerful model to formally
study many phenomena of LDF-based client-server settings, there are a few
additional factors in practice that are not captured by the model in its current
form. In particular, the model does not capture the option for the server to
(i) decide to split responses into pages (that have to be requested separately)
and (ii) send metadata with its responses that clients can use to adapt their
query execution plans. Additionally, in practice there may be a cache located
between the server and the client, which might have to be captured to study
metrics related to server load (given that such a cache is not equally eﬀective for
diﬀerent LDF interfaces [7,13]). We deliberately ignored these options to keep
our model suﬃciently simple. However, corresponding features may be added to
our notion of an LDFM if useful for future analyses.

A Formal Framework for Comparing Linked Data Fragments

373

2.4 Computability and Expressiveness for LDFMs

We conclude the introduction of our machine model by deﬁning notions of computability 
and expressiveness based on LDFMs.

The most basic notion of computability for LDFMs is that of a computable
query. We say that an RDF query q is computable under an LDFM M if for
every RDF graph G it holds that M(q, G) = (cid:2)q(cid:3)G. That is, q is computable
under M if, with (q, G) as input, M produces (cid:2)q(cid:3)G as output, for every possible
graph G. We can also extend this notion to classes of queries. Formally, the class
of queries computed by an LDFM M, denoted by C(M), is the set of all RDF
queries that are computable under M.

Notice that every LDFM comes with a response-combination language and
a server language, and thus we can also deﬁne classes of LDFMs in terms of the
languages that they use. In particular, we say that an LDFM M is an (LC ,LS)-
LDFM if the response-combination language of M is LC and the server language
of M is LS. Now, we can deﬁne our main notion of computability.
Deﬁnition 1. Let LC be a response-combination language and LS be a server
language. A class C of RDF queries is computable under (LC,LS) if there exists
an (LC,LS)-LDFM M such that every query q in C is computable under M.

Deﬁnition 1 is our main building block to compare diﬀerent combinations of
client and server languages independent of the possible LDFMs that use these
languages. The following deﬁnition formalizes our main comparison notion.
1 be response-combination languages, and L2 and
Deﬁnition 2. Let L1 and L(cid:4)
2 be server languages. Then, (L(cid:4)
2) is at least as expressive as (L1,L2),
L(cid:4)
denoted by (L1,L2) (cid:6)e (L(cid:4)
,L(cid:4)
2), if every class of queries that is computable
under (L1,L2) is also computable under (L(cid:4)

,L(cid:4)

,L(cid:4)

1

1

2).

1

1

,L(cid:4)

1

,L(cid:4)

,L(cid:4)

,L(cid:4)

2) and (L(cid:4)

We use (L1,L2) ≡e (L(cid:4)
,L(cid:4)

2) are equally
2) (cid:6)e (L1,L2). As usual, we
2) (cid:9)(cid:6)e

2) and (L(cid:4)

2) to denote that (L1,L2) and (L(cid:4)
,L(cid:4)

2) to denote that (L1,L2) (cid:6)e (L(cid:4)

expressive, that is, (L1,L2) (cid:6)e (L(cid:4)
write (L1,L2) ≺e (L(cid:4)
(L1,L2).
Example 3. It is easy to show that (∅, Dump) ≺e (∅, Tpf). That is, whenever you
have a server that can only provide a Dump of its dataset and you do not have
any additional power in the client, then you can accomplish strictly less tasks
compared with the case in which you have access to a server that can answer
Tpf queries. In the next section we prove more such relationships (including less
trivial ones).

,L(cid:4)

1

1

1

1

1

3 Expressiveness Lattice

In this section we show the relationships between diﬀerent pairs of client and
server capabilities in terms of expressiveness. In particular, we establish a lattice 
that provides a full picture of many combinations of the server languages

374

O. Hartig et al.

mentioned in Sect. 2.1 with almost every possible response-combination language
constructed by using some of the algebra operators in {(cid:2)(cid:3),∪, (cid:2)(cid:3), π}. Figure 4 illustrates 
this expressiveness-related lattice. As we will show, some of the equivalences 
and separations in this lattice do not necessarily follow from standard
expressiveness results in the query language literature. In particular, the lattice
highlights the expressive power of using the brTpf interface [7]. It should be
noticed that several other combinations of response-combination languages and
server languages might have been considered. We plan to cover more of them
as part of our future work. Before going into the results, we make the following
simple observation about the expressiveness of LDFMs.
Note 1. Let (L1,L2) and (L(cid:4)
server languages s.t. L1 ⊆ L(cid:4)
(L1,L2) (cid:6)e (L(cid:4)

,L(cid:4)
2) be arbitrary pairs of response-combination/
1 and L2 ⊆ L(cid:4)
2. Then, it is easy to prove that

1

,L(cid:4)

2).

1

Fig. 4. Expressiveness lattice for LDFMs

3.1 The Expressiveness of Using the BRTPF Interface

We begin with a result that shows that brTpf in combination with join
and union in the client side is as expressive as server-side coreSparql with
{(cid:2)(cid:3),∪, (cid:2)(cid:3), π} in the client.
Theorem 1. ({∪, (cid:2)(cid:3)}, brTpf) ≡e ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, coreSparql).

A Formal Framework for Comparing Linked Data Fragments

375

The result, that might seem surprising, follows from two facts: (1) an LDFM
can use unbounded computational power to issue server requests, and (2) a
brTpf server can accept arbitrary solutions mappings to be joined with triple
patterns in the server side. The proof is divided in several parts and exploits a
trick that is used in practice to avoid client-side joins when accessing a brTpf
interface. We illustrate the main idea with an example. Assume that one wants
to compute a SPARQL query P of the form (t1Optt2) over G where t1 and t2
are triple patterns. Since (cid:2)P (cid:3)G = (cid:2)t1(cid:3)G (cid:2)(cid:3) (cid:2)t2(cid:3)G, one can easily evaluate P with a
({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, coreSparql)-LDFM by just evaluating t1 and t2 separately in the
server, and then using (cid:2)(cid:3) in the client to construct the ﬁnal output. On the other
hand, one can use the following strategy to evaluate P with a ({∪, (cid:2)(cid:3)}, brTpf)-
LDFM M. Recall that

(cid:2)t1(cid:3)G (cid:2)(cid:3) (cid:2)t2(cid:3)G = ((cid:2)t1(cid:3)G (cid:2)(cid:3) (cid:2)t2(cid:3)G) ∪ ((cid:2)t1(cid:3)G (cid:4) (cid:2)t2(cid:3)G),

where (cid:2)t1(cid:3)G (cid:4) (cid:2)t2(cid:3)G is the set of all mappings in (cid:2)t1(cid:3)G that are not compatible
with any mapping in (cid:2)t2(cid:3)G [2]. We can ﬁrst evaluate t1 in the server to obtain
(cid:2)t1(cid:3)G as one of M’s result containers, say D1. Next, M can use D1 to construct
the brTpf query (t2, (cid:2)t1(cid:3)G), which can be evaluated in the server and stored
in the next container D2. Notice that D2 now contains all mappings in (cid:2)t2(cid:3)G
that can be joined with some mapping in (cid:2)t1(cid:3)G. Now M can use its internal
computational power to produce the following set of queries: for every mapping
μ in D1 that is not compatible with any mapping in D2, M constructs the brTpf
query (t1,{μ}), sends it to the server, and stores the result in one of the result
containers, starting in container D3. Notice that M is essentially mimicking the
diﬀerence operator (cid:4) using one mapping at a time. After all these requests,
M has all the mappings of the set (cid:2)t1(cid:3)G (cid:4) (cid:2)t2(cid:3)G stored in its containers, every
mapping in a diﬀerent container. Moreover, given that D1 (cid:2)(cid:3) D2 = (cid:2)t1(cid:3)G (cid:2)(cid:3) (cid:2)t2(cid:3)G,
M can generate the client query (D1 (cid:2)(cid:3) D2)∪D3∪···∪DcM which will give exactly
(cid:2)t1(cid:3)G (cid:2)(cid:3) (cid:2)t2(cid:3)G. A similar strategy can be used to compute all other operators.
It is not diﬃcult to prove that when having coreSparql for server requests,
the operators {(cid:2)(cid:3),∪, (cid:2)(cid:3), π} on the client do not add any expressiveness. Moreover,
 from proving Theorem 1 it is easy to also obtain that ({∪, (cid:2)(cid:3)}, brTpf) ≡e
({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, brTpf). Thus, we have that all the following four settings are
equivalent in expressiveness:

({∪, (cid:2)(cid:3)}, brTpf) ≡e ({∪, (cid:2)(cid:3), (cid:2)(cid:3), π}, brTpf)

≡e ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, coreSparql) ≡e (∅, coreSparql).

These equivalences are shown at the top of the lattice in Fig. 4.

Theorem 1 has several practical implications. One way to read this result
is that whenever a brTpf interface is available, a machine having operators
{(cid:2)(cid:3),∪, (cid:2)(cid:3), π} in the client has plenty of options to produce query execution plans
to answer user queries. In particular, for user queries needing (cid:2)(cid:3) or π, the machine
may decide if some of these operators are evaluated in the client or part of them
are evaluated in the server. What Theorem 1 does not state is an estimation
of the cost of executing these diﬀerent plans. In Sect. 5 we shed some light on

376

O. Hartig et al.

this issue, in particular, we study the additional cost payed when using diﬀerent
server interfaces in terms of the number of requests sent to the server and the
size of the data transferred between server and client.

The following result shows that union in the client is essential to obtain

Theorem 1.
Theorem 2. ({(cid:2)(cid:3)}, brTpf) ≺e ({∪, (cid:2)(cid:3)}, brTpf).

It should be noticed that this result does not directly follow from the fact that
∪ cannot be expressed using (cid:2)(cid:3) since, as we have shown, a brTpf interface is very
expressive when queried with unbounded computational power. Towards proving
Theorem 2, it is clear that ({(cid:2)(cid:3)}, brTpf) (cid:6)e ({∪, (cid:2)(cid:3)}, brTpf). Thus, to prove the
theorem it only remains to show that ({∪, (cid:2)(cid:3)}, brTpf) (cid:9)(cid:6)e ({(cid:2)(cid:3)}, brTpf). The
following lemma proves something that, by Note 1 above, is actually stronger.
Lemma 1. ({∪}, Tpf) (cid:9)(cid:6)e ({(cid:2)(cid:3), (cid:2)(cid:3), π}, brTpf).

Consider the coreSparql query q = ((?X, a, 2)Union (3, b, 4)). It is clear
that q is computable by a ({∪}, Tpf)-LDFM. It can be proved that q is not
computable by a ({(cid:2)(cid:3), (cid:2)(cid:3), π}, brTpf)-LDFM.

The following result proves that join is also needed to obtain Theorem 1.

Theorem 3. ({∪}, brTpf) ≺e ({∪, (cid:2)(cid:3)}, brTpf).

As for Theorem 2, we only need to prove that ({∪, (cid:2)(cid:3)}, brTpf)

(cid:9)(cid:6)e

({∪}, brTpf) which follows from the next, stronger result.
Lemma 2. ({(cid:2)(cid:3)}, Tpf) (cid:9)(cid:6)e ({∪, π}, brTpf).

The lemma follows from the fact that a ({(cid:2)(cid:3)}, Tpf)-LDFM can produce solution 
mappings with an unbounded number of variables in its domain while, given
the restrictions of the brTpf interface, every solution mapping in the output of
a ({∪, π}, brTpf)-LDFM has at most three variables in its domain.

3.2 The Expressiveness of Using the TPF Interface

One interesting point is the comparison between Tpf and brTpf. The ﬁrst
important question is whether Theorem 1 can be obtained by considering Tpf
instead of brTpf. Our next result provides a negative answer.
Theorem 4. ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, Tpf) ≺e ({∪, (cid:2)(cid:3)}, brTpf).

We have that ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, Tpf) (cid:6)e ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, coreSparql) because
it holds that Tpf ⊆ coreSparql. By combining this with Theorem 1 we
obtain that ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, Tpf) (cid:6)e ({∪, (cid:2)(cid:3)}, brTpf). Thus, to prove Theorem 4
it remains to show that ({∪, (cid:2)(cid:3)}, brTpf) (cid:9)(cid:6)e ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, Tpf). We prove something 
stronger:
Lemma 3. (∅, brTpf) (cid:9)(cid:6)e ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, Tpf).

A Formal Framework for Comparing Linked Data Fragments

377

It turns out that Filter is all that one needs to add to Tpf to make it
comparable with brTpf. In fact, in terms of expressive power of LDFMs, Tpf
with Filter and brTpf are equivalent regardless of the client language.
Proposition 1. (L, brTpf) ≡e (L, Tpf + Filter) holds for every responsecombination 
language L.1

Given Proposition 1, in every combination in the lattice of Fig. 4 we can

replace brTpf by Tpf+Filter and the relationships still hold.

The next result shows an equivalence concerning Tpf and Bgp.

Proposition 2. (∅, Bgp) ≡e ({(cid:2)(cid:3)}, Tpf) ≡e ({(cid:2)(cid:3)}, Bgp)

Our ﬁnal result in this section is a set of incompatibilities for Tpf and brTpf

which follow from our previous results.

Corollary 1. The following relationships hold.
1. ({(cid:2)(cid:3),∪, (cid:2)(cid:3), π}, Tpf) and (∅, brTpf) are not comparable in terms of (cid:6)e.
2. ({∪}, Tpf) and ({(cid:2)(cid:3)}, brTpf) are not comparable in terms of (cid:6)e.
3. ({(cid:2)(cid:3)}, Tpf) and ({∪}, brTpf) are not comparable in terms of (cid:6)e.

The lattice of the expressiveness of LDFMs shown in Fig. 4 is constructed by

composing all the results in this section.

4 Comparisons Based on Classical Complexity Classes

Besides expressiveness, another classical measure is the (computational) complexity 
of query evaluation. In this section we present a simple analysis to provide
a comparison of LDFs settings in terms of the complexity of the query evaluation 
problem for the server and response-combination languages. In particular,
we focus on the combined complexity that measures the complexity of problems
for which a query and a dataset are both assumed to be given as input [12]. We
begin by deﬁning two new comparison notions.
Deﬁnition 3. We say that (L1,L2) is at most as server-power demanding as
(L(cid:4)
2), if the combined complexity of the
evaluation problem for L2 is at most as high as the combined complexity of the
2. Similarly, (L1,L2) is at most as result-construction
evaluation problem for L(cid:4)
demanding as (L(cid:4)
2), if the combined complexity 
of the evaluation problem for L1 is at most as high as the combined
complexity of the evaluation problem for L(cid:4)
1.

2), denoted by (L1,L2) (cid:6)sp (L(cid:4)

,L(cid:4)

,L(cid:4)

,L(cid:4)

,L(cid:4)

2), denoted by (L1,L2) (cid:6)rc (L(cid:4)

1

1

1

1

1 This result and the next are given as propositions instead of theorems because they
are simple to prove with standard notions of logic (as detailed in the aforementioned 
appendix of this paper) and they do not add an important separation in the
expressiveness lattice (Fig. 4).

378

O. Hartig et al.

,L(cid:4)

1

1

1

,L(cid:4)

,L(cid:4)

2) and (L(cid:4)

2) if (L1,L2) (cid:6)c (L(cid:4)

We write (L1,L2) ≡c (L(cid:4)

2) (cid:6)c
(L1,L2), for c ∈ {sp, rc}. The next result follows trivially from the results of
P´erez et al. [10] and Schmidt et al. [11] that show that for the And-fragment and
the Union-fragment of SPARQL, the evaluation problem is in PTime, respectively,
 for the And-Union-fragment it is NP-complete, and for fragments containing 
Opt it is PSpace-complete.
Corollary 2. For any server language LS, the following properties hold:
1. (∅,LS) ≡rc ({(cid:2)(cid:3)},LS) ≡rc ({∪},LS)
2. (∅,LS) (cid:6)rc ({(cid:2)(cid:3),∪},LS) (cid:6)rc ({(cid:2)(cid:3)},LS)
3. ({(cid:2)(cid:3)},LS) ≡rc ({(cid:2)(cid:3), (cid:2)(cid:3)},LS) ≡rc ({(cid:2)(cid:3), (cid:2)(cid:3),∪},LS) ≡rc ({(cid:2)(cid:3), (cid:2)(cid:3),∪, π},LS)
Moreover, for any response-combination language LC, the following properties
hold:
4. (LC , Bgp) ≡sp (LC, brTpf) ≡sp (LC , Tpf) ≡sp (LC , Dump)
5. (LC , Bgp) (cid:6)sp (LC, coreSparql)

Notice that the pairs of response-combination and server languages mentioned 
in the corollary can be organized into two additional lattices along the
lines of the expressiveness lattice in Fig. 4. That is, Properties 1–3 in Corollary 2
establish a result-construction demand lattice, and Properties 4 and 5 establish
a server-power demand lattice. However, both of these lattices consist of only a
single path from top to bottom.

5 Additional Complexity Measures

In the previous sections we provide a base for comparing diﬀerent combinations
of client/server capabilities considering expressiveness and complexity. While
these comparisons are a necessary starting point, from a practical point of view
one would also want to compare the computational resources that have to be
payed when using one LDF interface or another. More speciﬁcally, assume that
you have two combinations of client and server capabilities that are equally
expressive, that is, (L1,L2) ≡e (L(cid:4)
2). Then, we know that every task that
can be completed in (L1,L2) can also be completed in (L(cid:4)
2). The question
however is: are we paying an additional cost when using one setting or the other?
Or more interestingly, is any of the two strictly better than the other in terms
of some of the resources needed to answer queries? In this section we show the
suitability of our proposed framework to also analyze this aspect of LDFs.

,L(cid:4)

,L(cid:4)

We begin this section with a deﬁnition that formalizes two important
resources used when consuming Linked Data Fragments, namely, the number
of requests sent to the server, and the total size of the data transferred from the
server to the client.

1

1

Deﬁnition 4. For an LDFM M, an RDF query q, and an RDF graph G, we
deﬁne the number of requests of M with input (q, G), denoted by rM (q, G), as

A Formal Framework for Comparing Linked Data Fragments

379

the ﬁnal value of counter cM during the computation of M with input (q, G).
Similarly, the amount of data transferred by M with input (q, G), denoted by
tM (q, G), is deﬁned as the value |D1| + |D2| + ··· + |DrM (q,G)|.

We can now deﬁne the request and transfer complexity of classes of RDF

queries.
Deﬁnition 5. Let f be a function from the natural numbers. A class C of
RDF queries has request complexity at most f under (L1,L2) if there exists
an (L1,L2)-LDFM M that computes every query q ∈ C such that for every q ∈ C
and RDF graph G it holds that rM (q, G) ≤ f(|q| + |G|). Similarly we say that
C has transfer complexity at most f under (L1,L2) if there exists an (L1,L2)-
LDFM M that computes every q ∈ C such that tM (q, G) ≤ f(|q| + |G|) for every
q ∈ C and RDF graph G.

We now have all the necessary to present our main notions to compare different 
classes of RDF queries in terms of the resources needed to compute them
with LDFMs.
1 be response-combination languages and L2,L(cid:4)
Deﬁnition 6. Let L1,L(cid:4)
2 be
,L(cid:4)
server languages. Then, (L1,L2) is at most as request demanding as (L(cid:4)
2),
denoted by (L1,L2) (cid:6)r (L(cid:4)
,L(cid:4)
2), if the following condition holds: For every function 
f and every class C of RDF queries expressible in both (L1,L2) and (L(cid:4)
,L(cid:4)
2),
2), then C has request comif 
C has request complexity at most f under (L(cid:4)
plexity at most f under (L1,L2). We similarly deﬁne the notions of being at
most as data-transfer demanding, and denote it using (cid:6)t.

,L(cid:4)

1

1

1

1

Regarding the notions in Deﬁnition 6 we make the following general observation.

Note 2. Let (L1,L2) and (L(cid:4)
server languages s.t. L1 ⊆ L(cid:4)
(L(cid:4)
putable under (L(cid:4)
putable under (L1,L2). Therefore, it follows trivially that (L(cid:4)
and (L(cid:4)

2) be arbitrary pairs of response-combination/
2), any
2)-LDFM that can be used to compute the class of RDF queries com-
2) can also be used to compute every RDF query that is com-
2) (cid:6)r (L1,L2)

2. Since (L1,L2) (cid:6)e (L(cid:4)

,L(cid:4)
1 and L2 ⊆ L(cid:4)

2) (cid:6)t (L1,L2).

,L(cid:4)

,L(cid:4)

,L(cid:4)

,L(cid:4)

,L(cid:4)

1

1

1

1

1

1

1

2) to denote that (L1,L2) (cid:6)c (L(cid:4)

We next show some (less trivial) results that provide more speciﬁc comparisons 
with respect to the above introduced notions. To this end, we write
(L1,L2) ≺c (L(cid:4)
2) (cid:9)(cid:6)c
,L(cid:4)
(L1,L2), for c ∈ {r, t}.
Recall that (∅, Bgp), ({(cid:2)(cid:3)}, Tpf), and ({(cid:2)(cid:3)}, Bgp) are all equivalent in terms
of expressive power. The next result proves formally that, in terms of the data
transferred, they can actually be separated.
Proposition 3. It holds that ({(cid:2)(cid:3)}, Bgp) ≺t ({(cid:2)(cid:3)}, Tpf). Moreover, ({(cid:2)(cid:3)}, Tpf)
and (∅, Bgp) are not comparable in terms of (cid:6)t. Regarding the number of requests
it holds that ({(cid:2)(cid:3)}, Bgp) ≡r (∅, Bgp) ≺r ({(cid:2)(cid:3)}, Tpf).

2) and (L(cid:4)

,L(cid:4)

,L(cid:4)

1

1

380

O. Hartig et al.

To see why the (cid:6)t incomparability result holds, consider the class C1 of
SPARQL queries of the form ((?X1, ?Y1, ?Z1) And (?X2, ?Y2, ?Z2)). It can be
shown that any (∅, Bgp)-LDFM M that computes C1 is such that tM (q, G),
as a function, is in Ω(|G|2). On the other hand there exists a ({(cid:2)(cid:3)}, Tpf)-
LDFM M(cid:4) such that tM(cid:2)(q, G) is in O(|G|). This shows that (∅, Bgp) (cid:9)(cid:6)t
({(cid:2)(cid:3)}, Tpf). Consider now the class C2 of SPARQL queries of the form
((a1, b1, c1) And ··· And (ak, bk, ck)). One can show that any ({(cid:2)(cid:3)}, Tpf)-
LDFM M that computes C2 is such that tM (q, G) is in Ω(|q|) in the worst case.
On the other hand, C2 can be computed with a (∅, Bgp)-LDFM that, in the worst
case, transfers a single mapping (the complete query result) thus showing that
({(cid:2)(cid:3)}, Tpf) (cid:9)(cid:6)t (∅, Bgp). Class C2 can also be used to show that (∅, Bgp) ≺r
({(cid:2)(cid:3)}, Tpf). Our ﬁnal result shows that even though ({∪, (cid:2)(cid:3)}, brTpf) is very
expressive, one may need to pay an extra overhead in terms of transfer and
request complexity compared with a setting with a richer response-combination
language.

Theorem 5. The following strict relationships hold.
1. ({∪, (cid:2)(cid:3), (cid:2)(cid:3), π}, brTpf) ≺t ({∪, (cid:2)(cid:3)}, brTpf)
2. ({∪, (cid:2)(cid:3), (cid:2)(cid:3), π}, brTpf) ≺r ({∪, (cid:2)(cid:3)}, brTpf)

The ﬁrst point of this last theorem can be intuitively read as follows: in terms
of bandwidth, the best possible query plans for an LDFM that access a brTpf
interface and then construct the output using operators in {∪, (cid:2)(cid:3), (cid:2)(cid:3), π}, are
strictly better than the best possible query plans that access a brTpf interface
and then construct the output using operators in {∪, (cid:2)(cid:3)}. The second point has
a similar interpretation regarding the best possible query plans in terms of the
number of requests sent to the server.

Although in this section we did not present a complete lattice as for the case
of expressiveness in Sect. 3, these results show the usefulness of our framework
to formally compare diﬀerent options of Linked Data Fragments.

6 Concluding Remarks and Future Work

In this paper we have presented LDFMs, the ﬁrst formalization to model LDF
scenarios. By proving formal results based on LDFMs we show the usefulness of
our model to analyze the ﬁne-grain interplay between several metrics. We think
that our formalization is a ﬁrst step towards a theory to compare diﬀerent access
protocols for Semantic Web data. We next describe some possible directions for
future research regarding LDFMs, extensions to the model, and its usage in some
alternative scenarios.

In this paper we consider a speciﬁc set of client and server capabilities but
our framework is by no means tailored to them. In particular, it would be really
interesting to consider more expressive operators in the client languages and
also new LDF interfaces, and compare them with the ones presented in this
paper. One notable interface that is widely used in practice and that we plan

A Formal Framework for Comparing Linked Data Fragments

381

to integrate in our study is the URI-lookup interface to retrieve Linked Data
documents [4,5].

Besides the classical metrics (expressiveness and computational complexity),
in this paper we considered only the number of requests sent to the server and the
data transferred from server to client. It is easy to include other practical metrics
in our framework. One important practical metric might be the amount of data
transferred from the client to the server. In particular this metric might be very
important for the brTpf interface which requires sending solution mappings
from the client to the server. Notice that this metric can be formalized by simply
considering the space complexity on the request tape TR of an LDFM. Similarly,
if we consider the space complexity of the client query tape TC, then we can
restrict the size of the output query which makes sense as a restriction for clients
with local memory constraints.

Finally, our model and results can be used as a ﬁrst step towards a foundation
for the theoretical study of Semantic Web query planning; more speciﬁcally, we
would like to compile into our model already proposed languages for querying
Linked Data, and to formally study what are the server interfaces and client
capabilities needed to execute queries expressed in these languages, considering
also the cost of compilation and execution according to our formal metrics. One
possible starting point would be to study languages designed for live queries on
the Web of Linked Data. For instance, we have recently proposed LDQL [8],
which is a navigational language designed to query Semantic Web data based
on the URI-lookup interface. Although we have presented a fairly complete formal 
analysis of LDQL [8], the computational complexity considered was only a
classical analysis that disregards some important features of querying the Web
such as server communication, latency, etc. Our machine model plus the results
on comparisons of diﬀerent LDFs can help to derive a more realistic complexity
analysis for languages such as LDQL. We plan to tackle this problem in our
future work.

Acknowledgements. Hartig’s work has been funded by the CENIIT program at
Link¨oping University (project no. 17.05). P´erez is supported by the Millennium Nucleus
Center for Semantic Web Research NC120004, and ENLACE-Fondecyt VID-UChile.

References

1. Abiteboul, S., Vianu, V.: Queries and computation on the web. Theor. Comput.

Sci. 239(2), 231–255 (2000)

2. Arenas, M., Gutierrez, C., Miranker, D.P., P´erez, J., Sequeda, J.: Querying semantic 
data on the web. SIGMOD Rec. 41(4), 6–17 (2012)

3. Beek, W., Rietveld, L., Bazoobandi, H.R., Wielemaker, J., Schlobach, S.: LOD
laundromat: a uniform way of publishing other people’s dirty data. In: Mika, P.,
et al. (eds.) ISWC 2014. LNCS, vol. 8796, pp. 213–228. Springer, Cham (2014).
doi:10.1007/978-3-319-11964-9 14

4. Berners-Lee, T.: Design issues: linked data, July 2006
5. Bizer, C., Heath, T., Berners-Lee, T.: Linked data - the story so far. Int. J. Semant.

Web Inf. Syst. 5(3), 1–22 (2009)

382

O. Hartig et al.

6. Hartig, O.: SPARQL for a web of

linked data: semantics and computability.
 In: Simperl, E., Cimiano, P., Polleres, A., Corcho, O., Presutti, V. (eds.)
ESWC 2012. LNCS, vol. 7295, pp. 8–23. Springer, Heidelberg (2012). doi:10.1007/
978-3-642-30284-8 8

7. Hartig, O., Buil-Aranda, C.: Bindings-restricted triple pattern fragments. In:
Debruyne, C., Panetto, H., Meersman, R., Dillon, T., K¨uhn, E., O’Sullivan, D.,
Ardagna, C.A. (eds.) OTM 2016. LNCS, vol. 10033, pp. 762–779. Springer, Cham
(2016). doi:10.1007/978-3-319-48472-3 48

8. Hartig, O., P´erez, J.: LDQL: a query language for the web of linked data. J. Web

Semant. 41, 9–29 (2016)

9. Mendelzon, A.O., Milo, T.: Formal models of web queries. Inf. Syst. 23(8), 615–637

(1998)

10. P´erez, J., Arenas, M., Gutierrez, C.: Semantics and complexity of SPARQL. ACM

Trans. Database Syst. 34(3), 16:1–16:45 (2009)

11. Schmidt, M., Meier, M., Lausen, G.: Foundations of SPARQL query optimization.
In: Proceedings of the 13th International Conference on Database Theory (ICDT)
(2010)

12. Vardi, M.Y.: The complexity of relational query languages. In: STOC (1982)
13. Verborgh, R., Sande, M.V., Hartig, O., Herwegen, J.V., Vocht, L.D., Meester, B.D.,
Haesendonck, G., Colpaert, P.: Triple pattern fragments: a low-cost knowledge
graph interface for the web. J. Web Semant. 37–38, 184–206 (2016)

