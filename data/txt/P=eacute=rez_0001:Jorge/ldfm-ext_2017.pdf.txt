A Formal Framework for

Comparing Linked Data Fragments

Olaf Hartig1, Ian Letter2, and Jorge P´erez3

1 Dept. of Computer and Information Science (IDA), Link¨oping University, Sweden

olaf.hartig@liu.se

2 Departamento de Ingenier´ıa Matem´atica, Universidad de Chile

iletter@dim.uchile.cl

3 Department of Computer Science, Universidad de Chile

jperez@dcc.uchile.cl

Abstract. The Linked Data Fragment (LDF) framework has been proposed as a
uniform view to explore the trade-offs of consuming Linked Data when servers
provide (possibly many) different interfaces to access their data. Every such interface 
has its own particular properties regarding performance, bandwidth needs,
caching, etc. Several practical challenges arise. For example, before exposing a
new type of LDFs in some server, can we formally say something about how this
new LDF interface compares to other interfaces previously implemented in the
same server? From the client side, given a client with some restricted capabilities
in terms of time constraints, network connection, or computational power, which
is the best type of LDFs to complete a given task? Today there are only a few
formal theoretical tools to help answer these and other practical questions, and
researchers have embarked in solving them mainly by experimentation.
In this paper we propose the Linked Data Fragment Machine (LDFM) which is
the ﬁrst formalization to model LDF scenarios. LDFMs work as classical Turing 
Machines with extra features that model the server and client capabilities. By
proving formal results based on LDFMs, we draw a fairly complete expressiveness 
lattice that shows the interplay between several combinations of client and
server capabilities. We also show the usefulness of our model to formally analyze
the ﬁne grain interplay between several metrics such as the number of requests
sent to the server, and the bandwidth of communication between client and server.

1

Introduction

The idea behind Linked Data Fragments (LDFs) is that different Semantic Web servers
provide (possibly many) different interfaces to access their datasets allowing clients to
decide which interface better satisﬁes a particular need. Every such interface provides
a particular type of so-called “fragments” of the underlying dataset [14]. Moreover, every 
interface has its own particular properties regarding performance, bandwidth needs,
cache effectiveness, etc. Clients can analyze the tradeoffs when using one of these interfaces 
(or a combination of them) for completing a speciﬁc task. There are a myriad
of possible interfaces in between SPARQL endpoints and RDF data dumps. Some interfaces 
that have already been proposed in the literature include Linked Data Documents 
[4,5], Triple Pattern Fragments (TPF) [14], and Bindings-Restricted Triple Pattern 
Fragments (brTPF) [8]. Different options for LDF interfaces are shown in Figure 1.

Fig. 1. Unidimensional view of Linked Data Fragments (from [8,14] )

Linked Data Fragments have already had a considerable practical impact. For instance,
 since the proposal of TPFs, the LOD Laundromat Website has published more
than 650,000 datasets on the Web with this interface [3]. Moreover, DBPedia [6] has
also published a TPF interface which had an uptime of 99.99% during its ﬁrst nine
months working [14]. Up to now, the research and development of LDFs have produced
interesting practical results, but they are deﬁnitely not the ﬁnal answer to querying semantic 
data on the Web, and one may expect that many new fragments with different
tradeoffs can be made available by Semantic Web data servers in the near future.

Several practical challenges arise. On the server side, developers need to construct
LDF interfaces that ensure a good cost/performance tradeoff. Before implementing a
new interface in some server, can we formally say something about the comparison of
this new type of LDFs with earlier-proposed types? If the new interface is somehow
subsumed in capabilities and cost by previously implemented interfaces (or by a simple
combination of them), then there might be no reason to implement it. Answering this
question requires an answer to the more general question on how to formally compare
the properties of two different LDF interfaces given only their speciﬁcations.

On the client side, developers need to efﬁciently use and perhaps combine LDF
interfaces. Thus, an interesting problem is the following: given a client with some restricted 
capabilities (in terms of time constraints, small budget, little computational
power, restricted local expressiveness, etc.) and a task to be completed, which is the
best interface that can be used to complete the task? Or even more drastically, can the
task be completed at all given the restrictions on the client and a set of LDF interfaces
to choose from? Today there are only a few formal tools to help answer the previously 
described questions, and researchers have embarked in solving them mainly by
experimentation. The main goal of this paper is to help ﬁll this gap by developing solid
theoretical foundations for studying and comparing LDF interfaces.

One of our main hypotheses is that it is possible to compare LDF interfaces in
different ways beyond a single axis as the one shown in Figure 1. In that ﬁgure three
criteria are considered: (1) client vs. server effort, (2) general vs. speciﬁc requests, and
(3) high vs. low availability. The ﬁgure suggests that whenever we need more speciﬁc
requests, then we will have more server effort and less availability. Similarly, more
general requests would imply higher availability and less server effort (and thus more
client work) [14]. More generally, the single axis implies that these three criteria are
correlated and, for example, the Linked Data Documents interface is always in between
data dumps and SPARQL endpoints. However, lets consider expressiveness as another
criterion; more speciﬁcally, lets consider the type of queries that can be answered if we

allow the client to use full computational power (Turing complete) to process data after
making as many requests to the server as it needs. Assume that we have a server that
provides data dumps, Linked Data Documents, and a SPARQL endpoint. Then, one can
formally prove that the client is strictly less expressive when accessing the Linked Data
Documents instead of the data dump or the SPARQL endpoint. To see this, consider a
query of the following form:

Q1: “Give me all the subjects and objects of RDF triples whose predicate is rdf:type.”

It can be argued that Q1 cannot be answered by accessing a dataset using the Linked
Data Document interface no matter how many requests the client sends to the server [7].
On the other hand, it is not difﬁcult to show that both data dumps and SPARQL endpoints 
can actually answer Q1. Thus, when considering the expressiveness dimension,
Linked Data Documents are not longer in between data dumps and SPARQL endpoints.
Consider another scenario in which one wants to measure only the number of requests 
that the client sends to the server in order to answer a speciﬁc query. Lets assume
this time that the server provides a data dump, a SPARQL endpoint, and a TPF interface,
and consider the following query.

Q2: “Give me all the persons reachable from Peter by following two foaf:knows links.”

It is straightforward to see that a client using either the data dump or the SPARQL
endpoint can answer this query by using a single request to the server, while a TPF
client needs at least two requests. Thus, in this case, data dumps are more efﬁcient than
TPFs in terms of number of server requests. On the other hand it is clear that in terms
of the amount of data transferred, TPFs are more desirable for Q2 than data dumps.

Although the two examples described above are very simple, they already show that
the comparison of LDF interfaces is not always one-dimensional. Moreover, the comparison 
can quickly become more complex as we want to analyze and compare more
involved scenarios. For instance, in both cases above we just analyzed a single query.
In general, one would like to compare LDF interfaces in terms of classes of queries.
Another interesting dimension is client-side computational power. In both cases above
we assumed that the client is Turing complete, and thus the client is able to apply any
computable function to the fragments obtained from an LDF interface. However, one
would like to consider also clients with restricted capabilities (e.g., in terms of computational 
power or storage). Moreover, other dimensions such as bandwidth from client
to server, bandwidth from server to client, time complexity on the server, cacheability
of results, and so on, can substantially add difﬁculty to the formal analysis. In this paper
we embark on the formal study of Linked Data Fragments by proposing a framework
in which several of the aforementioned issues can be formally analyzed.
Main contributions and organization of the paper: As our main conceptual contribution 
we propose the Linked Data Fragment Machine (LDFM). LDFMs work as classical
Turing Machines with some extra features that model the server and client capabilities
in an LDF scenario. Our machine model is designed to clearly separate three of the
main tasks done when accessing a Linked Data Fragment server: (1) the computation
that plans and drives the overall query execution process by making requests to the

server, (2) the computation that the server needs to do in order to answer requests issued 
by the client, and (3) the computation that the client needs to do to create the ﬁnal
output from the server responses. These design decisions allow us to have a model that
is powerful enough to capture several different scenarios while simple enough to allow
us to formally prove properties about it. The LDFM model is presented in Section 2.

As one of our main technical contributions, we use our machine to formalize the
notion of expressiveness of an LDF scenario and we draw a fairly complete lattice
that shows the interplay between several combinations of client and server capabilities.
While expressiveness is studied in Section 3, in Section 4 we analyze LDF scenarios in
terms of classical computational complexity. Moreover, our machine model also allows
us to formally analyze LDFs in terms of two additional important metrics, namely, the
number of requests sent to the server, and the bandwidth of communication between the
server and the client. Both notions are formalized as speciﬁc computational-complexity
measures over LDFMs. We present formal results comparing different scenarios and
demonstrate the suitability of our proposed framework to also analyze the ﬁne-grain
interplay between complexity metrics. These results are presented in Section 5.

For the sake of space most of the details on the proofs have been omitted but can be

found at http://dcc.uchile.cl/˜jperez/ldfm-ext.pdf.

2 Linked Data Fragment Machine

This section introduces our abstract machine model that captures possible client-server
systems that execute user queries, issued at the client side, over a server-side dataset.

Informally, the machine in our model resides in the client side and is in charge of
the communication with the server. To this end, the machine uses a server language,
LS, which essentially represents the type of requests that the server interface is able to
answer. Additionally, the machine is also in charge of producing the result of the given
user query by combining the responses from the server. The corresponding result-construction 
capability is captured by a client language, LC, which is an algebra over the
server responses. To answer a user query the machine performs the following general
process: The machine begins by creating requests for the server in the form of LS
queries. After issuing such a request, the corresponding response becomes available in
an internal result container. Then, the machine can decide to continue with this process
by issuing another request. Every response from the server is stored in a different result
container, and moreover, a result container cannot be modiﬁed after it is ﬁlled with a
server response (i.e., it can only be read by the machine). In the ﬁnal step, the machine
uses the client language LC to create a query over the result containers. The execution
of this LC query produces the ﬁnal output of the process (that is, the result of the user
query). In the following, we deﬁne the machine formally. We ﬁrst formally capture the
different types of query languages involved and next we provide the formal deﬁnition of
the machine; thereafter, we describe the rationale of the different parts of the machine
and we introduce notions of computability and expressiveness based on the machine.

2.1 Preliminaries
Our model assumes three types of queries: user queries, requests, and transformations.

User queries are queries that are issued at the client side and that the client-server
system (captured by our machine) executes over the server-side dataset. We assume that
this dataset is represented as an RDF graph without blank nodes. Then, a possible class
of user queries could be SPARQL queries. However, to make our model more general
we allow user queries to be expressed also in other query languages. To this end, for
our model we introduce the abstract notion of an RDF query. Formally, an RDF query
is an expression q for which there exists an evaluation function that is deﬁned for every

RDF graph G and that returns a set of SPARQL solution mappings, denoted by(cid:74)q(cid:75)G.

Requests are queries that the client sends to the server during the execution of
a user query. The form of these requests depends on the type of interface provided
by the server. We capture such interface types (and, thus, the possible requests) by
introducing the notion of a server language; that is, a language LS that is associated
with an evaluation function that, for every query qR ∈ LS and every RDF graph G,

returns a set of SPARQL solution mappings, which we denote by(cid:74)qR(cid:75)G. Examples of

server languages considered in this paper are given as follows:

– CORESPARQL is the core fragment of SPARQL that considers triple patterns, AND,
OPT, UNION, FILTER, and SELECT. Due to space limitations, we refer to [11,2] for
a formal deﬁnition of this fragment and its evaluation function.

– BGP is the basic graph pattern fragment of SPARQL (i.e., triple patterns and AND).
– TPF is the language composed of queries that are a single triple pattern. Hence, this

language captures servers that support the triple pattern fragments interface [14].

– TPF+FILTER is the language composed of queries of the form (tp FILTER θ) where

tp is a triple pattern and θ is a SPARQL built-in condition [11].

– BRTPF is the language composed of queries of the form (tp, Ω), where tp is a triple
pattern and Ω is a set of solution mappings. This language captures the bindingsrestricted 
triple pattern interface [8]. The evaluation function is deﬁned such that

for every RDF graph G it holds that(cid:74)(tp, Ω)(cid:75)G = πvars(tp)((cid:74)tp(cid:75)G (cid:111)(cid:110) Ω) where π
is the projection operator [12], vars(tp) is the set of variables in tp,(cid:74)tp(cid:75)G is the
function is simply(cid:74)tp(cid:75)G.

evaluation of tp over G [11], and (cid:111)(cid:110) is the join operator [11]. For simplicity we
assume that a triple pattern tp is also a BRTPF query in which case the evaluation

– DUMP is the language that has a single expression only, namely the triple pattern 
(?s, ?p, ?o) where ?s, ?p, and ?o are different variables. This language captures
interfaces for downloading the complete server-side dataset.

– URIF (URI-lookup fragment) is the language composed of queries of the form

(u, ?p, ?o) where u is a URI and ?p and ?o are distinct variables.

S we write LS ⊆ L(cid:48)

S. For instance, DUMP ⊆ TPF ⊆ BGP ⊆ CORESPARQL.

For any two server languages LS and L(cid:48)
also in L(cid:48)

S if every query in LS is
Server-response transformations are queries that describe how the result of a user
query can be produced from the server responses. Since each server response in our
model is a set of solution mappings, and so is the result of any user query, we assume
that server-response transformations can be expressed using languages that resemble
an algebra over sets of solution mappings. We call such a language a client language.
In this paper we denote such client languages by the set of algebra operators that they
implement. For instance, the client language denoted by the set {(cid:111)(cid:110), π} can be used

TO

(cid:104)M (q, G)(cid:105)

OC

TC

(cid:104)qC(cid:105)

TQ

(cid:104)q(cid:105)

D1
D2
D3

DcM

...
...

M

TD

(cid:104)G(cid:105)

OS

cM

TR

(cid:104)qR(cid:105)

...

(working tapes)

Fig. 2. (LC ,LS)-LDFM M

to combine multiple sets Ω1, . . . , Ωn of solution mappings by applying the aforementioned 
join and projection operators in an arbitrary manner. Other algebra operators that
we consider in this paper are the union and the left-outer join [2], denoted by ∪ and (cid:111)(cid:110),
respectively. Note that based on our notation, the empty operator set (∅) also denotes a
client language. This language can be used only to simply select one Ωi out of multiple
given sets Ω1, . . . , Ωn of solution mappings (i.e., without being able to modify Ωi).

2.2 Formalization

A Linked Data Fragment Machine (LDFM) M is a multi-tape Turing Machine with
the following special features. In addition to having several ordinary working tapes, M
has ﬁve special tapes: a query tape TQ, a data tape TD, a server-request tape TR, a
client tape TC, and an output tape TO. Tapes TQ and TD are read-only tapes, while TR,
TC, and TO are write-only tapes. As another special component, the machine has an
unbounded sequence D1, D2, . . . , Dk, . . . of result containers (which can also be considered 
as read-only tapes), and a counter cM , called the result counter, that deﬁnes the
last used result container. M also has four different modes: computing the next server
request (R), waiting for response (W ), computing client query (C), and done (F ). In
all these modes the machine works as a standard Turing Machine. Additionally, M has
access to two oracle machines: a server oracle OS, which is associated with a server
language LS, and a client oracle OC, associated with a client language LC.
An LDFM M receives as input an RDF query q and an RDF graph G. Before the
computation begins, q is assumed to be in tape TQ and G is assumed to be in tape TD.
All other tapes as well as the result containers are initially empty, the counter cM is
0, and the machine is in mode R. Then, during the computation, the machine can use
its ordinary working tapes arbitrarily (read/write). However, the access to the special
tapes is restricted. That is, tape TR can be used by the machine only when it is in mode
R, and tape TC can be used only in mode C. Moreover, the machine does not have
direct access to the tapes TD and TO; instead, the read-only tape TD can be accessed
only by the oracle OS, and the write-only tape TO can be accessed only by oracle OC.

Regarding the result containers, M is only able to read from them, and only oracle OS
is able to write in them. Figure 2 shows a diagram of an LDFM.
The computation of an LDFM M works as follows. While in mode R, the machine
can construct a query qR ∈ LS and write it in tape TR. When the machine is ﬁnished
writing qR, it may change to mode W, which is a call to oracle OS. The oracle then
increments the counter cM , deletes the content of tape TR, and writes the set of map-

pings(cid:74)qR(cid:75)G in the container DcM . Next, the computation continues, M changes back

to mode R, and the previous process may be repeated. Alternatively, at any point when
in mode R, the machine may decide to change to mode C. In this mode, M constructs
a query qC ∈ LC, writes it in tape TC, and changes to mode F , which is a call to oracle 
OC. Then, oracle OC evaluates qC over data D1, . . . , DcM , and writes the result
of this evaluation in tape TO which is the ﬁnal output of M. Hence, at this point the
computation terminates. We denote the ﬁnal output as M (q, G).

Example 1. A typical SPARQL endpoint scenario may be captured by an LDFM M
whose server language LS is CORESPARQL and the client language LC is ∅. For any
user query q, assuming q is in CORESPARQL, the machine simply copies q into tape TR
machine enters mode C, writes D1 (as an expression in LC = ∅) in tape TC, and enters

and enters mode W. After obtaining(cid:74)q(cid:75)G from oracle OS in result container D1, the
mode F . Then, oracle OC writes the query result(cid:74)q(cid:75)G from D1 to the output tape.

Example 2. Let M be an LDFM such that LS = BRTPF and LC = {(cid:111)(cid:110),∪}. Hence,
M has access to a server capable of handling BRTPF requests, and M can do joins
and unions to construct the ﬁnal output. Assume now that a user wants to answer a
SPARQL query q of the form ((?X, a, ?Y ) AND (?X, b, ?Y )), which is initially in tape
TQ. Then, to evaluate q over a graph G (in tape TD), M may work as follows: First, M
writes query (?X, a, ?Y ) in tape TR and calls OS by entering mode W. After this call

we have that D1 =(cid:74)(?X, a, ?Y )(cid:75)G. Now, M can write (?X, b, ?Y ) in tape TR, which
is another call to OS that produces D2 = (cid:74)(?X, b, ?Y )(cid:75)G. Finally, M writes query
is not difﬁcult to see that M (q, G) =(cid:74)q(cid:75)G. We may have an alternative LDFM M(cid:48) that
to obtain D1 =(cid:74)(?X, a, ?Y )(cid:75)G. Next, M(cid:48) performs the following iteration: for every
oracle OS to produce(cid:74)((?X, b, ?Y ),{µ})(cid:75)G = (cid:74)(?X, b, ?Y ))(cid:75)G (cid:111)(cid:110) {µ} in one of its
produces the ﬁnal output M(cid:48)(q, G). In this case we also have that M(cid:48)(q, G) =(cid:74)q(cid:75)G.

D1 (cid:111)(cid:110) D2 in tape TC and calls OC, which produces the output, M (q, G), in tape TO. It
computes q as follows. Initially, M(cid:48) calls the server oracle OS with query (?X, a, ?Y )
mapping µ ∈ D1 it writes the BRTPF query ((?X, b, ?Y ),{µ}) in TR and calls the
result containers. After all these calls, M(cid:48) writes query (D2 ∪ D3 ∪ ··· ∪ Dk) in tape
TC, where k = cM(cid:48) is the index of the last used result container. The oracle OC then

2.3 Rationale and Limitations of LDFMs
Machine models to formalize Web querying have been previously proposed in the literature 
[10,1,7]. Most of the early work in this context is based on an understanding
of the Web as a distributed hypertext system consisting of Web pages that are interconnected 
by hyperlinks. These machines then formalized the notion of navigation and
of data retrieval while navigating, and their focus was on classical computability issues 
(what can, and what cannot be computed in a distributed Web scenario). Though

similar in motivation, our machine model in contrast formalizes a different protocol to
access Web data. In this section we explain the rationale behind our design which also
differentiates it from previous proposals.
The perhaps most important characteristic of our model is that it separates the computation 
that creates the ﬁnal output (as done by the client oracle OC) from the computation 
that plans and drives the overall query execution process (as done by the LDFM
itself). This separation allows us to precisely pinpoint the computational power needed
for the latter without mixing it up with the power needed for constructing the output 
(and vice versa). Of course, in practice the two tasks do not need to be separated
into two consecutive phases as suggested by our model. In fact, an alternative version
of our model could allow the machine to use oracle OC multiple times to produce the
ﬁrst elements of the complete output as early as possible.
Another separation, which is perhaps more natural because it also exists in practice,
is the delegation of the computation of the server responses to the server oracle OS.
Besides also avoiding a mix-up when analyzing required computational power, this
separation additionally allows us to prevent the LDFM from accessing the data tape TD
directly. This features captures the fact that, in practice, a client also has to use the
server interface instead of being able to directly access the server-side dataset.

The result containers (D1, D2, . . .), with their corresponding result counter (cM ),
provide us with an abstraction based on which notions of network cost of different pairs
of client/server capabilities can be quantiﬁed. We shall use this abstraction to deﬁne
network-related complexity measures in Section 5.

While our notion of the LDFM provides us with a powerful model to formally study
many phenomena of LDF-based client-server settings, there are a few additional factors
in practice that are not captured by the model in its current form. In particular, the
model does not capture the option for the server to (i) split responses into pages (that
have to be requested separately) and (ii) send metadata with its responses that clients
can use to adapt their query execution plans. Additionally, in practice there may be a
cache located between the server and the client, which might have to be captured to
study metrics related to server load (given that such a cache is not equally effective
for different LDF interfaces [8,14]). We deliberately ignored these options to keep our
model sufﬁciently simple. However, corresponding features may easily be added to our
notion of an LDFM if useful for future analyses.

2.4 Computability and Expressiveness for LDFMs

We conclude the introduction of our machine model by deﬁning notions of computability 
and expressiveness based on LDFMs.

The most basic notion of computability for LDFMs is that of a computable query.
We say that an RDF query q is computable under an LDFM M if for every RDF graph G

it holds that M (q, G) =(cid:74)q(cid:75)G. That is, q is computable under M if with (q, G) as input,
M produces(cid:74)q(cid:75)G as output, for every possible graph G. We can also extend this notion

to classes of queries. Formally, the class of queries computed by an LDFM M, denoted
by C(M ), is the set of all RDF queries that are computable under M.

Notice that every LDFM comes with a client and a server language, and thus we
can also deﬁne classes of LDFMs in terms of the languages that they use. In particular,

we say that an LDFM M is an (LC,LS)-LDFM if the client language of M is LC and
the server language of M is LS. Now, we can deﬁne our main notion of computability.
Deﬁnition 1. Let LC be a client language and LS be a server language. A class C of
RDF queries is computable under (LC,LS) if there exists an (LC,LS)-LDFM M such
that every query q in C is computable under M.

1,L(cid:48)

We use (L1,L2) ≡e (L(cid:48)

1,L(cid:48)

1 be client languages and L2,L(cid:48)

2) is at least as expressive as (L1,L2), denoted by (L1,L2) (cid:22)e (L(cid:48)

Deﬁnition 1 is our main building block to compare different combinations of client
and server languages independent of the possible LDFMs that use these languages. The
following deﬁnition formalizes our main comparison notion.
Deﬁnition 2. Let L1,L(cid:48)
(L(cid:48)
class of queries that is computable under (L1,L2) is also computable under (L(cid:48)

2 be server languages. Then,
2), if every
1,L(cid:48)
2).
1,L(cid:48)
2) to denote that (L1,L2) and (L(cid:48)
1,L(cid:48)
2) are equally
2) (cid:22)e (L1,L2). As usual, we write
1,L(cid:48)
expressive, that is, (L1,L2) (cid:22)e (L(cid:48)
(L1,L2) ≺e (L(cid:48)
2) (cid:54)(cid:22)e (L1,L2).
1,L(cid:48)
2) and (L(cid:48)
1,L(cid:48)
Example 3. It is easy to show that (∅, DUMP) ≺e (∅, TPF). That is, whenever you have
a server that can only provide a DUMP of its dataset and you do not have any additional
power in the client, then you can accomplish strictly less tasks compared with the case
in which you have access to a server that can answer TPF queries. In the next section
we prove more such relationships (including less trivial ones).

1,L(cid:48)
2) to denote that (L1,L2) (cid:22)e (L(cid:48)

2) and (L(cid:48)

1,L(cid:48)

3 Expressiveness Lattice

In this section we show the relationships between different pairs of client and server
capabilities in terms of expressiveness. In particular, we establish a lattice that provides
a full picture of many combinations of the server languages mentioned in Section 2.1
with almost every possible client language constructed by using some of the algebra
operators in {(cid:111)(cid:110),∪, (cid:111)(cid:110), π}. Figure 3 illustrates this expressiveness-related lattice. As we
will show, some of the equivalences and separations in this lattice do not necessarily follow 
from standard expressiveness results in the query language literature. In particular,
the lattice highlights the expressive power of using the BRTPF interface [8]. It should be
noticed that several other combinations of client and server languages might have been
considered. We plan to cover more of them in the extended version of this paper.
expressiveness of LDFMs. Let (L1,L2) and (L(cid:48)
languages s.t. L1⊆L(cid:48)

Before going into the results, we make the following simple observation about the
2) be arbitrary pairs of client-server
1,L(cid:48)
2).

2. Then, it is easy to prove that (L1,L2) (cid:22)e (L(cid:48)

1 and L2⊆L(cid:48)

1,L(cid:48)

3.1 The Expressiveness of Using the BRTPF Interface

We begin with a result that shows that BRTPF in combination with join and union in the
client side is as expressive as server-side CORESPARQL with {(cid:111)(cid:110),∪, (cid:111)(cid:110), π} in the client.
Theorem 1. ({∪, (cid:111)(cid:110)}, BRTPF) ≡e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL).

({∪, (cid:111)(cid:110)}, BRTPF) ≡e ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF) ≡e ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, CORESPARQL) ≡e (∅, CORESPARQL)

({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, TPF)

({∪}, BRTPF)

({(cid:111)(cid:110)}, BRTPF)

({∪}, TPF)

(∅, BGP) ≡e ({(cid:111)(cid:110)}, TPF) ≡e ({(cid:111)(cid:110)}, BGP)

(∅, BRTPF)

(∅, TPF)

Fig. 3. Expressiveness lattice for LDFMs

The result, that might seem surprising, follows from two facts: (1) an LDFM can
use unbounded computational power to issue server requests, and (2) a BRTPF server
can accept arbitrary solutions mappings to be joined with triple patterns in the server
side. The proof is divided in several parts and exploits a trick that is used in practice to
avoid client-side joins when accessing a BRTPF interface. We illustrate the main idea
with an example. Assume that one wants to compute a SPARQL query P of the form
can easily evaluate P with a ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL)-LDFM by just evaluating
t1 and t2 separately in the server, and then using (cid:111)(cid:110) in the client to construct the ﬁnal
output. On the other hand, one can use the following strategy to evaluate P with a
({∪, (cid:111)(cid:110)}, BRTPF)-LDFM M. Recall that

(t1 OPT t2) over G where t1 and t2 are triple patterns. Since(cid:74)P(cid:75)G =(cid:74)t1(cid:75)G (cid:111)(cid:110)(cid:74)t2(cid:75)G, one

(cid:74)t1(cid:75)G (cid:111)(cid:110)(cid:74)t2(cid:75)G = ((cid:74)t1(cid:75)G (cid:111)(cid:110)(cid:74)t2(cid:75)G) ∪ ((cid:74)t1(cid:75)G (cid:114)(cid:74)t2(cid:75)G),

where(cid:74)t1(cid:75)G (cid:114)(cid:74)t2(cid:75)G is the set of all mappings in(cid:74)t1(cid:75)G that are not compatible with any
mapping in(cid:74)t2(cid:75)G [2]. We can ﬁrst evaluate t1 in the server to obtain(cid:74)t1(cid:75)G as one of M’s
result containers, say D1. Next, M can use D1 to construct the BRTPF query (t2,(cid:74)t1(cid:75)G),
D2 now contains all mappings in (cid:74)t2(cid:75)G that can be joined with some mapping in
(cid:74)t1(cid:75)G. Now M can use its internal computational power to produce the following set of

which can be evaluated in the server and stored in the next container D2. Notice that

queries: for every mapping µ in D1 that is not compatible with any mapping in D2, M
constructs the BRTPF query (t1,{µ}), sends it to the server, and stores the result in one
of the result containers, starting in container D3. Notice that M is essentially mimicking 
the difference operator (cid:114) using one mapping at a time. After all these requests, M

has all the mappings of the set(cid:74)t1(cid:75)G(cid:114)(cid:74)t2(cid:75)G stored in its containers, every mapping in a
different container. Moreover, given that D1 (cid:111)(cid:110) D2 =(cid:74)t1(cid:75)G (cid:111)(cid:110)(cid:74)t2(cid:75)G, M can generate

the client query (D1 (cid:111)(cid:110) D2) ∪ D3 ∪ ··· ∪ DcM which will give exactly(cid:74)t1(cid:75)G (cid:111)(cid:110)(cid:74)t2(cid:75)G.

A similar strategy can be used to compute all other operators.
It is not difﬁcult to prove that when having CORESPARQL for server requests, the operators 
{(cid:111)(cid:110),∪, (cid:111)(cid:110), π} on the client do not add any expressiveness. Moreover, from proving 
Theorem 1 it is easy to also obtain that ({∪, (cid:111)(cid:110)}, BRTPF) ≡e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, BRTPF).
Thus, we have that all the following four settings are equivalent in expressiveness:

({∪, (cid:111)(cid:110)}, BRTPF) ≡e ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF)

≡e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL) ≡e (∅, CORESPARQL).

These equivalences are shown at the top of the lattice in Figure 3.
Theorem 1 has several practical implications. One way to read this result is that
whenever a BRTPF interface is available, a machine having operators {(cid:111)(cid:110),∪, (cid:111)(cid:110), π} in
the client has plenty of options to produce query execution plans to answer user queries.
In particular, for user queries needing (cid:111)(cid:110) or π, the machine may decide if some of these
operators are evaluated in the client or part of them are evaluated in the server. What
Theorem 1 does not state is an estimation of the cost of executing these different plans.
In Section 5 we shed some light on this issue, in particular, we study the additional cost
payed when using different server interfaces in terms of the number of requests sent to
the server and the size of the data transferred between server and client.

The following result shows that union in the client is essential to obtain Theorem 1.

Theorem 2. ({(cid:111)(cid:110)}, BRTPF) ≺e ({∪, (cid:111)(cid:110)}, BRTPF).

It should be noticed that this result does not directly follow from the fact that ∪ cannot 
be expressed using (cid:111)(cid:110) since, as we have shown, a BRTPF interface is very expressive
when queried with unbounded computational power. Towards proving Theorem 2, it is
clear that ({(cid:111)(cid:110)}, BRTPF) (cid:22)e ({∪, (cid:111)(cid:110)}, BRTPF). Thus, to prove the theorem it only remains 
to show that ({∪, (cid:111)(cid:110)}, BRTPF) (cid:54)(cid:22)e ({(cid:111)(cid:110)}, BRTPF). We actually prove something
stronger in the following lemma.
Lemma 1. ({∪}, TPF) (cid:54)(cid:22)e ({(cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF).

Consider the CORESPARQL query q = ((?X, a, 2) UNION (3, b, 4)). It is clear that
q is computable by a ({∪}, TPF)-LDFM. It can be proved that q is not computable by a
({(cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF)-LDFM.

The following result proves that join is also needed to obtain Theorem 1.

Theorem 3. ({∪}, BRTPF) ≺e ({∪, (cid:111)(cid:110)}, BRTPF).

As for Theorem 2, we only need to prove that ({∪, (cid:111)(cid:110)}, BRTPF) (cid:54)(cid:22)e ({∪}, BRTPF)

which follows from the next, stronger result.
Lemma 2. ({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)e ({∪, π}, BRTPF).

The lemma follows from the fact that a ({(cid:111)(cid:110)}, TPF)-LDFM can produce solution
mappings with an unbounded number of variables in its domain while, given the restrictions 
of the BRTPF interface, every solution mapping in the output of a ({∪, π}, BRTPF)-
LDFM has at most three variables in its domain.

3.2 The Expressiveness of Using the TPF Interface

One interesting point is the comparison between TPF and BRTPF. The ﬁrst important
question is whether Theorem 1 can be obtained by considering TPF instead of BRTPF.
Our next result provides a negative answer.
Theorem 4. ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF) ≺e ({∪, (cid:111)(cid:110)}, BRTPF).

We have that ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF) (cid:22)e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL) because it
holds that TPF ⊆ CORESPARQL. By combining this with Theorem 1 we obtain that
({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF) (cid:22)e ({∪, (cid:111)(cid:110)}, BRTPF). Thus, to prove Theorem 4 it remains to show
that ({∪, (cid:111)(cid:110)}, BRTPF) (cid:54)(cid:22)e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF). We prove something stronger:
Lemma 3. (∅, BRTPF) (cid:54)(cid:22)e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF).

It turns out that FILTER is all that one should add to TPF to make it comparable with
BRTPF. In fact, in terms of expressive power of LDFMs, TPF and BRTPF are equivalent
regardless of the client language.
Proposition 1. (L, BRTPF) ≡e (L, TPF + FILTER) for every client language L.

Given Proposition 1, in every combination in the lattice of Figure 3 we can replace
BRTPF with TPF + FILTER and the relationships still hold. The next result shows an
equivalence concerning TPF and BGP.
Proposition 2. (∅, BGP) ≡e ({(cid:111)(cid:110)}, TPF) ≡e ({(cid:111)(cid:110)}, BGP)

Our ﬁnal result in this section is a set of incompatibilities for TPF and BRTPF which

follows from our previous results.

Corollary 1. The following relationships hold.
1. ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF) and (∅, BRTPF) are not comparable.
2. ({∪}, TPF) and ({(cid:111)(cid:110)}, BRTPF) are not comparable.
3. ({(cid:111)(cid:110)}, TPF) and ({∪}, BRTPF) are not comparable.

The lattice of the expressiveness of LDFMs shown in Figure 3 is constructed by

composing all the results in this section.

4 Comparisons Based on Classical Complexity Classes

Besides expressiveness, another classical measure is the (computational) complexity of
query evaluation. In this section we present a simple analysis to provide a comparison
of LDFs settings in terms of the complexity of the query evaluation problem for the
server and client languages. In particular, we focus on the combined complexity that
measures the complexity of problems for which a query and a dataset are both assumed
to be given as input [13]. We begin by deﬁning two new comparison notions.

1,L(cid:48)

1,L(cid:48)

1,L(cid:48)

1,L(cid:48)

2) if (L1,L2) (cid:22)c (L(cid:48)

1,L(cid:48)

We write (L1,L2) ≡c (L(cid:48)

2. Similarly, (L1,L2) is at most as result-construction demanding as (L(cid:48)

1,L(cid:48)
Deﬁnition 3. We say that (L1,L2) is at most as server-power demanding as (L(cid:48)
2),
denoted by (L1,L2) (cid:22)sp (L(cid:48)
2), if the combined complexity of the evaluation problem 
for L2 is at most as high as the combined complexity of the evaluation problem
for L(cid:48)
2), denoted 
by (L1,L2) (cid:22)rc (L(cid:48)
2), if the combined complexity of the evaluation problem
for L1 is at most as high as the combined complexity of the evaluation problem for L(cid:48)
1.
2) (cid:22)c (L1,L2),
for c ∈ {sp, rc}. The next result follows trivially from the results of Schmidt et al. [12].
Corollary 2. For any client language LC, the following properties hold:
1. (LC, BGP) ≡sp (LC, BRTPF) ≡sp (LC, TPF) ≡sp (LC, DUMP)
2. (LC, BGP) (cid:22)sp (LC, CORESPARQL)
Moreover, for any server language LS, the following properties hold:
3. (∅,LS) ≡rc ({(cid:111)(cid:110)},LS) ≡rc ({∪},LS)
4. (∅,LS) (cid:22)rc ({(cid:111)(cid:110),∪},LS) (cid:22)rc ({(cid:111)(cid:110)},LS)
5. ({(cid:111)(cid:110)},LS) ≡rc ({(cid:111)(cid:110), (cid:111)(cid:110)},LS) ≡rc ({(cid:111)(cid:110), (cid:111)(cid:110),∪},LS) ≡rc ({(cid:111)(cid:110), (cid:111)(cid:110),∪, π},LS)

2) and (L(cid:48)

1,L(cid:48)

Notice that the pairs of client and server languages mentioned in the corollary can
be organized into two additional lattices along the lines of the expressiveness lattice in
Figure 3. More speciﬁcally, Properties 1 and 2 in Corollary 2 establish a server-power
demand lattice, and Properties 3–5 establish a result-construction demand lattice. However,
 both of these lattices consist of only a single path from top to bottom.

5 Additional Complexity Measures

In the previous sections we provide a base for comparing different combinations of
client/server capabilities considering expressiveness and complexity. While these comparisons 
are a necessary starting point, from a practical point of view one would also
want to compare the computational resources that have to be payed when using one
LDF interface or another. More speciﬁcally, assume that you have two combinations of
client and server capabilities that are equally expressive, that is, (L1,L2) ≡e (L(cid:48)
1,L(cid:48)
2).
Then, we know that every task that can be completed in (L1,L2) can also be completed
in (L(cid:48)
2). The question however is: are we paying an additional cost when using one
setting or the other? Or more interestingly, is any of the two strictly better than the other
in terms of some of the resources needed to answer queries? In this section we show the
suitability of our proposed framework to also analyze this aspect of LDFs.

1,L(cid:48)

We begin this section with a deﬁnition that formalizes two important resources used
when consuming Linked Data Fragments, namely, the number of requests sent to the
server, and the total size of the data transferred from the server to the client.
Deﬁnition 4. For an LDFM M, an RDF query q, and an RDF graph G, we deﬁne the
number of requests of M with input (q, G), denoted by rM (q, G), as the ﬁnal value of
counter cM during the computation of M with input (q, G). Similarly, the amount of
data transferred by M with input (q, G), denoted by tM (q, G), is deﬁned as the value
|D1| + |D2| + ··· + |DrM (q,G)|.

We can now deﬁne the request and transfer complexity of classes of RDF queries.
Deﬁnition 5. Let f be a function from the natural numbers. A class C of RDF queries
has request complexity at most f under (L1,L2) if there exists an (L1,L2)-LDFM M
that computes every query q ∈ C such that for every q ∈ C and RDF graph G it holds
that rM (q, G) ≤ f (|q|+|G|). Similarly we say that C has transfer complexity at most f
under (L1,L2) if there exists an (L1,L2)-LDFM M that computes every q ∈ C such
that tM (q, G) ≤ f (|q| + |G|) for every q ∈ C and RDF graph G.

We now have all the necessary to present our main notions to compare different
classes of RDF queries in terms of the resources needed to compute them with LDFMs.
Deﬁnition 6. Let L1,L(cid:48)
2 be server languages. Then,
(L1,L2) is at most as request demanding as (L(cid:48)
1,L(cid:48)
2),
if the following condition holds: For every function f and every class C of RDF queries
expressible in both (L1,L2) and (L(cid:48)
2), if C has request complexity at most f under
2), then C has request complexity at most f under (L1,L2). We similarly deﬁne
(L(cid:48)
the notions of being at most as data-transfer demanding, and denote it using (cid:22)t.

1 be client languages and L2,L(cid:48)

2), denoted by (L1,L2) (cid:22)r (L(cid:48)

1,L(cid:48)

1,L(cid:48)

1,L(cid:48)

Regarding the notions in Deﬁnition 6 we make the following general observation.

1,L(cid:48)

1 and L2⊆L(cid:48)

Note 1. Let (L1,L2) and (L(cid:48)
2) be arbitrary pairs of client-server languages such
that L1⊆L(cid:48)
1,L(cid:48)
2)-LDFM that
can be used to compute the class of RDF queries computable under (L(cid:48)
1,L(cid:48)
2) can also
be used to compute every RDF query that is computable under (L1,L2). Therefore, it
2) (cid:22)t (L1,L2).
follows trivially that (L(cid:48)

2. Then, since (L1,L2) (cid:22)e (L(cid:48)

2) (cid:22)r (L1,L2) and (L(cid:48)

2), any (L(cid:48)

1,L(cid:48)

1,L(cid:48)

1,L(cid:48)

1,L(cid:48)

1,L(cid:48)

2) and (L(cid:48)

2) (cid:54)(cid:22)c (L1,L2), for c ∈ {r, t}.

respect to the above introduced notions. To this end, we write (L1,L2) ≺c (L(cid:48)
denote that (L1,L2) (cid:22)c (L(cid:48)

We next show some (less trivial) results that provide more speciﬁc comparisons with
2) to
Recall that (∅, BGP), ({(cid:111)(cid:110)}, TPF), and ({(cid:111)(cid:110)}, BGP) are all equivalent in terms of
expressive power. The next result proves formally that, in terms of the data transferred,
they can actually be separated.
Proposition 3. It holds that ({(cid:111)(cid:110)}, BGP) ≺t ({(cid:111)(cid:110)}, TPF). Moreover, ({(cid:111)(cid:110)}, TPF) and
(∅, BGP) are not comparable in terms of (cid:22)t. Regarding the number of requests it holds
that ({(cid:111)(cid:110)}, BGP) ≡r (∅, BGP) ≺r ({(cid:111)(cid:110)}, TPF).

1,L(cid:48)

To see why the (cid:22)t incomparability result holds, consider the class C1 of SPARQL
queries of the form ((?X1, ?Y1, ?Z1) AND (?X2, ?Y2, ?Z2)). It can be shown that
any (∅, BGP)-LDFM M that computes C1 is such that tM (q, G), as a function, is in
Ω(|G|2). On the other hand there exists a ({(cid:111)(cid:110)}, TPF)-LDFM M(cid:48) such that tM(cid:48)(q, G)
is in O(|G|). This shows that (∅, BGP) (cid:54)(cid:22)t ({(cid:111)(cid:110)}, TPF). Consider now the class C2
of SPARQL queries of the form ((a1, b1, c1) AND ··· AND (ak, bk, ck)). One can
show that any ({(cid:111)(cid:110)}, TPF)-LDFM M that computes C2 is such that tM (q, G) is in
Ω(|q|) in the worst case. On the other hand, C2 can be computed with a (∅, BGP)-
LDFM that, in the worst case, transfers a single mapping (the complete query result)
thus showing that ({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)t (∅, BGP). Class C2 can also be used to show that

(∅, BGP) ≺r ({(cid:111)(cid:110)}, TPF). Our ﬁnal result shows that even though ({∪, (cid:111)(cid:110)}, BRTPF) is
very expressive, one may need to pay an extra overhead in terms of transfer and request
complexity compared with a setting with a richer client language.

Theorem 5. The following strict relationships hold.
1. ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF) ≺t ({∪, (cid:111)(cid:110)}, BRTPF)
2. ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF) ≺r ({∪, (cid:111)(cid:110)}, BRTPF)

The ﬁrst point of this last theorem can be intuitively read as follows: in terms of
bandwidth, the best possible query plan for an LDFM that accesses a BRTPF interface
and then constructs the output using operators in {∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, is strictly better than the
best possible query plan that accesses a BRTPF interface and then constructs the output
using operators in {∪, (cid:111)(cid:110)}. The second point has a similar interpretation regarding the
best possible query plan in terms of the number of requests sent to the server.

Although in this section we did not present a complete lattice as for the case of
expressiveness in Section 3, these results show the usefulness of our framework to formally 
compare different options of Linked Data Fragments.

6 Concluding Remarks and Future Work

In this paper we have presented LDFMs, the ﬁrst formalization to model LDF scenarios.
By proving formal results based on LDFMs we show the usefulness of our model to
analyze the ﬁne-grain interplay between several metrics. We think that our formalization
is a ﬁrst step towards a theory to compare different access protocols for Semantic Web
data. We next describe some possible directions for future research regarding LDFMs,
extensions to the model, and its usage in some alternative scenarios.

In this paper we consider a speciﬁc set of client and server capabilities but our
framework is by no means tailored to them. In particular, it would be really interesting to
consider more expressive operators in the client languages and also new LDF interfaces,
and compare them with the ones presented in this paper. One notable interface that is
widely used in practice and that we plan to integrate in our study is URI-lookup interface
that we capture by the language URIF in Section 2.1.

Besides the classical metrics (expressiveness and computational complexity), in this
paper we considered only the number of requests sent to the server and the data transferred 
from server to client. It is easy to include other practical metrics in our framework.
 One important practical metric might be the amount of data transferred from the
client to the server. In particular this metric might be very important for the BRTPF interface 
which requires sending solution mappings from the client to the server. Notice
that this metric can be formalized by simply considering the space complexity on the request 
tape TR of an LDFM. Similarly, if we consider the space complexity of the client
query tape TC, then we can restrict the size of the output query which makes sense as a
restriction for clients with local memory constraints.

Finally, our model and results can be used as a ﬁrst step towards a foundation for
the theoretical study of Semantic Web query planning; more speciﬁcally, we would like
to compile into our model already proposed languages for querying Linked Data, and to

formally study what are the server interfaces and client capabilities needed to execute
queries expressed in these languages, considering also the cost of compilation and execution 
according to our formal metrics. One possible starting point would be to study
languages designed for live queries on the Web of Linked Data. In particular, we have
recently proposed the LDQL language [9] , which is a navigational language designed
to query Semantic Web data based on the URIF interface. Although we have presented a
fairly complete formal analysis of LDQL [9], the computational complexity considered
was only a classical analysis that disregards some important features of querying the
Web such as server communication, latency, etc. Our machine model plus the results on
comparisons of different LDFs can help to derive a more realistic complexity analysis
for languages such as LDQL. We plan to tackle this problem in our future work.

References

1. Abiteboul, S., Vianu, V.: Queries and Computation on the Web. Theor. Comput. Sci. 239(2),

231–255 (2000)

2. Arenas, M., Gutierrez, C., Miranker, D.P., P´erez, J., Sequeda, J.: Querying Semantic Data on

the Web. SIGMOD Record 41(4), 6–17 (2012)

3. Beek, W., Rietveld, L., Bazoobandi, H.R., Wielemaker, J., Schlobach, S.: LOD Laundromat:

A Uniform Way of Publishing Other People’s Dirty Data. In: ISWC (2014)

4. Berners-Lee,

T.: Design

issues:

Linked Data.

https://www.w3.org/

DesignIssues/LinkedData.html (July 2006)

5. Bizer, C., Heath, T., Berners-Lee, T.: Linked Data - The Story So Far. Int. J. Semantic Web

Inf. Syst. 5(3), 1–22 (2009)

6. DBpedia. http://dbpedia.org/
7. Hartig, O.: SPARQL for a Web of Linked Data: Semantics and Computability. In: Proceedings 
of the 9th Extended Semantic Web Conference (ESWC) (2012)

8. Hartig, O., Buil-Aranda, C.: Bindings-Restricted Triple Pattern Fragments. In: Proc. of the
15th Int. Conf. on Ontologies, Databases, and Applications of Semantics (ODBASE) (2016)
9. Hartig, O., P´erez, J.: LDQL: A Query Language for the Web of Linked Data. J. Web Sem.

41, 9–29 (2016)

10. Mendelzon, A.O., Milo, T.: Formal Models of Web Queries. Inf. Syst. 23(8), 615–637 (1998)
11. P´erez, J., Arenas, M., Gutierrez, C.: Semantics and Complexity of SPARQL. ACM Trans.

Database Syst. 34(3), 16:1–16:45 (2009)

12. Schmidt, M., Meier, M., Lausen, G.: Foundations of SPARQL Query Optimization. In: Proceedings 
of the 13th International Conference on Database Theory (ICDT) (2010)

13. Vardi, M.Y.: The Complexity of Relational Query Languages. In: STOC (1982)
14. Verborgh, R., Sande, M.V., Hartig, O., Herwegen, J.V., Vocht, L.D., Meester, B.D., Haesendonck,
 G., Colpaert, P.: Triple Pattern Fragments: A Low-Cost Knowledge Graph Interface 
for the Web. J. Web Sem. 37-38, 184–206 (2016)

A Proofs of Section 3

A.1 Proof of Theorem 1
We ﬁrst prove that ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL) (cid:22)e ({(cid:111)(cid:110),∪}, BRTPF). Let M be a
({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL)-LDFM, and assume that M receives as input (q, G).
We will construct a ({(cid:111)(cid:110),∪}, BRTPF)-LDFM that simulates M, such that ¯M (q, G) =
M (q, G). Recall that M works by sending some requests to the server, receiving them
in result containers D1, D2, . . . , DcM and ﬁnally constructs a query over them using
{(cid:111)(cid:110),∪, (cid:111)(cid:110), π} that the client oracle computes in the output tape. We construct ¯M with the
following idea: ¯M will mimic the complete process done by M by using its unbounded
local computational power plus BRTPF calls to the server, and then reconstructing the
output of M using {∪, (cid:111)(cid:110)}.
¯M works initially as follows. It ﬁrst constructs the BRTPF query (?s, ?p, ?o), sends it
to the server and stores its result in D1. Notice that D1 = {ν | (ν(?s), ν(?p), ν(?o)) ∈
G}, and thus D1 essentially stores the complete graph G. After this, ¯M uses its unbounded 
computational power to mimic the full computation of M including the calls
that M send to the server oracle but considering D1 as the input graph and using only
its internal working tapes. Finally, ¯M mimics the call that M sends to its client oracle
to compute M (q, G). Notice that after all this process ¯M has the complete output of M
in one of its working tapes. We next show how ¯M can use it to produce this very same
output in its own output tape.
We ﬁrst show the special case in which M (q, G) = {µ}, that is the case in which
M produces a single mapping as output. Let dom(µ) = {?x1, ?x2, .., ?x(cid:96)} and assume
that µ(?xi) = ki for i ∈ {1, . . . , (cid:96)}. Recall that ¯M has the set {µ} in one of its working
tapes, and has the complete graph G in D1. Now for every i ∈ {1, . . . , (cid:96)} our LDFM ¯M
does the following. For every {?s → a, ?p → b, ?o → c} ∈ D1, ¯M sends the BRTPF
queries ((?xi, b, c),{?xi → ki}), ((a, ?xi, c),{?xi → ki}) and ((a, b, ?xi),{?xi →
ki}) to the server and stores the respective results in its result containers. We claim
that it cannot be the case that the result of all these queries is empty. On the contrary
assume that all are empty. Then there is not a single triple in G containing the value
ki which contradicts the fact that value ki is in the domain of one of the mappings
in M (q, G). Thus we know that there is at least one of the result containers that is
not empty after all these calls. Lets call Di to an arbitrary of the non empty result
mappings. Notice that Di has a single mapping, lets call it νi. Moreover, νi is a mapping
such that νi(?xi) = ki and dom(νi) =?xi. Finally, ¯M can construct the client query
qC = D1 (cid:111)(cid:110) D2 (cid:111)(cid:110) ··· (cid:111)(cid:110) D(cid:96) which can be evaluated by the client oracle to give
exactly a set with a single mapping ν such that dom(ν) = {?x1, ?x2, . . . , ?x(cid:96)} and
such that ν(?xi) = ki for i ∈ {1, . . . , (cid:96)}. Thus, we have that ν = µ which implies that
¯M (q, G) = {µ} = M (q, G).
Now assume that M (q, G) = {µ1, µ2, . . . , µp}. From the strategy shown above ¯M
can produce a result container ¯Di = {µi} for each i ∈ {1, . . . , p}. Then ¯M produces
the client query ¯D1 ∪ ¯D2 ∪ ··· ∪ ¯Dp. By the discussion above, it is straightforward to
prove that the evaluation of this query is exactly M (q, G), which completes our proof.
We still need to prove that ({(cid:111)(cid:110),∪}, BRTPF) (cid:22)e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL).
This is very easy by using Proposition ?? that we prove later in the appendix. From

that proposition we obtain that ({(cid:111)(cid:110),∪}, BRTPF) (cid:22)e ({(cid:111)(cid:110),∪}, TPF + FILTER). Moreover,
 since {(cid:111)(cid:110),∪} ⊆ {(cid:111)(cid:110),∪, (cid:111)(cid:110), π} and TPF + FILTER ⊆ CORESPARQL we obtain 
that ({(cid:111)(cid:110),∪}, TPF + FILTER) (cid:22)e ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, CORESPARQL). Thus composing
({(cid:111)(cid:110),∪}, BRTPF) (cid:22)e ({(cid:111)(cid:110),∪}, TPF + FILTER) and ({(cid:111)(cid:110),∪}, TPF + FILTER) (cid:22)e ({(cid:111)(cid:110)
,∪, (cid:111)(cid:110), π}, CORESPARQL) we obtain the property that we needed to prove.

A.2 Proof of Lemma 1

Consider the CORESPARQL query q = ((?X, a, 2) UNION (3, b, 4)). It is clear that
q is computable by a ({∪}, TPF)-LDFM by sending two requests to the server and
then combining the result with ∪. We next prove that q is not computable by a ({(cid:111)(cid:110)
{µ1, µ2}, where µ1 is a mapping such that dom(µ) = {?X} and µ(?X) = 1, and µ2 is
the empty mapping (that is, dom(µ2) = ∅). Let M be an arbitrary ({(cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF)-

, (cid:111)(cid:110), π}, BRTPF)-LDFM. In particular, let G = {(1, a, 2), (3, b, 4)}. Notice that(cid:74)q(cid:75)G =
LDFM and assume that M (q, G) =(cid:74)q(cid:75)G. One can prove that no matter how M works,

its output M (q, G) satisﬁes the following property:
Claim: if a mapping in M (q, G) has variable ?X in its domain, then every mapping in
M (q, G) has ?X in its domain.

Notice that this is a contradiction with the assumption that M (q, G) =(cid:74)q(cid:75)G, which

completes our proof.
We now prove the above claim. Recall M (q, G) is the resault of the evaluation of a
query qC by OC. So we will prove our claim by induction on the numbers of operations
that make qC. First if qC = Di, then M (q, G) it’s equivalent to an answer containers 
that comes of the evaluation of qi by OS. Then if there is µ ∈ M (q, G) such that
?x ∈ dom(µ) = var(qi) then for every ν ∈ ¯D we have that ?x ∈ var(qi) = dom(ν).
We have then the base case.

Now for the induction step. For this will have to work every posible operation applied 
on qC. First if qC = πV (d). Well if there is µ ∈ M (q, G) such that ?x ∈ dom(µ)
that means two things: ﬁrst there is a mappings µi ∈ d such that ?x ∈ dom(µi) and
that ?x ∈ V . Well by induction step then for every νi ∈ d we have that ?x ∈ dom(νi).
But then, since ?x ∈ V we have that for all ν ∈ M (q, G) we have that ?x ∈ dom(ν).
Now if qC = d1 (cid:111)(cid:110) d2. If there is µ ∈ M (q, G) such that ?x ∈ dom(µ) then there
is two compatibles mappings µ1 ∈ d1, µ2 ∈ d2 such that µ = µ1 ∪ µ2. Well then since
dom(µ) = dom(µ1)∪dom(µ2), without loss of generality we have that ?x ∈ dom(µ1).
Well then we have proved that there is a mapping µ1 ∈ D1 such that ?x ∈ dom(µ1).
By induction the for every mapping ν1 ∈ D1 we have that ?x ∈ dom(ν1). Now let
η ∈ M (q, G) be any mapping. Then there is two compatible mappings η1 ∈ d1, η2 ∈ d2
such that η = η1 ∪ η2. But then, since η1 ∈ d1 we have that ?x ∈ dom(η1) ⊂ dom(η).
Finally if qC = d1 (cid:111)(cid:110) d2 = (d1 (cid:111)(cid:110) d2) ∪ (d1 \ d2). Now let be µ ∈ M (q, G) such
that ?x ∈ dom(µ). There is two cases, ﬁrst if µ ∈ d1 (cid:111)(cid:110) d2 we fall on the later case and
then for every ν1 ∈ d1 we have that ?x ∈ dom(ν1) and that for every η ∈ d1 (cid:111)(cid:110) d2 we
have that ?x ∈ dom(η). Well then, for every ν ∈ M (q, G) we have that d1 (cid:111)(cid:110) d2 or that

ν ∈ d1 \ d2 ⊂ d1; and in any case we have that ?x ∈ dom(ν). Now if µ ∈ d1 \ d2,
we have that µ ∈ d1. Then by induction step we have that for every ν1 ∈ d1 we have
that ?x ∈ dom(ν1). Then on the same manner as before we can deduce that for all
η ∈ M (q, G) we have that ?x ∈ dom(η). Now we can conclude like before.

A.3 Proof of Lemma 2
We need to prove that ({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)e ({∪, π}, BRTPF). Let M be a ({∪, π}, BRTPF)-
LDFM. We ﬁrst prove the following claim.
Claim: for every query q and every graph G it holds that if there is a mapping µ ∈
M (q, G) then | dom(µ)| ≤ 3.
To see this, notice that if D is a result container during the computation of M, then D
is a set of solution mappings obtained from executing a BRTPF query. Then, it is clear
that if µ ∈ D we have that µ is deﬁned in at most three variables and then it holds
that | dom(µ)| ≤ 3. Now assume that M produces an output query qO using operators
{∪, π}. It is not difﬁcult to see that qO is equivalent to a query of the form

πS1 (T1) ∪ πS2 (T2) ∪ ··· ∪ πSk (Tk)

where every Ti is one of M’s result containers. Thus, if µ ∈ M (q, G) then µ ∈
πSi(Ti) = πSi(Dj) for some j, and thus given that every mapping in Dj is deﬁned
in at most 3 variables, we have that | dom(µ)| ≤ 3 which is the property that we wanted
to show.
Consider now the query q = ((?X, ?Y, ?Z) AND (?U, ?V, ?W )) which is clearly
computable by a ({(cid:111)(cid:110)}, TPF)-LDFM. Moreover, given the above claim it is easy to conclude 
that q is not computable by a ({∪, π}, BRTPF)-LDFM, since there are graphs for
which q produces mappings with more that 3 variables in its domain. Thus we prove that
there exists a query that is computable under ({(cid:111)(cid:110)}, TPF) but not under ({∪, π}, BRTPF)
which shows that ({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)e ({∪, π}, BRTPF).

A.4 Proof of Lemma 3
Let µ1 be a mapping such that dom(µ1) = {?X} and µ1(?X) = 1. Consider a query
if (1, a, 1) /∈ G. It is clear that q can be computed by a (∅, BRTPF)-LDFM with just
one request to server of the form ((?X, a, ?X),{{?X → 1}}). Now consider the graph

q such that for every G it holds that(cid:74)q(cid:75)G = {µ1} if (1, a, 1) ∈ G and(cid:74)q(cid:75)G = ∅
G(cid:48) = {(1, a, 1), (2, a, 1), (1, a, 2), (2, a, 2)}. Notice that(cid:74)q(cid:75)G(cid:48) = {µ1}. Let M be an arbitrary 
({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, TPF)-LDFM and assume that M (q, G(cid:48)) =(cid:74)q(cid:75)G(cid:48). One can prove

that no matter how M works, its output M (q, G(cid:48)) satisﬁes the following property:
Claim: if there is a mapping µ in M (q, G(cid:48)) such that µ(?X) = 1, then there exists
a mapping µ(cid:48) ∈ M (q, G(cid:48)) such that µ(cid:48)(?X) = 2, and moreover, for every pair of
mappings ν, ν(cid:48) ∈ M (q, G(cid:48)) and every variable ?Y such that ?Y (cid:54)=?X, it holds that
ν(?Y ) = ν(cid:48)(?Y ).

M (q, G(cid:48)) =(cid:74)q(cid:75)G(cid:48).

Thus, given that µ1 ∈ M (q, G(cid:48)) we obtain that µ2 ∈ M (q, G(cid:48)) where µ2 is a
mapping such that dom(µ2) = {?X} and µ2(?X) = 2, which contradicts the fact that

We now prove the above claim. Remember that M (q, G(cid:48)) comes from the evaluation
of qC by OC. So we will prove our claim by induction on numbers of operations that
make qC. On the base case qC = Di, then M (q, G(cid:48)) is actually equivalent to the a answer 
container of a query qi sent to the server. First we will prove it if |var(qi)| = 1, on
that case the mappings must be ν = µ1 and ν(cid:48) = µ2. Note that the left implies right part
comes from the fact that the only qi as above are (?x, a, 1), (1, a, ?x), (?x, a, 2), (2, a, ?x),
which fulﬁlls our claim. Now for the other one, suppose qi has µ2 but no µ1. Then
the machine can have a register that have µ1 but not µ2. Indeed, it can just send
h(qi), where h is the homomorphism that changes 1 and 2. Note that G(cid:48) is invariant 
under h, so the answer of h(qi) must be the same as qi but changing 1 with 2,
this is a contradiction with what we proved. So we are done on this case, now if
|var(qi)| = 2, the only query with answer that include a mapping that send ?x to 1
are (?x, a, 1),(?x, a, 2),(?x, ?s, 1),(?x, ?s, 2) and the queries made changing the last
component with the ﬁrst one. Note that all those query have answers that goes along
our claim. Finally if |var(qi)| = 3 that means it can only be (?x, ?s, ?y) or (?y, ?s, ?x)
who also fulﬁls our property. We have the base case.

Now the induction step; we will prove only the if, cause the only if follow by symmetry 
of our proposition. If qC = d1 ∪ d2, and let be ν ∈ M (q, G(cid:48)). Well then, w.l.g.,
ν ∈ d1. From our induction hypotheses then this happens if and only if it’s exists the
mappings ν(cid:48) ∈ d1 and then ν(cid:48) ∈ M (q, G(cid:48)).

1(?x) = f(cid:48)

Now if qC = d1 (cid:111)(cid:110) d2 and let be ν ∈ M (q, G(cid:48)) that means there are two compatible
mapping f1 ∈ d1, f2 ∈ d2 such that ν = f1 ∪ f2. First suppose ?x ∈ dom(f1) ∩
dom(f2). Well since ν(?x) = 1 this implies f1(?x) = f2(?x) = 1. By induction
1 ∈ d1, f(cid:48)
2 ∈ d2 that are equal to f1 and f2
hypothesis then there exists mapping f(cid:48)
respectively, except on ?x where f(cid:48)
2(?x) = 2. Note these are clearly com2 
∈ d1 (cid:111)(cid:110) d2 is our mapping. Indeed, clearly
1 ∪ f(cid:48)
patible. Now note that ν(cid:48) = f(cid:48)
ν(cid:48)(?x) = 2, and by deﬁnition, for ?y ∈ dom(ν(cid:48)) \ {?x} there exists i such that
i (?y) = fi(?y) = ν(?y). Now lets rewind and suppose, w.l.g., that ?x (cid:54)∈
ν(cid:48)(?y) = f(cid:48)
dom(f2). Well in that case we use the induction hypothesis on f1 and get a mapping
f(cid:48)
1 with the same properties that on the latest case. Notice that f(cid:48)
1 and f2 are compatible,
 since f1 and f2 are and f(cid:48)
1 is only different from f1 on a variable that is not on
1 ∪ f2 ∈ d1 (cid:111)(cid:110) d2, which is our mapping.
f2 domains. We then can deﬁne ν(cid:48) = f(cid:48)
1(?x) = 2, and by deﬁnition for ?y ∈ dom(ν(cid:48)) \ {?x} we will
Indeed, ν(cid:48)(?x) = f(cid:48)
have two cases. If ?y ∈ dom(f(cid:48)
1(?y) = f1(?y) = ν(?y) and if
y ∈ dom(f2) then ν(cid:48)(?y) = f2(?y) = ν(?y). Then we have this case.

1) well then ν(cid:48)(?y) = f(cid:48)

Now if qC = d1 (cid:111)(cid:110) d2 = (d1 (cid:111)(cid:110) d2) ∪ (d1 \ d2), and let be ν ∈ M (q, G(cid:48)).
Note that if ν ∈ d1 (cid:111)(cid:110) d2 we fall on the latest case, so let’s suppose ν ∈ d1 \ d2.
Well that means ν ∈ d1 and for all f ∈ d2 we have that ν1 and f are not compatible.
 From the ﬁrst part and our induction hypothesis we then have that ν(cid:48) ∈ d1.

We have to show that ν(cid:48) ∈ d1 \ d2. Well if that’s not the case there exists a function 
f(cid:48) ∈ d2 such that ν(cid:48) and f(cid:48) are compatible, that means that f(cid:48)(?x) = 2. By our
induction hypothesis we then have there is a mapping g ∈ d2 that g(?x) = 1 and
for all ?y ∈ dom(f(cid:48)) \ {?x} we have g(?y) = f(cid:48)(?y). If we show that g and ν are
compatible we arrive at a contradiction, then we must have ν(cid:48) ∈ d1 \ d2 and that ﬁnish 
the proof. Indeed note that g(?x) = ν(?x) = 1, and ∀?y ∈ dom(ν) \ {?x} we
have that ν(cid:48)(?y) = ν(?y). But then ν(cid:48)(?y) was compatible with f(cid:48); we have two cases
then. If ?y ∈ dom(f(cid:48)) then ν(cid:48)(?y) = f(cid:48)(?y), but by deﬁnition of g we then have that
ν(?y) = ν(cid:48)(?y) = f(cid:48)(?y) = g(?y). Now if ?y (cid:54)∈ dom(f(cid:48)) then ?y (cid:54)∈ dom(g). Well
then ∀?z ∈ dom(ν)∩ dom(g) we have g(?z) = ν(?z). And so g and ν are compatible.
Finally if qC = πV (d1). If ν ∈ M (q, G(cid:48)) that means there is a mapping µ such
that mu(?y) = ν(?y) for all ?y ∈ V . If ?x (cid:54)∈ V we have our property, so let’s work
when ?x ∈ V and ν(?x) = 1. By our induction hypothesis then there is a mapping
µ(cid:48) such that µ(cid:48)(?x) = 2 and on all other variables it is equal to µ. We will show
that ν(cid:48) = ΠV (µ(cid:48)) ∈ ¯D is the mapping we are searching for. Indeed, ?x ∈ V , so
ν(cid:48)(?x) = µ(cid:48)(?x) = 2. Also, ∀?y ∈ dom(ν) \ {?x} = V \ {?x} we have that ν(?y) =
µ(?y) = µ(cid:48)(?y) = ν(cid:48)(?y). This ﬁnishes our proof.

A.5 Proof of Proposition 1
We ﬁrst prove that (L, BRTPF) (cid:22)e (L, TPF + FILTER) for every L. Let D be a result 
container of a (L, BRTPF)-LDFM and assume that D stores the result of (t, Ω).
Then, this request can be obtained by using the following server request in a (L, TPF +
FILTER) machine. Just consider a query of the form

 .



(cid:95)

ν∈Ω

(cid:94)

q(t,Ω) = t FILTER

?X∈dom(ν)∩vars(t)

?X = ν(?X)

µ |= α where α is the FILTER expression. Thus in particular µ |= αν for a ν ∈ Ω. That
is, for every ?X ∈ dom(ν) ∩ vars(t) we have that µ |= (?X = ν(?X)) which implies
that µ(?X) = ν(?X), and then µ and ν are compatibles. Notice that this implies that

We next show that(cid:74)q(t,Ω)(cid:75)G = (cid:74)(t, Ω)(cid:75)G. Let µ ∈ (cid:74)q(t,Ω)(cid:75)G then µ ∈ (cid:74)t(cid:75)G and
µ ∪ ν ∈(cid:74)t(cid:75)G (cid:111)(cid:110) Ω, and since dom(µ) ⊆ vars(t) we have that µ ∈ πvars(t)((cid:74)t(cid:75)G (cid:111)(cid:110) Ω)
and thus µ ∈ (cid:74)(t, Ω)(cid:75)G. For the other direction, assume that µ ∈ (cid:74)(t, Ω)(cid:75)G. Thus
µ ∈ πvars(t)((cid:74)t(cid:75)G (cid:111)(cid:110) Ω) which implies that there exists µ(cid:48) ∈ (cid:74)t(cid:75)G and ν ∈ Ω such
we have that µ = µ(cid:48) ∈ (cid:74)t(cid:75)G. Moreover, given that µ(cid:48) = µ and ν are compatible, we
and thus µ |= αν which implies that µ ∈(cid:74)q(t,Ω)(cid:75)G. This is enough to prove that every

that µ(cid:48) and ν are compatible and µ = (µ(cid:48) ∪ ν)|vars(t). Given that dom(µ(cid:48)) = vars(t)
have that µ(?X) = ν(?X) for all ?X ∈ dom(ν) ∩ vars(t) (since vars(t) = dom(µ)),
(L, BRTPF)-LDFM can be simulated with a (L, TPF + FILTER)-LDFM.

We now prove the opposite direction. Let D be a result container of a (L, TPF +
FILTER)-LDFM and assume that D stores the result of (t FILTER θ) when it is executed
with input graph G. We next show how a (L, BRTPF)-LDFM M can use two requests
to the server to obtain the same result D in one of its result containers. M ﬁrst constructs 
a BRTPF request (t,{µ∅}) where µ∅ is the empty mapping and stores it in a

computational power to construct the set of mappings Ω = {µ ∈ D(cid:48) | µ |= θ}, and

result container, say D(cid:48). Notice that D(cid:48) contains(cid:74)t(cid:75)G. After that, M uses its internal
sends to the server the BRTPF request (t, Ω). Given that D(cid:48) =(cid:74)t(cid:75)G then Ω is exactly
(cid:74)(t FILTER θ)(cid:75). Thus(cid:74)(t, Ω)(cid:75)G = (cid:74)t(cid:75)G (cid:111)(cid:110) (cid:74)(t FILTER θ)(cid:75)G = (cid:74)(t FILTER θ)(cid:75)G, and

thus M can produce exactly D as one of its result containers. This is enough to prove
that every (L, TPF + FILTER)-LDFM can be simulated with a (L, BRTPF)-LDFM.

A.6 Proof of Proposition 2

First let see that:

(∅, BGP) ≺e ({(cid:111)(cid:110)}, TPF)

Let C be a class expresable on (∅, BGP). We will show that it is expresable under
({(cid:111)(cid:110)}, TPF). Let M be the (∅, BGP)-LDFM machine such that C = C(M ) . We will
make a ({(cid:111)(cid:110)}, TPF)-LDFM machine ¯M such that M (q, G) = ¯M (q, G), for ever graph
G and q ∈ C.

For this ﬁrst remember that M do some computation and then send some query q1
on BGP language to the server. Our machine ¯M just have to see a way around the fact
that q1 have AND between its triple patterns. So for that the idea is to decompose the
query q1 on its triplets that are separated by the AND. Then we send each one of the
separated to the server and we get answer containers of the triple patterns. Then we
recompose the answer of the query; if we need to continue computing it’s easy to see
¯M could do it on it’s working tape, and if we need it to evaluate q on G we do it with
(cid:111)(cid:110) with the help of qC.

Let us formalize the last idea. So M work doing some sort of computation and send
queries of the form qj = (t1 ∧ t2 ∧ ... ∧ tn) to the server, that response on some answer
container Dj.After that, since M doesn’t have any language on the client side it have
to select, someway, a register Dm and send it as a query to the client. Now to simulate
this on ¯M instead of sending qj to the server ﬁrst we write qj on our workband and we
send each tk of the query separated to the server, this gives responses ¯Dk
j . With this we
can obtaining the registers Dj on the workband, ¯M can do the computation itself. Now
(cid:111)(cid:110) ¯D2
as a query to the client we send ¯D1
m. For this to work we just have
m
m
(cid:111)(cid:110) ... (cid:111)(cid:110) ¯Dn
to show that ¯D1
m = Dm.
m

(cid:111)(cid:110) ... (cid:111)(cid:110) ¯Dn

(cid:111)(cid:110) ¯D2

m

Indeed, consider a mapping µ ∈ Dm. So this mapping is an answer to the query
qm = (t1 AND t2 AND ... AND tn). So note that for every triple tk we can deﬁne the
restriction µtk as that dom(µtk ) = var(tk) and ∀?x ∈ var(tk), µtk (?x) = µ(?x). So
note that if k (cid:54)= l then µtk and µtl are compatible. Indeed, if ?x ∈ dom(µtk )∩dom(µtj )
then, by construction, µtk (?x) = µ(?x) = µtl(?x). Note that by deﬁnition µtk (tk) =
µ(tk). Also note that µtk ∈ ¯Dk
m, indeed, if µ ∈ Dm that means that µ(qm) ∈ G, which
means that µ(tk) = µtk (tk) ∈ G,∀k, which means that µtk ∈ ¯Dk
m. So then, note that
µ = µt1 ∪ µt2 ∪ ... ∪ µtn, where (µti)n
i=1 are compatible. In fact, we already show
that they are compatible pairwise, which be induction leads they are compatible like a

family, and by construction we have the equality of the mappings. So that means that
µ ∈ ¯D1

(cid:111)(cid:110) ¯D2

m

m

(cid:111)(cid:110) ... (cid:111)(cid:110) ¯Dn
m.
(cid:111)(cid:110) ¯D2

Now let be µ ∈ ¯D1

(cid:111)(cid:110) ... (cid:111)(cid:110) ¯Dn

m

m

m, that means there are compatible mapping
such that µt1 ∪ µt2 ∪ ... ∪ µtm = µ and (µti)n
i=1 are compatibles. By deﬁnition of ¯Di
that means that µti(ti) ∈ G,∀i = 1, .., n. However that implies that µ(qm) ∈ G since
m
the mappings are compatibles. But that mean that µ ∈ Dm, which ﬁnishes the proof.
Now note that since TPF ⊂ BGP we already have ({(cid:111)(cid:110)}, TPF) (cid:22)e ({(cid:111)(cid:110)}, BGP). So

we have just have to prove that ({(cid:111)(cid:110)}, BGP) (cid:22)e (∅, BGP).

So let C an expresable class of queries under ({(cid:111)(cid:110)}, BGP) with a machine M. We

will construct a machine ¯M that express it under (∅, BGP) as it follows.

M works doing some computation, send queries qj to the server, which send Dj
as an answer. Finally it selects come registers and send B1 ∧ B2, ..,∧Bm to the client,
where Bi is some register on the machine. Our machine ¯M will do the same, but also
will store which query was sent for each register. Then when M selects the registers
to send them to the client united by a joint, our new machine ¯M will select the send
registers but wil send them united by a ∧ to the server, which will give some answer ¯B
and that will be our answer to the client.

Look that, like our last proof, all we need for that to work is that ¯B = B1 (cid:46)(cid:47)

B2, ..., (cid:46)(cid:47) Bm, which is proven like the last case. We conclude the equivalence.

B Proofs of Section 5

B.1 Proof of Proposition 3
Consider the class C1 of queries of the form ((?X1, ?Y1, ?Z1) AND (?X2, ?Y2, ?Z2)).
It can be shown that any (∅, BGP)-LDFM M that computes C1 is such that tM (q, G), as
a function, is in Ω(|G|2). On the other hand there exists a ({(cid:111)(cid:110)}, TPF)-LDFM M(cid:48) such
that tM(cid:48)(q, G) is in O(|G|). This shows that (∅, BGP) (cid:54)(cid:22)t ({(cid:111)(cid:110)}, TPF). Consider now
the class C2 of SPARQL queries of the form ((a1, b1, c1) AND ··· AND (ak, bk, ck)),
With all ai’s, bi’s and ci’s distinct values. One can show that any ({(cid:111)(cid:110)}, TPF)-LDFM M
that computes C2 is such that tM (q, G) is in Ω(|q|) in the worst case. On the other
hand, C2 can be computed with a (∅, BGP)-LDFM that, in the worst case, transfers
a single mapping (the complete query result) from server to client thus showing that
({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)t (∅, BGP). Notice that this last fact implies that ({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)t ({(cid:111)(cid:110)
}, BGP). This last property plus the fact that ({(cid:111)(cid:110)}, BGP) (cid:22)t ({(cid:111)(cid:110)}, TPF) implies that
({(cid:111)(cid:110)}, BGP) ≺t ({(cid:111)(cid:110)}, TPF). Class C2 can also be used to show that (∅, BGP) ≺r ({(cid:111)(cid:110)
}, TPF).
Consider the class C1 of queries of the form ((?X1, ?Y1, ?Z1) AND (?X2, ?Y2, ?Z2)).
It can be shown that any (∅, BGP)-LDFM M that computes C1 is such that tM (q, G), as

a function, is in Ω(|G|2). Indeed, note that since M doesn’t have any algebraic operation 
on the client size M (q, G) must be equivalent to an answer container, let’s call it ¯D.
Also note, from the query q, it follows that any µ in M (q, G) must fulﬁll | dom(µ)| = 6.
So that means that whatever query ¯q, M sent to the server to obtaining ¯D we know that
¯q had at least two triple patterns with distinct variable. It’s easy to see that kind of query
make us have Ω(|G|2) data transfer.

On the other hand there exists a ({(cid:111)(cid:110)}, TPF)-LDFM M(cid:48) such that tM(cid:48)(q, G) = 2|G|.
Indeed M(cid:48) work sending q1 = (?X1, ?Y1, ?Z1) and then q2 = (?X2, ?Y2, ?Z2) to the
client, obtaining answer container D1 and D2 respectively and then sending the query
D1 (cid:111)(cid:110) D2 to the client. It easy to see that M(cid:48)(q, G) and that |D1| = |D2| = |G| and so
M(cid:48) works with 2|G| transfer. This shows that (∅, BGP) (cid:54)(cid:22)t ({(cid:111)(cid:110)}, TPF).

Consider now the class C2 of SPARQL queries of the form ((a1, b1, c1) AND ··· AND (ak, bk, ck)),

With all ai’s, bi’s and ci’s distinct values. One can show that any ({(cid:111)(cid:110)}, TPF)-LDFM M
that computes C2 is such that tM (q, G) is in Ω(|q|). Indeed suppose there is a ({(cid:111)(cid:110)
}, TPF)-LDFM M that can do better than that. It’s easy to see two things; ﬁrst M can’t
send a triple pattern that contains a variable. Cause with a graph large enough we could
easily surpass Ω(|q|). Also M can’t send all the triple pattern of every q, cause that
would make it work with Ω(|q|) transfer. So there is at least one triple of some q0 that
M doesn’t send. Let’s say, without loss of generality, it’s (a1, b1, c1) (the ﬁrst triple of
q0) and consider the graphs G = ∪|q0|
i=2{(ai, bi, ci}. Note
that since M only send triple patterns but doesn’t send the only triple where G and G(cid:48)
are different then M (q0, G) = M (q0, G(cid:48)). However note(cid:74)q0(cid:75)G (cid:54)= (cid:74)q0(cid:75)G(cid:48) and so M
answer G or G(cid:48) incorrectly. And so it follows our claim.

i=1{(ai, bi, ci} and G(cid:48) = ∪|q0|

On the other hand, C2 can be computed with a (∅, BGP)-LDFM that, in the worst
case, transfers a single mapping (the complete query result) from server to client thus
showing that ({(cid:111)(cid:110)}, TPF) (cid:54)(cid:22)t (∅, BGP). Notice that this last fact implies that ({(cid:111)(cid:110)
}, TPF) (cid:54)(cid:22)t ({(cid:111)(cid:110)}, BGP). This last property plus the fact that ({(cid:111)(cid:110)}, BGP) (cid:22)t ({(cid:111)(cid:110)
}, TPF) implies that ({(cid:111)(cid:110)}, BGP) ≺t ({(cid:111)(cid:110)}, TPF).

Now class C2 can also be used to show that (∅, BGP) ≺r ({(cid:111)(cid:110)}, TPF). Indeed, we
already know we can do it on one request to the server with (∅, BGP). Suppose we could
do it with the same amount of request with ({(cid:111)(cid:110)}, TPF)-LDFM M. Consider then the
query in C2; q = (a1, b1, c1) AND(a2, b2, c2) and the graph G = {(a1, b1, c1), (a2, b2, c2)}.

Note that(cid:74)q1(cid:75)G = {µ} where µ is the empty mapping. Notice that to obtain a answer 
container that contains µ on that graph M could only send q1 = (a1, b1, c1) or
q2 = (a2, b2, c2) to the server. Without lose of generality suppose M sends q1. Then
note M can’t send any other request, cause we are assuming M works on only one
server request. So now suppose M works on G(cid:48) = {(a1, b1, c1)}. Then M will send as
can’t send any query to the client that have answer ∅ having only access to D1 and (cid:111)(cid:110)

ﬁrst query q1 obtaining as an answer container D1 = {µ}. However(cid:74)q(cid:75)G(cid:48) = ∅ but M
(as D1 (cid:111)(cid:110) D1 = D1); and so M (q, G(cid:48)) (cid:54)=(cid:74)q(cid:75)G(cid:48). So M can’t work on only one request

to the server. This shows that (∅, BGP) ≺r ({(cid:111)(cid:110)}, TPF).

Now for our last claim ({(cid:111)(cid:110)}, BGP) ≡r (∅, BGP) we only need to prove that (∅, BGP) ≺r

({(cid:111)(cid:110)}, BGP). Indeed, ﬁrst we will show we can always assume a (∅, BGP)-LDFM M
works on at most 2 request to the server. Indeed; remember M works by sending some
queries to the server, obtaining some answer container, and then sending one of them
as an answer to the client. Note however that the construction of the query to the server
can depend on the answer containers. To ﬁx we make ¯M such that M (q, G) = ¯M (q, G)
with only 2 request by doing the following; ¯M ﬁrst send the query (?s, ?o, ?p), which
we already discussed give us a answer container with the entire graph. Then any query
M send to the server, ¯M will calculate it’s answer container on it’s working tape. Finally,
 whatever answer container M send as a query to the client; ¯M will send the
query that gives that answer container and then send it to the client. Note with this
procedure M and ¯M sends both the same query to the client, and so it follows that
M (q, G) = ¯M (q, G), and ¯M works on 2 request to the server.

So now suppose there is C a class of queries computable under (∅, BGP), such that
(∅, BGP) always make more request than ({(cid:111)(cid:110)}, BGP). Note by what we proved it’s
only possible if C is computable on at least two request on (∅, BGP) and there is a ({(cid:111)(cid:110)
}, BGP )-LDFM M that compute the query on only one request, and using one answer
container D1, that comes from a query made to the server q1. So note that then M (q, G)
is equivalent to D1 (cid:111)(cid:110) D1 (cid:111)(cid:110) ... = D1. However, since q1 doesn’t depends on any
answer container (cause there aren’t any answer containers when we send it) we could
use the procedure with only one request with a (∅, BGP)-LDFM ¯M; just send q1 to the
server and then D1 to the client. Note that with this procedure M (q, G) = ¯M (q, G) for
all graph G and q ∈ C; and then we are computing C on one request on (∅, BGP) which
is a contradiction. So there is not such a class C; and so (∅, BGP) (cid:22)r ({(cid:111)(cid:110)}, BGP),
ﬁnishing our claims.

B.2 Proof of Theorem 5
First note that it’s clear that ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF) (cid:22)t ({∪, (cid:111)(cid:110)}, BRTPF) and ({∪, (cid:111)(cid:110)
, (cid:111)(cid:110), π}, BRTPF) (cid:22)r ({∪, (cid:111)(cid:110)}, BRTPF). We just have to show that the inequalities are
strict.

For both of them we consider the query:

Now if we denote TRUE = {µ}, where µ is the empty mapping and FALSE = ∅ it

q = SELECT∅(?X1, b, c)

follows that:

(cid:40)

(cid:74)q(cid:75)G =

TRUE
FALSE

∃a, (a, b, c) ∈ G
(cid:54) ∃a, (a, b, c) ∈ G

We will ﬁrst proof the data transfer inequality. For this note the query can be answered 
with |(cid:74)(?X1, b, c)(cid:75)G| transfer on ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF); just send (?X1, b, c)

to the server obtaining a register container D1; and then send the query qC = D1 to the
client.

Now let’s consider a ({∪, (cid:111)(cid:110)}, BRTPF)-LDFM ¯M and suppose it can do it using

transfer |(cid:74)(X1, b, c)(cid:75)G| on every graph. First note that ¯M (q, G), which should be TRUE

any tripple pattern with a variable, on some graph, have at least the same size as

So now consider ¯M sends some tripple pattern, without a binding, containing some

or FALSE, must be equivalent to an answer container of ¯M. Indeed, ﬁrst note that if
the answer if TRUE we can’t asamble it using (cid:111)(cid:110) and ∪ and answer containers that
aren’t TRUE; and so it must be an answer container. Now if the answer is FALSE
we could asamble it using two containers D1, D2 that have no compatible mappings
beetween them. Note that this implies |D1|,|D2| > 0, which implies ¯M is working
with data transfer at least |D1| + |D2| > 1. However if the answer is F alse then

swer of these Bi, and denote bi = {?xj → {k1
j , ..., ki
pend on Bi. Alse note that with our asumption | ∪l,s {ks

|(cid:74)(?X, b, c)(cid:75)G| = 1, and it’s a contradiction that ¯M is working on the same transfer as
|(cid:74)(?X, b, c)(cid:75)G|.
variable. If that’s the case then ¯M would work on more than |(cid:74)(?X1, b, c)(cid:75)G|; cause
|(cid:74)(?X1, b, c)(cid:75)G|; and then ¯M must also obtain a TRUE or FALSE on a answer container 
to answer. So then ¯M can’t send tripple patterns with variables without biding.
So now suppose ¯M send some query of the type ti|bi to the server. Denote the an-
j}}. Note that bi+1 could de-
that’s not the case we could easily have that |(cid:74)(?X1, b, c)(cid:75)G| <(cid:80)|Bi| That’ means that
l }| ≤ |(cid:74)(?X1, b, c)(cid:75)G|, Cause if
the binding must admit a numbers of values that cant be greater than |(cid:74)(?X1, b, c)(cid:75)G|.
In particular note that for every graph we can’t send more queries than |(cid:74)(?X1, b, c)(cid:75)G|.
So let be G a graph, with N = |(cid:74)(?X1, b, c)(cid:75)G| > 0, and suppose that every ks
l ∈ G.
Note that then ¯M will send the query ti|bi, obtain the answer Bi and use them to answer
the query. So know consider G1, that is a graph that is exactly equal to G but every ks
1 is
know instead ¯ks
1. So now ¯M think that the register B1 is empty, cause we are not
allowing variables to take values of the graph. This will change it’s strategy to compute
2. Note that then ¯M
b2. So now consider G2, but not every ks
will think B2 is empty, what will change the strategy so compute b3. Repeat this process
up to N times, obtaining a graph ¯G. Note then that when ¯M works on ¯G it will think
B1, B2, ..., BN are empty. Also note that ¯M can’t send more request to the server, cause

it already have N empty answer containers, and so have N = |(cid:74)(?X, b, c)(cid:75)G| of data

transfer up to this point. Now since ¯M can’t send more queries, ¯M can’t diferentiate if
the graph ¯G is equal to the empty graph, and so it answer incorrectly on ¯G or on the
empty graph. So ¯M can’t send tripple patterns with biding.

j , k2

1 (cid:54)= ks

2 is know instead ¯ks

2 (cid:54)= ks

So then ¯M can’t send tripple patterns with variables, with binding or without them.
So then ¯M can only send tripple patterns without variables. But note that on them the
biding doesn’t have any effect, and ∪ and (cid:111)(cid:110) doesn’t have any effect when sending qC
to the client. So then if ¯M could do this strategy on better transfer than |(?X1, b, c)| so

could we do it with a ({(cid:111)(cid:110),∪, (cid:111)(cid:110), π}, BRTPF)-LDFM; using the same strategy that ¯M,
where the last thing is a contradiction.

So then ¯M can’t send anything to the server to do better than |(?X1, b, c)| transfer,
which is clearly a contradiction. So ¯M can’t do better, and so we the ﬁrst part of our
theorem.

Now for the request complexity inequality. For this we consider the same query q.

Note that we can answer the query on one request to the server with ({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF)
with the same strategy that we used on the last part. It’s also easy to see we couldn’t do
any better (We need to at least use some register to construct to answer to the client).
Now suppose we can do it the same amount of request on a ({∪, (cid:111)(cid:110)}, BRTPF)-LDFM ¯M

Indeed, note that the answer, that is TRUE or FALSE, must come from a answer container 
of ¯M. For that note that ¯M can only do one request to the server, and thus will
only have one answer container D1. If it’s diferent than T rue or F alse then there is at
least one mapping µ ∈ D1 such that there is ?x ∈ dom(µ). It’s clear that then whenever
we operate combinations of D1 with (cid:111)(cid:110) and ∪ we will still have some mapping ν with
?x ∈ dom(ν). And so the answer it’s diferent from TRUE or FALSE; and so the answer
must come from a answer container.

Now consider G1 = {(1, b, c)}. Remember that ¯M can only do one resquest to
the server, and since it must obtain TRUE, ¯M is obligated to ﬁrst send q1 = (1, b, c).
Note that then when working with G2 = {(2, b, c)} ¯M will ﬁrst send the same query
q1, obtaining FALSE as it’s only answer container. So then, to answer correctly, ¯M
should send another request, which is a contradiction that ¯M can do better than on a
({∪, (cid:111)(cid:110), (cid:111)(cid:110), π}, BRTPF)-LDFM. And so we conclude the second part of the theorem.

